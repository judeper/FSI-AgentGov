{
  "schema_version": 2,
  "last_run": "2026-01-26T01:03:12.094601+00:00",
  "urls": {
    "https://learn.microsoft.com/en-us/power-platform/admin/managed-environment-overview": {
      "content_hash": "sha256:3f2b50fd9b891da97b3d72a85d26eef09933c07d9aa8e522b6ae4711c06eead8",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManaged Environments overview\nFeedback\nSummarize this article for me\nManaged Environments is a suite of premium capabilities that allows admins to manage Power Platform at scale with more control, less effort, and more insights. Admins can use Managed Environments with any type of environment. Certain features can be configured upon enabling a Managed Environment. Once an environment is managed, it unlocks more features across the Power Platform.\nLearn how to use Managed Environments\n.\nA Managed Environment encompasses, but isn't limited to, the following features:\nEnvironment groups\nLimit sharing\nWeekly usage insights\nData policies\nPipelines in Power Platform\nMaker welcome content\nSolution checker\nIP Firewall\nIP cookie binding\nCustomer Managed Key (CMK)\nLockbox\nExtended backup\nData policies for desktop flow\nExport data to Azure Application Insights\nAdminister the catalog\nDefault environment routing\nCreate an app description with Copilot\nVirtual Network support for Power Platform\nConditional access on individual apps\nControl which apps are allowed in your environment\nConfigure auditing for an environment\nCreate and manage masking rules\nNote\nManaged Environments is included as an entitlement with standalone Power Apps, Power Automate, Microsoft Copilot Studio, Power Pages, and Dynamics 365 licenses. Trial licenses can be used to license users in Managed Environments, with the restrictions specific to these types of licenses. To learn more about Managed Environment licensing, see\nLicensing\nand\nLicensing overview for Microsoft Power Platform\n.\nManaged Environment isn't included as an entitlement in the Developer Plan when users run their assets. For more information about Managed Environments and the Developer Plan, see\nAbout the Power Apps Developer Plan\n.\nRelated content\nEnable Managed Environments\nUsage insights\nLimit sharing\nData policies\nLicensing\nView license consumption (preview)\nTenant settings\nDefault environment routing\nConsiderations for using Managed Environments\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Managed Environments",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/managed-environment-enable": {
      "content_hash": "sha256:e3c1fb5975d5353c1e8487d0e5ffb64e438a8a2477014421dd0dbbcb4742b6cc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEnable Managed Environments\nFeedback\nSummarize this article for me\nAdmins enable, disable, and edit Managed Environments in the Power Platform admin center. Admins can also use PowerShell to disable Managed Environments. This article explains the permissions you need to manage environments and the steps to get started in the Microsoft Power Platform admin center or with PowerShell.\nPermissions\nTo enable or edit Managed Environments, you need the Power Platform Administrator or Dynamics 365 Administrator role in Microsoft Entra ID. You can learn more about these roles in\nUse service admin roles to manage your tenant\n.\nAny user with permission to view environment details can see the Managed Environments property for an environment.\nUsers with the Delegated Admin role or the Environment Admin security role can't change the Managed Environments property in an environment.\nImportant\nThe Managed Environments property must be the same in the source and destination before you can start to copy and restore environment lifecycle operations.\nDataverse is required to use Managed Environments in an environment type.\nEnable or edit Managed Environments in the admin center\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, and then in the\nManage\npane, select\nEnvironments\n.\nSelect the ellipsis next to an environment, and then in the menu, select\nEnable Managed Environments\n. If the environment is already managed, select\nEdit Managed Environments\n.\nConfigure the settings, and then select\nEnable\nor\nSave\n.\nEnable Managed Environments using PowerShell\nAdmins can also use PowerShell to enable Managed Environments. The following PowerShell script enables it for a single environment.\n$GovernanceConfiguration = [pscustomobject] @{ \n protectionLevel = \"Standard\" \n settings = [pscustomobject]@{ \n extendedSettings = @{} \n }\n} \n\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentID> -UpdatedGovernanceConfiguration $GovernanceConfiguration\nCopy Managed Environment settings using PowerShell\nAdmins can use PowerShell to copy settings from one Managed Environment to another environment. If the target environment isn't a Managed Environment, copying settings also enables it as a Managed Environment.\n#Get settings from the source Managed Environment\n$sourceEnvironment = Get-AdminPowerAppEnvironment -EnvironmentName <SourceEnvironmentId>\n\n# Copy the settings from the source Managed Environment above to the target environment\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <TargetEnvironmentId> -UpdatedGovernanceConfiguration $sourceEnvironment.Internal.properties.governanceConfiguration\nDisable Managed Environments using PowerShell\nAdmins can use PowerShell to remove the Managed Environments property from an environment. Before you disable Managed Environments, make sure none of the Managed Environments capabilities are in use.\nHere's an example PowerShell script that calls the API to set the Managed Environments property:\n$UpdatedGovernanceConfiguration = [pscustomobject]@{\n protectionLevel = \"Basic\"\n}\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentID> -UpdatedGovernanceConfiguration $UpdatedGovernanceConfiguration\nRelated content\nManaged Environments overview\nUsage insights\nLimit sharing\nData policies\nLicensing\nView license consumption (preview)\nTenant settings\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Enable Managed Environments",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/managed-environment-sharing-limits": {
      "content_hash": "sha256:5a21768b4d4bb5a7e5cf397c6309738fdba68a3634306004921ea71158123134",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLimit sharing\nFeedback\nSummarize this article for me\nIn Managed Environments, admins can limit how broadly users can share canvas apps, flows, and agents.\nTo configure these rules:\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, select a managed environment.\nIn the command bar,\nEdit Managed Environments\n.\nThe sharing rules are located in the\nManage sharing\nsection.\nChoose the desired settings, then select\nSave\nto apply the changes.\nCanvas app sharing rules\nCanvas app sharing rule\nDescription\nDon't set limits\nSelect to not limit sharing canvas apps.\nExclude sharing with security groups\nSelect if users aren't allowed to share canvas apps with any security groups or with everyone.\nLimit total individuals who can be shared to\nIf\nExclude sharing with security groups\nis selected, you can control the maximum number of users with whom a canvas app can be shared.\nSolution-aware cloud flow sharing rules\nSolution-aware cloud flow sharing rules\nDescription\nLet people share solution-aware cloud flows\nWhen selected:\nUsers can share solution-aware cloud flows and agent flows with any number of individuals or security groups.\nWhen not selected:\nUsers can't share their cloud flows or agent flows with any individual or security group.\nAgent sharing rules\nAgent sharing rule\nDescription\nLet people grant\nEditor\npermissions when agents are shared\nWhen selected:\nOwners and editors can share with any individual as an editor.\nWhen not selected:\nOwners and editors can't share with an individual as an editor. This control doesn't affect the ability of owners or editors to share with viewers.\nLet people grant\nViewer\npermissions when agents are shared\nWhen selected:\nOwners and editors can share with any individual as a viewer and any security group.\nWhen not selected:\nOwners and editors can't share with an individual as a viewer, nor can they share with a security group. This control doesn't prevent them from sharing their copilots with individuals as editors.\nOnly share with individuals (no security groups)\nIf this setting is selected, owners and editors can only share with individuals as viewers. They can't share with a security group. This control doesn't affect an owner's or editor's ability to share with individuals as editors.\nLimit number of viewers who can access each agent\nIf\nOnly share with individuals (no security groups)\nis selected, you can control the maximum number of viewers with whom an agent can be shared with.\nImportant\nThis is a production-ready preview feature.\nProduction-ready previews are subject to\nsupplemental terms of use\n.\nTo learn more about\nEditor\nand\nViewer\npermissions on agents, go to\nCopilot Studio security and governance\n.\nNote\nSharing rules are enforced when users try to share an app, flow, or agent. This restriction doesn't impact any existing users who already have access to the app, flow, or agent before the application of the sharing rules. However, if an app, flow, or agent is out of compliance after rules are set, only unsharing is allowed until the app, flow, or agent is compliant with the new rules.\nAfter sharing rules are set in the Power Platform admin center, it may take up to an hour for them to start getting enforced.\nSharing rules in Dataverse for Teams environments don't impact sharing to a Team when you select\nPublish to Teams\n. However, when a user attempts to share with individuals or groups in a Team other than the one bound to the environment, the sharing limits are enforced.\nIf a user tries to share a canvas app, solution-aware cloud flow, or agent that contradicts the sharing rules, they're informed as shown.\nUse PowerShell to set sharing limits\nYou can also use PowerShell to set and remove sharing limits.\nSet sharing limits\nHere's a PowerShell script that prevents canvas apps from being shared with security groups and limits the number of individuals that the canvas app can be shared with to 20.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'limitSharingMode' -Value \"excludeSharingToSecurityGroups\" -Force\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'maxLimitUserSharing' -Value \"20\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nHere's a PowerShell script that turns off sharing for solution-aware cloud flows.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'solutionCloudFlows-limitSharingMode' -Value \"disableSharing\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nHere's a PowerShell script that prevents agents from being shared with security groups and limits the number of viewers that can access an agent to 20.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'bot-limitSharingMode' -Value \"ExcludeSharingToSecurityGroups\" -Force\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'bot-maxLimitUserSharing' -Value \"20\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nHere's a PowerShell script that turns off the ability to share your agents with individuals as Editors.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'bot-authoringSharingDisabled' -Value True -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nSet 'bot-authoringSharingDisabled' to False to enable sharing with individuals as Editors.\nRemove sharing limits\nHere's a PowerShell script that removes the canvas app sharing limits.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'limitSharingMode' -Value \"noLimit\" -Force\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'maxLimitUserSharing' -Value \"-1\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nTo remove sharing limits for solution-aware cloud flows, run the following script.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'solutionCloudFlows-limitSharingMode' -Value \"noLimit\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nTo remove limits on sharing your agent with security groups or individuals as Viewers, run the following script.\n# Retrieve the environment\n$environment = Get-AdminPowerAppEnvironment -EnvironmentName <EnvironmentId>\n\n# Update the Managed Environment settings\n$governanceConfiguration = $environment.Internal.properties.governanceConfiguration\n$governanceConfiguration.settings.extendedSettings | Add-Member -MemberType NoteProperty -Name 'bot-limitSharingMode' -Value \"noLimit\" -Force\n\n# Save the updated Managed Environment settings\nSet-AdminPowerAppEnvironmentGovernanceConfiguration -EnvironmentName <EnvironmentId> -UpdatedGovernanceConfiguration $governanceConfiguration\nSurface your organizationâs governance error content\nIf you specify governance, error message content to appear in error messages, it's included in the error message displayed to users. Learn more in\nPowerShell governance error message content commands\n.\nRelated content\nManaged Environments overview\nEnable Managed Environments\nUsage insights\nData policies\nLicensing\nView license consumption (preview)\nTenant settings\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Managed Environment Sharing Limits",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/managed-environment-solution-checker": {
      "content_hash": "sha256:06a7aa6266ed1aa23dcf12dce76ab1516882c1e6e19711e8b3f835f0c865d4bd",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSolution checker enforcement in Managed Environments\nFeedback\nSummarize this article for me\nThe solution checker is a powerful tool that performs a comprehensive static analysis of your solution objects against a set of best practice rules. By using solution checker, you can quickly identify problematic patterns in solution components and receive detailed reports that highlight issues, affected components, and provide links to documentation on how to resolve each issue.\nAdministrators can use solution checker to enforce checks to identify problematic patterns on solutions when the solution is imported in the Managed Environment.\nSolution checker settings\nWhen you turn on solution checker for a Managed Environment, there are different levels to choose from that are enforced during solution import.\nSetting\nDescription\nNone\nTurns off the automatic solution validations during solution import. There aren't any experience or behavioral changes to solution authoring, exports, or imports.\nWarn\nAll custom solutions are automatically verified during solution import. When a solution with highly-critical issues is being imported, you're warned about the action but the import itself continues, and if everything else with the import is fine, the solution is imported into the environment. After a successful import, a message stating that the imported solution had validation issues is shown. Additionally, a summary email is sent with details of the solution validation.\nBlock\nAll custom solutions are automatically verified during solution import. When a solution has highly-critical issues, the import process is canceled, and a message stating that the imported solution had validation issues is shown. This happens before the actual import, so there aren't any changes to the environment due to the import failure. Additionally, a summary email is sent with details of the solution validation.\nFor more information on what to do when encountering a warn or block, see the\ntroubleshooting guide\n.\nFor more information about solution checker and the list of rules used, go to\nSolution checker overview\n.\nTurn on solution checker in a Managed Environment\nTo turn on solution checker enforcement for your Managed Environment:\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nSelect a managed environment.\nOn the command bar, select\nEdit Managed Environments\n, and then select the appropriate\nenforcement setting\nunder\nSolution checker enforcement\n.\nNote\nSolution checker enforcement is\nnot available\nwhen the environment is in the\nAdministration mode\n.\nEmail messages to the admin\nWhen the validation mode is set to\nWarn\nor\nBlock\n, a summary email is sent when a solution is imported or blocked. When the solution is imported into an environment, the summary email shows the count of issues by severity in the solution. The contents of the email may include a link to the solution analysis results. In some instances, the link to the results may have expired. To get new results, submit the solution to solution checker.\nSolutions checked from Power Apps\nmake.powerapps.com\nhave the results stored in the source environment. Solutions imported to an environment with solution checker enforcement turned on may have results stored in the target, import environment.\nThe email is sent to all users with the roles of\nPower Platform administrator\nand\nDynamics 365 service administrator\n. It's also sent to recipients of the\nweekly digest emails\n.\nSuppress validation emails\nBy default, emails are sent when a solution contains medium and above severities. When the checkbox is selected, emails aren't sent in warn mode. Emails aren't sent in block mode, as well, except for critical violations which block solution import.\nRule exclusions\nYou can select to exclude solution checker rules from enforcement. For example, a particular rule might take significant time and effort to fix across the solution, but you would still like the rest of the rules to be enforced. Use the\nExcluded Rules\ndropdown list to select the rules to exclude from enforcement.\nThe list contains rule names and descriptions grouped by category and sorted by severity. As a reminder, only critical severity rules block a solution from being imported.\nUse PowerShell to turn on solution checker enforcement\nYou can use PowerShell to turn on solution checker enforcement. These functions are defined in the\nPowerApps-Samples repo\n, which must be imported before invoking.\nTurn on solution checker enforcement in block mode\nHere's an example PowerShell script that turns on solution checker enforcement in block mode. After you run it, the slider shows block mode in the\nSolution checker\nsection of the Managed Environments settings.\nSetManagedEnvironmentSolutionCheckerEnforcementLevel -EnvironmentId 8d996ece-8558-4c4e-b459-a51b3beafdb4 -Level block\nTurn on solution checker enforcement in warn mode\nHere's an example PowerShell script that turns on solution checker enforcement in warn mode. After you run it, the slider shows warn mode in the\nSolution checker\nsection of the Managed Environments settings.\nSetManagedEnvironmentSolutionCheckerEnforcementLevel -EnvironmentId 8d996ece-8558-4c4e-b459-a51b3beafdb4 -Level warn\nTurn off solution checker enforcement\nHere's an example PowerShell script that turns off solution checker enforcement. After you run it, the slider shows\nOff\nin the\nSolution checker\nsection of the Managed Environments settings.\nSetManagedEnvironmentSolutionCheckerEnforcementLevel -EnvironmentId 8d996ece-8558-4c4e-b459-a51b3beafdb4 -Level none\nSet rule exclusions\nHere's an example PowerShell script that turns on solution checker enforcement in block mode and adds rule exclusions. After you run it, the slider shows block mode in the\nSolution checker\nsection of the Managed Environments settings, and the rule exclusions are set.\nSetManagedEnvironmentSolutionCheckerEnforcementLevel -EnvironmentId 8d996ece-8558-4c4e-b459-a51b3beafdb4 -Level none -RuleExclusions \"web-use-async,web-use-offline\"\nRelated content\nManaged Environments overview\nImport solutions\nSolution checker enforcement in Managed Environments blocks or warns on import\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Solution Checker Enforcement",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/managed-environment-usage-insights": {
      "content_hash": "sha256:23d3664941799ec0c63599b04a4dc8019474575432ebbf5daf77f3cb3ec31b2c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nUsage insights\nFeedback\nSummarize this article for me\nStay informed about whatâs happening in your managed environments with Power Platformâs weekly admin digest. Analytics about your top apps, your most impactful makers, and inactive resources you can safely clean up are distilled and delivered to your mailbox once a week.\nTo enable a weekly email digest, do the following.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nSelect a managed environment.\nOn the command bar, select\nEdit Managed Environments\n, select the settings under\nUsage insights\n, and then select\nInclude insights for this environment in the weekly email digest\n.\nNote\nYou must\nturn on tenant-level analytics\nto get usage insights.\nCurrently, usage insights arenât available in sovereign clouds, such as Government Community Cloud (GCC), Government Community Cloud â High (GCC High), Department of Defense (DoD), and Power Platform and Dynamics 365 services in China.\nWhat information is provided in the weekly digest?\nThe first section of the weekly digest shows the number of apps used and active users in your managed environments in the past month.\nThe second section lists apps and flows that haven't been launched in a while. The\nLast launch\ncolumn shows the last date a user launched the application or flow. If the application or flow has never been launched, the column contains âNone.\" If an app or flow isn't being used, we recommend that you work with its owner to update or remove it.\nThe third section shows the most popular apps and flows in your managed environments in the past month, indicated by the number of sessions and runs. When a user launches and interacts with an application, that's considered a session. It also shows the top makers over the past month, as measured by total sessions of apps they own.\nWhich environments are included in the weekly digest?\nThe weekly digest provides insights into all managed environments in your tenant that you haven't excluded from reporting.\nTo include a managed environment in the weekly digest, select\nInclude insights for this environment in the weekly email digest\nin the\nUsage insights\nsection of the Managed Environment settings. If you exclude all your managed environments, Power Platform won't send a weekly digest.\nNote\nClear the check box to exclude a managed environment. If you exclude all your managed environments, Power Platform won't send a weekly digest.\nWho can receive the weekly digest?\nThe weekly digest is sent to all users with the roles of\nPower Platform administrator\nand\nDynamics 365 service administrator\n.\nTo add more recipients, select\nAdd additional recipients for the weekly email digest\n, and then select\nWeekly digest\n. Enter email addresses in the Additional recipients box.\nYou can also select\nSettings\nfrom the left-side menu, and then select\nWeekly digest\nto add additional recipients.\nUse PowerShell to add and remove recipients\nYou can also use PowerShell to add and unsubscribe email addresses.\nAdd email recipients\nHere's an example PowerShell script that adds two recipients. After you run it, the new addresses appear in the\nAdditional recipients\nbox in the\nUsage insights\nsection of the Managed Environments settings.\n$tenantSettings = Get-TenantSettings \n($tenantSettings.powerPlatform.governance) | Add-Member -MemberType NoteProperty -Name additionalAdminDigestEmailRecipients -Value 'fakeEmail@contoso.com;otherFakeEmail@contoso.com' \nSet-TenantSettings -RequestBody $tenantSettings\nRemove email recipients\nHere's an example PowerShell script that unsubscribes your entire organization from the weekly digest.\n$tenantSettings = Get-TenantSettings \n$tenantSettings.powerPlatform.governance.disableAdminDigest = $True \nSet-TenantSettings -RequestBody $tenantSettings\nTo resubscribe everyone, set the value for\n$tenantSettings.powerPlatform.governance.disableAdminDigest\nto\n$False\n.\nSee also\nManaged Environments overview\nEnable Managed Environments\nLimit sharing\nData policies\nLicensing\nView license consumption (preview)\nTenant settings\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Usage Insights",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/environment-groups": {
      "content_hash": "sha256:326653126f3cafd8932bff01c9576178f102810c64dec456eef44b485b359529",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEnvironment groups\nFeedback\nSummarize this article for me\nManaging the Power Platform on a large scale across numerous environments, ranging from hundreds to tens of thousands, poses a significant challenge for both startup and enterprise IT teams. To address these complexities, environment groups offer a premium governance solution designed to streamline management tasks by organizing environments into logical collections and enforcing uniform policies and configurations.\nThink of an environment group as a \"folder\" for your environments. Administrators can cluster a flat list of environments into structured groups based on criteria such as business unit, project, geographic region, or purpose. By creating these logical collections, IT teams gain the ability to manage multiple environments simultaneously and efficiently implement security, governance, and compliance policies on a large scale through centrally managed rules. This centralized approach eliminates the need to configure each environment one-by-one, ensures consistency, significantly reduces administrative overhead, and prevents issues such as configuration drift and chaotic management practices common in extensive deployments.\nNote\nEnvironment groups can only contain Managed Environments.\nEach environment can belong to only one group, and groups can't overlap or be nested.\nEnvironments in a group can span different regions and types as long as each is managed.\nEnvironments can be transferred between groups by removing them from one and adding them to another.\nRules\nA key advantage of environment groups is their ability to enforce governance at scale through\nrules\n. Environment groups allow tenant administrators to define rules that automatically apply standardized settings or policies across all member environments. These rules span critical areas of environment management, such as security and sharing, AI feature enablement, data retention policies, and application lifecycle management (ALM).\nWhen a rule is published at the environment group level, it's enforced across every environment within that group. This means the corresponding setting or policy becomes locked (read-only) within individual environments, ensuring that local system administrators can't modify or override these centrally defined rules. Any subsequent changes can only be made by a tenant administrator with appropriate edit rights at the environment group level.\nLearn more about the rules available in\nRules for environment groups\n.\nNote\nPer-environment exceptions aren't currently supported.\nWhen an environment is added to the group, it inherits the group's published rules.\nWhen an environment is removed, it retains the last applied configuration from the group's rules but becomes unlocked, allowing a local admin to modify it going forward.\nUse cases and scenarios for environment groups\nEnvironment groups are flexible. Whether you need to enforce compliance by region, provide personal sandbox spaces for makers, roll out AI features selectively, or standardize development and testing vs. production practices, environment groups can be adapted to fit. Some common use cases and scenarios where environment groups add value include:\nPersonal productivity environments\nWhen using default environment routing, each maker can automatically get their own personal developer environment. It's best practice to place these environments into a dedicated group as they're created. For example, you may want a group named\nPersonal Productivity\n. Within this group, apply rules that treat each environment as a safe, individual sandbox. For instance, restrict agent sharing to prevent accidental exposure of in-progress work, and include productivity aids like the\nmaker welcome content\n. This approach isolates each user's work, similar to each person having their own OneDrive, and helps keep the default environment clean and secure.\nAI feature management\nOrganizations exploring AI capabilities can use environment groups to roll out features in a controlled and intentional way. For example, an enterprise might create a\nCopilot Pilot\ngroup with sandbox environments where AI features are turned on for early testing and feedback. At the same time, production or sensitive environments can remain in a separate group with a more gradual rollout timeline. This setup supports safe, phased adoption while giving teams space to experiment and build readiness. As confidence grows, admins can update the rules to expand Copilot access to more groups or move environments between them. This ensures a clear and manageable path toward broader AI use.\nGlobal environment strategy\nLarge organizations with many environments can group the environments by organizational units, such as by department, region, or subsidiary. For example, a global enterprise might have separate groups for North America, Europe, and APAC environments to enforce region-specific compliance and data residency rules. Each regionâs group can have rules aligning with local regulations or business policies, like turning on certain features only where allowed. This structure brings order to a sprawling environment landscape and makes it easier to apply updates or policy changes en masse.\nDevelopment vs. production environments\nIn an ALM strategy, you might separate environments by lifecycle such as development, test, and production. Using environment groups, an admin can create a\nDev/Test Group\nwith relaxed policies such as one that allows some preview features or unmanaged customizations for agility, and a\nProduction Group\nwith stricter rules such as one that forces solution checker, blocks previews or unmanaged changes, or that has a longer backup retention for safety. This approach maintains high standards in production environments while giving development teams the flexibility they need to innovate. It helps strike a strong balance between governance and productivity.\nCreate an environment group\nComplete the following steps to create a new environment group in the Power Platform admin center.\nSign in to the\nPower Platform Admin center\nas a\nPower Platform tenant administrator\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nOn the\nEnvironment groups\npage, select\nNew group\n.\nIn the\nCreate group\npane that appears:\nAdd a name for your group in the\nName\nfield such as\nPersonal Productivity\n.\nAdd a brief description of the group in the\nDescription\nfield.\nSelect\nCreate\n.\nAfter a few moments, the new group appears in your Environment groups list. At this point, the group is empty (contains no environments) and none of its rules are configured. You can now add environments and configure rules, as needed.\nNote\nIf you prefer to operate outside of the Power Platform admin center, the\nPower Platform for Admins V2 (Preview) connector\noffers an alternative solution. It allows the creation and deletion of environment groups and the ability to add or remove environments from these environment groups, facilitating opportunities for automation.\nConfigure the rules for your environment group\nAfter you create the environment group, Power Platform tenant administrators can immediately add Managed Environments or configure the group's rules. Both approaches work, but keep in mind that only published rules are enforced across environments.\nSign in to\nPower Platform Admin center\nas a\nPower Platform tenant administrator\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nOn the\nEnvironment groups\npage, select the group you created.\nSelect the\nRules\ntab for that group. You see a list of available rules.\nSelect a rule to open its configuration panel. Adjust it as needed, then\nSave\nthe rule.\nRepeat this step for all the rules you want to configure in this group.\nSelect the\nPublish rules\nbutton in the command bar.\nThe following screenshot shows an environment-level setting that is locked by an environment group rule.\nNote\nConfigure only the rules relevant to your scenario.\nUntouched rules are managed at the environment level.\nUpdated rules appear in bold with an asterisk (*) until published. Remember to republish rules to apply changes across environments.\nRoute environments to your environment group\nOne powerful way to use environment groups is in combination with default environment routing. Instead of having new makers build in the shared Default environment, environment routing provisions a dedicated developer environment for each maker and optionally assigns it to an environment group of your choice. If you want all new developer environments to be automatically placed under a specific groupâand thus immediately governed by its rulesâset up environment routing to point to that group.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nSelect the\nEnvironment Routing\nbutton in the command bar.\nUnder the\nEnvironment group\nsection, choose the group you want your new developer environments to be created in.\nSelect\nSave\n.\nGoing forward, whenever a new maker triggers the creation of a personal developer environment, the platform automatically creates their environment inside the specified group. The environment comes preconfigured as a Managed Environment with all the groupâs rules already applied from the start. The maker doesn't need to choose an environment or set anything up. The maker is routed directly into a governed space that IT has predefined. Admins gain peace of mind knowing that even automatically created environments follow organizational policies, and makers get a ready-to-use environment without needing to worry about configuration.\nNote\nIf an environment group is selected for routing but later you decide to change it, you can update the Environment routing settings to point new environments to a different group. Existing developer environments remain in whichever group they were originally placed, unless moved manually.\nAdd environments to your environment group\nIn addition to using routing for new environments, you can manually add existing environments to a group at any time.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nSelect the target group (the group you want to add environments into).\nSelect the\nAdd environments\nbutton in the command bar.\nSelect one or more environments from the list.\nSelect\nAdd\n.\nNote\nEnvironments without Dataverse can't be selected in the picker.\nIf you select an environment that has Dataverse, but it's not managed, you can upgrade it automatically as part of adding it to the group.\nManually create environments in the group\nWhen manually creating a new environment, you can choose to place it into a group at creation time.\nSelect\nManage\nin the navigation pane.\nGo to the\nEnvironments\npage.\nSelect\nNew\nin the command bar.\nSelect a\ngroup\nfor your created environment.\nEnter the other details.\nSelect\nSave\n.\nBy selecting a group here, the environment is created as a Managed Environment within that group, automatically inheriting the group's rules upon creation. If no group is selected, the environment is created outside of any group. You can always add it to a group later.\nRemove an environment from your environment group\nYou can remove an environment from a group if it needs unique governance or if you created it by accident.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nSelect the group.\nSelect the environment you wish to remove.\nSelect\nRemove from group\nin the command bar.\nAfter removal, the environment retains the configuration previously applied by the group. However, its settings and policies are now unlocked, allowing the local environment admin to manage them directly. The environment remembers the last known state from the group, but is now free to evolve independently.\nDelete an environment group\nIf an environment group is no longer needed, administrators can delete it to avoid clutter.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironment groups\n.\nSelect the environment group that you wish to delete.\nSelect\nDelete group\nin the command bar.\nImportant\nWhen you delete a group, first remove all of its environments and ensure no developer environments are routed to it. If a group still has environments, you see a warning that prevents you from deleting the group.\nKnown limitation\nIf you've published any of the following rules within your environment group, the corresponding settings at the environment level are overridden when added added to the group: sharing limits, maker welcome content, solution checker, usage insights, backup retention, and generative AI settings. For example, if you've published sharing limits in your environment group, but already had maker welcome content and sharing limits set at the environment level, upon adding the environment to the group, the sharing limits are updated to match the group's sharing limits and the maker welcome content is reset.\nRelated content\nManaged Environments overview\nUsage insights\nLimit sharing\nData policies\nLicensing\nView license consumption (preview)\nTenant settings\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Environment Groups",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/environment-groups-rules": {
      "content_hash": "sha256:d26eb28037b06074cf156fd1ad981743a0ab95adb30aaaa679803209c1a5b585",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRules for environment groups\nFeedback\nSummarize this article for me\nThe following\nrules\ncan be applied to\nenvironment groups\n.\n#\nRules (in alphabetical order)\n1\nAccessing transcripts from conversations in Copilot Studio agents\n2\nAdvanced connector policy (preview)\n3\nAI prompts\n4\nAI-generated descriptions (preview)\n5\nAI-powered Copilot features\n6\nBack-up retention\n7\nDefault deployment pipeline (preview)\n8\nGenerative AI settings\n9\nExternal models\n10\nMaker welcome content\n11\nPower Apps component framework for canvas apps\n12\nPreview and experimental AI models\n13\nRelease channel\n14\nSharing agents with Editor permissions\n15\nSharing agents with Viewer permissions\n16\nSharing controls for canvas apps\n17\nSharing controls for solution-aware cloud flows\n18\nSharing data between Copilot Studio and Viva Insights\n19\nSolution checker enforcement\n20\nUnmanaged customizations\n21\nUsage insights\nNote\nThe rules that have \"(preview)\" in their name are in public preview, while rules without it are considered generally available.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Environment Group Rules",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/default-environment-routing": {
      "content_hash": "sha256:b9e13e5e4eb7b4303d6852cd137cfa7a3b91cb12538e7f2fd19280af19bd3db2",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEnvironment routing\nFeedback\nSummarize this article for me\nEnvironment routing is a premium governance feature. This feature allows Power Platform admins to automatically direct new or existing makers into their own personal developer environments when they visit\nCopilot Studio\n,\nPower Apps\n,\nPower Automate\n, or Power Automate for desktop. Environment routing offers makers a personal, safe space to build with Microsoft Dataverse without the fear of others accessing their apps or data.\nIn this video, check out what's new with environment routing in the Power Platform admin center.\nWhen the\nEnvironment routing\nsetting is enabled in\nPower Platform admin center\n, the maker lands in their own personal developer environment instead of the default environment. Personal developer environments are the makers' own spaces, like OneDrive, for personal productivity where they can start building apps and solutions in their own workspace. Makers don't need to know which environment to work in, since the personal developer environment appears automatically.\nWhen the feature is turned on, the selected maker type (that is, new or existing makers), are directed into their own, personal developer environment. If the maker has access to one or more existing developer environments that aren't owned by them, they're routed to a new developer environment.\nDataverse is available in developer environments, and these environments are\nManaged Environments\nwith the admin settings preconfigured according to the assigned environment group rules. Admins no longer need to worry that their makers are working in the default environment, where their work can conflict with others.\nImportant\nBy default, all developer environments created through environment routing are managed.\nManaged Environments isn't included as an entitlement in the Developer Plan when users run their assets. For more information about Managed Environments and the Developer Plan, see\nAbout the Power Apps Developer Plan\n.\nNon-managed\ndeveloper environments are\nunaffected\nby this feature. Learn more about the developer environment and developer plan in\nAbout the Power Apps Developer Plan\n.\nMulti-rule environment routing\nMulti-rule environment routing is an advanced governance feature in Power Platform that allows tenant administrators to define multiple routing rules to control how makers are directed to development environments across various portals, such as Power Apps, Power Automate, and Copilot Studio.\nThis capability builds on the original environment routing feature, which routed makers to a single environment group. The multi-rule enhancement introduces flexibility by allowing routing to multiple environment groups based on rule logic. This feature is especially useful for organizations where governance, security, and scalability are critical. It allows:\nFine-grained control over where makers build.\nConsistent policy enforcement across environments.\nReduced risk of conflicts in shared or default environments.\nAll routed environments are Managed Environments, meaning they inherit standardized policies like data retention, AI features, and application lifecycle management (ALM) settings defined by the admin through environment groups.\nPrerequisites\nEnvironment routing is a tenant-level admin setting. Understand that:\nOnly Power Platform admins can enable environment routing.\nIt requires the use of Managed Environments, since all of the newly created environments are managed. Users in a\nmanaged\ndeveloper environment must have premium licenses to run Power Platform assets.\nA personal developer environment is automatically created for new or existing makers (depending on the configured user type) when accessing a supported product's maker portal.\nRouted makers land in their existing developer environment if they already have a developer environment that they own.\nMakers are assigned to the admin role in their newly created developer environments.\nBy default, all developer environments created through environment routing are managed.\nTurn on environment routing in the admin center\nThe\nEnvironment routing\nsetting is turned off by default and must be turned on using the Power Platform admin center.\nGo to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nTenant settings\n.\nIn the\nTenant settings\npage, select\nEnvironment routing\n. The\nCreate and manage environment routing rules\npane is displayed.\nIn the\nTurn on environment routing for\nsection, select the product portals for which you want to allow routing.\nSelect\nNew rule\nto define a new rule. The\nCreate a new routing rule\npane appears. Take the following action:\nIn the\nName\nfield, enter a name for the rule.\nApply the routing rule to\nEveryone\nor specific security groups.\nSelecting\nEveryone\nroutes all makers into existing or new personal developer environments. Selecting a security group to limit routing only to the member makers of the configured security group.\nSelect an environment group to which the newly created developer environments are automatically assigned. This environment group inherits all the defined, environment group rules. Learn more in\nEnvironment groups\n.\nSelect\nSave\n. The\nCreate and manage environment routing rules\npane is displayed again.\nUse the arrow icons to change the priority of the rules.\nWhen a maker accesses a portal, the system evaluates the rules in order and applies the first matching rule.\nIf a matching rule is found, the maker is routed to an existing or newly provisioned developer environment.\nIf no rule matches, or if environment routing isn't turned on, the maker is routed to the default environment.\nSelect\nSave\n.\nTurn on environment routing using PowerShell\nSign in to your tenant account.\nAdd-PowerAppsAccount -Endpoint \"prod\" -TenantID <Tenant_ID>\nRetrieve and store your tenant settings in\nTenantSettings\n.\n$tenantSettings = Get-TenantSettings\nSet the\nenableDefaultEnvironmentRouting\nflag to\nTrue\n.\ntenantSettings.powerPlatform.governance.enableDefaultEnvironmentRouting = $True\nSet-TenantSettings -RequestBody $tenantSettings\nSet the\nenvironmentRoutingAllMakers\nflag to\nTrue\nto allow routing for all makers or\nFalse\nto limit routing to new makers.\ntenantSettings = Get-TenantSettings\ntenantSettings.powerPlatform.governance | Add-Member -MemberType NoteProperty -Name 'environmentRoutingAllMakers' -Value $True -Force\n(Optional) Set the\nenvironmentRoutingTargetEnvironmentGroupId\nto the desired Environment Group ID.\ntenantSettings.powerPlatform.governance | Add-Member -MemberType NoteProperty -Name 'environmentRoutingTargetEnvironmentGroupId' -Value \"<GUID for the group that has published rules>\" -Force\n(Optional) Set the\nenvironmentRoutingTargetSecurityGroupId\nto the desired Security Group.\ntenantSettings.powerPlatform.governance | Add-Member -MemberType NoteProperty -Name 'environmentRoutingTargetSecurityGroupId' -Value \"<GUID for the security group>\" -Force\nSave\nTenantSettings\n.\nSet-TenantSettings -RequestBody $tenantSettings\nTurn off environment routing using PowerShell\ntenantSettings = Get-TenantSettings  \n\ntenantSettings.powerPlatform.governance.enableDefaultEnvironmentRouting = $False\n\nSet-TenantSettings -RequestBody $tenantSettings\nFor more information about using PowerShell in Power Apps, see the\nOverview\n.\nFrequently asked questions (FAQs)\nAre the developer environments managed?\nYes, all the newly created developer environments are Managed Environments by default.\nWhat environment types are created when environment routing is enabled?\nThe created environments are developer environments.\nWhat roles do the makers get assigned in the developer environments?\nThe makers get assigned the admin security role in the developer environments.\nCan new makers switch to the default environment or other environments after launching their own developer environment?\nYes, makers can always switch to other environments.\nDoes the developer environment affect my tenant Dataverse quota?\nNo, the developer environments don't affect your tenant Dataverse quota.\nWhat happens if the developer environment creation fails?\nIf the creation of the developer environment fails, makers are automatically routed to the default environment.\nWhat data policies are applied for the developer environment?\nNo specific data policies are assigned to the developer environment. The developer environment inherits existing, tenant-level data policies.\nWhat are the preconfigured Managed Environments settings for the newly created developer environments?\nAll developer environments have the following Managed Environments settings preconfigured:\nSharing limits\n: Set to exclude sharing with security groups, and preconfigured to share with five individuals.\nSolution Checker\n: Set to\nWarn\n.\nUsage insights\n: Is selected.\nMaker welcome message\n: Not established.\nIs the environment routing also available for Power Pages?\nEnvironment routing is currently available for Microsoft Copilot Studio, Power Apps, and Power Automate cloud and desktop workflows.\nDo I need to be a Power Platform tenant admin to enable this feature?\nYes, you need to have a Power Platform tenant admin privilege to enable this feature in your tenant, or you can ask your tenant admin to turn it on for you.\nDoes creating an app or flow in a managed developer environment require a premium license?\nA premium license isn't required for the creation or preview of an app or flow in a managed developer environment. However, a user or maker needs a premium license to\nrun\nan app or flow in a managed developer environment.\nDoes the default environment need to be managed to enable environment routing?\nNo, the default environment doesn't need to be managed to enable environment routing.\nWhich development environment is the maker routed to if they have more than one developer environment?\nThe maker is always routed to their own existing personal developer environment, such as the developer environment created by them or on their behalf. If they created multiple developer environments, they're routed to the first one in alphabetical order.\nWhat happens if the Power Platform admin changes the developer environment assignments setting from \"Everyone\" to \"Only specific admins\" while environment routing is on?\nChanging the developer environment assignments setting has no impact on environment routing.\nWhere are makers routed to if they donât have an existing developer environment?\nIf new or existing makers donât have their own developer environment, they're routed to a new developer environment.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Environment Routing",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/developer/create-developer-environment": {
      "content_hash": "sha256:2fef6bd37df23dc15b8ae643453929646b3ade0914532a6881b33db0886eadb5",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate a developer environment with the Power Apps Developer Plan\nFeedback\nSummarize this article for me\nTo fully use the\nPower Apps Developer Plan\nas a developer, you need an Azure account and a work account. This article guides you through the process for creating a Power Platform environment and a test tenant if needed.\nWhere do I start?\nIf you have a\nwork account\n, and want to use it to learn Power Platform, go to the\nnext section\n.\nIf you don't have a work account or prefer a Sandbox tenant to learn Power Platform, read information in the\ncreate a test tenant\nsection later in this article before signing up for the developer environment.\nSign up for the Power Apps Developer Plan\nThe Power Apps Developer Plan gives you a free development environment to build and test with Power Apps, Power Automate, and Microsoft Dataverse.\nIt's simple to sign up for the Power Apps Developer Plan:\nEnsure that you have a work account. If you don't,\ncreate a test tenant\nfirst.\nSign up on the\nPower Apps Developer Plan website\n.\nAfter signing up for the Developer Plan, you'll be redirected to\nPower Apps\n. The environment uses your name, for example\nJohn Doe's environment\n. If there's already an environment with that name, the developer new environment is named\nJohn Doe's (1) environment\n.\nImportant\nUse the developer environment instead of your tenant's default environment to work with certain capabilities such as premium and custom connectors.\nYou might need to select your developer environment from the top-right corner of the screen in Power Apps.\nIt might take a couple of minutes for the new environment to be provisioned and become available in the list of the environments. You can see the progress of the environment creation in the\nPower Platform admin center\n.\nIn some situations, your admin might have turned off the sign up process. In this case, please contact your administrator, or create a test tenant.\nFor detailed information about the developer plan, go to\nSign up for the Power Apps Developer Plan\n.\nHow to create a test tenant?\nIf you don't already have a dedicated test tenant, you might qualify for one through the\nMicrosoft 365 Developer Program\n; for details, see the\nFAQ\n. Alternatively, you can\nsign up for a one-month free trial or purchase a Microsoft 365 plan\n.\nYou can also\nmanually create a test tenant\n.\nNow that you have your test tenant, sign up for the Power Apps Developer Plan as explained earlier in this article.\nSee also\nPower Platform for developers\nFusion Development\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Developer Environments",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/advanced-connector-policies": {
      "content_hash": "sha256:646bf273ea813390f06a51caed7717e4d92660a0c9e91eb7704b82f1331796b7",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAdvanced connector policies (preview)\nFeedback\nSummarize this article for me\n[This article is prerelease documentation and is subject to change.]\nOverview\nAdvanced connector policies (ACP) represent the next generation of securing connector usage within the Power Platform. This feature provides a modern and flexible approach to managing all\ncertified connectors\n, aligning with the broader governance strategy of per-environment security controls paired with\nenvironment group support\n.\nBy adopting advanced connector policies, administrators gain greater control and granularity in securing and managing connector usage while enhancing the overall governance of their Power Platform environments.\nImportant\nThis is a preview feature.\nPreview features arenât meant for production use and might have restricted functionality. These features are subject to\nsupplemental terms of use\n, and are available before an official release so that customers can get early access and provide feedback.\nKnown limitations\nWhile advanced connector policies (ACP) offer robust capabilities, there are a few limitations to consider:\nEnvironment group dependencies\n: Per-environment support isn't yet available. When it becomes available, we'll update this article.\nEndpoint filtering\n: Endpoint filtering will be replaced by a broader connection parameter filtering capability of which isn't yet available.\nManaged Environments\n: This feature requires Managed Environments to be enabled. In the future, you'll be able to use it on non-Managed Environments if you're not limiting the nonblockable connectors.\nConfigure an advanced connector policy\nTo configure an advanced connector policy, complete the following steps.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironment groups\n.\nIn the\nEnvironment groups\npage, select the environment group where you want the policy applied.\nThe environment group's page is displayed. Select the\nRules\ntab.\nSelect\nAdvanced connector policies (preview)\n. The\nAdvanced connector policies (preview)\npane is displayed.\nDefine the policy. Keep the following points in mind:\nBy default, the nonblockable connectors are preloaded as\nallowed\n.\nTo add new connectors, select\nAdd connectors\nto choose from all certified connectors.\nTo remove connectors, select them and then select\nRemove connector\n. You can remove any connector to block it.\nWhen all connectors are set as you require, select\nSave\n.\nThe environment group's page is redisplayed. After all rules are updated to your requirements, select\nPublish rules\nin the command bar.\nDuring publishing, an environment lifecycle operation is performed on every environment that's part of the group, or the individual environment depending on where you're configuring the policy. This operation is available in environment history as\nUpdate Managed Environment Settings\nand cascades the new connector policy to the design time and runtime infrastructure.\nMore visibility and control\nIn\ndata policies\n, customers couldn't see triggers, internal actions, or if an action is deprecated. By adding these tags across all certified connectors, administrators can quickly decide to block specific triggers from use or turn off actions that are deprecated and no longer supported by the connector publisher.\nEasier management experience\nBased on customer feedback, the management experience is drastically simplified by making the policy a strict\nallowlist\n. When configured, all new connectors are blocked. If you configure the allowed actions on a given connector, then no new actions, triggers, or internal actions are allowed. The concept of the business and nonbusiness categories in data policies isn't brought forward, as it wasn't deemed effective in policy management.\nProactive policy management\nAdvanced connector policies are available as part of environment groups and rules. The\nPower Platform API\nprovides publicly documented APIs so you can build automated scenarios such as creating new policies, updating policies, and moving environments into groups for management at scale.\nModel Context Protocol (MCP) server management\nAdvanced connector policies now support visibility and management of Model Context Protocol (MCP) servers. MCP servers are special connector endpoints that expose MCP-enabled APIs and tooling capabilities within Power Platform.\nWithin advanced connector policies, administrators can now see MCP servers listed alongside other connector types and can choose to block an entire MCP server. As of now, granular control over individual MCP tools (endpoints and actions) within an MCP server isn't available. Blocking the entire MCP server is supported.\nData policy mixed mode\nUse advanced connector policies (ACP) in mixed mode with classic data policies. This approach allows you to complement configurations so that data policies can achieve action control and endpoint filtering until such time as those features are native to ACP. In addition, you can use ACP to block any connector that isn't possible in classic data policies.\nAt runtime, when a connector operation is invoked, it queries the effective policy for the current hosting environment. This query includes a combined policy that merges the most restrictive settings from both classic data policies and ACP to provide full enforcement.\nIn the future, a separate rule will become available to allow you to skip data policy evaluation in favor of only relying upon connector policy.\nProvide feedback\nTrying out the new advanced connector policies? The product team would love your feedback! Join the Viva Engage network for keeping the conversation going under non-disclosure agreement:\nPublic Preview - Advanced Connector Policies\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Advanced Connector Policies",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/wp-data-loss-prevention": {
      "content_hash": "sha256:1c97081717a3aefe057710555ddab4bc2fea9ecab47849bb029eaaee1e2196c7",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nData policies\nFeedback\nSummarize this article for me\nData policies are a critical aspect of maintaining data security and compliance within the Microsoft Power Platform ecosystem.\nYou can create data policies that can act as guardrails to help reduce the risk of users from unintentionally exposing organizational data. A core component of Power Apps, Power Automate, and Microsoft Copilot Studio is the use of connectors to enumerate, populate, push, and pull data. Data policies in Power Platform admin center allow administrators to control access to these connectors in various ways to help reduce risk in your organization.\nThis overview describes some high-level concepts related to connectors and several important considerations to take into account when setting up your policies or making policy changes.\nConnectors\nConnectors, at their most basic level, are strongly typed representations of restful, application programming interfaces, also known as APIs. For example, the Power Platform API provides several operations related to functionality in Power Platform admin center.\nWhen wrapping the Power Platform API in to a connector, it becomes easier for makers and citizen developers to utilize the API in their low-code apps, workflows, and chatbots. For example, the Power Platform for Admins V2 connector is the representation of the Power Platform API and we see the 'Get Recommendations' action is simply drag and dropped on to the flow:\nThere are several types of connectors mentioned in this article, and each has capabilities within data policies.\nCertified connectors\nCertified connectors refer to connectors that have undergone rigorous testing and certification processes to ensure they meet Microsoft's standards for security, reliability, and compliance. These connectors provide users with a reliable means of integrating with other Microsoft services and external services, all while maintaining data integrity and security.\nFor more information on certified connectors, see\nCertification Submission Guidelines\n.\nCustom connectors\nCustom connectors allow makers to create their own connectors to integrate with external systems or services not covered by the standard set of certified connectors. While offering flexibility and customization options, custom connectors require careful consideration to ensure that they comply with data policies and don't compromise data security.\nLearn more about\ncreating and managing custom connectors\n.\nVirtual connectors\nVirtual connectors are connectors that are shown in data policies for administrators to control, however they're not based on a restful API. The proliferation of virtual connectors has stemmed from data policies being one of the most popular governance controls in Power Platform. More of these types of \"on/off\" capabilities are expected to surface as rules within\nEnvironment groups\n.\nSeveral virtual connectors are provided for governing Microsoft Copilot Studio. These connectors facilitate the ability to turn off various features of Copilots and chatbots.\nExplore virtual connectors and their role in\ndata loss prevention in Microsoft Copilot Studio\n.\nModel Context Protocol (MCP) connectors\nModel Context Protocol (MCP) connectors are a class of connectors that provide more metadata to expose MCP-enabled API endpoints, known as\ntools\n. MCP connectors extend typical connector functionality and enable richer experiences for generative AI in Microsoft Copilot Studio.\nMany of the nonblockable connectors in Microsoft Power Platform now support MCP. These connectors and their MCP servers can be managed and restricted through\nadvanced connector policies\n.\nConnections\nWhen a maker is building an app or a flow and needs to connect to data, they can use one of the above connector types. When a connector is first added to an app, a connection is established using the authentication protocols supported by that particular connector. These connections represent a saved credential and are stored within the environment that is hosting the app or flow. or more information about authenticating to connectors, see\nConnecting and authenticating to data sources\n.\nDesign-time versus runtime\nWhen an administrator chooses to limit access to either a whole connector or specific actions of a connector, there are impacts both to the maker experience and to the execution of previously created apps, flows, and chatbots.\nMaker experiences, often referred to as\ndesign-time\nexperiences, limit what connectors makers can interact with. If a data policy blocked the use of MSN Weather connector, then a maker can't save their flow or app that utilizes this, and instead receives an error message that the connector has been blocked by policy.\nExperiences where an app is being run or a flow is executing on a predefined schedule, such as every day at 3:00 AM, are often referred to as\nruntime\nexperiences. Continuing with the example earlier, if the connection was inactivated by the background process outlined below, then the result is that the app or flow provides an error message that the MSN Weather connection is broken and needs resolution. When the maker attempts to update their connection to fix it, they get an error in the design-time experience that the connector is blocked by policy.\nProcess for policy changes\nAs new data policies are created, or when existing policies are updated, there's a specific process that's triggered within the Power Platform ecosystem of services that helps to get those policies enforced across the entire set of resources a customer has in their tenant. This process involves the following steps.\nData policy configuration is saved at the customer management level.\nConfigurations are cascaded down to each environment in the customer tenant.\nResources in each environment (such as apps, flows, and chatbots) periodically check for updated policy configurations.\nWhen a configuration change is detected, each app, flow, and chatbot is evaluated to see if it violates the policy.\nIf a violation occurs, the app, flow, or chatbot is put in to a\nsuspended\nor\nquarantine\nstate so that it can't operate.\nConnections are scanned. If the policy blocks the whole connector then the connection is set to a\ndisabled\nstate so that it can't operate.\nAny resources that are running and attempting to use an inactive connection, action, trigger, or MCP server that is blocked, fail at runtime.\nLatency considerations\nThe time it takes to effectively implement data policies varies from customer to customer based on their volume of environments and resources within those environments. The more apps, flows, and chatbots a customer has, the longer it takes for policy changes to take full effect. For the most extreme cases, the latency for full enforcement is 24 hours. In most cases, it is within an hour.\nRelated content\nManage data policies\nData policies for Power Automate\nAdvanced connector policies\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DLP Policies (Power Platform)",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/dlp-connector-classification": {
      "content_hash": "sha256:d36c9545c512a75bfc979c6798ec13e1e97a3e7d0f7ec14b5c25198a0c7487b8",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConnector classification\nFeedback\nSummarize this article for me\nData groups are a simple way to categorize connectors within a data policy. The three data groups available are the\nBusiness\ndata group, the\nNon-Business\ndata group, and the\nBlocked\ndata group.\nA good way to categorize connectors is to place them in groups based on the business-centered or personal-use-centered services that they connect to in the context of your organization. Connectors that host business-use data should be classified as\nBusiness\n, and connectors that host personal-use data should be classified as\nNon-Business\n. Any connectors that you want to keep from being used at all across one or more environments should be classified as\nBlocked\n.\nWhen a new policy is created, by default all connectors are placed in the\nNon-Business\ngroup. From there they can be moved to\nBusiness\nor\nBlocked\nbased on your preference. You manage the connectors in a data group when you create or modify the properties of a data policy from the admin center. See\nManage data policies\n. You can also change the initial classification of connectors by editing your data policy. More information:\nEdit a data policy\nNote\nUntil recently, some HTTP connectors weren't readily available for data policy configuration by using the data policy UI or PowerShell. As of May 2020, the following HTTP connectors can now be classified by using the data policy UI and PowerShell, like any other Power Platform connector:\nHTTP\n,\nHTTP Webhook\n, and\nWhen an HTTP request is received\n. If legacy data policies are being updated by using the new data policy UI, a warning message is displayed to admins indicating that these three HTTP connectors are now being added to the data policies purview and that they should ensure that these connectors are placed in the right data policies grouping.\nBecause child flows share an internal dependency with the HTTP connector, the grouping that admins choose for HTTP connectors in a data policy might affect the ability to run child flows in that environment or tenant. Make sure your HTTP connectors are classified in the appropriate group for your child flows to function. If there are any concerns in classifying the connector as\nBusiness\nin shared environments such as the default environment, our advice is to classify it as\nNon-Business\nor to block it. Then, create dedicated environments where makers can use HTTP connectors, but restrict the maker list so that you can unblock makers from building child flows.\nThe\nContent Conversion\nconnector is an integral feature of Microsoft Power Platform, used to convert an HTML document to plain text. It applies both to\nBusiness\nand\nNon-Business\nscenarios and doesn't store any data context of the content converted through it; therefore, it's not available for classification through data policies.\nHow data is shared among data groups\nData can't be shared among connectors that are located in different groups. For example, if you place SharePoint and Salesforce connectors in the\nBusiness\ngroup and you place Gmail in the\nNon-Business\ngroup, makers can't create an app or flow that uses both the SharePoint and Gmail connectors. This in turn restricts data flows between these two services in Microsoft Power Platform.\nAlthough data can't be shared among services in different groups, it can be shared among services within a specific group. From the earlier example, because SharePoint and Salesforce were placed in the same data group, makers can create an app or flow that uses both SharePoint and Salesforce connectors together. This in turn allows data flows between these two services in Microsoft Power Platform.\nThe key point is that connectors in the same group can share data in Microsoft Power Platform, whereas connectors in different groups can't share data.\nThe effect of the Blocked data group\nData flow to a specific service can be blocked altogether by marking that connector as\nBlocked\n. For example, if you place Facebook in the\nBlocked\ngroup, makers can't create an app or flow that uses the Facebook connector. This in turn restricts data flows to this service in Microsoft Power Platform.\nAll third-party connectors can be blocked. All Microsoft-owned premium connectors (except Microsoft Dataverse) can be blocked.\nList of connectors that can't be blocked\nAll connectors driving core Microsoft Power Platform functionality (like Dataverse, Approvals, and Notifications), in addition to connectors that enable core Office customization scenarios like Microsoft Enterprise Plan standard connectors, remain nonblockable to ensure that core user scenarios remain fully functional.\nNote\nThese connectors can be limited or blocked using\nadvanced connector policies\n.\nHowever, these nonblockable connectors can be classified into\nBusiness\nor\nNon-Business\ndata groups. These connectors broadly fall into the following categories:\nMicrosoft Enterprise Plan standard connectors (with no other licensing implications).\nMicrosoft Power Platformâspecific connectors that are part of the base platform capabilities. Within this, Dataverse connectors are the only premium connectors that can't be blocked because Dataverse is an integral part of Microsoft Power Platform.\nThe following connectors can't be blocked by using data policies.\nMicrosoft Enterprise Plan standard connectors\nCore Power Platform connectors\nDefender for Cloud Apps\nApprovals\nDynamics 365 Customer Voice\nNotifications\nExcel Online (Business)\nDataverse (legacy)\nKaizala\nDataverse\nMicrosoft 365 Groups\nPower Apps Notifications (\nv1\nand\nv2\n)\nMicrosoft 365 Groups Mail (Preview)\nMicrosoft Copilot Studio\nMicrosoft 365 Outlook\nMicrosoft 365 Users\nMicrosoft Teams\nMicrosoft To-Do (Business)\nOneDrive for Business\nOneNote (Business)\nPlanner\nPower BI\nSharePoint\nShifts\nSkype for Business Online\nYammer\nNote\nIf a currently unblockable connector is already in the\nBlocked\ngroup (for example, because it was blocked when restrictions were different), it remains in the same group until you edit the policy. You get an error message stopping you from saving the policy until you move the unblockable connector to a\nBusiness\nor\nNon-Business\ngroup.\nViewing the classification of connectors\nWhen editing data policies in the Power Platform admin center, all available and visible connectors are shown, regardless of whether they have been classified in a policy. However, when viewing a data policy in PowerShell or through the Power Platform for Admins connector, you see only the connectors that have been explicitly classified in the Business, Non-business, or Blocked categories. data policies viewed from PowerShell or the Power Platform for Admins connector may include stale references to connectors that are no longer available or visible.\nIn general, the list of Power Platform connectors can differ depending on where you're viewing them, and there are several reasons for this. Some connectors may require specific licensing, and if your license doesn't include them, they're not visible. Different environments can also have different connectors available due to compliance and regulatory requirements. Microsoft may release updates to connectors, which may not be immediately available across all Power Platform components. Some connectors may only be available in Power Automate and not in Power Apps. Depending on your role and permissions, you may not have access to all connectors.\nCustom connector classification\nEnvironment-level data policies\nEnvironment admins can now find all the custom connectors in their environments alongside prebuilt connectors on the\nConnectors\npage in\nData Policies\n. Similar to prebuilt connectors, you can classify custom connectors into\nBlocked\n,\nBusiness\n, or\nNon-Business\ncategories. Custom connectors that aren't explicitly classified will be put under the default group (or\nNon-Business\n, if no default group setting is explicitly chosen by admins).\nYou can also use data policy PowerShell commands to set custom connectors into\nBusiness\n,\nNon-Business\n, and\nBlocked\ngroups. More information:\nData policy commands\nTenant-level data policies\nThe Power Platform admin center also has support for tenant admins to classify custom connectors by their Host URL endpoints by using a pattern-matching construct for tenant-level data policies. Because the scope of custom connectors is environment-specific, these connectors don't show up on the\nConnectors\npage for you to classify. Instead, you see a new page in\nData Policies\nnamed\nCustom connectors\n, which you can use to specify an ordered list of Allow and Deny URL patterns for custom connectors.\nThe rule for the wildcard character (\n*\n) is the last entry in the list, which applies to all custom connectors. Admins can tag the\n*\npattern to\nBlocked\n,\nBusiness\n,\nNon-business\n, or\nIgnore\n. By default, the pattern is set as\nIgnore\nfor new data policies.\nIgnore\nignores data polciy classification for all connectors in this tenant-level policy, and defers evaluation of a pattern to other environments or tenant-level policies to attribute them into the\nBusiness\n,\nNon-Business\n, or\nBlocked\ngrouping as appropriate. If no specific rule exists for the custom connectors, an\nIgnore *\nrule allows custom connectors to be used with both\nBusiness\nand\nNon-Business\nconnector groupings. Except for the last entry in the list,\nIgnore\nas an action isn't supported for any other URL pattern added to the custom connector pattern rules.\nYou can further add new rules by selecting\nAdd connector pattern\non the\nCustom connectors\npage.\nThis opens a side panel where you can add custom connector URL patterns and classify them. New rules are added to the end of the pattern list (as the second-to-the-last rule, because\n*\nis the last entry in the list). However, you can update the order while adding a new pattern.\nYou can also update the order of the patterns by using the\nOrder\ndropdown list or selecting\nMove up\nor\nMove down\n.\nAfter a pattern has been added, you can edit or delete these patterns by selecting a specific row and selecting\nEdit\nor\nDelete\n.\nDefault data group for new connectors\nOne data group must be designated as the default group to automatically classify any new connectors added to Microsoft Power Platform after your policy has been created. Initially, the\nNon-Business\ngroup is the default group for new connectors and all services. You can\nchange the default data group\nto the\nBusiness\nor\nBlocked\ndata group, but we don't recommend that you do so.\nAny new services that are added to apps are placed in the designated default group. For this reason, we recommend that you keep\nNon-Business\nas the default group, and manually add services into the\nBusiness\nor\nBlocked\ngroup after your organization has evaluated the impact of allowing business data to be shared with the new service.\nNote\nMicrosoft 365 Enterprise license connectors and a few core Microsoft Power Platform connectors are exempt from being marked as\nBlocked\n, and can only be classified as\nBusiness\nor\nNon-Business\n. If Microsoft adds any new connectors that can't be blocked and you've set the default group for the data policy as\nBlocked\n, these connectors will be automatically marked as\nNon-Business\ninstead of\nBlocked\n.\nRelated information\nPower Platform data policies\nData policies for Power Automate\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Connector Classification",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/wp-connectors": {
      "content_hash": "sha256:3889d315d892c0fe309ef58aa4b04a51d5d8c4109841c937c0c4ccb9540e40d3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of connectors for canvas apps\nFeedback\nSummarize this article for me\nData is at the core of most apps, including apps you build in Power Apps. You store data in a\ndata source\n, and you bring that data into your app by creating a\nconnection\n. The connection uses a specific\nconnector\nto talk to the data source. Power Apps has connectors for many popular services and on-premises data sources, including SharePoint, SQL Server, Office 365, Salesforce, and Twitter. To get started adding data to a canvas app, see\nAdd a data connection in Power Apps\n.\nA connector might provide\ntables\nof data or\nactions\n. Some connectors provide only tables, some provide only actions, and some provide both. Also your connector might be either a standard or custom connector.\nNote\nKeep the number of connectors in a canvas app to a maximum of 10, and connection references to no more than 20. Going beyond these limits can lead to longer loading times for users when launching the app and can cause problems when saving the app.\nTables\nIf your connector provides tables, add your data source, and then select the table in the data source that you want to manage. Power Apps retrieves table data into your app and updates data in your data source automatically. For example, add a data source that has a table named\nLessons\n, and then set the\nItems\nproperty of a control, such as a gallery or a form, to this value in the formula bar:\nSpecify the data that your app retrieves by customizing the\nItems\nproperty of the control that shows your data. Continuing the previous example, sort or filter the data in the\nLessons\ntable by using that name as an argument for the\nSearch\nand\nSortByColumn\nfunctions. In this graphic, the formula set for the\nItems\nproperty specifies that the data is sorted and filtered based on the text in\nTextSearchBox1\n.\nFor more information about customizing your formula with tables, see these articles:\nUnderstand data sources in Power Apps\nGenerate an app from Excel data\nCreate an app from scratch\nUnderstand tables and records in Power Apps\nNote\nTo connect to data in an Excel workbook, host it in a cloud storage service like OneDrive. For more information, see\nConnect to cloud-storage from Power Apps\n.\nActions\nIf your connector provides actions, select your data source as you did before. Instead of selecting a table as the next step, manually connect a control to an action by editing the\nItems\nproperty of the control that shows your data. The formula you set for the\nItems\nproperty specifies the action that retrieves data. For example, the app doesn't retrieve any data if you connect to Yammer and then set the\nItems\nproperty to the name of the data source. To populate a control with data, specify an action such as\nGetMessagesInGroup(5033622).messages\n.\nTo handle custom data updates for action connectors, build a formula that includes the\nPatch\nfunction. In the formula, identify the action and the fields that bind to the action.\nNote\nFor action-based connectors, galleries and other controls don't automatically page in more data like they do for tabular connectors. For example, if you bind a tabular data source to a gallery, it retrieves the first set or page of records (for example, 100 records), and then it pages in more data as the control requests it. For an action-based connector, it retrieves a \"page\" of data, but if the data requested exceeds the page size, the control doesn't automatically get the next page.\nFor more information about how to customize your formula for custom updates, see these articles:\nPatch\nCollect\nUpdate\nDynamic schema is a common type of result for action based connectors. Dynamic schema refers to the possibility that the same action might return a table with different columns depending on how it's called. Conditions that might cause the columns in the table to differ include input parameters, the user or role executing the action, and the group in which the user is working, among others. For example, SQL Server stored procedures might return different columns if run with different inputs, or an Azure DevOps instance might use custom fields that aren't available by default.\nNote\nThe\nconnector documentation\nshows dynamic schema results with this message\n\"The outputs of this operation are dynamic.\"\nas the return value.\nFor more information about how to work with dynamic schema in Power Apps, see\nWorking with Dynamic values\nfor an overview and\nConnect to Azure DevOps from Power Apps\nfor a detailed example.\nPopular connectors\nThis table links to more information about popular connectors. For a complete list, see\nAll connectors\n.\nMicrosoft Dataverse\nCloud storage\n**\nDynamics AX\nExcel\nMicrosoft Translator\nOffice 365 Outlook\nOffice 365 Users\nOracle\nPower BI\nSharePoint\nSQL Server\nTwitter\n** Applies to Azure Blob, Box, Dropbox, Google Drive, and OneDrive.\nStandard and custom connectors\nPower Apps provides\nstandard\nconnectors for many commonly used data sources. If Power Apps has a standard connector for the type of data source you want to use, use that connector. To connect to other types of data sources, like a service you built, see\nRegister and use custom connectors\n.\nAll standard connectors\nStandard connectors don't require special licensing. For more information, see\nPower Apps plans\n.\nAsk questions about a specific connector in the\nPower Apps forums\n, and suggest connectors you want to add or other improvements in\nPower Apps Ideas\n.\nSecurity and types of authentication\nAs you author your app and create a connection to a data source, you might see that your choice of connector offers different ways to authenticate. For instance, the SQL Server connector allows you to use Microsoft Entra Integrated, SQL Server Authentication, and Windows Authentication. Each type of authentication has different levels of security. Understand what information and rights you share with users who use your application. The primary example in this article is SQL Server. However, the principles apply to all types of connections.\nNote\nFor detailed information about security considerations when using a relational database server, such as Microsoft SQL Server or Oracle, as the data source for an app, see\nUse Microsoft SQL Server securely with Power Apps\n.\nPower Apps doesn't support\nExternal member\nidentities. For more information, see\nProperties of a Microsoft Entra B2B collaboration user\n.\nGateway selection isn't supported for custom connectors that use the anonymous authentication type.\nMicrosoft Entra ID\nThis authentication is a secure type of connection. For example, SharePoint uses this type of authentication. SQL Server also allows for this type of authentication. When you connect, the Microsoft Entra service identifies you separately to SharePoint on your behalf. You don't have to supply a username or password. As an author, you can create and work with the data source by using your credentials. When you publish your application, your application user signs in by using their credentials. If the data is appropriately secured on a back-end, your users can only see what they're authorized to see based on their credentials. This type of security allows you to change rights for specific application users on the back-end data source after the application is published. For instance you can grant access, deny access, or refine what a user or set of users can see all on the back-end data source.\nOpen-standard authorization (OAuth)\nThis type of connection is also secure. For example, Twitter uses this type of authentication. When you connect,\nyou must supply your user name and password.\nAs an author, you can create and work with the data source by using your credentials. When you publish your application and your application user signs in, they must also supply their credentials. Therefore this type of connection is secure as your users must use their own credentials to access the data source service.\nShared connections and secure implicit connections\nIn a shared connection, the Power Apps author provides the user name and password for the connection when creating the data source in the application. The connection authentication to the data source is then\nimplicitly shared\nwith end users. Once the application is published, the connection is also published and available to your users.\nBefore January 2024, your end users could take the connection that you shared with them and create separate new applications. Your users can't see the user name or password, but the connection is available to them. However,\nafter January 2024, all newly created shared connections are secured.\nTo secure existing apps, republish them. The connection is no longer shared with end users. The published Power App talks to a connection proxy. The connection proxy only talks to the specific Power App for which it's linked. The connection proxy limits the actions that are sent to the connections to the ones in the Power App\n{Get, Put/Patch, Delete}\nfor a given data source. If you have an app using the connections published before January 2024, republish your application and unshare any connections with end users that shouldn't have them.\nIn SQL Server, an example of this type of connection is\nSQL Server Authentication\n. Many other database data sources provide a similar capability. When you publish your application, your users don't need to supply a unique user name and password.\nNote\nYour end-users might encounter the error message\nYou do not have correct permissions to use this connection\nin the consent dialog. Two situations might cause this error. First, the application might have a shared implicit connection that\nisn't\na secure implicit connection. Sharing the connection with the end user resolves this issue but isn't recommended because all shared connections should be secure implicit connections. The author should convert all connections in the application to be secure implicit connections to resolve this issue. Second, the connection might already be a secure implicit connection. Republishing might resolve this issue. If it doesn't, then a product bug should be filed.\nNotification to update your apps (secure implicit connections)\nIf you have applications that might be upgraded to use this feature, you see a message on the\nApps\npage. It indicates the number of apps that need your attention.\nSelect the link and it opens a side panel that lists all of the apps that need attention.\nSelect the\nopen\nicon to the right of the app name to open and republish it. Continue with the following directions.\nEnable secure implicit connections for an existing app\nOpen an existing\napp open for editing\nwith implicitly shared connections already published:\nOn the command bar, select\nSettings\nand search for\n\"Secure\"\n.\nUpdate the feature switch appropriately to enable secure implicit connections.\nSave and publish the app.\nUnsharing\nOnce you publish the app, follow these steps to verify that sharing works correctly:\nCheck if connections are shared with co-owners. If you don't want an end-user to get a connection, then uncheck the\nCo-owner\ncheckbox.\nTo verify the feature works correctly, share the app with a different user who isn't an owner. Once you share the app, check the\nConnections\nlist in the\nDataverse\ntab in\nPower Apps\nfor that user. Verify that the user doesn't have a connection available.\nOpen the\nSharing\npanel to change the end-user's right to the connection. Choose the\nX\nto remove the user's access to the connection.\nUse apps with a new secure implicit connection\nWhen you republish and share your app, end-users don't have access to the connection but work with the hidden proxy connection. Users can't create a new app based on your original connection.\nLimitations\nAll types of implicitly shared connections work, such as action and tabular.\nServer and database names are hidden in network traces but visible in the consent dialog. Column names aren't hidden.\nFor tabular connectors, the feature only limits CRUD actions such as Get, Post, Put, or Delete. If you have permissions to\nPut\n, then you have access to\nPost\n.\nAction based connectors limit based on the specific API being used in the application.\nWarnings are still enabled in sharing. The warning around implicitly shared connections still warns while in preview. However, your connection with this feature is secure â despite the warning.\nPublishing to an entire tenant, as opposed to specific groups or individuals isn't supported.\nThere's a known issue when importing an implicitly shared secure connection via a connection reference. The security isn't set properly in the target environment.\nThere's a known issue importing a solution using a service principal, causing import failure. A workaround is to share the connection with the service principal.\nWindows Authentication\nThis type of connection isn't secure because it doesn't rely on end-user authentication. Use Windows authentication when you need to connect to a data source that is\non-premises\n. An example of this type of connection is to an on-premises server that has a SQL Server. The connection must go through a gateway. Since it goes through a gateway, the connector has access to all of the data on that data source. As a result, any information that you can access with the Windows credentials you supply is available to the connector. When you publish the application, you also publish the connection and make it available to your users. This behavior means that your end users can create applications by using this same connection and access the data on that machine. Connections to the data source are also\nImplicitly Shared\nwith users that the app is shared with. This type of connection might be valid when your data source only lives on an on-premises server and the data on that source is freely shareable.\nData sources in solutions\nSolutions help with\napplication lifecycle management\nand offer other ways to manage the lifecycle of\ndata sources\n. If a canvas app is in a solution, you can create\nconnection references\nand\nenvironment variables\nto store information about the data sources. This setup makes it easy to change or reconnect data sources when you move solutions to different environments.\nRename data sources in apps\nLearn how to rename data sources in an app, and understand the difference between tabular and action-based data sources. For more information, see\nRename Power Apps action-based data sources\n.\nConnection consent dialog\nWhen users open an app that uses connectors for the first time, they see a connection consent dialog for the following purposes.\nTo inform users about the data sources accessed by the app.\nTo outline the actions a connector might or might not perform in an app. For example, for apps using the\nOffice 365 Users\nconnector:\nThis app is able to:\nRead your full user profile\nRead the full profile of all users\nThe app can't:\nModify or delete any user-profile information\nTo capture end-user consent to connect to the data sources that the app uses.\nTo facilitate manual end-user authentication, when needed.\nFor some connections, Power Platform can automatically authenticate a user to access a data source. However, if the automatic sign-in fails, this dialog prompts users to fix a connection by manually signing in. Power Platform can only attempt automatic sign-in for a connection when a data source preauthorizes Microsoftâs Azure API connections service principal, granting it permission to perform single sign-on for a user when a connection is created. For more information on single sign-on, see\nWhat is single sign-on (SSO)?\nFor model-driven apps that use custom pages, when there are multiple custom pages in an app, the consent dialog asks for data permissions for all of the connectors in all the custom pages even if users don't open them.\nThe following image is an example of the connection consent dialog for an app connecting to a SharePoint site.\nFor select connectors, admins can suppress this dialog and consent on behalf of end users to connect to a data source. The following table explains which types of connectors the consent dialog might be suppressed for an app.\nNote\nIf an admin suppresses the consent dialog but the platform canât perform single sign-on for an end-user, the dialog is presented to the user when they launch the app.\nConnector type\nConsent dialog suppressible?\nReference\nMicrosoft connectors that support single sign-on (such as SharePoint, Office 365 users)\nYes\nPower Apps admin cmdlet\nConnector accessing a non-Microsoft, partner service, such as Salesforce\nNo\nNot applicable\nCustom connectors using OAuth with Microsoft Entra ID as the identity provider. These custom connectors are built by organizations, and are only accessible by the users within the organization (for example, built by Contoso for only Contoso users)\nYes\nManage Connections\nMicrosoft Power Platform can only suppress the consent dialog for connections to data sources where all the following conditions are true:\nThe data source doesn't require an explicit consent UI.\nThe data source preauthorizes Microsoftâs Azure API connections service principal to enable single sign-on.\nAn admin configures an app to suppress the consent for the preceding connections.\nMicrosoftâs Azure API connections service principal preauthorization exists for Microsoft's first-party data sources. Custom applications registered in a Microsoft Entra tenant that are used by custom connectors might configure this preauthorization. An admin manages consent suppression on a per-app basis (as opposed to connector basis), so suppression is managed at the most granular app experience level. This level of granularity prevents consent suppression for an organizationâs \"approved apps\" from inadvertently suppressing consent for apps that aren't approved or reviewed.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Third-Party Connectors",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/connectors/connector-reference/": {
      "content_hash": "sha256:c1c142fbd08b64f5a40471a7f03b28a6db57ee350b81e88b04263689502ad2f3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConnector reference overview\nFeedback\nSummarize this article for me\nThis page summarizes key information of all connectors currently provided for Microsoft Power Automate, Microsoft Power Apps, and Azure Logic Apps. In addition to the connector icon and name, the following information is provided:\nAvailable in Azure Logic Apps.\nAvailable in Power Automate.\nAvailable in Power Apps.\nThis is an MCP Server connector.\nThis is a Preview connector.\nThis is a Premium connector for Power Automate and Power Apps or a Standard connector for Azure Logic Apps.\nYou can select a connector to view more detailed connector-specific documentation including its functionality and region availability. You can also filter all connectors by a certain category. Note that filters do not stack and each link will take you to another page within the documentation site.\nFilter all connectors by:\nTier\nRelease Status\nProduct\nPublisher\nStandard\nPreview\nPower Apps\nMicrosoft\nPremium\nProduction\nPower Automate\nNon-Microsoft\nLogic Apps\nMCP Server\nList of Connectors\n}exghts gen. Document & more\nBy: }exghts\n10to8 Appointment Scheduling\nBy: 10to8 Ltd\n1DocStop\nBy: 1DocStop\n1Me Corporate\nBy: 1Me\n1pt (Independent Publisher)\nBy: Troy Taylor\n24 pull request (Independent Publisher)\nBy: Bernard Karaba\n365 Training\nBy: We Speak You Learn, LLC\n3E Events\nBy: Elite Technology\n9A Raptor Document Warehouse\nBy: 9altitudes\nAbbreviations\nBy: Troy Taylor\nAbortion Policy (Independent Publisher)\nBy: That API Guy\nabsentify\nBy: BrainCore Solutions\nAbstract Company Enrichment (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract Email Validator (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract Exchange Rates (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract Holidays (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract IBAN Validator (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract IP Geolocation (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract Phone Validator (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAbstract Timezones (Independent Publisher)\nBy: System Administrator\nAbstract VAT Validator (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAccuWeather (Independent Publisher)\nBy: troystaylor\nAct!\nBy: Swiftpage ACT!\nActivityInfo\nBy: ActivityInfo\nAcumatica\nBy: Acumatica\nAddress Labs (Independent Publisher)\nBy: Richard Wilson\nAdobe Acrobat Sign\nBy: ADOBE INC.\nAdobe Acrobat Sign Sandbox\nBy: Adobe Inc.\nAdobe Creative Cloud\nBy: Adobe Inc\nAdobe Experience Manager\nBy: Adobe\nAdobe PDF Services\nBy: Adobe Inc.\nAdvanced Data Operations\nBy: State Solutions\nAdvanced Scraper (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nAffirmations (Independent Publisher)\nBy: Troy Taylor\nAfrica's Talking Airtime\nBy: Africa's Talking\nAfrica's Talking SMS\nBy: Africa's Talking\nAfrica's Talking Voice\nBy: Africa's Talking\nAfterShip (Independent Publisher)\nBy: Taiki Yoshida\nAgilePoint NX\nBy: AgilePoint Inc\nAgilite\nBy: Agilit-e\nAhead\nBy: ahead AG\nAhead (Intranet)\nBy: ahead AG\nAI or Not (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nAIForged\nBy: Larc AI (PTY) Ltd\nAIHW MyHospitals (Independent Publisher)\nBy: Paul Culmsee\nAikiDocs\nBy: Aiki-Mind Services Inc.\nAirlabs\nBy: FÃ¶rdÅs AndrÃ¡s\nAirly (Independent Publisher)\nBy: Tomasz Poszytek\nAirmeet\nBy: Airmeet\nairSlate\nBy: airSlate Inc.\nAirtable (Independent Publisher) [DEPRECATED]\nBy: Woong Choi\nAlemba ITSM\nBy: Alemba Ltd\nAletheia\nBy: Aletheia\nAlisQI\nBy: AlisQI BV\nAlkymi\nBy: Alkymi\nallGeo\nBy: Abaqus\nAlly\nBy: Aliru\nAlmabase\nBy: Almabase, Inc.\nAlmanac (Independent Publisher)\nBy: Troy Taylor\nALVAO\nBy: ALVAO\nAmazon Redshift\nBy: Microsoft\nAmazon S3\nBy: Microsoft\nAmazon S3 Bucket (Independent Publisher)\nBy: Michael Megel\nAmazon SQS\nBy: Microsoft\nAmbee (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nAMEE Open Business (Independent Publisher)\nBy: Paul Culmsee\nAnnature (Independent Publisher)\nBy: Dr Adrian Colquhoun (Strategik)\nAnt Text Automation\nBy: Insight Office\nAnthropic (Independent Publisher)\nBy: Troy Taylor\nANY.RUN Threat Intelligence\nBy: ANYRUN FZCO\nApache Impala\nBy: Microsoft\nAPITemplate (Independent Publisher)\nBy: Troy Taylor\nAPlace.io (Independent Publisher)\nBy: Troy Taylor\nApp Power Forms\nBy: App Power Solutions LLC\nApp Store Connect - App Store (Independent Publisher)\nBy: Farhan Latif\nAppfigures\nBy: Microsoft\nAppsForOps Timeline\nBy: AppsForOps\nApptigent PowerTools\nBy: Apptigent\nApptigent PowerTools LITE\nBy: Apptigent Limited\nApyHub (Independent Publisher)\nBy: Troy Taylor\nApyHub Document Readability (Independent Publisher)\nBy: Troy Taylor\nApyHub Generate iCal (Independent Publisher)\nBy: Troy Taylor\nAquaforest PDF\nBy: Aquaforest Limited\nAranda Service Management\nBy: Aranda Software Corporation\nArcGIS\nBy: Esri, Inc.\nArcGIS Enterprise\nBy: Esri, Inc.\nArcGIS PaaS\nBy: Esri, Inc.\nAS2\nBy: Microsoft\nAsana\nBy: Microsoft\nAsite\nBy: Asite Solutions Pvt Ltd\nAsite (Canada)\nBy: Asite Solutions Limited\nAsite (Hong Kong)\nBy: Asite Solutions Limited\nAsite (KSA)\nBy: Asite Solutions Limited\nAsite (UAE)\nBy: Asite Solutions Limited\nAsite (US Gov.)\nBy: Asite Solutions Limited\nASPSMS\nBy: Vadian .Net AG\nAssemblyAI\nBy: AssemblyAI\nAssently E-Sign\nBy: Assently AB\nAtBot Admin\nBy: H3 Solutions Inc.\nAtBot Logic\nBy: H3 Solutions Inc.\nAutenti E-Signature Workflow\nBy: Autenti sp. z o.o.\nAutodesk Data Exchange\nBy: Autodesk, Inc.\nAutoReview\nBy: Power DevBox\nAutoSeller\nBy: Microsoft Corporation\nAvePoint Cloud Governance\nBy: AvePoint, inc.\nAviationstack (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nAWeber\nBy: Microsoft\nAzure AD Identity and Access\nBy: Microsoft, Daniel Laskewitz\nAzure AI Document Intelligence (form recognizer)\nBy: Microsoft\nAzure AI Foundry Agent Service\nBy: Microsoft\nAzure AI Foundry Inference\nBy: Microsoft\nAzure AI Search\nBy: Microsoft\nAzure App Service\nBy: Microsoft\nAzure Application Insights\nBy: Microsoft\nAzure Automation\nBy: Microsoft\nAzure Batch Speech-to-text\nBy: Microsoft\nAzure Blob Storage\nBy: Microsoft\nAzure Cognitive Service for Language\nBy: Microsoft\nAzure Communication Chat\nBy: Microsoft\nAzure Communication Email\nBy: Microsoft\nAzure Communication Services Identity\nBy: Microsoft\nAzure Communication Services SMS\nBy: Microsoft\nAzure Communication Services SMS Events\nBy: Microsoft\nAzure Confidential Ledger\nBy: Microsoft Corporation\nAzure Container Instance\nBy: Microsoft\nAzure Cosmos DB\nBy: Microsoft\nAzure Data Explorer\nBy: Microsoft\nAzure Data Factory\nBy: Microsoft\nAzure Data Lake\nBy: Microsoft\nAzure Database for MySQL\nBy: Microsoft\nAzure Databricks\nBy: Databricks Inc.\nAzure DevOps\nBy: Microsoft\nAzure Digital Twins\nBy: Microsoft Corporation\nAzure Event Grid\nBy: Microsoft\nAzure Event Grid Publish\nBy: Microsoft\nAzure File Storage\nBy: Microsoft\nAzure IoT Central V2\nBy: Microsoft Corporation\nAzure IoT Central V3\nBy: Microsoft Corporation\nAzure Key Vault\nBy: Microsoft\nAzure Log Analytics [DEPRECATED]\nBy: Microsoft\nAzure Log Analytics Data Collector\nBy: Microsoft\nAzure Monitor Logs\nBy: Microsoft\nAzure OpenAI\nBy: Microsoft\nAzure Queues\nBy: Microsoft\nAzure Resource Manager\nBy: Microsoft\nAzure Speech Pronunciation Assessment\nBy: Microsoft\nAzure SQL Data Warehouse\nBy: Microsoft\nAzure Table Storage\nBy: Microsoft\nAzure Text to speech\nBy: Microsoft\nAzure VM\nBy: Microsoft\nBadgr (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nBasecamp 2\nBy: Microsoft\nBasecamp 3\nBy: Microsoft\nBBC News (Independent Publisher)\nBy: krautrocker\nBeauhurst (Independent Publisher)\nBy: Axazure\nBenchmark Email\nBy: Microsoft\nBenifex\nBy: Benefex Ltd\nBillsPLS\nBy: IN-D by Intain\nBIN Checker (Independent Publisher)\nBy: Troy Taylor\nBinance.us (Independent Publisher)\nBy: Roy Paar\nBing Maps\nBy: Microsoft\nBing Search\nBy: Microsoft\nBitbucket\nBy: Microsoft\nBitly\nBy: Microsoft\nBitlyIP (Independent Publisher)\nBy: Troy Taylor\nBitskout\nBy: Bitskout\nBitvore Cellenus\nBy: Bitvore Corp.\nBizTalkServer\nBy: Microsoft\nBKK Futar (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nBlackbaud Altru Constituent\nBy: Blackbaud, Inc.\nBlackbaud Church Management [DEPRECATED]\nBy: Blackbaud, Inc.\nBlackbaud CRM Constituent\nBy: Blackbaud, Inc.\nBlackbaud CRM Prospect\nBy: Blackbaud, Inc.\nBlackbaud FENXT General Ledger\nBy: Blackbaud, Inc.\nBlackbaud FENXT Payable\nBy: Blackbaud, Inc.\nBlackbaud FENXT Query\nBy: Blackbaud. Inc\nBlackbaud Raisers Edge NXT\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Constituents\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Documents\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Events\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Fundraising\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Interactions\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Lists\nBy: Blackbaud, Inc.\nBlackbaud Raisers Edge NXT Prospects\nBy: Blackbaud, Inc.\nBlackbaud RENXT Gifts\nBy: Blackbaud, Inc.\nBlackbaud RENXT Query\nBy: Blackbaud. Inc\nBlackbaud RENXT Reports\nBy: Blackbaud, Inc.\nBlackbaud SKY Add-ins\nBy: Blackbaud. Inc\nBlogger\nBy: Microsoft\nBloomflow\nBy: Bloomflow\nBlueInk\nBy: Blueink\nBluesky Social (Independent Publisher)\nBy: krautrocker\nBoldSign\nBy: Syncfusion-Inc\nboomapp connect\nBy: Boomerang I-Comms Ltd\nBox\nBy: Microsoft\nBox MCP Server\nBy: Box.\nBrave Search (Independent Publisher)\nBy: Troy Taylor\nbttn\nBy: Microsoft\nBttn ONE\nBy: Bttn\nBuffer\nBy: Microsoft\nBuildingMinds DigitalTwin Core\nBy: BuildingMinds\nBulkSMS\nBy: BulkSMS.com\nBureau of Labor Statistics (Independent Publisher)\nBy: krautrocker\nBusiness Assist [DEPRECATED]\nBy: Microsoft\nBusinessmap\nBy: Businessmap\nBuy Me A Coffee (Independent Publisher)\nBy: Troy Taylor\nByword (Independent Publisher)\nBy: Troy Taylor\nCalculate Working Day\nBy: Tweed Technology Ltd\nCalendar Pro\nBy: Witivio\nCalendarific (Independent Publisher)\nBy: Fordos Andras\nCalendly\nBy: Calendly\nCalendly (legacy)\nBy: Microsoft\nCampfire\nBy: Microsoft\nCandidateZip Resume/Job Parser\nBy: CandidateZip CV/Job Parser\nCapsule CRM\nBy: Microsoft\nCaptisa Forms\nBy: Connect Captisa\nCarbon Intensity (Independent Publisher)\nBy: Hasan Unlu\nCarbonFootprint (Independent Publisher)\nBy: Troy Taylor\nCardPlatform Adaptive Cards\nBy: CardPlatform\nCarsXE (Independent Publisher)\nBy: Troy Taylor\nCascade\nBy: Cascade\nCascade Strategy New\nBy: Nicolas Durik-Ha\nCasper365 for Education\nBy: Microsoft\nCB Blockchain Seal\nBy: Connecting Software s.r.o. & Co. KG\nCData Connect AI\nBy: CData Software Inc\nCDC Content Services (Independent Publisher)\nBy: Troy Taylor\nCDK Drive Customer\nBy: CDK Global\nCDK Drive Service Vehicles\nBy: CDK Global\nCelonis\nBy: Celonis\nCelonis MCP Server\nBy: Celonis GmbH\nCentrical\nBy: Centrical\nCertinal eSign\nBy: Certinal Inc.\nCertopus\nBy: DevSquirrel Technologies Private Limited\nCGTrader\nBy: Microsoft\nChainpoint [DEPRECATED]\nBy: Chainpoint\nChatter\nBy: Microsoft\nCheckly (Independent Publisher)\nBy: Troy Taylor\nChuck Norris IO (Independent Publisher)\nBy: Daniel Laskewitz\ncioplenu\nBy: cioplenu GmbH\nCireson Service Manager Portal\nBy: Cireson\nCisco Webex Meetings\nBy: Cisco\nCitymapper (Independent Publisher)\nBy: Troy Taylor\nCivicPlus Transform\nBy: OneBlink\nClearbit (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nCleverTap\nBy: CleverTap Pvt. ltd.\nClickSend\nBy: Sinch Sweden AB\nClickSend Postcards\nBy: ClickSend Postcards\nClickUp Team Manager (Independent Publisher)\nBy: Duke DeVan\nClimatiq (Independent Publisher)\nBy: Troy Taylor\nClinical Trials (Independent Publisher)\nBy: Troy Taylor\nClockify (Independent Publisher)\nBy: Dr Adrian Colquhoun (Strategik)\nCloud BOT\nBy: C-RISE Ltd.\nCloud Connect Studio\nBy: Fuji Xerox\nCloud PKI Management\nBy: 509 Solutions Pty Ltd\nCloudConvert\nBy: Lunaweb GmbH\nCloudmersive Barcode\nBy: Cloudmersive, LLC\nCloudmersive CDR\nBy: Cloudmersive, LLC\nCloudmersive Currency\nBy: Cloudmersive, LLC\nCloudmersive Data Validation\nBy: Cloudmersive, LLC\nCloudmersive Document Conversion\nBy: Cloudmersive, LLC\nCloudmersive File Processing\nBy: Cloudmersive, LLC\nCloudmersive Image Processing\nBy: Cloudmersive, LLC\nCloudmersive NLP\nBy: Cloudmersive, LLC\nCloudmersive PDF\nBy: Cloudmersive, LLC\nCloudmersive Security\nBy: Cloudmersive, LLC\nCloudmersive Video and Media\nBy: Cloudmersive, LLC\nCloudmersive Virus Scan\nBy: Cloudmersive, LLC\nCloudTools for Salesforce\nBy: Apptigent\nCloverly (Independent Publisher)\nBy: Troy Taylor\nCluedIn\nBy: CluedIn Official\nCMI\nBy: CM Informatik AG\nCO2 Signal (Independent Publisher)\nBy: Paul Culmsee\nCobbleStone - Contract Insight\nBy: Cobblestone Software\nCognito Forms\nBy: Cognito Forms\nCognizant Automation Center\nBy: Cognizant\nCohere (Independent Publisher)\nBy: Troy Taylor\nCohesity Gaia\nBy: Cohesity, Inc.\nCoinbase (Independent Publisher)\nBy: Roy Paar\nCommercient\nBy: Commercient LLC\nCompanies House (Independent Publisher)\nBy: Matt Collins\nCompany Connect\nBy: InSpark\nComposer by Tachytelic\nBy: Accendo Solutions Ltd\nComputer Vision API\nBy: Microsoft\nConfluence\nBy: Microsoft\nConnect2All\nBy: GAC Business Solutions\nConnect2All on-premises\nBy: GAC Business Solutions\nConnective eSignatures\nBy: Connective\nConnectWise PSA (Independent Publisher)\nBy: howellchrisj\nconnpass (Independent Publisher)\nBy: Miyake Hideo\nConsenSys Ethereum (Deprecated) [DEPRECATED]\nBy: ConsenSys\nContacts Pro\nBy: Witivio\nContent Conversion\nBy: Microsoft\nContent Gate\nBy: SignUp Software Netherlands B.V\nContent Manager Power Connect\nBy: Kapish Services Pty Ltd\nContent Moderator\nBy: Microsoft\nContoso Hub\nBy: Microsoft\nConverter by Power2Apps\nBy: Power2Apps P2A GmbH\nConvertKit (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nCopilot for Finance\nBy: Microsoft\nCopilot for Sales\nBy: Microsoft Corporation\nCopilot for Service extension (preview)\nBy: Microsoft Corporation\nCopy.ai\nBy: Troy Taylor\nCorda Blockchain [DEPRECATED]\nBy: Microsoft\nCornerstone Learning vILT\nBy: Cornerstone On Demand\nCorporate Buzzword Generator (Independent Publisher)\nBy: Troy Taylor\nCOSMO Bot\nBy: COSMO CONSULT GmbH\nCoupa (Independent Publisher)\nBy: NovaGL\nCourier (Independent Publisher)\nBy: Troy Taylor\nCOVID-19 JHU CSSE (Independent Publisher)\nBy: Woong Choi\nCPQSync\nBy: Cincom Systems\nCPSC Recalls Retrieval (Independent Publisher)\nBy: Troy Taylor\nCQC Data (Independent Publisher)\nBy: Martyn Lesbirel\nCradl AI\nBy: Cradl AI\nCraftMyPDF (Independent Publisher)\nBy: Troy Taylor\nCRM Bot\nBy: CRM Bot Ltd\nCrossbeam\nBy: Crossbeam\nCSV Converter by Power2Apps\nBy: Power2Apps P2A GmbH\nCustom Vision\nBy: Microsoft\nCustomJS\nBy: TechnologyCircle GmbH\nCX Cards by Surveyapp\nBy: VOC Metrics Limited\nCyberday\nBy: Agendium Ltd\nCyberProof\nBy: CyberProof Inc.\nD&B Optimizer [DEPRECATED]\nBy: Dun & Bradstreet\nd.velop\nBy: d.velop AG\nD7Messaging\nBy: Signtaper Technologies FZCO\nD7SMS\nBy: Signtaper Technologies FZCO\nDad Jokes (Independent Publisher)\nBy: Troy Taylor\nDadJokesIO (Independent Publisher)\nBy: Troy Taylor\nDaffy (Independent Publisher)\nBy: Troy Taylor\nDailyMed (Independent Publisher)\nBy: Troy Taylor\nDandelion (Independent Publisher)\nBy: Troy Taylor\nData Activator\nBy: Microsoft, Data Activator\nData Activator Early Access\nBy: Microsoft\nData8 Data Enrichment\nBy: Data8 Limited\nDatablend\nBy: DataBlend\nDatabook C4S\nBy: Databook Labs, Inc.\nDatabox (Independent Publisher)\nBy: Troy Taylor\nDatabricks\nBy: Databricks Inc.\nDataMotion\nBy: DataMotion, Inc.\nDatamuse (Independent Publisher)\nBy: Troy Taylor\nDataScope Forms\nBy: DataScope\nDB2\nBy: Microsoft\nDBF2XML\nBy: SMART\nDe Lijn (Independent Publisher)\nBy: Lenard Schockaert\nDecentraland (Independent Publisher)\nBy: Roy Paar\nDeck of Cards (Independent Publisher)\nBy: Troy Taylor\nDeepgram (Independent Publisher)\nBy: Troy Taylor\nDeepL\nBy: DeepL\nDeepLIP (Independent Publisher)\nBy: Michal Romiszewski\nDeepSign\nBy: DeepCloud\nDefault title\nBy: WordLift\nDefender for Cloud Apps\nBy: Microsoft\nDeprecated Integration [DEPRECATED]\nBy: Maximizer\nDerdack SIGNL4\nBy: Derdack GmbH\nDesk365\nBy: Kani Technologies Inc\nDeskDirector\nBy: DeskDirector\nDesktop flows\nBy: Microsoft\nDexcom (Independent Publisher)\nBy: FlowJoe\nDHL Tracking (DEPRECATED) (Independent Publisher) [DEPRECATED]\nBy: Rapid Circle\nDiceBear (Independent Publisher)\nBy: Troy Taylor\nDid You Mean This (Independent Publisher)\nBy: Troy Taylor\nDiffchecker\nBy: FÃ¶rdÅs AndrÃ¡s\nDigiDates (Independent Publisher)\nBy: Troy Taylor\nDigiLEAN Connect\nBy: DigiLEAN AS\nDigitalHumani (Independent Publisher)\nBy: Troy Taylor\nDime.Scheduler\nBy: Dime Software\nDime.Scheduler (on-prem)\nBy: Dime Software\nDiscord (Independent Publisher)\nBy: Daniel Laskewitz | Microsoft & Michael Guzowski | Developico\nDisqus\nBy: Microsoft\nDo Not Call Reported Calls (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nDoc To PDF\nBy: Spot Solutions, Inc\nDocFusion365 â SP\nBy: Assimilated Information Systems\nDocJuris\nBy: DocJuris\nDocparser\nBy: Docparser\nDocugami\nBy: Docugami.com\nDocuGenerate\nBy: DocuGenerate\nDocument AI Konfuzio\nBy: Helm & Nagel GmbH\nDocument Drafter\nBy: Document Drafter\nDocument Merge\nBy: CIRRUS SOFT LTD\nDocumentero\nBy: Documentero\nDocumentsCorePack\nBy: mscrm-addons.com ( PTM EDV Systeme )\nDocuMotor\nBy: Omnidocs\nDocurain\nBy: root42 Inc.\nDocusign\nBy: DocuSign, Inc.\nDocusign Demo\nBy: DocuSign, Inc.\nDocuWare\nBy: DocuWare\nDokobit Portal\nBy: Dokobit\nDokobit Universal API\nBy: Dokobit\nDomainTools Iris Enrich\nBy: DomainTools, LLC\nDomainTools Iris Investigate\nBy: DomainTools, LLC\nDoppler Farhan Latif (Independent Publisher)\nBy: Farhan Latif\ndox42\nBy: dox42\nDPIRD Radar - West Australia (Independent Publisher)\nBy: Paul Culmsee\nDPIRD Science - West Australia (Independent Publisher)\nBy: Paul Culmsee\nDPIRD Weather - West Australia (Independent Publisher)\nBy: Paul Culmsee\nDQ on Demand\nBy: DQ Global\nDraup\nBy: Draup\nDraup MCP Server\nBy: Draup\nDropbox\nBy: Microsoft\nDuration Calculator (Independent Publisher)\nBy: Troy Taylor\nDVLA Vehicle Enquiry Service (Independent Publisher)\nBy: Gulshan Khurana and Pranav Khurana\nDynamic Signal\nBy: Dynamic Signal\nDynamicDocs (Independent Publisher)\nBy: Troy Taylor\nDynamics 365 (deprecated)\nBy: Microsoft\nDynamics 365 Business Central\nBy: Microsoft\nDynamics 365 Business Central (on-premises)\nBy: Microsoft\nDynamics 365 Commerce - Ratings and Reviews\nBy: Microsoft\nDynamics 365 Commerce Merchandising [DEPRECATED]\nBy: Microsoft\nDynamics 365 Customer Insights\nBy: Microsoft\nDynamics 365 Customer Voice\nBy: Microsoft\nDynamics 365 Fraud Protection\nBy: Microsoft\nDynamics 365 Sales Insights\nBy: Microsoft\nDynamics NAV\nBy: Microsoft\nDynamics Translation Service\nBy: Microsoft Corporation\nDynatrace\nBy: Dynatrace\nEasy Redmine\nBy: Microsoft\nEasyPost Mail\nBy: Bing Technologies\nEasyship (Independent Publisher)\nBy: Troy Taylor\nEasyvista Self Help\nBy: Easyvista\nEasyVista Service Manager\nBy: Easyvista\neBay (Independent Publisher)\nBy: Artesian Software Technologies LLP\nEBMS\nBy: Eagle Business Software\neCFR (Independent Publisher)\nBy: Dan Romano\nEcologi (Independent Publisher)\nBy: Troy Taylor\nedatalia Sign Online (Independent Publisher)\nBy: Victor Sanchez Olaya\nEden AI\nBy: Eden AI\nEdgility\nBy: Edgility\nEdifact\nBy: Microsoft\nEduframe\nBy: Microsoft\nEgain\nBy: eGain Corporation\nEgnyte\nBy: Egnyte\nE-goi\nBy: E-goi\nEigen Events\nBy: Eigen Ltd\nElastic Forms\nBy: Workai\nElasticOCR [DEPRECATED]\nBy: ElasticOCR\nElead Product Reference Data\nBy: CDK Global\nElead Sales Customers\nBy: CDK Global\nElead Sales Opportunities\nBy: CDK Global\nElectricity Maps (Independent Publisher)\nBy: Vitalii Sorokin\nElfsquad Data\nBy: Elfsquad B.V.\nElfsquad Product Configurator\nBy: Elfsquad\nEmail Domain Checker\nBy: Mightora.io\nEmail Veritas â URL Checker\nBy: eVeritas\nemfluence Marketing Platform\nBy: emfluence, llc\nEmigo\nBy: Sagra Technology Sp. z o.o.\nEmojiHub (Independent Publisher)\nBy: Troy Taylor\nEMT ATLAS AIMS\nBy: Enable My Team\nEnadoc\nBy: Enadoc Pte Ltd\nEncodian - Barcode\nBy: Encodian\nEncodian - Convert\nBy: Encodian\nEncodian - Excel\nBy: Encodian\nEncodian - General\nBy: Encodian\nEncodian - Image\nBy: Encodian\nEncodian - PDF\nBy: Encodian\nEncodian - PowerPoint\nBy: Encodian\nEncodian - Utilities\nBy: Encodian\nEncodian - Word\nBy: Encodian\nEncodian [DEPRECATED]\nBy: Encodian\nEncodian Filer\nBy: Encodian\nEncodian Trigr\nBy: Encodian\nEngagement Cloud\nBy: dotdigital\nEnlyft Insights\nBy: Enlyft.\nEnlyft MCP\nBy: Enlyft.\nEntegrations.io\nBy: entegrations.io inc\nEntersoft\nBy: Entersoft SA\nEnveloop (Independent Publisher)\nBy: Troy Taylor\nEnvoy\nBy: Envoy, Inc.\nEONET by NASA (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nEphesoft Semantik For Invoices\nBy: Ephesoft Inc.\nE-Sign\nBy: E-Sign\nEthereum Blockchain [DEPRECATED]\nBy: Microsoft\nEtsy (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nEvent Hubs\nBy: Microsoft\nEvent Tickets\nBy: The Events Calendar\nEventbrite\nBy: Microsoft\nEvery (Independent Publisher)\nBy: Troy Taylor\nEvocom\nBy: Evocom Informationssysteme GmbH\neWay-CRM\nBy: eWay-CRM\nExact Online Premium [DEPRECATED]\nBy: Exact MKB Software BV\nExact Time & Billing (Independent Publisher)\nBy: Indocs\nExasol\nBy: Exasol AG\nExcel [DEPRECATED]\nBy: Microsoft\nExcel Online (Business)\nBy: Microsoft\nExcel Online (OneDrive)\nBy: Microsoft\nExchange Rate (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nExpensya\nBy: EXPENSYA SA\nExperlogix CPQ\nBy: Experlogix US\nExperlogix Smart Flows\nBy: Experlogix US\nExpiration Reminder\nBy: SkyXoft Technologies, Inc.\nEXPOCAD\nBy: EXPOCAD\nFace API\nBy: Microsoft\nFactSet\nBy: FactSet Research Systems\nFantasy Premier League (Independent Publisher)\nBy: Joe Unwin (FlowJoe)\nFarsight DNSDB\nBy: Farsight Security\nFBI Most Wanted (Independent Publisher)\nBy: Richard Wilson\nFCA (Independent Publisher)\nBy: Gulshan Khurana\nFeathery\nBy: Troy Taylor\nFeathery Forms\nBy: Feathery\nFederal Reserve Economic Data (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nFederal Reserve Markets (Independent Publisher)\nBy: Dan Romano\nFEMA (Independent Publisher)\nBy: Troy Taylor\nFestivo (Independent Publisher)\nBy: Troy Taylor\nFHIRBase\nBy: Microsoft\nFHIRClinical\nBy: Microsoft\nFHIRlink\nBy: Microsoft Cloud for Healthcare\nFieldEquip\nBy: FieldEquip\nFile System\nBy: Microsoft\nFile.io (Independent Publisher)\nBy: Troy Taylor\nFiles.com\nBy: Files.com\nFin & Ops Apps (Dynamics 365)\nBy: Microsoft\nFinalcad One Connect 4.0\nBy: FINALCAD\nFinancial Edge NXT Query [DEPRECATED]\nBy: Blackbaud. Inc\nFinnish BIS (Independent Publisher)\nBy: Timo Pertila\nFinnish Railway Traffic (Independent Publisher)\nBy: Timo PertilÃ¤\nFINRA (Independent Publisher)\nBy: Dan Romano\nFireText\nBy: FireText\nFiscal Data Service (Independent Publisher)\nBy: Dan Romano\nFishWatch (Independent Publisher)\nBy: Fordos Andras\nFitbit (Independent Publisher)\nBy: Ashwin Ganesh Kumar\nFlic\nBy: Microsoft\nFliplet\nBy: Fliplet\nFlotiq headless CMS\nBy: CodeWave LLC\nFlowForma\nBy: FlowForma Limited\nFlowForma V2\nBy: FlowForma Limited\nFocusmate (Independent Publisher)\nBy: Phil Cole\nFORCAM FORCE Bridge\nBy: FORCAM GmbH\nForceManager CRM\nBy: Tritium Software S.L.\nForem (Independent Publisher)\nBy: Daniel Laskewitz\nFormstack Documents\nBy: Formstack LLC\nFormstack Forms\nBy: Formstack LLC\nFraudLabs Pro (Independent Publisher)\nBy: Troy Taylor\nFreeAgent (Independent Publisher)\nBy: Nirmal Kumar\nFreshBooks\nBy: Microsoft\nFreshdesk\nBy: Microsoft\nFreshservice\nBy: Microsoft\nFTP\nBy: Microsoft\nFun Translations (Independent Publisher)\nBy: Troy Taylor\nFuseLagNotam1.1 (Independent Publisher)\nBy: Falana Kidd\nFuxsy-ADSKFusionManagePaid (Independent Publisher)\nBy: Fuxsy.eu\nGenerative actions\nBy: Microsoft\nGeoDB (Independent Publisher)\nBy: Troy Taylor\nGerman Federal Parliament (Independent Publisher)\nBy: Dan Romano\nGetAccept\nBy: GetAccept, Inc.\nGetMyInvoices\nBy: GetMyInvoices\nGieni TS Server MCP\nBy: Orderfox-Gieni\nGIPHY (Independent Publisher)\nBy: Priyanshu Srivastav\nGIS Cloud\nBy: HandyGeo Solutions\nGitHub\nBy: Microsoft\nGithub Data (Independent Publisher)\nBy: Nathalie-Leenders\nGitHub Gists (Independent Publisher)\nBy: Troy Taylor\nGitHub Utils (Independent Publisher)\nBy: Daniel Laskewitz\nGitLab (Independent Publisher)\nBy: Roy Paar\nGivebutter (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nGlaass Pro\nBy: Glaass Pty Ltd\nGlobal Exchange Rates\nBy: MEMENTO SRL\nGlobalGiving Project (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nGmail\nBy: Microsoft\nGMO Sign\nBy: GMO GlobalSign Holdings K.K.\nGoFileRoom\nBy: Thomson Reuters\nGoogle BigQuery - Dev (Independent Publisher)\nBy: Ashwani Kumar\nGoogle Books (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nGoogle Calendar\nBy: Microsoft\nGoogle Cloud Translation (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nGoogle Contacts\nBy: Microsoft\nGoogle Drive\nBy: Microsoft\nGoogle Gemini (Independent Publisher)\nBy: Priyaranjan KS , Vidya Sagar Alti [Tata Consultancy Services]\nGoogle PaLM (Independent Publisher)\nBy: Priyaranjan KS , Vidya Sagar Alti [Tata Consultancy Services]\nGoogle Photos (Independent Publisher)\nBy: Julia Muiruri\nGoogle Sheets\nBy: Microsoft\nGoogle Tasks\nBy: Microsoft\nGoQR (Independent Publisher)\nBy: Rui Santos\nGoToMeeting\nBy: LogMeIn Inc\nGoToTraining\nBy: Microsoft\nGoToWebinar\nBy: Microsoft\nGovee (Independent Publisher)\nBy: Richard Wilson\nGratavid\nBy: Gratavid\nGravity Forms by reenhanced\nBy: Reenhanced LLC\nGravity Forms Professional\nBy: Reenhanced, LLC\nGroopit\nBy: Groopit\nGroupMgr\nBy: GroupMgr\nGSA Analytics (Independent Publisher)\nBy: Richard Wilson\nGSA Per Diem (Independent Publisher)\nBy: Richard Wilson\nGSA Public Comment (Independent Publisher)\nBy: Dan Romano\nGSA Site Scanning (Independent Publisher)\nBy: Richard Wilson\nHarness PDFx\nBy: Harness Data Intelligence Ltd.\nHarvest\nBy: Microsoft\nHash Generator (Independent Publisher)\nBy: Troy Taylor, Jeffrey Irwin, Ramiro Melgoza\nHashify (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nHashtag API (Independent Publisher)\nBy: Troy Taylor\nHave I Been Pwned (Independent Publisher)\nBy: Troy Taylor\nHelloSign\nBy: Microsoft\nHHS Media Services (Independent Publisher)\nBy: Troy Taylor\nHighGear Workflow\nBy: HighGear Software, Inc.\nHighQ\nBy: Thomson Reuters Incorporated\nHighspot\nBy: Highspot\nHipChat\nBy: Microsoft\nHitHorizons\nBy: FinStat, s. r. o.\nHive CPQ Product Configurator\nBy: NimbleOps NV\nHolopin\nBy: Troy Taylor\nHolopin (Independent Publisher)\nBy: troystaylor\nHoneywell Forge\nBy: Honeywell International\nHost.io (Independent Publisher)\nBy: Troy Taylor\nHotProfile\nBy: Hammock corporation\nHoudin.io\nBy: Houdin.io\nHouseRater QA\nBy: HouseRater, LLC\nHR Cloud\nBy: HR Cloud\nHrFlow.ai\nBy: HrFlow.ai\nHTML to PDF by Pascalcase\nBy: Pascalcase\nhttp garden (Independent Publisher)\nBy: Troy Taylor\nHTTP With Microsoft Entra ID\nBy: Microsoft\nHTTP with Microsoft Entra ID (preauthorized)\nBy: Microsoft\nHubSpot CMS (Independent Publisher)\nBy: Hitachi Solutions\nHubSpot CMS V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot Conversations V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot CRM (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nHubSpot CRM V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot Engagements V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot Files V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot Marketing (Independent Publisher)\nBy: Hitachi Solutions\nHubSpot Marketing V2 (Independent Publisher)\nBy: Troy Taylor\nHubSpot Settings V2 (Independent Publisher)\nBy: Troy Taylor\nHuddle\nBy: Huddle\nHuddle for US Gov & Healthcare\nBy: Huddle\nHuddo Boards\nBy: Huddo by ISW Development Pty Ltd\nHUE Datagate\nBy: Works Applications Co., Ltd.\nHugging Face (Independent Publisher)\nBy: Troy Taylor\nHume (Independent Publisher)\nBy: Troy Taylor\nHunter (Independent Publisher)\nBy: Troy Taylor\nHVI Vehicle Inspection V1.2\nBy: JRS Innovation/Ram Upadhayay\nHYAS Insight\nBy: HYAS Infosec\nIA-Connect Dynamic Code\nBy: Ultima Business\nIA-Connect Java\nBy: Ultima Labs\nIA-Connect JML\nBy: Ultima Business\nIA-Connect Mainframe\nBy: Ultima Labs\nIA-Connect SAP GUI\nBy: Ultima Business\nIA-Connect Session\nBy: Ultima Business\nIA-Connect to Microsoft Office\nBy: Ultima Business\nIA-Connect UI\nBy: Ultima Business\nIA-Connect Web Browser\nBy: Ultima Business\niAuditor\nBy: SafetyCulture Pty Ltd\nIBM 3270\nBy: Microsoft\nIBM Watson Assistant (Independent Publisher)\nBy: Lucas Titus\nIBM Watson Text to Speech (Independent Publisher)\nBy: Lucas Titus\nicanhazdadjoke (Independent Publisher)\nBy: Daniel Laskewitz\nIce and Fire (Game of Thrones) (Independent Publisher)\nBy: Troy Taylor\nIcon Horse (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nID Analyzer\nBy: Evith Techology\nIdeanote\nBy: Ideanote ApS\niFacto Proof Of Delivery\nBy: iFacto Business Solutions NV\niLovePDF\nBy: i Love PDF\niLoveSign\nBy: i Love PDF\niManage Data Marts\nBy: iManage Power Platform Connector\niManage Insight Plus\nBy: iManage LLC\niManage Tracker\nBy: iManage LLC\niManage Work\nBy: iManage Power Platform Connector\niManage Work for Admins\nBy: iManage Power Platform Connector\niMIS\nBy: Computer System Innovations, Inc.\nImpexium\nBy: Impexium Corporation\nImpower ERP\nBy: Impower GmbH\nImprezian360-CRM\nBy: KnowTia Concepts Corporation\nIN-D Aadhaar Number Masking\nBy: IN-D by Intain\nIN-D Face Match\nBy: IN-D by Intain\nIN-D Insurance (ICD10 & CPT)\nBy: IN-D by Intain\nIN-D Invoice Data Capture\nBy: IN-D AI\nIN-D KYC India\nBy: IN-D by Intain\nIN-D Payables\nBy: IN-D by Intain\nIndustrial App Store\nBy: Intelligent Plant\nInEight\nBy: InEight\nInfluenza and Covid-19 (Independent Publisher)\nBy: Kevin Comba Gatimu, Denis Wachira Kathuri\nInfobip\nBy: Infobip\nInfoQuery\nBy: InfoQuery LLC\nInformix\nBy: Microsoft\nInfoShare\nBy: Kendox AG\nInfoVetted\nBy: InfoVetted\nInfura Ethereum (Independent Publisher)\nBy: Sebastian Zolg\nInfusionsoft\nBy: Microsoft\nInLoox\nBy: InLoox\nInoreader\nBy: Microsoft\ninQuba Journey\nBy: Inquba Customer Intelligence Pty Ltd\nInsightly\nBy: Microsoft\nInstagram Basic Display (Independent Publisher)\nBy: Reshmee Auckloo\nInstapaper\nBy: Microsoft\nInstatus (Independent Publisher)\nBy: Troy Taylor\nIntegrable PDF\nBy: Integrable, LLC\nIntegration Toolbox [DEPRECATED]\nBy: LF Software Engineering\nIntelix IOC Analysis MCP\nBy: Sophos Ltd.\nintelliHR\nBy: intelliHR\nIntentional Data Sources\nBy: Microsoft\nInterAction\nBy: LexisNexis Legal and Professional\nIntercom\nBy: Microsoft\niObeya\nBy: iObeya\nIP2LOCATION (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nIP2WHOIS (Independent Publisher)\nBy: Fordos Andras\nIPQS Fraud and Risk Scoring\nBy: IPQualityScore\nIQAir (Independent Publisher)\nBy: Fordos Andras\nISOPlanner\nBy: REDLAB\nITautomate\nBy: ITautomate LTD\nITGlue (Independent Publisher)\nBy: Nirmal Kumar\nJasper (Independent Publisher)\nBy: Troy Taylor\nJBHunt\nBy: Microsoft\nJedox OData Hub\nBy: Jedox\nJG Integrations\nBy: JG Software Solutions Limited\nJira\nBy: Microsoft\nJIRA Search (Independent Publisher)\nBy: Paul Culmsee\nJotForm\nBy: JotForm Inc.\nJotform Enterprise\nBy: JotForm Admin\nJservice (Independent Publisher) [DEPRECATED]\nBy: Troy Taylor\nJungleMail 365\nBy: EnovaPoint, UAB\nJupyrest\nBy: Microsoft\nK2 Workflow\nBy: K2\nKagi (Independent Publisher)\nBy: Troy Taylor\nKanban Tool\nBy: Shore Labs\nKhalibre LMS Test\nBy: Khalibre\nkintone\nBy: Kintone\nKnowledgeLake\nBy: KnowledgeLake\nKnowledgeone RecFind6\nBy: Knowledgeone Corporation\nKORTO V2\nBy: Korto\nKroki\nBy: Troy Taylor\nKrozu PM (Independent Publisher)\nBy: Osazee Odigie\nKyndryl mainframe\nBy: Ryan Treacy\nLang.ai\nBy: Lang.ai\nLanguage - Question Answering\nBy: Microsot\nLanguageTool (Independent Publisher) (deprecated) [DEPRECATED]\nBy: Fordos Andras\nLansweeper App For Sentinel\nBy: Lansweeper\nLasso X\nBy: Lasso X A/S\nLatinShare Documents\nBy: LatinShare\nLatinShare SHP Management\nBy: LatinShare\nLatinShare SHP Permissions\nBy: LatinShare\nLaunch Library 2 (Independent Publisher)\nBy: Troy Taylor\nLawlift\nBy: Lawlift GmbH\nLawVu\nBy: LAWVU LIMITED\nLCP - iCordis\nBy: LCP nv\nLeadDesk\nBy: LeadDesk\nLeanKit\nBy: Microsoft\nLeap (Independent Publisher)\nBy: Chandra Sekhar Malla, Troy Taylor\nLeave Dates (Independent Publisher)\nBy: Tiago Ramos (novalogica)\nLegalBot AI Tools\nBy: LegalBot.io\nLegalesign\nBy: Legalesign\nLegiScan (Independent Publisher)\nBy: krautrocker\nLetterdrop (Independent Publisher)\nBy: Troy Taylor\nLettria (Independent Publisher)\nBy: Troy Taylor\nLettria GDPR Compliance\nBy: lettria\nLex Power Sign\nBy: Lex Persona\nLexica (Independent Publisher)\nBy: Troy Taylor\nLexoffice (Independent Publisher)\nBy: LowCodeInvestigator\nLibrary of Congress\nBy: Troy Taylor\nLibreBor (Independent Publisher)\nBy: Mario Trueba and Marco Amoedo\nLIFX\nBy: Microsoft\nLine Message (Independent Publisher)\nBy: Felaray Ho\nLINK Mobility\nBy: LINK Mobility\nLinkedIn [DEPRECATED]\nBy: Microsoft\nLinkedIn V2\nBy: Microsoft\nLit Ipsum (Independent Publisher)\nBy: Troy Taylor\nLitera Search\nBy: Litera\nLiveChat\nBy: Microsoft\nLiveTiles Bots\nBy: LiveTiles Pty Ltd.\nLMS365\nBy: Zensai International Aps\nLnk.Bio\nBy: Lnk.Bio\nLoginLlama\nBy: Troy Taylor\nLoopio\nBy: Loopio\nLoopio-EU\nBy: Loopio\nLoopio-Int01\nBy: Loopio\nLoripsum (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nLUIS\nBy: Microsoft\nLuware Nimbus\nBy: Luware\nM365 Search (Deprecated) [DEPRECATED]\nBy: Microsoft\nMaersk (Independent Publisher)\nBy: Dan Romano\nMail\nBy: Microsoft\nMailboxValidator (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nMailChimp\nBy: Microsoft\nMailform\nBy: Mailform, Inc.\nMailinator\nBy: Troy Taylor\nMailJet (Independent Publisher)\nBy: Clement Olivier\nMailParser\nBy: SureSwift Capital, Inc.\nMaintenance Request - Oxmaint (Independent Publisher)\nBy: JRS Innovation/Ram Upadhayay\nMandrill\nBy: Microsoft\nMap Pro\nBy: Witivio\nMapbox (Independent Publisher)\nBy: Simone Lin\nMarkdown Converter (Independent Publisher)\nBy: troystaylor\nMarketing Content Hub\nBy: Stylelabs\nMarketo MA\nBy: Microsoft Inc.\nMavim-iMprove\nBy: Mavim\nMaximizer CRM\nBy: Maximizer\nMCP Hive.T Integration\nBy: Tesselate\nMeaningCloud (Independent Publisher)\nBy: Clement Olivier\nMedallia\nBy: Medallia, Inc.\nMediastack (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nMedium\nBy: Microsoft\nMeekou Share (Independent Publisher)\nBy: Meekou\nMeetingRoomMap\nBy: TNS Holding ApS\nMeisterplan\nBy: itdesign GmbH\nMeme (Independent Publisher)\nBy: Troy Taylor\nMensagia\nBy: Mensagia\nMensagia (Independent Publisher)\nBy: Sistemas Informaticos ICON, S.L.\nMessageBird SMS (Independent Publisher)\nBy: Troy Taylor\nMetatask\nBy: Build My Team LLC\nMichael Scott Quotes (Independent Publisher) [DEPRECATED]\nBy: Troy Taylor\nMicrosoft 365 compliance\nBy: Microsoft\nMicrosoft 365 message center\nBy: Microsoft\nMicrosoft 365 Self-Help\nBy: Microsoft\nMicrosoft Acronyms\nBy: Troy Taylor\nMicrosoft Bookings\nBy: Microsoft Corporation\nMicrosoft Copilot Studio\nBy: Microsoft\nMicrosoft D365CE v9 OnPrem (Independent Publisher)\nBy: Roy Paar\nMicrosoft Dataverse\nBy: Microsoft\nMicrosoft Dataverse [DEPRECATED]\nBy: Microsoft\nMicrosoft Defender ATP\nBy: Microsoft\nMicrosoft Defender for Cloud Alert\nBy: Microsoft\nMicrosoft Defender for Cloud Recommendation\nBy: Microsoft\nMicrosoft Defender for Cloud Regulatory Compliance\nBy: Microsoft\nMicrosoft Entra ID\nBy: Microsoft\nMicrosoft Entra ID App Registrations\nBy: Paul Culmsee (Rapid Circle) and Microsoft\nMicrosoft Entra ID Protection\nBy: Microsoft\nMicrosoft Forms\nBy: Microsoft\nMicrosoft Graph Add Users (Independent Publisher)\nBy: Troy Taylor\nMicrosoft Graph Security (deprecated) [DEPRECATED]\nBy: Microsoft\nMicrosoft Kaizala\nBy: Microsoft\nMicrosoft Learn Catalog (Independent Publisher)\nBy: Sean Kelly\nMicrosoft Learn Docs MCP\nBy: Microsoft\nMicrosoft Loop [DEPRECATED]\nBy: Microsoft\nMicrosoft Partner Center [DEPRECATED]\nBy: Microsoft\nMicrosoft School Data Sync V2\nBy: Microsoft\nMicrosoft Security Copilot\nBy: Microsoft\nMicrosoft Sentinel\nBy: Microsoft\nMicrosoft Sentinel MCP\nBy: Microsoft\nMicrosoft Teams\nBy: Microsoft\nMicrosoft Teams Virtual Events (deprecated) [DEPRECATED]\nBy: Microsoft\nMicrosoft To-Do (Business)\nBy: Microsoft\nMicrosoft To-Do (Consumer)\nBy: Microsoft\nMicrosoft Translator [DEPRECATED]\nBy: Microsoft\nMicrosoft Translator V2\nBy: Microsoft\nMicrosoft Translator V3\nBy: Microsoft Translator\nMime Automation (Independent Publisher)\nBy: Andreas Cieslik\nMiniSoup HTML Parser (Independent Publisher)\nBy: Shogo Shindo\nMintlify (Independent Publisher)\nBy: Troy Taylor\nMintNFT (Independent Publisher)\nBy: Shreyan J D Fernandes\nMiro (Independent Publisher)\nBy: Michal Romiszewski\nMistral (Independent Publisher)\nBy: Troy Taylor\nMitto\nBy: Mitto AG\nMobili Stotele\nBy: Tele2\nMobilyWS\nBy: MobilyWS\nMOBSIM Send SMS\nBy: MOBSIM Comunicacao Mobile SMS\nMockaroo (Independent Publisher)\nBy: Richard Wilson\nMockster\nBy: Mockster\nModuleQ [DEPRECATED]\nBy: ModuleQ, Inc.\nmonday\nBy: Plugin Genie\nmonday.com\nBy: monday.com ltd\nmondaycom (Independent Publisher)\nBy: Woong Choi\nMongoDB\nBy: MongoDB Corp\nMonster API (Independent Publisher)\nBy: Troy Taylor\nMoosend (Independent Publisher)\nBy: Troy Taylor\nMoreApp Forms\nBy: MoreApp International\nMorf\nBy: AFTIA Solutions\nMorningstar\nBy: Morningstar Test\nMorta\nBy: Morta\nMotaWord Translations\nBy: MotaWord\nMotimate\nBy: Motimate AS\nMQ\nBy: Microsoft\nMS Graph Groups and Users\nBy: Jay Jani\nMSN Weather\nBy: Microsoft\nMtarget SMS\nBy: Mtarget SAS\nMuhimbi PDF\nBy: Muhimbi trading as Nutrient\nMURAL\nBy: MURAL\nMy Acclaro\nBy: Acclaro Inc.\nMy Hours\nBy: Spica International\nMySQL\nBy: Microsoft\nmyStrom (Independent Publisher)\nBy: Tomasz Poszytek\nN-able Cloud Commander\nBy: N-Able Technologies Ltd.\nN-able Cloud User Hub\nBy: N-able Cloud User Hub B.V.\nNameAPI (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nNarvar\nBy: Microsoft\nNASA FIRMS (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nNASA Image and Video Library (Independent Publisher)\nBy: Paul Culmsee, Seven Sigma\nNational Park Service (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nNational Weather Service (Independent Publisher)\nBy: Troy Taylor\nNationalize_io (Independent Publisher)\nBy: Tomasz Poszytek\nnBold\nBy: nBold\nNCEI Climate Data (Independent Publisher)\nBy: Troy Taylor\nNederlandse Spoorwegen (Independent Publisher)\nBy: Miguel Verweij\nNEOWs (Independent Publisher)\nBy: Troy Taylor\nNetDocuments\nBy: NetDocuments Software, Inc.\nNetvolution\nBy: Atcom S.A\nNeum (Independent Publisher)\nBy: Troy Taylor\nNew York Times (Independent Publisher)\nBy: Roy Paar\nNewsData.io (Independent Publisher)\nBy: Troy Taylor\nNexmo\nBy: Microsoft\nNextcom\nBy: Nextcom Evolution AS\nNH360 Portfolio Insights\nBy: UMT Software\nNHTSA vPIC (Independent Publisher)\nBy: Troy Taylor\nNifty Gateway (Independent Publisher)\nBy: Roy Paar\nNimflow\nBy: Nimflow LLC\nNintex Workflow\nBy: Nintex USA LLC.\nNIST NVD (Independent Publisher)\nBy: Paul Culmsee\nNitro\nBy: Nitro Software, Inc.\nNitro Sign Enterprise Verified\nBy: Nitro Software Belgium NV\nNodefusion Portal\nBy: Nodefusion d.o.o\nNosco\nBy: Nosco ApS\nNotifications\nBy: Microsoft\nNotiivy Browser Notifications\nBy: Notiivy\nNotion (Independent Publisher)\nBy: Chandra Sekhar & Harshini Varma\nNoxtua AI\nBy: Xayn\nNozbe\nBy: NOZBE SP Z O O\nnps.today\nBy: nps.today\nNREL (Independent Publisher)\nBy: Troy Taylor\nNumlookupAPI (Independent Publisher)\nBy: Troy Taylor\nnunify\nBy: nunify\nNutrient - Convert to PDF\nBy: Muhimbi trading as Nutrient\nNutrient - Extract from PDF\nBy: Muhimbi trading as Nutrient\nNutrient - PDF OCR\nBy: Muhimbi trading as Nutrient\nNutrient - Watermark to PDF\nBy: Muhimbi trading as Nutrient\nNutrient Document Converter\nBy: Muhimbi trading as Nutrient\nNutrient Workflow Automation\nBy: Muhimbi trading as Nutrient\nObjective Connect\nBy: Objective Corporation\nOccuspace\nBy: Occuspace Inc\nOffice 365 Groups\nBy: Microsoft\nOffice 365 Groups Mail\nBy: Microsoft\nOffice 365 Outlook\nBy: Microsoft\nOffice 365 Users\nBy: Microsoft\nOffice 365 Video [DEPRECATED]\nBy: Microsoft\nOK dokument (Independent Publisher)\nBy: Seyfor Slovensko, a.s.\nOMDb (Independent Publisher)\nBy: Aaryan Arora\noncehub\nBy: OnceHub\nOneBlink\nBy: OneBlink\nOneDrive\nBy: Microsoft\nOneDrive for Business\nBy: Microsoft\nOneflow\nBy: Oneflow\nOneNote (Business)\nBy: Microsoft\nOneNote Consumer (Independent Publisher)\nBy: Troy Taylor\nOnePlan\nBy: OnePlan, LLC\nOne-Time Secret (Independent Publisher)\nBy: Aldo Gillone\nOodrive Sign\nBy: Oodrive Sign\nOpen Brewery DB (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nOpen Charge Map (Independent Publisher)\nBy: Troy Taylor\nOpen Experience\nBy: Open Experience GmbH\nOpenAI (Independent Publisher)\nBy: Robin RosengrÃ¼n\nOpenAI Assistants (Independent Publisher)\nBy: Troy Taylor\nOpenAI GPT (Independent Publisher)\nBy: Troy Taylor\nOpenCage Geocoding (Independent Publisher)\nBy: Ahmad Najjar\nOpen-Elevation (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nopenFDA Drug (Independent Publisher)\nBy: Woong Choi\nOpenFEC (Independent Publisher)\nBy: krautrocker\nOpenLegacy IBM I (AS400)\nBy: OpenLegacy Technologies Inc.\nOpenLegacy IBM Mainframe\nBy: OpenLegacy Technologies Inc.\nOpenNEM (Independent Publisher)\nBy: Paul Culmsee\nOpenPLZ (Independent Publisher)\nBy: LowCodeInvestigator\nopenpm (Independent Publisher)\nBy: Troy Taylor\nOpenQR (Independent Publisher)\nBy: Troy Taylor\nOpenRouter (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nOpenSanctions (Independent Publisher)\nBy: krautrocker\nOpenText Core Share\nBy: One Fox\nOpenText Documentum\nBy: One Fox\nOpenText eDOCS\nBy: One Fox\nOpenText Extended ECM\nBy: One Fox\nOpenTrivaDatabase (Independent Publisher)\nBy: Kiveshan Naidoo\nOptiAPI\nBy: Busk\nOQSHA\nBy: Osmosys Software Solutions UK Limited\nOracle Database\nBy: Microsoft\nORB Intelligence (Independent Publisher)\nBy: Aaryan Arora, Ankita Singh\nOrbusInfinity\nBy: Orbus Software\nOrdnance Survey Places\nBy: Ordnance Survey\nOriginality.AI (Independent Publisher)\nBy: Osazee Odigie\nOtto.bot\nBy: Otto.bot, LLC\nOutlook Tasks [DEPRECATED]\nBy: Microsoft\nOutlook.com\nBy: Microsoft\nOutreach Insights\nBy: Outreach\nOwlbot (Independent Publisher)\nBy: Troy Taylor\nPagePixels Screenshots\nBy: PagePixels: Screenshots\nPagerDuty\nBy: Microsoft\nPantry (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nPanviva\nBy: Panviva\nPappers (Independent Publisher)\nBy: Troy Taylor\nParishSoft Family Suite\nBy: Ministry Brands ParishSOFT\nParserr\nBy: Parserr LLC\nParseur\nBy: Parseur\nPartner Center Events\nBy: Microsoft\nPartner Center Referrals\nBy: Microsoft Corporation\nPartnerLinq\nBy: Visionet Systems Inc.\nPassage by 1Password - Auth (Independent Publisher)\nBy: Troy Taylor\nPassage by 1Password - Manage (Independent Publisher)\nBy: Troy Taylor\nPaylocity\nBy: Paylocity\nPaySpace (Independent Publisher)\nBy: Mint Management Technologies\nPDF Blocks\nBy: Integrable, LLC\nPDF Tools\nBy: ConvertAPI\nPDF4me\nBy: Ynoox GmbH\nPDF4me AI\nBy: Ynoox GmbH\nPDF4me Connect\nBy: Ynoox GmbH\nPDF4me Excel\nBy: Ynoox GmbH\nPDF4me SwissQR\nBy: Ynoox GmbH\nPDF4me Word\nBy: Ynoox GmbH\nPDFco\nBy: PDF.co\nPDFcross\nBy: PotCross GK.\nPdfless\nBy: Synapsium\nPeakboard\nBy: Peakboard GmbH\nPeltarion AI\nBy: Peltarion\nPerfect Wiki\nBy: OOO RD17\nPerplexity AI (Independent Publisher)\nBy: Troy Taylor\nPersonr\nBy: Microsoft\nPexels (Independent Publisher)\nBy: That API Guy\nPhilips HUE (Independent Publisher)\nBy: Tomasz Poszytek\nPilot Things\nBy: Pilot Things\nPinecone\nBy: Troy Taylor\nPinterest\nBy: Microsoft\nPipedrive\nBy: Microsoft\nPipeliner CRM\nBy: Pipelinersales Corporation\nPIPware KPIs\nBy: PIPware Solutions\nPitney Bowes Data Validation [DEPRECATED]\nBy: Not Available\nPitney Bowes Tax Calculator [DEPRECATED]\nBy: Not Available\nPivotal Tracker\nBy: Microsoft\nPixel Encounter (Independent Publisher)\nBy: Fordos Andras\nPixela (Independent Publisher)\nBy: Troy Taylor\nPixelMe\nBy: Troy Taylor\nPKIsigning\nBy: SBRS B.V.\nPlacedog (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nPlanful\nBy: Planful\nPlanner\nBy: Microsoft\nPling\nBy: Fellowmind Denmark\nPlivo\nBy: Plivo Inc\nPlumsail Actions\nBy: Plumsail\nPlumsail Documents\nBy: Plumsail\nPlumsail Forms\nBy: Plumsail Inc.\nPlumsail HelpDesk\nBy: Plumsail Inc.\nPoka\nBy: Poka Inc\nPokeAPI Core (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nPokeAPI World (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nPolaris PSA\nBy: Replicon Inc\nPoliteMail\nBy: PoliteMail Software\nPolygon (Independent Publisher)\nBy: Itransition Group Ltd\nPortfolio and Roadmap\nBy: Microsoft\nPostgreSQL\nBy: Microsoft\nPostman (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nPowell Teams\nBy: Powell Software\nPower Apps for Admins\nBy: Microsoft\nPower Apps for Makers\nBy: Microsoft\nPower Apps Notification\nBy: Microsoft\nPower Apps Notification V2\nBy: Microsoft\nPower Assist\nBy: Elevate Digital\nPower Automate for Admins\nBy: Microsoft\nPower Automate Management\nBy: Microsoft\nPower BI\nBy: Microsoft\nPower Form 7\nBy: Reenhanced LLC\nPower Platform for Admins\nBy: Microsoft\nPower Platform for Admins V2\nBy: Microsoft\nPower Query Dataflows\nBy: Microsoft\nPower Textor\nBy: Imperium Dynamics\nPower Virtual Agents\nBy: Microsoft\nPPM Express\nBy: PPM Express Corporation\nPreserve365\nBy: Preservica\nPrexView (Independent Publisher)\nBy: Troy Taylor\nPriority Matrix\nBy: Appfluence Inc\nPriority Matrix HIPAA\nBy: Appfluence Inc\nPriva\nBy: Microsoft, Purview Privacy\nProcess Mining\nBy: Microsoft\nProcess Street\nBy: Process Street\nProfisee\nBy: Profisee\nProgressus Advanced Projects\nBy: Plumbline Consulting\nProject Online\nBy: Microsoft\nProjectPlace\nBy: Planview inc.\nProjectum Present It\nBy: Projectum\nProjectWise Design Integration\nBy: Bentley Systems, Incorporated\nProjectwise Share [DEPRECATED]\nBy: Bently Systems, Inc.\nProPublica Campaign Finance (Independent Publisher)\nBy: Troy Taylor\nProPublica Congress (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nProPublica Nonprofit Explorer (Independent Publisher)\nBy: Troy Taylor\nPROS AI\nBy: PROS Inc.\nPublic 360\nBy: Tietoevry Norway\nPUG Gamified Engagement\nBy: Pug Interactive Inc\nPure Leads\nBy: Pure Digital Pte Ltd\nPushcut\nBy: Pushcut\nPushover (Independent Publisher)\nBy: Glen Hutson\nQdrant (Independent Publisher)\nBy: Anush\nQnA Maker\nBy: Microsoft\nQPP NextGen\nBy: Quark Software Inc.\nQuickbase (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nQuickBooks Time (Independent Publisher)\nBy: Artesian Software Technologies LLP\nQuickChart (Independent Publisher)\nBy: Troy Taylor\nr/SpaceX (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nRainbird\nBy: Rainbird Technologies ltd\nRamQuest Actions\nBy: Ramquest Software, Inc\nRamQuest Events\nBy: RamQuest Software, Inc\nRAPID Platform\nBy: RAPID Platform\nRarible (Independent Publisher)\nBy: Roy Paar\nReachability (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nReadwise (Independent Publisher)\nBy: Troy Taylor\nRealFaviconGenerator (Independent Publisher)\nBy: Troy Taylor\nRebrandly (Independent Publisher)\nBy: That API Guy\nRebrickable (Independent Publisher)\nBy: Troy Taylor\nReceptful\nBy: Los Trigos, Inc\nRecorded Future [DEPRECATED]\nBy: Recorded Future\nRecorded Future Identity\nBy: Recorded Future\nRecorded Future Sandbox\nBy: Recorded Future\nRecorded Future V2\nBy: Recorded Future\nRedmine\nBy: Microsoft\nRedque\nBy: Redque s.r.o.\nReflect\nBy: Troy Taylor\nRefuge Restrooms (Independent Publisher)\nBy: Troy Taylor\nRegEx Matching (Independent Publisher) [DEPRECATED]\nBy: Mitanshu Garg\nRegexFlow ExecutePython\nBy: Epicycle\nRegexFlow Regular Expression\nBy: Epicycle\nRegoLink for Clarity PPM\nBy: Rego Consulting Corporation\nReliefWeb (Independent Publisher)\nBy: Troy Taylor\nRencore Code\nBy: Rencore GmbH\nRencore Governance\nBy: Rencore GmbH\nRepfabric\nBy: Repfbaric\nRepfabric Job Loader\nBy: Repfabric LLC\nRepfabric Lead Loader\nBy: Repfabric LLC\nReplicate (Independent Publisher)\nBy: Troy Taylor\nReplicon\nBy: Replicon Inc\nRequestor\nBy: Requestor\nResco Cloud\nBy: Resco\nResco Reports\nBy: Resco\nRescueGroups (Independent Publisher)\nBy: Troy Taylor\nResend (Independent Publisher)\nBy: Troy Taylor\nREST Countries (Independent Publisher)\nBy: Siddharth Vaghasia\nRetarus SMS\nBy: retarus GmbH\nRev AI (Independent Publisher)\nBy: Troy Taylor\nRevelation helpdesk\nBy: Yellowfish Software\nReversingLabs A1000\nBy: ReversingLabs\nReversingLabs TitaniumCloud\nBy: ReversingLabs\nRevue (Independent Publisher)\nBy: Daniel Laskewitz\nRijksmuseum (Independent Publisher)\nBy: Ashwin Ganesh Kumar\nRijksoverheid (Independent Publisher)\nBy: Dennis Goedegebuure\nRiskIQ\nBy: Microsoft\nRiskIQ Digital Footprint\nBy: RiskIQ\nRiskIQ Illuminate\nBy: RiskIQ\nRobohash (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nRobolytix\nBy: Robolytix\nRobots for Power BI\nBy: DevScope S.A.\nRon Swanson Quotes (Independent Publisher)\nBy: Troy Taylor\nRowShare\nBy: ROWSHARE\nRSS\nBy: Microsoft\nSalesforce\nBy: Microsoft\nSAP\nBy: Microsoft\nSAP ERP\nBy: Microsoft\nSAP OData\nBy: Microsoft\nSapling.ai (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nSAS Decisioning\nBy: SAS Institute, Inc.\nScanCloud\nBy: Scancloud\nSchiphol Airport (Independent Publisher)\nBy: Michel Gueli\nSchoolDigger (Independent Publisher)\nBy: Troy Taylor\nScrapingBee (Independent Publisher)\nBy: Troy Taylor\nScreenshot One (Independent Publisher)\nBy: Troy Taylor\nScrive eSign\nBy: Scrive\nScryfall (Independent Publisher)\nBy: Troy Taylor\nSearchAPI - Google Search (Independent Publisher)\nBy: Troy Taylor\nSECIB\nBy: SECIB\nSecret Server\nBy: Delinea, Inc.\nSecure Code Warrior (Independent Publisher)\nBy: Hitachi Solutions\nSeeBotRun - Link\nBy: SeeBotRun\nSeekTable\nBy: SeekTable.com\nSeismic\nBy: Seismic Software, Inc.\nSeismic Configuration\nBy: Seismic\nSeismic Content Discovery\nBy: Seismic\nSeismic Engagement\nBy: Seismic\nSeismic for Copilot for Sales\nBy: Seismic Software\nSeismic Library\nBy: Seismic\nSeismic Livedoc\nBy: Seismic\nSeismic Planner\nBy: Seismic\nSeismic Programs\nBy: Seismic Software\nSeismic Workspace\nBy: Seismic\nSendFox (Independent Publisher)\nBy: Troy Taylor\nSendGrid\nBy: Microsoft\nSendmode\nBy: SendMode\nServerless360 BAM & Tracking\nBy: Kovai Limited\nService Bus\nBy: Microsoft\nService Objects\nBy: Service Objects\nServiceDesk Plus Cloud\nBy: ManageEngine (A division of Zoho Corporation)\nServiceNow\nBy: Microsoft\nSerwerSMS\nBy: SerwerSMS\nSessionize (Independent Publisher)\nBy: Nanddeep Nachan, Smita Nachan\nSFTP - SSH\nBy: Microsoft\nSFTP [DEPRECATED]\nBy: Microsoft\nShadify (Independent Publisher)\nBy: Troy Taylor\nShare-Effect\nBy: ShareEffect\nSharePoint\nBy: Microsoft\nShields.io (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nShifts for Microsoft Teams\nBy: Microsoft\nShipStation IP (Independent Publisher)\nBy: Kristian Matthews\nShop (Independent Publisher)\nBy: Microsoft\nShopify (Independent Publisher)\nBy: Ray Bennett (MSFT)\nShopranos\nBy: SoftOne Technologies S.A\nShort URL\nBy: APPS 365 LTD\nShortySMS (Independent Publisher)\nBy: Troy Taylor\nShowcase Workshop\nBy: Showcase Software Ltd\nShowpad eOS\nBy: Showpad\nSHRTCODE (Independent Publisher)\nBy: Chandra Sekhar Malla\nSigma Conso CR\nBy: Sigma Conso\nSignatureAPI\nBy: SignatureAPI\nSignhost\nBy: Signhost\nSigni.com\nBy: NETWORG\nSigningHub\nBy: Ascertia\nSIGNL4 - Mobile Alerting\nBy: Derdack\nSignNow\nBy: DaDaDocs\nSignNow EU\nBy: DaDaDocs\nSignRequest\nBy: SignRequest B.V.\nSignUpGenius (Independent Publisher)\nBy: Troy Taylor\nSimple EDI\nBy: Weavo Liquid Loom\nSimpleSurvey\nBy: SimpleSurvey\nSinch\nBy: Sinch Sweden AB\nSirva Relocating Employee\nBy: Sirva Relocation\nSkribble Sign\nBy: busitec GmbH\nSkype for Business Online [DEPRECATED]\nBy: Microsoft\nSkyPoint Cloud\nBy: SkyPoint Cloud\nSlack\nBy: Microsoft\nSlascone\nBy: SLASCONE GmbH\nsmapOne\nBy: smapOne AG\nSmarp\nBy: Smarp\nSmartCOMM DocGen\nBy: Smart Communications\nSmartDialog\nBy: Arena Interactive Oy\nSmarter Drafter\nBy: Tensis Group\nSmartsheet\nBy: Microsoft\nSmileBack\nBy: ConnectWise SmileBack\nSMS Wireless Services (Independent Publisher)\nBy: ViaData\nsms77io\nBy: sms77 e.K.\nSMSAPI\nBy: LINK Mobility Poland\nSMSLink\nBy: ASTINVEST COM SRL (SMSLink)\nSMTP\nBy: Microsoft\nSnowflake\nBy: Snowflake\nSociabble\nBy: Sociabble\nSocialinsider\nBy: Socialinsider\nSoft1\nBy: SoftOne Technologies S.A\nSoftone Web CRM\nBy: Softone Technologies\nSoftools\nBy: Softools Limited\nSolarEdge (Independent Publisher)\nBy: Richard Wierenga\nSoloSign HMAC Hash Creator\nBy: Solort\nSOS Inventory (Independent Publisher)\nBy: Harold Anderson\nSparkPost\nBy: Microsoft\nSparse Power Box Tools\nBy: Sparse Development\nSpinpanel\nBy: Spinpanel B.V.\nSpoonacular Food (Independent Publisher)\nBy: Amjed Ayoub\nSpoonacular Meal Planner (Independent Publisher)\nBy: Amjed Ayoub\nSpoonacular Recipe (Independent Publisher)\nBy: Amjed Ayoub\nSpotify (Independent Publisher)\nBy: Daniel Laskewitz\nSpring Global\nBy: Enavate\nSQL Server\nBy: Microsoft\nSquare Business (Independent Publisher)\nBy: Troy Taylor\nSquare Payments (Independent Publisher)\nBy: Troy Taylor\nStability.ai (Independent Publisher)\nBy: Troy Taylor\nStaffbase\nBy: Staffbase GmbH\nStaffCircle\nBy: StaffCircle\nStandard approvals\nBy: Microsoft\nStar Wars (Independent Publisher)\nBy: Paul Culmsee\nStarmind\nBy: Starmind (inc)\nStarRez REST v1\nBy: StarRez, Inc.\nStorm Glass (Independent Publisher)\nBy: Paul Culmsee\nStormboard\nBy: Stormboard\nStraker Verify\nBy: Straker Group\nStrava (Independent Publisher)\nBy: Richard Wierenga\nStripe\nBy: Microsoft\nStudio Ghibli (Independent Publisher)\nBy: Troy Taylor\nSunrise-Sunset (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nSupportivekoala (Independent Publisher)\nBy: Troy Taylor\nSureXeroLite (Independent Publisher)\nBy: The 848 Group\nSurvalyzer EU\nBy: Survalyzer AG\nSurvalyzer Swiss\nBy: Survalyzer AG\nSurvey123\nBy: ArcGIS Survey123\nSurveyMonkey\nBy: Microsoft\nSurveyMonkey Canada\nBy: SurveyMonkey\nSwagger Converter (Independent Publisher)\nBy: Fordos Andras\nSynthesia (Independent Publisher)\nBy: Troy Taylor\nT.LY (Independent Publisher)\nBy: Troy Taylor\nTabscanner Receipt OCR (Independent Publisher)\nBy: Ben Smith\nTAGGUN Receipt OCR Scanning (Independent Publisher)\nBy: Amjed Ayoub\nTago\nBy: Tago LLC\nTaktikal Core\nBy: Taktikal\nTalkdesk\nBy: Talkdesk\nTallyfy\nBy: Tallyfy, Inc\nTALXIS Data Feed\nBy: TALXIS\nTaqnyat\nBy: Taqnyat Network Operation\nTavily (Independent Publisher)\nBy: Troy Taylor\nTax ID Pro (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nTDox\nBy: Seltris srl\nTeam Forms\nBy: VP LABS PTY LTD\nTeamflect\nBy: Teamflect\nTeams-Spirit\nBy: D.F.K. Digitalteamwork GmbH\nTeamWherx\nBy: Actsoft\nTeamwork Projects\nBy: Microsoft\ntegolySIGN\nBy: tegoly GmbH\nTelegram Bot (Independent Publisher)\nBy: Woong Choi\nTelephony Xtended Serv Interf\nBy: BluIP, Inc.\nTeleSign SMS\nBy: TeleSign Corporation\nTemplafy\nBy: Templafy\nTendocs Documents\nBy: Deepdale BV\nTeradata\nBy: Microsoft\nTesseron Asset Management\nBy: Tesseron by Luithle + Luithle GmbH\nTesseron Basic Data\nBy: Tesseron by Luithle + Luithle GmbH\nTesseron Invoice\nBy: Tesseron by Luithle + Luithle GmbH\nTesseron Ticket\nBy: Tesseron by Luithle + Luithle GmbH\nText Analytics\nBy: MAQ Software\nText Request\nBy: Text Request\nThe Bot Platform\nBy: The Bot Platform\nThe BrÃ¸nnÃ¸ysund Registries (Independent Publisher)\nBy: Ahmad Najjar\nThe Color (Independent Publisher)\nBy: Troy Taylor\nThe Events Calendar\nBy: The Events Calendar\nThe Guardian (Independent Publisher)\nBy: Troy Taylor\nThe IT Tipster\nBy: The IT Tipster\nThe Lord of the Rings (Independent Publisher)\nBy: Troy Taylor\nThe SMS Works (Independent Publisher)\nBy: Troy Taylor\nThe Weather Channel (Independent Publisher)\nBy: Roy Paar\nTheGoodAPI (Independent Publisher)\nBy: Troy Taylor\nTheMealDB (Independent Publisher)\nBy: John Muchiri\nThreads (Independent Publisher)\nBy: Troy Taylor\nTicketing.events\nBy: Ventipix\nTicketmaster (Independent Publisher)\nBy: Troy Taylor\nTikit\nBy: Cireson\nTiliter Vision Agents\nBy: Tiliter Pty Ltd\nTilkee\nBy: Microsoft\nTimeAPI (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\ntimeghost\nBy: timeghost.io\nTimeneye\nBy: DM Digital Software SRL\nTLDR\nBy: Troy Taylor\nToday in History (Independent Publisher)\nBy: Troy Taylor\nTodoist\nBy: Microsoft\nToggl Plan (Independent Publisher)\nBy: Daniel Laskewitz\nToggl Track (Independent Publisher)\nBy: troystaylor\nTomorrow.io (Independent Publisher)\nBy: Troy Taylor\nToodledo\nBy: Microsoft\nTophhie Cloud\nBy: Chris Greenacre\nTopMessage\nBy: TOP X\ntouchSMS\nBy: Edgility\nTPC Portal\nBy: The Portal Connector\nTraction Guest\nBy: Traction Guest\nTrade.Gov (Independent Publisher)\nBy: Dan Romano\nTransform2All\nBy: GAC Business Solutions\nTree-Nation (Independent Publisher)\nBy: Troy Taylor\nTrello\nBy: Microsoft\nTribal - Maytas\nBy: Tribal Group\nTribal - Platform\nBy: Tribal Group\nTribal - SITS\nBy: Tribal Group\nTRIGGERcmd\nBy: VanderMey Consulting, LLC\nTrovve\nBy: Trovve Inc\nTrueDialog SMS\nBy: TrueDialog Dynamics\nTrustual\nBy: Practical Crypto SpA\nTulip\nBy: Tulip Interfaces\nTumblr (Independent Publisher)\nBy: Troy Taylor\nTuxMailer\nBy: TuxMailer\nTwilio\nBy: Microsoft\nTxtSync\nBy: TxtSync Limited\ntyntec 2FA\nBy: tyntec GmbH\ntyntec Phone Verification\nBy: tyntec GmbH\ntyntec SMS Business\nBy: tyntec GmbH\ntyntec Viber Business\nBy: tyntec GmbH\ntyntec WhatsApp Business\nBy: tyntec GmbH\nTypeform\nBy: Microsoft\nU.S. Bank Treasury Management\nBy: U.S. Bank\nUber Freight\nBy: Microsoft\nUbiqod by Skiply\nBy: Skiply\nUbiqod by Taqt\nBy: Skiply\nUdemy (Independent Publisher)\nBy: Nanddeep Nachan, Smita Nachan\nUiPath\nBy: UiPath Incorporated\nUiPath Orchestrator\nBy: UiPath\nUK Bank Holidays (Independent Publisher)\nBy: Martyn Lesbirel, Troy Taylor\nUK Check VAT (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nUKG Pro HCM\nBy: Dilip Chenani\nUKG PRO WFM Authentication\nBy: UKG, Inc.\nUKG Pro WFM Employee\nBy: Ria Gupta\nUKG Pro WFM People\nBy: Dilip Chenani\nUKG Pro WFM Timekeeping\nBy: Ria Gupta\nUnix Timestamp (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nUnofficial Netflix Search (Independent Publisher)\nBy: Troy Taylor\nUnsplash (Independent Publisher)\nBy: Troy Taylor, Hitachi Solutions\nUpdates App (Microsoft 365)\nBy: Microsoft\nUpdown (Independent Publisher)\nBy: Fordos Andras\nUpland Panviva US\nBy: Upland Software Inc..\nURL.dev (Independent Publisher)\nBy: Troy Taylor\nUrLBae (Independent Publisher)\nBy: Troy Taylor\nUS Congress CRS (Independent Publisher)\nBy: Dan Romano\nUS Patent & Trademark Office (Independent Publisher)\nBy: krautrocker\nUSAJOBS (Independent Publisher)\nBy: Richard Wilson\nUSB4SAP\nBy: Ecoservity\nUserVoice\nBy: Microsoft\nUSGS Earthquake Hazards (Independent Publisher)\nBy: Troy Taylor\nVantage 365 Imaging\nBy: Vantage 365 LTD\nVaruna\nBy: Univera Computer Systems Industry and Trade Inc.\nvatcheckapi\nBy: FÃ¶rdÅs AndrÃ¡s\nVena Solutions\nBy: Vena Solutions\nVentipix Asset and Inventory\nBy: Ventipix\nVerified\nBy: Crm - Konsulterna i Sverige AB\nVeteran Confirmation (Independent Publisher)\nBy: Troy Taylor\nVeterans Affairs Facilities (Independent Publisher)\nBy: Richard Wilson\nVeterans Affairs Forms (Independent Publisher)\nBy: Richard Wilson\nVeterans Affairs Providers (Independent Publisher)\nBy: Richard Wilson\nViafirma\nBy: Viafirma\nVideo Indexer (V2)\nBy: Microsoft\nVIES (Independent Publisher)\nBy: Tomasz Poszytek\nVimeo\nBy: Microsoft\nVirtual Data Platform\nBy: Virtual_Data_Platform_GmbH\nVirus Total\nBy: Microsoft\nViva Engage\nBy: Microsoft\nVocean\nBy: Vocean AB\nVoice Monkey (Independent Pubshisher)\nBy: Richard Wilson\nVoiceRSS (Independent Pubisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nVome\nBy: Vome Volunteer\nVonage\nBy: Vonage\nWaaila\nBy: Cross Masters s.r.o.\nWay We Do\nBy: Way We Do\nWayback Machine (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nWeather Forecast (Independent Publisher)\nBy: Haimantika Mitra\nWeavo Liquid Loom\nBy: Weavo Liquid Loom\nWebex\nBy: Cisco\nWebex Integration (Independent Publisher)\nBy: University College London, Oscar Hui\nWebhood URL Scanner\nBy: Webhood\nWebsite Carbon (ndependent Publisher)\nBy: Clement Olivier\nWenDocs Linker\nBy: WenDocs Ltd\nWhat3Words (Independent Publisher)\nBy: Matt Beard\nWhatIsMyBrowser (Independent Publisher)\nBy: Troy Taylor\nWhatsApp (Independent Publisher)\nBy: Zakariya Fakira\nWindows 365\nBy: Microsoft\nWithoutWire Inventory Platform\nBy: Enavate\nWitivio\nBy: Witivio\nWMATA (Independent Publisher)\nBy: Richard Wilson, Daniel Cox\nWooCommerce\nBy: Reenhanced, LLC\nWoodpecker (Independent Publisher)\nBy: Troy Taylor\nWord Cloud by Textvis (Independent Publisher)\nBy: Troy Taylor\nWord Online (Business)\nBy: Microsoft\nWordPress\nBy: Microsoft\nWorkable (Independent Publisher)\nBy: David Kjell\nWorkday HCM\nBy: Microsoft\nWorkday SOAP\nBy: Microsoft\nWorking days (Independent Publisher)\nBy: Tomasz Poszytek\nWorkMobile\nBy: eSAY Solutions Ltd\nWorkPoint\nBy: WorkPoint\nWorkSpan\nBy: WorkSpan\nWorkstem AU\nBy: OneJob Group Limited\nWorkstem HK\nBy: OneJob Group Limited\nWorld Academia\nBy: Kelcho Tech\nWorldTime (Independent Publisher)\nBy: FÃ¶rdÅs AndrÃ¡s\nWorldwide Bank Holidays (Independent Publisher)\nBy: Reshmee Auckloo\nWP Connectr for WordPress\nBy: Reenhanced, LLC\nWPForms by Reenhanced LLC\nBy: Reenhanced, LLC\nWQRM Risk Forecast Services\nBy: Western QRM\nWritesonic (Independent Publisher)\nBy: Troy Taylor\nwttr.in (Independent Publisher)\nBy: Troy Taylor\nX\nBy: Microsoft\nX12\nBy: Microsoft\nXbridger Document Manager\nBy: Xbridger Solutions\nXC-Gate\nBy: TECHNOTREE CO., LTD.\nXero Accounting - Magnetism\nBy: Magnetism\nxkcd (Independent Publisher)\nBy: Troy Taylor\nXooa Blockchain Database\nBy: Xooa Inc\nXooa Blockchain Smart Contract\nBy: Xooa Inc\nXpertdoc (Deprecated) [DEPRECATED]\nBy: Xpertdoc Technologies Inc.\nXSOAR (Independent Publisher)\nBy: Landon Chelf\nXSS PDF Solutions Integrations\nBy: Cross-Service-Solutions\nXSS QR Code Solutions\nBy: Cross-Service-Solutions\nYakChat\nBy: YakChat Ltd.\nYarado\nBy: Yarado\nYeeflow\nBy: YEEFLOW SINGAPORE PTE LTD\nYeelight\nBy: Qingdao Yeelink Information Technology Co., Ltd.\nYelp (Independent Publisher)\nBy: Ahmad Najjar\nYou Need A Budget (Independent Publisher)\nBy: Troy Taylor\nYouTube\nBy: Microsoft\nYouTube Transcript (Independent Publisher)\nBy: troystaylor\nZahara\nBy: Zahara Systems Ltd\nZanran Scaffolder\nBy: Zanran Ltd\nZapier MCP\nBy: Zapier Inc\nZapier NLA (Independent Publisher)\nBy: Troy Taylor\nZellis\nBy: Zellis\nZendesk\nBy: Microsoft\nZenkraft\nBy: Zenkraft\nZenler (Independent Publisher)\nBy: Troy Taylor\nZenlogin (Independent Publisher)\nBy: Troy Taylor\nZippopotamus (Independent Publisher)\nBy: Tomasz Poszytek\nZIPPYDOC\nBy: ZippyDoc GmbH\nZoho Mail\nBy: Zoho Corporation Private Limited\nZoho Calendar\nBy: Zoho Mail\nZoho Invoice Basic (Independent Publisher)\nBy: Troy Taylor\nZoho Sign\nBy: Zoho Corporation\nZoho TeamInbox\nBy: Zoho Corporation Private Limited\nZoho ZeptoMail\nBy: Zoho Corporation Private Limited\nZoom Meetings (Independent Publisher)\nBy: Akuthota Deekshith\nzReports\nBy: zReports Software s.r.o.\nZuva DocAI\nBy: Zuva Inc.\nZvanu Parvaldnieks\nBy: Latvijas Mobilais Telefons\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Connector Reference",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/connectors/custom-connectors/": {
      "content_hash": "sha256:6f162b6dd372343d21f2b75a11340b3290b1f6178cde8173ad22aeec33630470",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCustom connectors overview\nFeedback\nSummarize this article for me\nAzure Logic Apps\n,\nMicrosoft Power Automate\n,\nMicrosoft Power Apps\n, and\nMicrosoft Copilot Studio\noffer over\n1,000 connectors\nto connect to Microsoft and verified services, but you might want to communicate with services that aren't available as prebuilt connectors. Custom connectors address this scenario by allowing you to create (and even share) a connector with its own triggers and actions.\nLifecycle\n1. Build your API\nA custom connector is a wrapper around a REST API that allows Logic Apps,\nPower Automate, Power Apps, or Copilot Studio to communicate with that REST or SOAP API. These APIs can be:\nPublic (visible on the public internet) such as\nSpotify\n,\nSlack\n,\nRackspace\n, or an API you manage.\nPrivate (visible only to your network).\nLogic Apps also supports SOAP APIs.\nFor public APIs that you plan to create and manage, consider using one of these Microsoft Azure products:\nAzure Functions\nAzure Web Apps\nAzure API Apps\nFor private APIs, Microsoft offers on-premises data connectivity through an\non-premises data gateway\n.\n2. Secure your API\nUse one of these standard authentication methods for your APIs and connectors (\nMicrosoft Entra ID\nis recommended):\nGeneric OAuth 2.0\nOAuth 2.0 for specific services, including Microsoft Entra ID, Dropbox, GitHub, and SalesForce\nBasic authentication\nAPI Key\nYou can set up Microsoft Entra ID authentication for your API in the Azure portal so you don't have to implement authentication. Or, you can require and enforce authentication in your API's code. For more information about Microsoft Entra ID for custom connectors, see\nSecure your API and connector with Microsoft Entra ID\n.\n2.1. OAuth 2.0\nNewly created custom connectors that use OAuth 2.0 to authenticate automatically have a per connector redirect URI. Existing OAuth 2.0 connectors must be updated to use a per-connector redirect URI before February 17, 2024.\nIf you created your custom connectors with the web interface, edit your custom connectors, go to the\nSecurity\ntab and check the box,\nUpdate to unique redirect URL\n, and then save to enable the per connector redirect URI.\nIf you created your custom connectors with\nmulti-auth using the command line interface (CLI) tool\n, you need to update your connector using the CLI tool to set\n\"redirectMode\": \"GlobalPerConnector\"\n.\nOnce custom connectors are updated to use the per-connector redirect URI either through the setting in the\nSecurity\ntab or the CLI tool, remove the global redirect URI from your OAuth 2.0 apps. You should add the newly generated unique redirect URL to your OAuth 2.0 apps.\nWe'll enforce this update for existing OAuth 2.0 custom connectors starting on February 17, 2024. Any custom connector not updated to use a per-connector redirect URI stops working for new connections and shows an error message to the user.\nTo find out which custom connectors need an update to migrate to per-connector redirect URL, you can create a flow that uses the\nGet Custom Connectors as Admin\naction of Power Apps for Admin connector and parse its result. The flow attached later in this article fetches all the custom connectors using the same. It then applies a filter condition on the connection parameter's property to filter out non-Oauth custom connector, followed by another filter to select only connectors that don't use the per connector unique redirect URL. Finally, it puts the selected custom connectors into an array variable initialized in the beginning of the flow and generates an HTML table showing name and creator of those connectors. You can import this flow into your environment by importing\nthis solution\n. You can extend the flow further to send the HTML table as an email to yourself. or you can extend it to send emails to the connector creators directly and provide them with the names of the connector that needs to be updated.\n3. Describe the API and define the custom connector\nOnce you have an API with authenticated access, the next thing to do is to describe your API so that Logic Apps, Power Automate, Power Apps, or Copilot Studio can communicate with your API. The following approaches are supported:\nAn OpenAPI definition (formerly known as a Swagger file)\nCreate a custom connector from an OpenAPI definition\nOpenAPI documentation\nA Postman collection\nCreate a Postman collection\nCreate a custom connector from a Postman collection\nPostman documentation\nStart from scratch using the custom connector portal (Power Automate and Power Apps only)\nCreate a custom connector from scratch\nOpenAPI definitions and Postman collections use different formats, but both are language-agnostic, machine-readable documents that describe your API. You can generate these documents from various tools based on the language and platform used by your API. Behind the scenes, Logic Apps, Power Automate, Power Apps, and Copilot Studio use OpenAPI to define connectors.\n4. Use your connector in Copilot Studio, Logic Apps, Power Automate, or a Power Apps app\nCustom connectors are used the same way prebuilt connectors are used. You need to create a connection to your API in order to use that connection to call any operations that you expose in your custom connector.\nConnectors created in Power Automate are available in Power Apps and Copilot Studio, and connectors created in Power Apps are available in Power Automate and Copilot Studio. This availability isn't true for connectors created in Logic Apps. However, you can reuse the OpenAPI definition or Postman collection to recreate the connector in any of these services. For more information, see the appropriate tutorial:\nUse a custom connector from a flow\nUse a custom connector from an app\nUse a custom connector from a logic app\nUse connector actions in Copilot Studio\nTip\nIf you update (remove, add, or change) a field in the API, perform these steps:\nRepublish the connector so it looks at the updated Swagger for the API.\nRemove any connection / data source in any app that used that connector.\nRe-add the connection / data source for that connector back into the apps.\n5. Share your connector\nYou can share your connector with users in your organization the same way that you share resources in Copilot Studio, Logic Apps, Power Automate, or Power Apps. Sharing is optional, but you might have scenarios where you want to share your connectors with other users.\nLearn more in\nShare custom connectors in your organization\n.\n6. Certify your connector\nIf you want to share your connector with all users of Copilot Studio, Logic Apps, Power Automate, and Power Apps, you need to\nsubmit your connector for Microsoft certification\n. Microsoft reviews your connector, checks for technical and content\ncompliance, and validates functionality.\nVirtual Network support\nWhen the connector is used in a\nPower Platform environment linked to a Virtual Network\n, limitations apply:\nWhen custom code is used, limitations are explained in\nWrite code in a custom connector\n.\nCustom connectors created before the environment was associated to a Virtual Network need to be resaved.\nTriggers that return location header which do not call back into custom connector are not supported.\nProvide feedback\nWe greatly appreciate feedback on issues with our connector platform, or new feature ideas. To provide feedback, go to\nSubmit issues or get help with connectors\nand select your feedback type.\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Custom Connectors",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/security/security-overview": {
      "content_hash": "sha256:979bf6089dd5d28560a24dc686c48a020bd7d01acd1eab6d5f3920a5fe8f6037",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSecurity overview\nFeedback\nSummarize this article for me\nThe\nSecurity\n>\nOverview\npage in the Power Platform admin center is designed to enhance your organization's security and streamline management. It provides a centralized location where you can view and manage security recommendations, assess your security score, and implement proactive policies to safeguard your organization.\nAdministrators can complete these tasks:\nAssess your security score\n: Use the security score to understand and improve your organization's security policies. The security score is shown on a qualitative scale (\nLow\n,\nMedium\n, or\nHigh\n). It helps you measure your organizational security position for Microsoft Power Platform and Dynamics 365 workloads.\nAct on recommendations\n: Identify and implement impactful recommendations that the system generates. These recommendations are based on best practices for improving a tenant's security score.\nManage proactive policies\n: Manage proactive policies for governance and security.\nPrerequisite\nTo view your security score, you must turn on tenant-wide analytics. You can find instructions in\nHow do I turn on tenant-level analytics?\nNote\nAfter you turn on tenant-wide analytics, it might take up to 24 hours for the\nSecurity\n>\nOverview\npage to be populated with data. Until then, most sections of the page show the message \"Calculating security score.\"\nAccess the Security > Overview page\nTo access the\nSecurity\n>\nOverview\npage, you must have Microsoft Entra ID roles such as Power Platform administrator or Dynamics 365 administrator. Learn more about these roles in\nUse service admin roles to manage your tenant\n. Environment administrators can manage security and compliance features for owned environments by opening the\nSecurity\npage as explained in the following procedure.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select the page that you want to open. You can open pages for the overview,\ndata protection and privacy\n,\nidentity and access management\n, and\ncompliance\n.\nNote\nOnly tenant administrators can access the scorecard and recommendations on the\nSecurity\n>\nOverview\npage.\nOnly tenant administrators can convert an environment to a managed type.\nOn every security page, features that apply to Managed Environments are marked with the following meter symbol:\nSecurity score (preview)\n[This section is prerelease documentation and is subject to change.]\nImportant\nThis is a preview feature.\nPreview features arenât meant for production use and might have restricted functionality. These features are subject to\nsupplemental terms of use\n, and are available before an official release so that customers can get early access and provide feedback.\nThe security score is calculated based on the security features that are turned on in your environment. It provides a measurement of your organizational security position for Microsoft Power Platform and Dynamics 365 workloads.\nQualitative scale\n: The security score is shown on a qualitative scale that uses three assessment labels:\nLow\n: For scores from 0 through 50\nMedium\n: For scores from 51 through 80\nHigh\n: For scores from 81 through 100\nThe more security features are turned on in your environment, the higher your security score. The\nMedium\nand\nHigh\nassessment labels indicate that more recommended actions were taken and led to an improvement in the security position of the tenant.\nFeature impact\n: Each security feature is assigned a score, based on the feature's scope and the number of resources that are affected by turning it on or off. As new security features are added, the total possible score might change. Therefore, your overall score might be affected even if your settings remain the same.\nScore calculation formula\n: The security score is expressed as a percentage and is calculated by using the following formula:\n(\nYour score\nÃ·\nTotal possible score\n) Ã 100\nFor example, your tenant has 10 environments, five Managed Environments and five non-Managed Environments. The following features are configured:\nIP firewall\n: Turned on in two of the 10 environments (2 points).\nTenant isolation\n: Turned on in all 10 environments (10 points).\nEnvironment security group\n: Turned on in five of the 10 environments (5 points).\nIn this case, your total score is 2 + 10 + 5 = 17, and the total possible score is 30. Therefore, your security score is (17 Ã· 30) Ã 100 = 56.66%.\nImportant\nThe security score is updated every 24 hours. Therefore, any action that is taken might take up to 24 hours to reflect the updated score.\nThe score calculation considers all environments, both Managed Environments and non-Managed Environments.\nIf there are no Managed Environments that you can take action on in the recommendation pane, no environments are listed.\nTurn on environment management to unlock full security benefits\nNote\nThis feature is in the process of rolling out and might not be available in your region yet.\nTo ensure your organization benefits from the complete suite of managed security features, each environment must be configured as a managed environment.\nAs an admin, you can now view the percentage of environments in your tenant that are currently unmanaged. This new experience allows you to convert environments from unmanaged to managed at scaleâwith just a few clicks.\nSelect\nGet started\nto begin the conversion process. The\nGet enhanced security features\npane appears.\nSelect environments from the\nRecommended environments\ntab, which prioritizes environments based on data volume. Alternatively, switch to the\nAll eligible environments\ntab to manually select environments you want to convert.\nReview and accept the terms and conditions.\nSelect\nTurn on environment management\nto complete the conversion.\nIf you prefer to turn on environment management later, select\nNot now\nto dismiss the prompt and revisit when ready.\nBy using\nenvironment management\n, youâre taking a proactive step toward stronger, more consistent security across your organization.\nReactive governance through recommendations\nThe system generates various recommendations, based on common best practices that improve the security score of your tenant. Recommendations refer to actions or measures that the administrator can take to enhance the overall security status.\nAdministrators are guided through an intuitive experience where they take relevant actions on environments, based on specific recommendations.\nEach recommendation shows the potential increase to the overall security score.\nAlthough the recommendations span all environments, you can act on them only in Managed Environments. If non-Managed Environments, you can turn on recommended features by opening the\nSettings\npage, finding the required feature, and turning it on for those environments.\nConditions that trigger feature recommendations\nThe following table outlines the conditions that trigger specific feature recommendations.\nFeature\nScope\nCondition that triggers recommendations\nAdministrator privileges\nEnvironment\nEnvironments that have more than 10 administrators\nAuditing\nEnvironment\nEnvironments where auditing is turned off\nCustomer Lockbox\nTenant\nTenants where Customer Lockbox is turned on, but that have no Managed Environments\nClient application access control\nEnvironment\nEnvironments where auditing is turned on and client application access control isn't configured\nData policy\nTenant\nNo tenant-level policy is set.\nEnvironments Azure Virtual Network\nEnvironment\nEnvironments that have no Virtual Network policy\nEnvironment security group\nEnvironment\nEnvironments that have no security group\nGuest access\nEnvironment\nEnvironments where restricted guest access is turned off\nIP firewall\nEnvironment\nEnvironments where IP firewall isn't configured\nIP address-based cookie binding\nEnvironment\nEnvironments where IP address-based cookie binding isn't configured\nSharing\nEnvironment\nEnvironments that have no sharing limit\nTenant isolation\nTenant\nThe tenant isolation setting is turned off.\nManage proactive policies for governance and security\nSeveral security features are available to help secure your tenant. For some of these features, a Managed Environment is a prerequisite. Therefore, before you can configure such a feature, you're asked to convert the environment to a managed type if it isn't one.\nUse the following links to view and manage proactive policies for governance and security:\nData protection and privacy\n: Ensure that personal information is securely handled, stored, and protected; prevent unauthorized access to data; and protect apps and cloud workloads from network-based cyberattacks through features such as\ncustomer-managed keys\n, data policies, and Azure Virtual Network.\nIdentity and access management\n: Ensure that authorized users are the only people who can access sensitive data in items across the tenant, through features such as IP firewall, IP address-based cookie binding, tenant isolation, environment security groups, sharing controls, and guest access.\nCompliance\n: Implement robust compliance measures to safeguard organizational data and ensure adherence to industry regulations, through features such\nCustomer Lockbox\nand auditing.\nDismiss recommendations\nAdministrators now have the ability to dismiss security recommendations that have been mitigated through alternative solutions. Previously, unaddressed recommendations could result in a stagnant security score, despite proactive measures taken outside the recommended solutions.\nDismissed recommendations no longer negatively impact the security score, ensuring an accurate reflection of the organization's security posture.\nYour dismissed recommendations are always accessible, meaning that you can review their history at any time. If circumstances change or you wish to revisit a previously dismissed recommendation, you can easily reactivate it to ensure continuous security optimization.\nTo dismiss a recommendation, complete the following steps.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nOverview\n.\nThe\nOverview\npage appears. Scroll down to the\nTake action to increase your security score\nsection.\nIn the\nActive\ntab, select the recommendations that you want to dismiss.\nSelect the\nX\nicon to dismiss the recommendation.\nThe\nDismiss\nwindow is displayed. Select a reason for dismissing the recommendation from the dropdown list. Then select\nDismiss\n.\nThe recommendation moves to the\nDismissed\ntab.\nTo make a recommendation active again, complete the following steps.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nOverview\n.\nThe\nOverview\npage appears. Scroll down to the\nTake action to increase your security score\nsection.\nSelect the\nDismissed\ntab.\nSelect the recommendation that you want to make active.\nSelect the\nArrows\nicon to make the recommendation active.\nThe recommendation moves to the\nActive\ntab.\nManage security settings at an environment group-level\nManaging Power Platform at scale presents challenges for IT teams overseeing numerous environments. To streamline security governance, administrators can configure security settings at the\nenvironment group\nlevel, ensuring uniform enforcement of policies across all environments within a group.\nCurrently, security management at the environment group-level is available for\nSharing\n,\nIP Firewall\n, and\nIP address-based cookie binding\nfeatures, with plans to extend support to other security capabilities soon. This structured approach simplifies administration, enhances security, and optimizes large-scale environment management for both startups and enterprises.\nTo configure security settings at the environment group-level, complete the following steps.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nOverview\n.\nThe\nOverview\npage appears. Scroll down to the\nTake action to increase your security score\nsection.\nSelect a recommendation.\nIn the pane that is displayed, select the\nEnvironment groups\ntab and the\nEnvironments\ntab to select the environment groups or environments to which you want the security setting applied.\nSelect the\nManage sharing\nbutton.\nNote\nThe name of the button is determined by the security setting you're applying. In this specific example, we're applying a\nSharing\nsecurity setting, that's why\nManage sharing\nis the name of the button mentioned in this step.\nSelected settings are applied to all the environments in that environment group.\nProvide feedback\nEvery security page includes a\nFeedback\nbutton in the lower-right corner. Select this button to open a Microsoft Form where you can submit feedback and suggestions about the\nSecurity\npage and related features.\nFrequently asked questions (FAQ)\nHow is the security score calculated?\nThe security score is calculated based on the security features that are turned on in your environment. Each security feature is assigned a score, based on the feature's scope and the number of resources that are affected by turning it on or off. It's important to note that the total possible score might change as new security features are added. Therefore, your overall security score might be affected even if your settings remain the same.\nWhy don't all environments appear in the recommended action?\nAlthough the recommendations span all environments, you can act on them only in Managed Environments. If non-Managed Environments, you can turn on recommended features by opening the\nSettings\npage, finding the required feature, and turning it on for those environments.\nCan customers modify the recommendations based on their needs?\nNo. The recommendations are system-generated and are based on Microsoft best practices and guidance.\nWhen can the security score be updated after I take recommended actions?\nAfter you take action to turn on the feature, it might take up to 24 hours to reflect the overall security score. The security score isn't updated in real time.\nWhy don't administrator privileges work for environment administrators, such as the System Administrator role?\nThis issue is a known limitation. Only tenant administrators can manage the administrator privileges.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Security",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/security-roles-privileges": {
      "content_hash": "sha256:bde83651d1bc8009d1aeb4394d709f4e54739e19781a101d0e648fd2334e5b10",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSecurity roles and privileges\nFeedback\nSummarize this article for me\nTo control who can access restricted or sensitive data and resources and what they can do with them, assign users to security roles. This article provides an overview of security roles and their associated privileges.\nSecurity roles for users\nSecurity roles define how different users access different types of records. To control access to data and resources, you can create or modify security roles and change the security roles that are assigned to users.\nA user can have multiple security roles. Security role privileges are cumulative. Users are granted the privileges that are available in each role assigned to them.\nView a list of security roles in an environment\nTo view a list of security roles for an environment, take the following steps:\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. Then select an environment.\nSelect\nSettings\non the command bar. The\nSettings\npage for that environment is displayed.\nSelect\nUsers + Permissions\n>\nSecurity roles\n.\nRole name and description of a security role\nGive the Dataverse security role a descriptive name, include a brief statement of its purpose, define the\nApplies To\nscope (such as the service or application where the role is enforced), and summarize the key business tables for which the role grants permissions.\nView and update the security role description\nNote\nThe description, applies to and summary are protected and cannot be updated for system security roles.\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. Then select an environment.\nSelect\nSettings\nin the command bar. The\nSettings\npage for that environment is displayed.\nSelect\nUsers + Permissions\n>\nSecurity roles\n.\nSelect a security role and select\nSettings\non the action bar, or select a security role and then select the\nMore actions (...)\nicon, and select\nSettings\n.\nDefine the privileges and properties of a security role\nAfter you\ncreated a security role\nor while you're\nediting one\n, set the\nMember's privilege inheritance\noption:\nTeam privileges only\n: A user is granted these privileges as a member of a team. Team members who don't have user privileges of their own can create records with the team as the owner. They can access records that the team owns if they're given the\nUser\naccess level for Create and Read privileges.\nDirect User (Basic) access level and Team privileges\n: A user is granted these privileges directly when the security role is assigned. Users can create records with themselves as the owner. They can access records that they created or owned when the\nUser\naccess level for Create and Read privileges was given to them. This setting is the default for new security roles.\nThen, configure the privileges associated with the security role.\nA security role consists of record-level privileges and task-based privileges of the following three types:\nTables:\nTable privileges define which tasks a user with access to a table record can do, such as Read, Create, Delete, Write, Assign, Share, Append, and Append To.\nAppend\nmeans to attach another record, such as an activity or note, to a record.\nAppend to\nmeans to be attached to a record.\nSet table privileges\n.\nMiscellaneous privileges:\nThese task-based privileges give a user permission to perform specific, miscellaneous (nonrecord) tasks, such as publish articles or activate business rules.\nLearn more about miscellaneous privileges\n.\nPrivacy-related privileges\n: These privileges give a user permission to perform tasks that involve data that's integrated, downloaded, or exported outside of Dataverse, such as exporting data to Microsoft Excel or printing.\nLearn more about privacy-related privileges\n.\nEach set of privilege types has its own tab. For each tab, you can filter the view by all privileges, assigned privileges, or unassigned privileges for the selected security role.\nTable privileges\nThe\nTables\ntab lists the Dataverse tables in the environment. The following table describes the attributes that are shown in the security role editor when the\nCompact Grid View\noption is off.\nProperty\nDescription\nTable\nThe name of the Dataverse table\nName\nThe logical name of the Dataverse table; helpful for developers\nRecord ownership\nWhether records are owned by the organization or business unit or can be owned by a user or team\nPermission Settings\nWhich predefined set of permissions the table is using, or custom permissions\nTables are grouped into the following categories:\nBusiness Management\nBusiness Process Flows\nCore Records\nCustom Tables\nCustomization\nMissing Tables\nSales\nService\nService Management\nTo quickly find a specific table or privilege, enter its name in the search box at the upper-right corner of the page, and then select the magnifying glass icon or press\nEnter\n. To clear your search, select the\nX\nicon.\nYou can only edit one table at a time, but you can copy settings from one table to multiple tables in a single action.\nWhen you configure a security role, you need to determine the privileges it should grant for each table related to the application.\nThe following table describes the table privileges you can grant in a security role. In all cases, which records a privilege applies to depends on the access level of the permission defined in the security role.\nPrivilege\nDescription\nCreate\nRequired to make a new record\nRead\nRequired to open a record to view the contents\nWrite\nRequired to make changes to a record\nDelete\nRequired to permanently remove a record\nAppend\nRequired to associate the current record with another record; for example, if users have Append rights on a note, they can attach the note to an opportunity\nFor many-to-many relationships, a user must have Append privilege for both tables being associated or disassociated.\nAppend to\nRequired to associate a record with the current record; for example, if users have Append To rights on an opportunity, they can add a note to the opportunity\nAssign\nRequired to give ownership of a record to another user\nShare\nRequired to give access to a record to another user while keeping your own access\nAccess levels\nEach privilege has a menu that allows you to define its\naccess level\n. Access levels determine how deep in the business unit hierarchy the user can perform the privilege.\nThe following table describes the levels of access. For organization-owned tables, miscellaneous privileges and privacy-related privileges only have access levels of\nOrganization\nor\nNone\n.\nType\nDescription\nOrganization\nUsers can access all records in the organization, regardless of the business unit hierarchical level they or the environment belong to. Users with organization access automatically have all other types of access as well.\nBecause this level gives access to information throughout the organization, it should be restricted to match the organization's data security plan. This level of access is reserved for managers with authority over the organization.\nParent: Child Business Unit\nUsers can access records in their business unit and all business units subordinate to it.\nUsers with this access automatically have business unit and user access.\nBecause this level gives access to information throughout the business unit and subordinate business units, it should be restricted to match the organization's data security plan. This level of access is reserved for managers with authority over the business units.\nBusiness Unit\nUsers can access records in their business unit.\nUsers with business unit access automatically have user access.\nBecause this access level gives access to information throughout the business unit, it should be restricted to match the organization's data security plan. This level of access is reserved for managers with authority over the business unit.\nUser\nUsers can access records they own, objects that are shared with the organization, objects that are shared with them, and objects that are shared with a team that they're a member of.\nThis level of access is typical for sales and service representatives.\nNone\nNo access is allowed.\nFor each table, select the appropriate type for each privilege. Select\nSave\nwhen you're finished.\nCopy table permissions\nSetting the privileges for each table in your app can be time-consuming and tedious. To make it easier, you can copy the permissions from one table to one or more other tables.\nTip\nCreate your new security roles by copying the\npredefined template security roles\nin an environment.\nUse\nApp Opener\nrole, which has the minimum privileges to run an app.\nUse\nBasic User\nrole for the minimum privileges and including privileges to the core business tables.\nSelect a table, and then select\nCopy table permissions\n.\nSearch for and select the table or tables you want to copy the permissions to.\nRemember, the new configuration overwrites any previous settings.\nSelect\nSave\n.\nLet's take a closer look at how copy table permissions work with privileges and access levels.\nFor permissions that exist in both the source table and the target tables:\nIf the source permission settings depth exists in the target, then the copy is successful.\nIf the source permission settings depth\ndoesn't\nexist in the target, then the copy fails and an error message is displayed.\nFor permissions that only exist in either the source table or the target tables:\nIf the permission exists in the source but not in the target, then the permission is ignored in the target. The copy for the remaining permissions is successful.\nIf the permission\ndoesn't\nexist in the source but does exist in the target, then the depth of the permission is retained in the target. The copy for the remaining permissions is successful.\nPermission settings\nAnother way to speed up the configuration of table permissions is to use predefined groups of permissions and assign them to tables.\nThe following table describes the permission setting groups that you can assign.\nPermission setting\nDetails\nNo Access\nNo users can access the table.\nFull Access\nUsers can view and edit all records in the table.\nCollaborate\nUsers can view all records, but they can only edit their own.\nPrivate\nUsers can only view and edit their own records.\nReference\nUsers can only view records, not edit them.\nCustom\nIndicates that permission settings have been changed from the default value.\nSelect a table, and then select\nPermission Settings\nin the command bar or select\nMore Actions\n(\nâ¦\n) >\nPermission Settings\n.\nSelect the appropriate setting.\nRemember, the new configuration overwrites any previous settings.\nSelect\nSave\n.\nAdd users to a security role\nFollow these steps to add users to a security role.\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. Then select an environment.\nSelect\nSettings\nin the command bar. The\nSettings\npage for that environment is displayed.\nSelect\nUsers + permissions\n>\nSecurity roles\n.\nSelect a security role and then select the\nMore actions\n(\n...\n) icon.\nSelect\nMembers\nin the menu that appears.\nIn the\nMembers\npage, select the\n+ Add people\n.\nIn the\nAdd people\npane, enter a name, email address, or team name to search for the users you want to add to the security role.\nSelect\nAdd\nto add those users to the security role.\nRemove users from a security role\nYou can remove users from a security role through the modern UI. Follow these steps to remove users from a security role.\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. Then select an environment.\nSelect\nSettings\nin the command bar. The\nSettings\npage for that environment is displayed.\nSelect\nUsers + permissions\n>\nSecurity roles\n.\nSelect a security role and then select the\nMore actions\n(\n...\n) icon.\nSelect\nMembers\nin the menu that appears.\nIn the\nMembers\npage, select the users you want to remove from the security role.\nSelect\nRemove\nat the top of the page.\nThe\nRemove from role?\nwindow appears, asking you to confirm that you want privileges associated with that role removed for the selected user. Select\nRemove\n.\nRelated information\nVideo: Administer application users, security roles, teams, and users in the Power Platform admin center\nVideo: Check Access feature\nPredefined security roles\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Security Roles",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/create-edit-security-role": {
      "content_hash": "sha256:7e4e29c49c22eec2d40f1d769cad3b97d1fa5bfadf05cac818b59424fbd859bc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate or edit a security role to manage access\nFeedback\nSummarize this article for me\nCreate security roles or edit the privileges associated with an existing security role to accommodate changes in your business requirements. You can\nexport your changes as a solution\nto make a backup or for use in a different implementation.\nThis article also helps you make sure that your users have a security role with the minimum privileges that are needed for common tasks like opening model-driven apps. Be sure to watch the video in\nMinimum privileges for common tasks\n.\nPrerequisites\nMake sure you have the System Administrator permission\n. If you don't, contact your system administrator.\nCreate a security role\nTo create a security role, take these steps:\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\non the navigation pane.\nOn the\nManage\npane, select\nEnvironments\nand then select an environment.\nOn the command bar, select\nSettings\n.\nExpand\nUsers + permissions\nand select\nSecurity roles\n.\nOn the command bar, select\n+ New role\nto access the\nCreate New Role\npanel.\nEnter a\nrole name\n.\nSelect a business unit from the dropdown.\nEnter a\ndescription\n. For example, a brief statement of its purpose.\nEnter an\napplies to\n. For example, identify the service or application where this role is used.\nEnter a\nsummary of core table privileges\n. For example,the key business tables for which the role grants permissions.\nTo allow team members to inherit the privileges of this role when you assign it to a team, accept the default\nMember's privilege inheritance\nsetting, which is\nDirect User (Basic) access level and Team privileges\n. Learn more about the\nMember's privilege inheritance\nsetting in\nSecurity roles and privileges\n.\nTo use the new role to run model-driven apps, accept the default\nInclude App Opener privileges for running Model-Driven apps\nsetting, which is set to\nOn\n.\nSelect\nSave\n. The new role's properties are displayed.\nGrant table privileges\nTo grant table privileges, follow these steps:\nYou need to grant your app's table privileges to this newly created security role. Review and update the default privileges copied from the\nApp Opener security role's minimum privileges for common tasks\n. Some privileges grant organization-level read access, such as process (flows), that allow the user to run system-supplied flows. If your app or user doesn't need to run system-supplied flows, you can change this privilege to\nUser\n(basic) level.\nEnter your table name in the\nSearch\ninput field to find your app's table.\nSelect your table and set the permission settings.\nOn the command bar, select\nSave\n.\nRepeat the steps to grant table privileges to each table in your app.\nCreate a security role by copying an existing role\nTo create a security role by copying an existing role, follow these steps:\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\non the navigation pane.\nOn the\nManage\npane, select\nEnvironments\nand then select an environment.\nOn the command bar, select\nSettings\n.\nExpand\nUsers + permissions\nand select\nSecurity roles\n.\nChoose the security role you want to copy.\nOn the command bar, select\nCopy security role\nto display the\nCopy role\ndialog box.\nEnter a\nname\nfor the new role. Select\nCopy\n.\nEnter a\ndescription\n. For example, a brief statement of its purpose.\nEnter an\napplies to\n. For example, identify the service or application where this role is used.\nEnter a\nsummary of core table privileges\n. For example,the key business tables for which the role grants permissions.\nGo back to the\nSecurity roles\npage and select the new role you created.\nSpecify privileges for the security role. For more information, see\nSecurity roles and privileges\n.\nSelect\nSave + close\n.\nEdit settings of a security role\nTo edit settings, like name, description, applies to, and summary, of a security role, take these steps:\nNote\nYou can't edit the settings of system security roles.\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\non the navigation pane.\nOn the\nManage\npane, select\nEnvironments\nand then select an environment.\nOn the command bar, select\nSettings\n.\nExpand\nUsers + permissions\nand select\nSecurity roles\n.\nChoose the security role you want to edit.\nOn the command bar, select\nSettings\n.\nUpdate the\nname\n.\nUpdate the\ndescription\n. For example, a brief statement of its purpose.\nUpdate the\napplies to\n. For example, identify the service or application where this role is used.\nUpdate the\nsummary of core table privileges\n. For example,the key business tables for which the role grants permissions.\nSelect\nSave + close\n.\nEdit privileges of a security role\nBefore you edit a security role, make sure you understand the principles of\ncontrolling data access\n. To edit privileges of a security role, take these steps:\nNote\nYou can't edit the System Administrator security role. Instead, copy the System Administrator security role and make changes to the new role.\nSign in to the\nPower Platform admin center\n.\nSelect\nManage\non the navigation pane.\nOn the\nManage\npane, select\nEnvironments\nand then select an environment.\nOn the command bar, select\nSettings\n.\nExpand\nUsers + permissions\nand select\nSecurity roles\n.\nChoose the security role you want to edit.\nSpecify privileges for the security role.\n.\nSelect\nSave + close\n.\nMinimum privileges for common tasks\nMake sure that your users have a security role with the minimum privileges that they need for common tasks like opening model-driven apps.\nDon't use the\nmin prv apps use\nrole\nthat's available in the Microsoft Download Center. It's retiring soon. Instead, use or\ncopy the predefined security role App Opener\n, and then set the appropriate privileges.\nTo allow users to open a model-driven app or any Dynamics 365 customer engagement app, assign the\nApp Opener\nrole.\nTo allow users to view tables, assign the following privileges:\nCore Records:\nRead privilege on the table, Read Saved View, Create/Read/Write User Entity UI Settings\nand assign the following privilege on the Business Management tab: Read User.\nWhen signing in to Dynamics 365 for Outlook:\nTo render navigation for customer engagement apps and all buttons: assign the min prv apps use security role or a copy of this security role to your user\nTo render a table grid: assign Read privilege on the table\nTo render tables: assign Read privilege on the table\nPrivacy notices\nLicensed Dynamics 365 Online users with specific security roles are automatically authorized to access the service by using Dynamics 365 for phones, and other clients. Examples of authorized roles include: CEO, Business Manager, Sales Manager, Salesperson, System Administrator, System Customizer, and Vice President of Sales.\nAn admin has full control, at the user's security role or entity level, to access and the level of authorized access associated with the phone client. Users can then access Dynamics 365 Online by using Dynamics 365 for phones. Customer data will be cached on the device running the specific client.\nBased on the specific settings at the user security and entity levels, the types of customer data that can be exported from Dynamics 365 Online. The data that can be cached on an end userâs device include record data, record metadata, entity data, entity metadata, and business logic.\nThe Dynamics 365 for tablets and phones, and Project Finder for Project Finder for Dynamics 365 (the \"App\") enables users to access their Microsoft Dynamics CRM or Dynamics 365 instance from their tablet and phone device. In order to provide this service, the App processes and stores information, such as user's credentials and the data the user processes in Microsoft Dynamics CRM or Dynamics 365. The App is provided for use only by end users of Microsoft customers who are authorized users of Microsoft Dynamics CRM or Dynamics 365. The App processes user's information on behalf of the applicable Microsoft customer, and Microsoft may disclose information processed by the App at the direction of the organization that provides users access to Microsoft Dynamics CRM or Dynamics 365. Microsoft does not use information users process via the App for any other purpose.\nIf users use the App to connect to Microsoft Dynamics CRM (online) or Dynamics 365, by installing the App, users consent to transmission of their organization's assigned ID and assigned end user ID, and device ID to Microsoft for purposes of enabling connections across multiple devices, or improving Microsoft Dynamics CRM (online), Dynamics 365 or the App.\nLocation data.\nIf users request and enable location-based services or features in the App, the App may collect and use precise data about their location. Precise location data can be Global Position System (GPS) data, as well as data identifying nearby cell towers and Wi-Fi hotspots. The App may send location data to Microsoft Dynamics CRM or Dynamics 365. The App may send the location data to Bing Maps and other third party mapping services, such as Google Maps and Apple Maps, a user designated in the user's phone to process the user's location data within the App. Users may disable location-based services or features or disable the App's access to user's location by turning off the location service or turning off the App's access to the location service. Users' use of Bing Maps is governed by the Bing Maps End User Terms of Use available at\nhttps://go.microsoft.com/?linkid=9710837\nand the Bing Maps Privacy Statement available at\nhttps://go.microsoft.com/fwlink/?LinkID=248686\n. Users' use of third party mapping services, and any information users provide to them, is governed by their service specific end user terms and privacy statements. Users should carefully review these other end user terms and privacy statements.\nThe App may include links to other Microsoft services and third party services whose privacy and security practices may differ from those of Microsoft Dynamics CRM or Dynamics 365.  IF USERS SUBMIT DATA TO OTHER MICROSOFT SERVICES OR THIRD PARTY SERVICES, SUCH DATA IS GOVERNED BY THEIR RESPECTIVE PRIVACY STATEMENTS. For the avoidance of doubt, data shared outside of Microsoft Dynamics CRM or Dynamics 365 is not covered by users' Microsoft Dynamicss CRM or Dynamics 365 agreement(s) or the applicable Microsoft Dynamics Trust Center. Microsoft encourages users to review these other privacy statements.\nLicensed Dynamics 365 Online users with specific Security Roles (CEO â Business Manager, Sales Manager, Salesperson, System Administrator, System Customizer, and Vice President of Sales) are automatically authorized to access the service by using Dynamics 365 for tablets, as well as other clients.\nAn administrator has full control (at the user security role or entity level) over the ability to access and the level of authorized access associated with the tablet client. Users can then access Dynamics 365 (online) by using Dynamics 365 for tablets, and Customer Data will be cached on the device running the specific client.\nBased on the specific settings at the user security and entity levels, the types of Customer Data that can be exported from Dynamics 365 (online) and cached on an end userâs device include record data, record metadata, entity data, entity metadata, and business logic.\nIf you use Microsoft Dynamics 365 for Outlook, when you go offline, a copy of the data you are working on is created and stored on your local computer. The data is transferred from Dynamics 365 (online) to your computer by using a secure connection, and a link is maintained between the local copy and Dynamics 365 Online. The next time you sign in to Dynamics 365 (online), the local data will be synchronized with Dynamics 365 (online).\nAn administrator determines whether or not an organizationâs users are permitted to go offline with Microsoft Dynamics 365 for Outlook by using security roles.\nUsers and administrators can configure which entities are downloaded via Offline Sync by using the\nSync Filters\nsetting in the\nOptions\ndialog box. Alternatively, users and Administrators can configure which fields are downloaded (and uploaded) by using\nAdvanced Options\nin the\nSync Filters\ndialog box.\nIf you use Dynamics 365 (online), when you use the Sync to Outlook feature, the Dynamics 365 data you are syncing is âexportedâ to Outlook. A link is maintained between the information in Outlook and the information in Dynamics 365 (online) to ensure that the information remains current between the two. Outlook Sync downloads only the relevant Dynamics 365 record IDs to use when a user attempts to track and set regarding an Outlook item. The company data is not stored on the device.\nAn administrator determines whether your organizationâs users are permitted to sync Dynamics 365 data to Outlook by using security roles.\nIf you use Microsoft Dynamics 365 (online), exporting data to a\nstatic\nworksheet creates a local copy of the exported data and stores it on your computer. The data is transferred from Dynamics 365 (online) to your computer by using a secure connection, and no connection is maintained between this local copy and Dynamics 365 (online).\nWhen you export to a\ndynamic\nworksheet or PivotTable, a link is maintained between the Excel worksheet and Dynamics 365 (online). Every time a dynamic worksheet or PivotTable is refreshed, youâll be authenticated with Dynamics 365 (online) using your credentials. Youâll be able to see the data that you have permissions to view.\nAn administrator determines whether or not an organizationâs users are permitted to export data to Excel by using security roles.\nWhen Dynamics 365 (online) users print Dynamics 365 data, they are effectively âexportingâ that data from the security boundary provided by Dynamics 365 (online) to a less secure environment, in this case, to a piece of paper.\nAn administrator has full control (at the user security role or entity level) over the data that can be extracted. However, after the data has been extracted it is no longer protected by the security boundary provided by Dynamics 365 (online) and is instead controlled directly by the customer.\nRelated content\nSecurity concepts\nPredefined security roles\nCopy a security role\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create Security Roles",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/database-security": {
      "content_hash": "sha256:2b1651c420f368f552ff1b074df1db49b3baef1f1d4efe78401e7dcca5efd8c3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRole-based security roles\nFeedback\nSummarize this article for me\nMicrosoft Dataverse uses a role-based security model to control access to a database and its resources in an environment. Use security roles to configure access to all resources in an environment or to specific apps and data in the environment. A combination of access levels and permissions in a security role determines which apps and data users can view and how they can interact with those apps and data.\nAn environment can have no or one Dataverse database. You assign security roles differently for\nenvironments that have no Dataverse database\nand\nenvironments that have a Dataverse database\n.\nPredefined security roles\nEnvironments include predefined security roles that reflect common user tasks. The predefined security roles follow the security best practice of \"minimum required access\": provide the least access to the minimum business data that a user needs to use an app. These security roles can be assigned to a user,\nowner team\n, and\ngroup team\n. The predefined security roles that are available in an environment depend on the environment type and the apps installed in it.\nAnother set of security roles is assigned to\napplication users\n. Those security roles are installed by our services and can't be updated.\nEnvironments without a Dataverse database\nEnvironment Maker and Environment Admin are the only predefined roles for environments that have no Dataverse database. These roles are described in the following table.\nSecurity role\nDescription\nEnvironment Admin\nTheâ¯Environment Adminâ¯role can perform all administrative actions on an environment, including:\nAdd or remove a user from either the Environment Admin or Environment Maker role.\nProvision a Dataverse database for the environment. After a database is provisioned, assign the System Customizer role to an Environment Admin to give them access to the environment's data.\nView and manage all resources created in an environment.\nCreate\ndata loss prevention policies\n.\nEnvironment Maker\nCan create new resources associated with an environment, including apps, connections, custom APIs, and flows using Microsoft Power Automate. However, this role doesn't have privileges to access data in an environment.\nEnvironment makers can also\ndistribute the apps they build\nin an environment to other users in your organization. They can share the app with individual users, security groups, or all users in the organization.\nEnvironments with a Dataverse database\nIf the environment has a Dataverse database, a user must be assigned the System Administrator role instead of the Environment Admin role to have full admin privileges.\nUsers who make apps that connect to the database and need to create or update entities must have the System Customizer role in addition to the Environment Maker role. The Environment Maker role doesn't have privileges on the environment's data. These security roles do not have the privileges to create or update security roles.\nThe following table describes the predefined security roles in an environment that has a Dataverse database. You can't edit these roles.\nSecurity role\nDescription\nApp Opener\nHas\nminimum privileges for common tasks\n. This role is primarily used as a template to\ncreate a custom security role\nfor model-driven apps. It doesn't have any privileges to the core business tables, such as Account, Contact, and Activity. However, it has\nOrganization\n-level read access to system tables, such as\nProcess\n, to support reading system-supplied workflows. This security role is used when a\nnew, custom security role is created\n.\nBasic User\nFor out-of-the-box entities only, can run an app in the environment and perform common tasks on the records they own. It has privileges to the core business tables, such as Account, Contact, Activity, and Process.\nNote\n: The Common Data Service\nUser\nsecurity role was renamed\nBasic User\n. Only the name was changed; user privileges and role assignment are the same. If you have a solution with the Common Data Service\nUser\nsecurity role, you should update the solution before you import it again. Otherwise, you might inadvertently change the security role name back to\nUser\nwhen you import the solution.\nDelegate\nAllows code to\nimpersonate\n, or run as, another user\n. Typically used with another security role to allow access to records.\nDynamics 365 Administrator\nDynamics 365 administrator\nis a Microsoft Power Platform service admin role. Users of this role can do admin functions on Microsoft Power Platform after they\nself-elevate\nto the system administrator role.\nEnvironment Maker\nCan create new resources associated with an environment, including apps, connections, custom APIs, and flows using Microsoft Power Automate. However, this role doesn't have any privileges to access data in an environment.\nEnvironment makers can also\ndistribute the apps they build\nin an environment to other users in your organization. They can share the app with individual users, security groups, or all users in the organization.\nGlobal Administrator\nGlobal administrator\nis a Microsoft 365 administrator role. A person who purchases the Microsoft business subscription is a global administrator and has unlimited control over products in the subscription and access to most data. Users of this role must\nself-elevate\nto the system administrator role.\nGlobal Reader\nThe\nGlobal Reader\nrole isn't supported yet in the Power Platform admin center.\nOffice Collaborator\nHas Read permission to tables in which a record was shared with the organization. Doesn't have access to any other core and custom table records. This role is assigned to the Office Collaborators owner team and not to an individual user.\nPower Platform administrator\nPower Platform administrator\nis a Microsoft Power Platform service administrator role. Users of this role can do admin functions on Microsoft Power Platform after they\nself-elevate\nto the system administrator role.\nService Deleted\nHas full Delete permission to all entities, including custom entities. This role is primarily used by the service and requires deleting records in all entities.\nThis role can't be assigned to a user or team.\nService Reader\nHas full Read permission to all entities, including custom entities. This role is primarily used by the service and requires reading all entities.\nThis role can't be assigned to a user or team.\nService Writer\nHas full Create, Read, and Write permission to all entities, including custom entities. This role is primarily used by the service and requires creating and updating records.\nThis role can't be assigned to a user or team.\nSupport User\nHas full Read permission to customization and business management settings, which allow support staff to troubleshoot environment configuration issues. This role doesn't have access to core records.\nThis role can't be assigned to a user or team.\nSystem Administrator\nHas full\npermission to customize\nor administer the environment, including creating, modifying, and assigning security roles. Can view all data in the environment.\nSystem Customizer\nHas full\npermission to customize the environment\n. Can view all custom table data in the environment. However, users with this role can only view records that they create in Account, Contact, Activity tables.\nWebsite App Owner\nA user who owns the\nwebsite application registration\nin the\nAzure portal\n.\nWebsite Owner\nThe user who created the Power Pages website.\nThis role is managed and can't be changed.\nIn addition to the predefined security roles described for Dataverse, other security roles might be available in your environment depending on the Power Platform componentsâPower Apps, Power Automate, Microsoft Copilot Studioâyou have. The following table provides links to more information.\nPower Platform component\nInformation\nPower Apps\nPredefined security roles for environments with a Dataverse database\nPower Automate\nSecurity and privacy\nPower Pages\nRoles required for website administration\nMicrosoft Copilot Studio\nAssign environment security roles\nDataverse for Teams environments\nLearn more about\npredefined security roles in Dataverse for Teams environments\n.\nApp-specific security roles\nIf you deploy Dynamics 365 apps in your environment, other security roles are added. The following table provides links to more information.\nDynamics 365 app\nSecurity role docs\nDynamics 365 Sales\nPredefined security roles for Sales\nDynamics 365 Marketing\nSecurity roles added by Dynamics 365 Marketing\nDynamics 365 Field Service\nDynamics 365 Field Service roles + definitions\nDynamics 365 Customer Service\nRoles in Omnichannel for Customer Service\nDynamics 365 Customer Insights\nCustomer Insights roles\nApp profile manager\nRoles and privileges associated with app profile manager\nDynamics 365 Finance\nSecurity roles in the public sector\nFinance and operations apps\nSecurity roles in Microsoft Power Platform\nSummary of resources available to predefined security roles\nThe following table describes which resources each security role can author.\nResource\nEnvironment Maker\nEnvironment Admin\nSystem Customizer\nSystem Admin\nCanvas app\nX\nX\nX\nX\nCloud flow\nX (nonâsolution-aware)\nX\nX\nX\nConnector\nX (nonâsolution-aware)\nX\nX\nX\nConnection\n*\nX\nX\nX\nX\nData gateway\n-\nX\n-\nX\nDataflow\nX\nX\nX\nX\nDataverse tables\n-\n-\nX\nX\nModel-driven app\nX\n-\nX\nX\nSolution framework\nX\n-\nX\nX\nDesktop flow\n**\n-\n-\nX\nX\nAI Builder\n-\n-\nX\nX\n*Connections are used in\ncanvas apps\nand\nPower Automate\n.\n**Dataverse for Teams users don't get access to desktop flows by default. You need to upgrade your environment to full Dataverse capabilities and acquire\ndesktop flow license plans\nto use desktop flows.\nRelated content\nAssign a security role to a user\nSecurity roles and privileges\nHow access to a record is determined\nConfigure user security in an environment\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Database Security",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/field-level-security": {
      "content_hash": "sha256:318de516ad93dfe92db74e4230e0cdf3556b83179e072a487728bd61425ff45d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nColumn-level security to control access\nFeedback\nSummarize this article for me\nManage access to records at the table level using\nprivileges associated with security roles\n. Some columns in a table might contain data that is more sensitive than others. Use column-level security to manage access to data in specific columns. Column-level security configurations are organization-wide and apply to all data access requests.\nYou can use column level security to prevent certain users from:\nSetting the value of a column in a record.\nViewing the data in a column. You can choose to mask this value to show a portion of it, or not return any data at all.\nNote\nTo configure column-level security, you need the system administrator role.\nColumn-level security doesn't apply for users who have the system administrator role. Data is never hidden from system administrators. To verify the configured results, you must use an account that doesn't have the system administrator security role assigned.\nColumn-level security is available\nfor most columns\nusing this process:\nEnable column-level security\non one or more columns for a given table.\nOptionally, select a\nmasking rule\n.\nAssociate one more existing security profiles\n, or create one or more new security profiles to grant the appropriate access to specific users or teams.\nEnable column security\nUse the following steps to secure a column:\nSign in to\nPower Apps\n.\nSelect\nSolutions\n.\nSelect the unmanaged solution that contains the table that has the column, or create a new solution to hold your changes and add the table to it.\nWithin the solution, in\nObjects\n, within\nTables\n, select the table.\nUnder\nSchema\n, select\nColumns\n.\nIn the\nColumns\nlist, select a column.\nExpand\nAdvanced options\n, and then under\nGeneral\n, select\nEnable column security\n.\nSelect\nSave\n.\nTip\nLearn how a developer can retrieve a list of all the secured columns in an environment\nor\nsecure a column using code\nAdd teams or users to a column security profile to control access\nA column security profile determines:\nUsers and teams assigned access.\nPermissions to the secure columns.\nUse a column security profile to grant user or team members the following permissions:\nPermission\nOptions\nResult\nRead\nAllowed\nNot Allowed\nWhether people can view the data for the column.\nMasked values are shown if masking rule is applied to the column.\nRead unmasked\nAll Records\nOne record\nNot Allowed\nWhen a secured column has a masking rule, a developer can write code to request unmasked data be returned.\nThis setting controls whether or not that request succeeded.\nThe default setting is\nNot Allowed\n.\nLearn more about granting permissions to a secured column with a masking rule\nUpdate\nAllowed\nNot Allowed\nWhether people can update the data in the column.\nCreate\nAllowed\nNot Allowed\nWhether people can set the data in the column when creating a record.\nConfigure a combination of these four permissions to determine the user privileges for a specific data column.\nImportant\nUnless one or more security profiles are assigned to a column with security, only users with the system administrator security role can access the column.\nAny users not defined in the column security profiles won't have access to the column on forms or views. The column value displays\n********, indicating that the column is secured.\nAdd a column and set permissions for a column security profile\nTo add a column and set permissions for a column security profile, use the following steps:\nSign in to theâ¯\nPower Platform admin center\n.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. Then select an environment.\nSelect\nSettings\n>\nUsers + permissions\n>\nColumn security profiles\n.\nSelect an existing profile, or select\nNew Profile\n, enter a name, enter a description, and then select\nSave\n.\nSelect the\nTeams\nor\nUsers\ntab, select\n+ Add Teams\nor\n+ Add Users\n, select the teams or users that you want to control access, and then select\nAdd\n.\nSelect the\nColumn Permission\ntab, in the\nName\ncolumn select one or more columns, and then select\nEdit\n. Configure the four properties for the desired access. These permissions control whether people in this security profile can read or set column values.\nSelect\nSave\n.\nTip\nLearn how a developer can provide access to secured columns using code\nWhich columns can be secured?\nWhen a column is eligible for column-level security, the\nEnable column security\ncheckbox is enabled in the\nAdvanced options\narea of the column definition in\nPower Apps\n.\nYou can view this area when you\ncreate or edit a column\n.\nColumns that can't be secured include:\nColumns in virtual tables\nLookup columns\nFormula columns\nPrimary name columns (The single-line of text column each table has to show the value in a lookup field. Typically with a name ending with\nname\n.)\nSystem columns like\ncreatedon\n,\nmodifiedon\n,\nstatecode\n, and\nstatuscode\n.\nNote\nFile and Image data types can be secured, but they can't be masked.\nText data type with Rich text format can be secured, but an embedded image in Rich text can't be masked or bypassed for masking.\nWhether the\nEnable column security\ncheckbox is enabled depends on the value of these column properties:\nCanBeSecuredForCreate\n,\nCanBeSecuredForRead\n, and\nCanBeSecuredForUpdate\n. You can view this data by installing the Metadata Browser solution described in\nBrowse table definitions in your environment\n.\nTip\nLearn how a developer can query Dataverse to get a list of all the columns that can be secured\nBest practices\nWhen a\ncalculated column\nincludes a column that is secured, data might be displayed in the calculated column to users that don't have permission to the secured column. Both the original column and the calculated column should be secured.\nComposite columns\ninclude data from multiple columns. For example, the\ncontact\ntable\nfullname\nand\naddress1_composite\ncolumns are composite columns. To completely secure data included in composite columns, you must secure and configure the appropriate column security profiles on multiple columns for the table. For example, to completely secure the\naddress1_composite\ncolumn, you need to secure all of these the columns that begin with\naddress1_\nin both the\ncontact\nand\naddress (\ncustomeraddress\n)\ntables.\nNote\nChanges to column security require a browser refresh from the end user on the client (like a model-driven app) for the changes to take effect. This should be considered when dynamically adjusting access rules.\nActivity logging data\nThe column values in the before-and-after audit change events show as \"*\" in the\nCreate\nand\nUpdate\nPurview activity logs\n.\nRelated information\nEnable or disable security for a column to control access\nColumn-level security example\nHierarchy security\nColumn-level security with code\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Column-Level Security",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/manage-high-privileged-admin-roles": {
      "content_hash": "sha256:8c90fbdc155bf603716ca92d8b4251beb0ecdbbb7fa76782771caabd3a4435cb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage admin roles with Microsoft Entra Privileged Identity Management\nFeedback\nSummarize this article for me\nManage high-privileged admin roles in the Power Platform admin center using Microsoft Entra Privileged Identity Management (PIM).\nPrerequisites\nRemove old system administrator role assignments in your environments. You can use\nPowerShell scripts\nto inventory and remove unwanted users from the\nSystem Administrator\nrole in one or more Power Platform environments.\nChanges to feature support\nMicrosoft no longer automatically assigns the\nSystem Administrator\nrole to users with global or service level admin roles such as Power Platform Administrator and Dynamics 365 Administrator.\nThese admins can continue to sign in, to the Power Platform admin center, with these privileges:\nEnable or disable tenant level settings\nView analytics information for environments\nView capacity consumption\nThese admins can't perform activities that require direct access to Dataverse data without a license. Examples of these activities include:\nUpdating the security role for a user in an environment\nInstalling apps for an environment\nImportant\nGlobal admins, Power Platform admins, and Dynamics 365 service administrators must complete another step before they can perform activities requiring access to Dataverse. They must elevate themselves to the\nSystem Administrator\nrole in the environment where they need access. All elevation actions are logged to Microsoft Purview.\nIf you use Privileged Identity Management to get just-in-time access to admin roles in Microsoft Entra ID and then self-elevate, Microsoft removes your\nSystem Administrator\nrole when role assignment expires in Privileged Identity Management, usually after a short duration.\nKnown limitations\nWhen using the API, if the caller is a system administrator, the self-elevate call returns a success instead of indicating that they are already exit.\nThe user making the call must have the tenant admin role assigned. For a full list of users who meet the tenant admin criteria, see\nChanges to feature support\nIf you're a Dynamics 365 administrator and the environment is protected by a security group, you must be a member of the security group. This rule doesn't apply to users with the global administrator or Power Platform administrator roles.\nThe user who needs to elevate their status must invoke the elevation API. It does not allow API calls to elevate another user's status.\nA workaround is available for customers using the Microsoft Power Platform CoE Starter Kit. See\nPIM Issue and Workaround #8119\nfor more information and details.\nRole assignments through groups aren't supported. Make sure that you assign roles directly to the user.\nSelf-elevate to the system administrator role\nWe support elevation using either PowerShell or through an intuitive experience in Power Platform admin center.\nNote\nUsers who attempt to self-elevate must be a Global admin, Power Platform admin, or Dynamics 365 admin. The user interface in Power Platform admin center isn't available for users with other Entra ID admin roles and attempting to self-elevate through the PowerShell API returns an error.\nSelf-elevate through PowerShell\nTo self-elevate through PowerShell, install the\nMSAL\nPowerShell module and follow the steps in this section.\nInstall-Module -Name MSAL.PS\nYou only need to install the module once. For more information about setting up PowerShell, see\nQuick Start Web API with PowerShell and Visual Studio Code\n.\nStep 1: Run the script to elevate\nIn this PowerShell script, you:\nAuthenticate, using the Power Platform API.\nBuild an\nhttp\nquery with your environment ID.\nRequest elevation, using the Power Platform API.\nLocate and add your environment ID\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, choose the environment you want to modify.\nLocate the\nEnvironment ID\nin the\nDetails\npane.\nAdd your unique\n<environment id>\nto the script.\nRun the script\nCopy and paste the script into a PowerShell console.\n# Set your environment ID\n$environmentId = \"<your environment id>\"\n$clientId = \"<client id of your Microsoft Entra ID application registration>\"\n\nImport-Module MSAL.PS\n\n# Authenticate\n$AuthResult = Get-MsalToken -ClientId $clientId -Scope 'https://api.powerplatform.com/.default'\n\n$Headers = @{\n Authorization = \"Bearer $($AuthResult.AccessToken)\"\n 'Content-Type' = \"application/json\"\n} \n\n$uri = \"https://api.powerplatform.com/usermanagement/environments/$environmentId/user/applyAdminRole?api-version=2022-03-01-preview\";\n\ntry { \n\n $postRequestResponse = Invoke-RestMethod -Method Post -Headers $Headers -Uri $uri \n \n} \n \ncatch { \n \n # Dig into the exception to get the Response details. \n \n Write-Host \"Response CorrelationId:\" $_.Exception.Response.Headers[\"x-ms-correlation-id\"] \n \n Write-Host \"StatusCode:\" $_.Exception.Response.StatusCode.value__ \n \n Write-Host \"StatusDescription:\" $_.Exception.Response.StatusDescription \n \n $result = $_.Exception.Response.GetResponseStream() \n \n $reader = New-Object System.IO.StreamReader($result) \n \n $reader.BaseStream.Position = 0 \n \n $reader.DiscardBufferedData() \n \n $responseBody = $reader.ReadToEnd(); \n \n Write-Host $responseBody \n \n} \n \n$output = $postRequestResponse | ConvertTo-Json -Depth 2 \n \nWrite-Host $output\nStep 2: Confirm the result\nUpon success, you see an output similar to the following output. Look for\n\"Code\": \"UserExists\"\nas evidence that you successfully elevated your role.\n{\n \"errors\": [],\n \"information\": [\n {\n \"Subject\": \"Result\",\n \"Description\": \"[\\\"SyncMode: Default\\\",\\\"Instance df12c345-7b56-ee10-8bc5-6045bd005555 exists\\\",\\\"Instance df85c664-7b78-ee11-8bc5-6045bd005555 in enabled state\\\",\\\"Instance Url found https://orgc1234567.crm.dynamics.com\\\",\\\"User found in AD tenant\\\",\\\"User in enabled state in AD tenant\\\",\\\"SystemUser with Id:11fa11ab-4f75-ee11-9999-6045bd12345a, objectId:aaaaaaaa-0000-1111-2222-bbbbbbbbbbbb exists in instance\\\"]\",\n \"Code\": \"UserExists\"\n },\n { ... }\n}\nErrors\nYou might see an error message if you don't have the right permissions.\n\"Unable to assign System Administrator security role as the user is not either a Global admin, Power Platform admin, or Dynamics 365 admin. Please review your role assignments in Entra ID and try again later. For help, please reach out to your administrator.\"\nExample script\nRemove-RoleAssignmentFromUsers\n-roleName \"System Administrator\" \n-usersFilePath \"C:\\Users\\<My-Name>\\Desktop\\<names.csv>\"\n-environmentUrl \"<my-name>-environment.crm.dynamics.com\"\n# Or, include all your environments\n-processAllEnvironments $true\n-geo \"NA\"\n-outputLogsDirectory \"C:\\Users\\<My-Name>\\Desktop\\<log-files>\"\nSelf-elevate through Power Platform admin center\nTo self-elevate through Power Platform center, take the following steps:\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, choose the environment you want to modify.\nIn the command bar, select\nMembership\nto request self-elevation.\nIn the\nSystem Administrators\npane, select\nAdd me\nto add yourself to the system administrator role.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "High-Privileged Admin Roles",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/ip-firewall": {
      "content_hash": "sha256:79a1dd15b5d60725fc24e4b534782cec3fae23ef5d58e876f2c7993ee5093b0a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nIP firewall in Power Platform environments\nFeedback\nSummarize this article for me\nThe IP firewall protects your organizational data by ensuring users can only access Microsoft Dataverse from allowed IP locations. The IP firewall analyzes the IP address of each request in real time. For example, you can turn on the IP firewall in your production Dataverse environment and set allowed IP addresses in the ranges associated with your office locations and not any external IP location, like a coffee shop. If a user tries to access organizational resources from a coffee shop, Dataverse denies access in real time.\nKey benefits\nTurning on the IP firewall in your Power Platform environments offers several key benefits.\nMitigate insider threats like data exfiltration\n: A malicious user who tries to download data from Dataverse using a client tool like Excel or Power BI from a disallowed IP location is blocked from doing so in real time.\nPrevent token replay attacks\n: If a user steals an access token and tries to use it to access Dataverse from outside allowed IP ranges, Dataverse denies the attempt in real time.\nIP firewall protection works in both interactive and noninteractive scenarios.\nHow does the IP firewall work?\nWhen a request is made to Dataverse, the request IP address is evaluated in real time against the IP ranges configured for the Power Platform environment. If the IP address is in the allowed ranges, the request is allowed. If the IP address is outside the IP ranges configured for the environment, the IP firewall denies the request with an error message:\nThe request you are trying to make is rejected as access to your IP is blocked. Contact your administrator for more information\n.\nPrerequisites\nThe IP firewall is a feature of\nManaged Environments\n.\nYou must have a Power Platform admin role to enable or disable the IP firewall.\nEnable the IP firewall\nYou can enable the IP firewall in a Power Platform environment by using either Power Platform admin center or the Dataverse OData API.\nEnable the IP firewall using Power Platform admin center\nSign in to\nPower Platform admin center\nâ¯as an administrator.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nIdentity and access\n.\nIn the\nIdentity and access management\npage, select\nIP firewall\n.\nIn the\nSet up IP firewall\npane, select an environment. Then select\nSet up IP firewall\n.\nIn the\nSet up IP firewall for this environment\npane, select\nIP Firewall\nto\nOn\n.\nUnder\nAllowed list of IP addresses\n, specify the allowed IP ranges in classless interdomain routing (CIDR) format as per\nRFC 4632\n. If you have multiple IP ranges, separate them with a comma. This field accepts up to 4,000 alphanumeric characters and allows a maximum of 200 IP ranges. IPv6 addresses are allowed both in hexadecimal and compressed format.\nSelect other advanced settings, as appropriate:\nAllowed list of service tags\n: From the list, select service tags that can bypass IP firewall restrictions.\nAllow access for Microsoft trusted services\n: This setting enables Microsoft trusted services like monitoring and\nsupport user\netc. to bypass the IP firewall restrictions to access the Power Platform environment with Dataverse. Enabled by default.\nAllow access for all application users\n: This setting allows\nall application users\nthird-party and first-party access to Dataverse APIs. Enabled by default. If you clear this value, it only blocks third-party application users.\nEnable IP firewall in audit-only mode\n: This setting enables the IP firewall but allows requests regardless of their IP address. Enabled by default.\nReverse proxy IP addresses\n: If your organization has reverse proxies configured, enter the IP addresses separated by commas. The reverse proxy setting applies to both\nIP-based cookie binding\nand the IP firewall. Reach out to your network administrator to get the reverse proxy IP addresses.\nNote\nReverse proxy must be configured to send user client IP addresses in the\nforwarded\nheader.\nSelect\nSave\n.\nEnable IP firewall at an environment group-level\nTo configure IP firewall settings at the environment group-level, complete the following steps.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nIdentity and access\n.\nSelect a IP firewall pane.\nIn the pane that is displayed, select the\nEnvironment groups\ntab to which you want the security setting applied.Then select\nSet up IP firewall\n.\nIn the\nSet up IP firewall\npane, select\nIP Firewall\nto\nOn\n.\nUnder\nAllowed list of IP addresses\n, specify the allowed IP ranges in classless interdomain routing (CIDR) format as per\nRFC 4632\n. If you have multiple IP ranges, separate them with a comma. This field accepts up to 4,000 alphanumeric characters and allows a maximum of 200 IP ranges. IPv6 addresses are allowed both in hexadecimal and compressed format.\nSelect other advanced settings, as appropriate:\nAllowed list of service tags\n: From the list, select service tags that can bypass IP firewall restrictions.\nAllow access for Microsoft trusted services\n: This setting enables Microsoft trusted services like monitoring and\nsupport user\netc. to bypass the IP firewall restrictions to access the Power Platform environment with Dataverse. Enabled by default.\nAllow access for all application users\n: This setting allows\nall application users\nthird-party and first-party access to Dataverse APIs. Enabled by default. If you clear this value, it only blocks third-party application users.\nEnable IP firewall in audit-only mode\n: This setting enables the IP firewall but allows requests regardless of their IP address. Enabled by default.\nReverse proxy IP addresses\n: If your organization has reverse proxies configured, enter the IP addresses separated by commas. The reverse proxy setting applies to both\nIP-based cookie binding\nand the IP firewall. Reach out to your network administrator to get the reverse proxy IP addresses.\nSelect\nSave\n.\nNote\nReverse proxy must be configured to send user client IP addresses in the\nforwarded\nheader.\nSelected settings are applied to all the environments in that environment group.\nEnable IP firewall using the Dataverse OData API\nYou can use the Dataverse OData API to retrieve and modify values within a Power Platform environment. For detailed guidance, see\nQuery data using the Web API\nand\nUpdate and delete table rows using the Web API (Microsoft Dataverse)\n.\nYou have the flexibility to select the tools that you prefer. Use the following documentation to retrieve and modify values through the Dataverse OData API:\nUse Insomnia with Dataverse Web API\nQuick Start Web API with PowerShell and Visual Studio Code\nConfigure the IP firewall by using the OData API\nPATCH https://{yourorg}.api.crm*.dynamics.com/api/data/v9.2/organizations({yourorgID})\nHTTP/1.1\nContent-Type: application/json\nOData-MaxVersion: 4.0\nOData-Version: 4.0\nPayload\n[\n {\n \"enableipbasedfirewallrule\": true,\n \"allowediprangeforfirewall\": \"18.205.0.0/24,21.200.0.0/16\",\n \"enableipbasedfirewallruleinauditmode\": true,\n \"allowedservicetagsforfirewall\": \"AppService,ActionGroup,ApiManagement,AppConfiguration,AppServiceManagement,ApplicationInsightsAvailability,AutonomousDevelopmentPlatform,AzureActiveDirectory,AzureAdvancedThreatProtection,AzureArcInfrastructure,AzureAttestation,AzureBackup,AzureBotService\",\n \"allowapplicationuseraccess\": true,\n \"allowmicrosofttrustedservicetags\": true\n }\n]\nenableipbasedfirewallrule\nâ Enable the feature by setting the value to\ntrue\n, or disable it by setting the value to\nfalse\n.\nallowediprangeforfirewall\nâ List the IP ranges that should be allowed. Provide them in CIDR notation, separated by a comma.\nImportant\nMake sure that the service tag names exactly match what you see on the IP firewall's settings page. If there's any discrepancy, IP restrictions might not work correctly.\nenableipbasedfirewallruleinauditmode\nâ A value of\ntrue\nindicates audit-only mode, whereas a value of\nfalse\nindicates enforcement mode.\nallowedservicetagsforfirewall\nâ List the service tags that should be allowed, separated by a comma. If you don't want to configure any service tags, leave the value null.\nallowapplicationuseraccess\nâ The default value is\ntrue\n.\nallowmicrosofttrustedservicetags\nâ The default value is\ntrue\n.\nImportant\nWhen\nAllow Access for Microsoft trusted services\nand\nAllow access for all application users\nare disabled, some services that use Dataverse, such as Power Automate flows, might no longer work.\nTest the IP firewall\nYou should test the IP firewall to verify that it's working.\nFrom an IP address that isn't in the allowed list of IP addresses for the environment, browse to your Power Platform environment URI.\nYour request should be rejected with a message that says, \"The request you are trying to make is rejected as access to your IP is blocked. Contact your administrator for more information.\"\nFrom an IP address that's in the allowed list of IP addresses for the environment, browse to your Power Platform environment URI.\nYou should have the access to the environment that's defined by your security role.\nYou should test the IP firewall in your test environment first, followed by audit-only mode in Production environment before enforcing the IP firewall on your Production environment.\nNote\nBy default,\nTDS endpoint\nis turned on within the Power Platform environment.\nSPN filtering for application users\nThe IP Firewall feature in Power Platform allows administrators to restrict access to environments based on IP address ranges. For scenarios where specific application users (Service Principal Names or SPNs) need to bypass these restrictions, you can enable SPN filtering using an API-based approach.\nSteps to enable SPN filtering\nAdd the application user.\nIf not already added, add the\napplication user\nto the target environment and assign the appropriate security roles.\nExample:\nAdd the app user with ID 123 and name TestSPN to the environment and assign the necessary roles\nRetrieve the system user ID.\nUse the following API call to fetch the\nsystemuserid\nfor the application user:\nGET https://{root-url}/api/data/v9.0/systemusers?$filter=applicationid eq {application-id}&$select=systemuserid\nHTTP/1.1\nContent-Type: application/json\nOData-MaxVersion: 4.0\nOData-Version: 4.0\nAllowlist the application user.\nPOST https://{yourorg}.api.crm*.dynamics.com/api/data/v9.2/systemusers(SystemuserID)\nHTTP/1.1\nContent-Type: application/json\nOData-MaxVersion: 4.0\nOData-Version: 4.0\nPayload\n[\n {\n \"isallowedbyipfirewall\": true\n }\n]\nConfigure IP firewall settings in PPAC.\nNavigate to the Power Platform Admin Center (PPAC) and configure the IP Firewall settings.\nEnsure that the option \"Allow access for all application users\" is unchecked to enforce filtering.\nLicensing requirements for IP firewall\nThe IP firewall is only enforced on environments that are activated for Managed Environments. Managed Environments are included as an entitlement in standalone Power Apps, Power Automate, Microsoft Copilot Studio, Power Pages, and Dynamics 365 licenses that give premium usage rights. Learn more about\nManaged Environment licensing\nwith the\nLicensing overview for Microsoft Power Platform\n.\nIn addition, access to using IP firewall for Dataverse requires users in the environments where the IP firewall is enforced to have one of these subscriptions:\nMicrosoft 365 or Office 365 A5/E5/G5\nMicrosoft 365 A5/E5/F5/G5 Compliance\nMicrosoft 365 F5 Security & Compliance\nMicrosoft 365 A5/E5/F5/G5 Information Protection and Governance\nMicrosoft 365 A5/E5/F5/G5 Insider Risk Management\nLearn more about Microsoft 365 licenses\nFrequently asked questions (FAQ)\nWhat does the IP firewall cover in Power Platform?\nThe IP firewall is supported in any Power Platform environment that includes Dataverse.\nHow soon does a change to the IP address list take effect?\nChanges to the list of allowed IP addresses or ranges typically take effect in about 5-10 minutes.\nDoes this feature work in real time?\nIP firewall protection works in real time. Since the feature works at the network layer, it evaluates the request after the authentication request is completed.\nIs this feature enabled by default in all environments?\nThe IP firewall isn't enabled by default. The Power Platform administrator needs to enable it for Managed Environments.\nWhat is audit-only mode?\nIn audit-only mode, the IP firewall identifies the IP addresses that are making calls to the environment and allows them all, whether they're in an allowed range or not. It's helpful when you're configuring restrictions on a Power Platform environment. We recommend that you enable audit-only mode for at least a week and disable it only after careful review of the\naudit logs\n.\nIs this feature available in all the environments?\nThe IP firewall is available for\nManaged Environments\nonly.\nIs there a limit on the number of IP addresses that I can add in the IP address text box?\nYou can add up to 200 IP addresses ranges in CIDR format as per\nRFC 4632\n, separated by commas.\nWhat should I do if requests to Dataverse start to fail?\nAn incorrect configuration of IP ranges for IP firewall might be causing this issue. You can check and verify the IP ranges on the IP firewall settings page. We recommend that you turn on the IP firewall in Audit-only mode before enforcing it.\nHow do I download the audit log for audit-only mode?\nUse the Dataverse OData API to download the audit log data in JSON format. The format of the audit log API is:\nhttps://[orgURI]/api/data/v9.1/audits?$select=createdon,changedata,action&$filter=action%20eq%20118&$orderby=createdon%20desc&$top=1\nReplace\n[orgURI]\nwith the Dataverse environment URI.\nSet the action value to\n118\nfor this event.\nSet the number of items to return in\ntop=1\nor specific the number you want to return.\nMy Power Automate flows aren't working as expected after configuring the IP firewall on my Power Platform environment. What should I do?\nIn the IP firewall settings, allow the service tags listed in\nManaged connectors outbound IP addresses\n.\nI have configured the reverse proxy address correctly, but the IP firewall isn't working. What should I do?\nMake sure your reverse proxy is configured to send the client IP address in the forwarded header.\nIP firewall audit functionality isn't working in my environment. What should I do?\nIP firewall audit logs aren't supported in tenants enabled for bring-your-own-key\n(BYOK)\nencryption keys. If your tenant is enabled for bring-your-own-key, then all environments in a BYOK-enabled tenant are locked down to SQL only, therefore audit logs can only be stored in SQL. We recommend that you migrate to\ncustomer-managed key\n. To migrate from BYOK to customer-managed key (CMKv2), follow the steps in\nMigrate bring-your-own-key (BYOK) environments to customer-managed key\n.\nDoes IP firewall support IPv6 IP ranges?\nYes, IP firewall supports IPv6 IP ranges.\nNext steps\nSecurity in Microsoft Dataverse\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "IP Firewall",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/cross-tenant-restrictions": {
      "content_hash": "sha256:415ad01ddf6f09f2b4c937aa9c8a737ef3c8da74e07d52242ac2445efe0b06d0",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCross-tenant inbound and outbound restrictions\nFeedback\nSummarize this article for me\nMicrosoft Power Platform has a rich ecosystem of connectors based on Microsoft Entra that allow authorized Microsoft Entra users to build compelling apps and flows establishing connections to the business data available through these data stores. Tenant isolation makes it easy for administrators to ensure that these connectors can be harnessed in a safe and secure way within the tenant while minimizing the risk of data exfiltration outside the tenant. Tenant isolation allows Power Platform administrators to effectively govern the movement of tenant data from Microsoft Entra authorized data sources to and from their tenant.\nPower Platform tenant isolation is different from Microsoft Entra ID-wide tenant restriction. It\ndoesn't\nimpact Microsoft Entra ID-based access outside of Power Platform. Power Platform tenant isolation only works for connectors using Microsoft Entra ID-based authentication such as Office 365 Outlook or SharePoint.\nWarning\nThere's a\nknown issue\nwith\nAzure DevOps connector\nthat results in tenant isolation policy to not be enforced for connections established using this connector. If an insider attack vector is a concern, we recommend you limit using the connector or its actions using data policies.\nThe default configuration in Power Platform with tenant isolation\nOff\nis to allow cross-tenant connections to be established seamlessly, if the user from tenant A establishing the connection to tenant B presents appropriate Microsoft Entra credentials. If admins want to allow only a select set of tenants to establish connections to or from their tenant, they can turn tenant isolation\nOn\n.\nWith tenant isolation\nOn\n,\nall\ntenants are restricted. Inbound (connections to the tenant from external tenants) and outbound (connections from the tenant to external tenants) cross-tenant connections are blocked by Power Platform even if the user presents valid credentials to the Microsoft Entra-secured data source. You can use rules to add exceptions.\nAdmins can specify an explicit allow list of tenants that they want to allow\ninbound\n,\noutbound\n, or both, which bypasses tenant isolation controls when configured. Admins can use a special pattern â*â to allow\nall\ntenants in a specific direction when tenant isolation is turned on. All other cross-tenant connections except the ones in the allow list are rejected by Power Platform.\nTenant isolation can be configured in theâ¯Power Platform admin center. It affects Power Platform canvas apps and Power Automate flows. To set up tenant isolation, you need to be aâ¯tenant admin.\nPower Platform tenant isolation ability is available with two options: one-way or two-way restriction.\nUnderstand tenant isolation scenarios and impact\nBefore you begin configuring the tenant isolation restrictions, review the following list to understand the scenarios and impact of tenant isolation.\nAdmin wants to turn on tenant isolation.\nAdmin is concerned that existing apps and flows using cross tenant connections stop working.\nAdmin decides to enable tenant isolation and add exception rules to eliminate the impact.\nAdmin runs the cross-tenant isolation reports to determine the tenants that need to be exempt. More information:\nTutorial: Create cross tenant isolation reports (preview)\nTwo-way tenant isolation (inbound and outbound connection restriction)\nTwo-way tenant isolation blocks connection establishment attempts to your tenant from other tenants. Additionally, two-way tenant isolation also blocks connection establishment attempts from your tenant to other tenants.\nIn this scenario, the tenant admin allows two-way tenant isolation on the Contoso tenant while the external Fabrikam tenant hasn't been added to the allow list.\nUsers signed in to Power Platform in the Contoso tenant canât establish outbound Microsoft Entra ID-based connections to data sources in the Fabrikam tenant despite presenting appropriate Microsoft Entra credentials to establish the connection. This is outbound tenant isolation for the Contoso tenant.\nSimilarly, users signed in to Power Platform in the Fabrikam tenant canât establish inbound Microsoft Entra ID-based connections to data sources in the Contoso tenant despite presenting appropriate Microsoft Entra credentials to establish the connection. This is inbound tenant isolation for the Contoso tenant.\nConnection creator tenant\nConnection sign-in tenant\nAccess allowed?\nContoso\nContoso\nYes\nContoso (tenant isolation\nOn\n)\nFabrikam\nNo (outbound)\nFabrikam\nContoso (tenant isolation\nOn\n)\nNo (inbound)\nFabrikam\nFabrikam\nYes\nNote\nA connection attempt initiated by a guest user, from their host tenant that targets data sources within the same host tenant, isn't evaluated by the tenant isolation rules.\nTenant isolation with allow lists\nOne-way tenant isolation or inbound isolation blocks connection establishment attempts to your tenant from other tenants.\nScenario: Outbound allow list â Fabrikam is added to the outbound allow list of the Contoso tenant\nIn this scenario, the admin adds the Fabrikam tenant in the outbound allow list while tenant isolation is\nOn\n.\nUsers signed in to Power Platform in the Contoso tenant can establish outbound Microsoft Entra ID-based connections to data sources in the Fabrikam tenant if they present appropriate Microsoft Entra credentials to establish the connection. Outbound connection establishment to the Fabrikam tenant is permitted by virtue of the configured allowl ist entry.\nHowever, users signed in to Power Platform in the Fabrikam tenant still can't establish inbound Microsoft Entra ID-based connections to data sources in the Contoso tenant despite presenting appropriate Microsoft Entra credentials to establish the connection. Inbound connection establishment from the Fabrikam tenant is still disallowed even as the allow list entry is configured and permits outbound connections.\nConnection creator tenant\nConnection sign-in tenant\nAccess allowed?\nContoso\nContoso\nYes\nContoso (tenant isolation\nOn\n)\nFabrikam added to outbound allow list\nFabrikam\nYes\nFabrikam\nContoso (tenant isolation\nOn\n)\nFabrikam added to outbound allow list\nNo (inbound)\nFabrikam\nFabrikam\nYes\nScenario: Bidirectional allow list â Fabrikam is added to the inbound and outbound allow lists of the Contoso tenant\nIn this scenario, the admin adds the Fabrikam tenant to both the inbound and outbound allow lists while tenant isolation is\nOn\n.\nConnection creator tenant\nConnection sign-in tenant\nAccess allowed?\nContoso\nContoso\nYes\nContoso (tenant isolation\nOn\n)\nFabrikam added to both allow lists\nFabrikam\nYes\nFabrikam\nContoso (tenant isolation\nOn\n)\nFabrikam added to both allow lists\nYes\nFabrikam\nFabrikam\nYes\nAllow tenant isolation and configure the allow list\nGo to the\nPower Platform admin center\n.\nIn the navigation pane, select\nSecurity\n.\nIn the\nSecurity\npane, select\nIdentity and access\n.\nIn the\nIdentity and access management\npage, select\nTenant isolation\n.\nTo allow tenant isolation, turn on the\nRestrict cross-tenant connections\noption.\nTo allow cross tenant communication, select\nAdd exceptions\nin the\nTenant isolation\npane.\nIf tenant isolation is\nOff\n, you can still add or edit the exception list. However, the exception lists aren't enforced until you turn on tenant isolation.\nFrom the\nAllowed direction\ndropdown list, select the direction of the allow list entry.\nEnter the value of the allowed tenant as either the tenant domain or tenant ID in the\nTenant ID\nfield. Once saved, the entry gets added to the allow list along with other allowed tenants. If you use the tenant domain to add the allow list entry, the Power Platform admin center automatically calculates the tenant ID.\nYou can use \"*\" as a special character to signify all tenants are allowed in the designated direction when tenant isolation is turned on.\nSelect\nSave\n.\nNote\nYou must have a Power Platform administrator role to see and set the tenant isolation policy.\nTo ensure that tenant isolation doesn't block any calls when used, turn tenant isolation\nOn\n, add a new tenant rule, set\nTenant ID\nas \"*\", and set allowed direction to\ninbound\nand\noutbound\n.\nDue to technical limitations, the threshold limit for rules is 500.\nYou can perform all the allow list operations like add, edit, and delete while tenant isolation is turned\nOn\nor\nOff\n. Allow list entries do have an effect on the connection behavior when tenant isolation is turned\nOff\nsince all cross-tenant connections are allowed.\nDesign time impact on apps and flows\nUsers who create or edit a resource, affected by the tenant isolation policy, see a related error message. For example, Power Apps makers see the following error when they use cross-tenant connections in an app that's blocked by tenant isolation policies. The app doesn't add the connection.\nSimilarly, Power Automate makers see the following error when they try to save a flow that uses connections in a flow that's blocked by tenant isolation policies. The flow itself is saved, but it's marked as \"Suspended\" and isn't executed unless the maker resolves the data loss prevention policy (DLP) violation.\nRuntime impact on apps and flows\nAs an admin, you can decide to modify the tenant isolation policies for your tenant at any point. If apps and flows were created and executed in compliance with earlier tenant isolation policies, some of them might be negatively affected by any policy changes you make. Apps or flows that are in violation of the tenant isolation policy don't run successfully. For example, run history within Power Automate indicates that the flow run failed. Further, selecting the failed run shows details of the error.\nFor existing flows that donât run successfully because of the latest tenant isolation policy, run history within Power Automate indicates that the flow run failed.\nSelecting the failed run shows details of the failed flow run.\nNote\nIt takes about an hour for the latest tenant isolation policy changes to be assessed against active apps and flows. This change isn't instantaneous.\nKnown issues\nAzure DevOps connector\nuses Microsoft Entra authentication as the identity provider, but uses its own OAuth flow and STS for authorizing and issuing a token. Since the token returned from the ADO flow based on that Connectorâs configuration isn't from Microsoft Entra ID, the tenant isolation policy isn't enforced. As a mitigation, we recommend using other types of\ndata policies\nto limit the use of the connector or its actions.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Cross-Tenant Restrictions",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/manage-encryption-key": {
      "content_hash": "sha256:32883b672c9b86fc2830d25f9fb792f2e0eb369d89ed2aa500f99ea57bc99ebc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage the encryption key\nFeedback\nSummarize this article for me\nAll environments of Microsoft Dataverse use SQL Server Transparent Data Encryption (TDE) to perform real-time encryption of data when written to disk. This is also known as encryption at rest.\nBy default, Microsoft stores and manages the database encryption key for your environments so you don't have to. The managed keys feature in the Microsoft Power Platform admin center gives administrators the ability to self-manage the database encryption key that is associated with the Dataverse tenant.\nImportant\nStarting January 6, 2026, we'll discontinue support for bring-your-own-key (BYOK). Customers are encouraged to transition to customer-managed keys (CMK), an enhanced solution that offers improved functionality, broader support for data sources, and better performance. Learn more in\nManage your customer-managed encryption key\nand\nMigrate bring-your-own-key (BYOK) environments to customer-managed key\n.\nEncryption key management is only applicable to Azure SQL environment databases. The following features and services continue to use the Microsoft-managed encryption key to encrypt their data and can't be encrypted with the self-managed encryption key:\nCopilots and generative AI features in\nMicrosoft Power Platform and Microsoft Dynamics 365\nDataverse search\nElastic tables\nMobile Offline\nActivity Log (Microsoft 365 portal)\nExchange (Server-side sync)\nNote\nThe self-managed database encryption key feature must be turned on by Microsoft for your tenant before you can use the feature.\nTo use the data encryption management features for an environment, the environment must be created\nafter\nthe self-managed database encryption key feature is turned on by Microsoft.\nAfter the feature is turned on in your tenant, all new environments are created with Azure SQL storage only. These environments, regardless of whether they're encrypted with bring-your-own-key (BYOK) or a Microsoft-managed key, have restrictions with file upload size, can't use Azure Cosmos DB and data lake services, and Dataverse search indexes are encrypted with a Microsoft-managed key. To use these services, you must\nmigrate to a customer-managed key\n.\nFiles\nand\nImages\nwith sizes of less than 128 MB can be used if your environment is version 9.2.21052.00103 or higher.\nMost existing environments have file and log stored in non-Azure SQL databases. These environments can't be opted in to the self-managed encryption key. Only new environments (once you sign up for this program) can be enabled with a self-managed encryption key.\nIntroduction to key management\nWith key management, administrators can provide their own encryption key or have an encryption key generated for them, which is used to protect the database for an environment.\nThe key management feature supports both PFX and BYOK encryption key files, such as those stored in a hardware security module (HSM). To use the upload encryption key option, you need both the public and private encryption key.\nThe key management feature takes the complexity out of encryption key management by using Azure Key Vault to securely store encryption keys. Azure Key Vault helps safeguard cryptographic keys and secrets used by cloud applications and services. The key management feature doesn't require that you have an Azure Key Vault subscription and for most situations there's no need to access encryption keys used for Dataverse within the vault.\nThe managed keys feature lets you perform the following tasks:\nEnable the ability to self-manage database encryption keys that are associated with environments.\nGenerate new encryption keys or upload existing PFX or BYOK encryption key files.\nLock and unlock tenant environments.\nWarning\nWhile a tenant is locked, no one can access any environments within the tenant. More information:\nLock the tenant\nUnderstand the potential risk when you manage your keys\nAs with any business-critical application, personnel within your organization who have administrative-level access must be trusted. Before you use the key management feature, you should understand the risk when you manage your database encryption keys. It's conceivable that a malicious administrator (a person who is granted or has gained administrator-level access with intent to harm an organization's security or business processes) working within your organization might use the managed keys feature to create a key and use it to lock all environments in the tenant.\nConsider the following sequence of events.\nThe malicious administrator signs in to the Power Platform admin center, goes to the\nEnvironments\npage and selects\nManage encryption key\n. The malicious administrator then creates a new key with a password and downloads the encryption key to their local drive, and activates the new key. Now all the environment databases are encrypted with the new key. Next, the malicious administrator locks the tenant with the newly downloaded key, and then takes or deletes the downloaded encryption key.\nThese actions result in disabling all the environments within the tenant from online access and make all database backups unrestorable.\nImportant\nTo prevent the malicious administrator from interrupting the business operations by locking the database, the managed keys feature doesn't allow tenant environments to be locked for 72 hours after the encryption key has changed or activated. This provides up to 72 hours for other administrators to roll back any unauthorized key changes.\nEncryption key requirements\nIf you provide your own encryption key, your key must meet these requirements that are accepted by Azure Key Vault.\nThe encryption key file format must be PFX or BYOK.\n2048-bit RSA.\nRSA-HSM key type (requires a Microsoft Support request).\nPFX encryption key files must be password protected.\nFor more information about generating and transferring an HSM-protected key over the internet, see\nHow to generate and transfer HSM-protected keys for Azure Key Vault\n. Only\nnCipher Vendor HSM key\nis supported. Before generating your HSM key, go to the Power Platform admin center\nManage encryption keys\n>\nCreate New key\nwindow to obtain the subscription ID for your environment region. You need to copy and paste this subscription ID into your HSM to create the key. This ensures that only our Azure Key Vault can open your file.\nKey management tasks\nTo simplify the key management tasks, the tasks are broken down into three areas:\nGenerate or upload the encryption key for a tenant\nActivate an encryption key for a tenant\nManage encryption for an environment\nAdministrators can use the\nPower Platform admin center\nor the\nPower Platform administration module\ncmdlets to perform the tenant protection key management tasks described here.\nGenerate or upload the encryption key for a tenant\nAll encryption keys are stored in the Azure Key Vault, and there can only be one active key at any time. Since the active key is used to encrypt all the environments in the tenant, managing the encryption is operated at the tenant level. Once the key is activated, each individual environment can then be selected to use the key for encryption.\nUse this procedure to set the managed key feature the first time for an environment or to change (or roll over) an encryption key for an already self-managed tenant.\nWarning\nWhen you perform the steps described here for the first time, you're opting in to self-managing your encryption keys. More information:\nUnderstand the potential risk when you manage your keys\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nSelect\nManage encryption keys\non the toolbar.\nSelect\nConfirm\nto acknowledge the managed key risk.\nSelect\nNew key\non the toolbar.\nOn the left pane, complete the details to generate or upload a key:\nSelect a\nRegion\n. This option is only shown if your tenant has multiple regions.\nEnter a\nKey name\n.\nChoose from the following options:\nTo create a new key, select\nGenerate new (.pfx)\n. More information:\nGenerate a new key (.pfx)\nTo use your own generated key, select\nUpload (.pfx or .byok)\n. More information:\nUpload a key (.pfx or .byok)\nSelect\nNext\n.\nGenerate a new key (.pfx)\nEnter a password and then reenter the password to confirm.\nSelect\nCreate\nand then select the created file notification on your browser.\nThe encryption key .pfx file is downloaded to your web browser's default download folder. Save the file in a secure location (we recommend that this key is backed up along with its password).\nUpload a key (.pfx or .byok)\nSelect\nUpload the Key\n, select the .pfx or .byok\n1\nfile, and then select\nOpen\n.\nEnter the password for the key and then select\nCreate\n.\n1\nFor .byok encryption key files, make sure you use the subscription ID as shown on the screen when you export the encryption key from your local HSM. More information:\nHow to generate and transfer HSM-protected keys for Azure Key Vault\nNote\nTo reduce the number of steps for the administrator to manage the key process, the key is automatically activated when it's uploaded the first time. All subsequent key uploads require an extra step to activate the key.\nActivate an encryption key for a tenant\nOnce an encryption key is generated or uploaded for the tenant, it can be activated.\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nSelect\nManage encryption keys\non the toolbar.\nSelect\nConfirm\nto acknowledge the managed key risk.\nSelect a key that has an\nAvailable\nstate and then select\nActivate key\non the toolbar.\nSelect\nConfirm\nto acknowledge the key change.\nWhen you activate a key for the tenant, it takes a while for the key management service to activate the key. The status of the\nKey state\ndisplays the key as\nInstalling\nwhen the new or uploaded key is activated.\nOnce the key is activated, the following occurs:\nAll encrypted environments automatically get encrypted with the active key (there's no downtime with this action).\nWhen activated, the encryption key is applied to all environments that are changed from Microsoft-provided to self-managed encryption key.\nImportant\nTo streamline the key management process so that all environments are managed by the same key, the active key can't be updated when there are locked environments. All locked environments must be unlocked before a new key can be activated. If there are locked environments that don't need to be unlocked, they must be deleted.\nNote\nAfter an encryption key is activated, you can't activate another key for 24 hours.\nManage encryption for an environment\nBy default, each environment is encrypted with the Microsoft-provided encryption key. Once an encryption key is activated for the tenant, administrators can elect to change the default encryption to use the activated encryption key. To use the activated key, follow these steps.\nApply encryption key to an environment\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nOpen a\nMicrosoft-provided\nencrypted environment.\nSelect\nSee all\n.\nIn the\nEnvironment Encryption\nsection, select\nManage\n.\nSelect\nConfirm\nto acknowledge the managed key risk.\nSelect\nApply this key\nto accept changing the encryption to use the activated key.\nSelect\nConfirm\nto acknowledge that you're managing the key directly and that there's downtime for this action.\nReturn a managed encryption key back to Microsoft-provided encryption key\nReturning to the Microsoft-provided encryption key configures the environment back to the default behavior where Microsoft manages the encryption key for you.\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nSelect an environment that is encrypted with a self-managed key.\nSelect\nSee all\n.\nIn the\nEnvironment Encryption\nsection, select\nManage\nand then select\nConfirm\n.\nUnder\nReturn to standard encryption management\n, select\nReturn\n.\nFor production environments, confirm the environment by entering the environment's name.\nSelect\nConfirm\nto return to standard encryption key management.\nLock the tenant\nSince there's only one active key per tenant, locking the encryption for the tenant\ndisables all the environments\nthat are in the tenant. All locked environments remain inaccessible to everyone, including Microsoft, until a Power Platform admin in your organization unlocks it by using the key that was used to lock it.\nCaution\nYou should never lock the tenant environments as part of your normal business process. When you lock a Dataverse tenant, all the environments are taken offline and they can't be accessed by anyone, including Microsoft. Additionally, services such as synchronization and maintenance are all stopped. If you decide to leave the service, locking the tenant can ensure that your online data is never accessed again by anyone.\nNote the following about tenant environments locking:\nLocked environments can't be restored from backup.\nLocked environments are deleted if not unlocked after 28 days.\nYou can't lock environments for 72 hours after an encryption key change.\nLocking a tenant\nlocks all active environments\nwithin the tenant.\nImportant\nYou must wait at least one hour after you lock active environments before you can unlock them.\nOnce the lock process begins, all encryption keys with either an Active or Available state are deleted. The lock process can take up to an hour and during this time unlocking locked environments isn't allowed.\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nSelect\nManage encryption keys\non the toolbar.\nSelect the\nActive\nkey and then select\nLock active environments\n.\nOn the right pane select\nUpload active key\n, browse to and select the key, enter the password, and then select\nLock\n.\nWhen prompted, enter the text that is displayed on your screen to confirm that you want to lock all environments in the region, and then select\nConfirm\n.\nUnlock locked environments\nTo unlock environments, you must first\nupload\nand then\nactivate\nthe tenant encryption key with the same key that was used to\nlock the tenant\n. Locked environments don't get unlocked automatically once the key has been activated. Each locked environment has to be unlocked individually.\nImportant\nYou must wait at least one hour after you lock active environments before you can unlock them.\nThe unlock process can take up to an hour. Once the key is unlocked, you can use the key to\nManage encryption for an environment\n.\nYou can't generate a new or upload an existing key until all locked environments are unlocked.\nUnlock encryption key\nSign in to the\nPower Platform admin center\nas an admin (Dynamics 365 admin or Microsoft Power Platform admin).\nSelect the\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage is displayed.\nSelect\nManage encryption keys\non the toolbar.\nSelect the key that has a\nLocked\nstate, and then on the command bar select\nUnlock key\n.\nSelect\nUpload locked key\n, browse to and select the key that was used to lock the tenant, enter the password, and then select\nUnlock\n.\nThe key goes into an\nInstalling\nstate. You must wait until the key is in an\nActive\nstate before you can unlock locked environments.\nTo unlock an environment, see the next section.\nUnlock environments\nGo to the\nEnvironments\npage, and then select the locked environment name.\nTip\nDon't select the row. Select the environment name.\nIn the\nDetails\nsection, select\nSee all\nto display the\nDetails\npane on the right.\nIn the\nEnvironment\nencryption section on the\nDetails\npane, select\nManage\n.\nOn the\nEnvironment encryption\npage, select\nUnlock\n.\nSelect\nConfirm\nto confirm that you want to unlock the environment.\nRepeat the previous steps to unlock other environments.\nEnvironment database operations\nA customer tenant can have environments that are encrypted using the Microsoft managed key and environments that are encrypted with the customer managed key. To maintain data integrity and data protection, the following controls are available when managing environment database operations.\nRestore\nThe environment to overwrite (the restored to environment) is restricted to the same environment that the backup was taken from or to another environment that is encrypted with the same customer-managed key. Additionally, a past backup taken when the environment was encrypted with Microsoft-managed key can't be restored to an environment that is currently encrypted with the customer-managed key. In other words, restoring a backup to an environment is allowed when the current environment encryption state (whether Microsoft-managed key or customer-managed key) matches the environment encryption state at the time of when the backup was taken.\nCopy\nThe environment to overwrite (the copied to environment) is restricted to another environment that is encrypted with the same customer-managed key.\nNote\nIf a Support Investigation environment was created to resolve a support issue in a customer-managed environment, the encryption key for the Support Investigation environment must be changed to customer-managed key before the Copy environment operation can be performed.\nReset\nThe environment's encrypted data is deleted, including backups. After the environment is reset, the environment encryption will revert back to the Microsoft-managed key.\nRelated content\nSQL Server: Transparent Data Encryption (TDE)\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Encryption",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/analytics-common-data-service": {
      "content_hash": "sha256:9b8e8af7ecf52a0e3c248579a424fc1eb9a5f14c3cca3511557aee3d804cc732",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nView and download Microsoft Dataverse analytics\nFeedback\nSummarize this article for me\nViewing metrics for your organization is now an improved experience. You no longer need to install or update a solution. Instead, you can view Dataverse analytics right from the Microsoft Power Platform admin center to quickly view adoption and user metrics for your organization.\nTo access these reports:\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, under\nProducts\n, select\nDataverse\n.\nView the Dataverse analytics options on the page.\nRequired roles to view the reports\nAdmins with these roles and a\nlicense\ncan view the reports in Dataverse analytics:\nEnvironment Admin - can view reports for the environments that the admin has access to.\nPower Platform admin â can view reports for all environments.\nDynamics 365 admin - can view reports for all environments.\nMicrosoft 365 Global admin â can view reports for all environments.\nFor more information on the different roles for managing your tenant across the platform, see\nUse service admin roles to manage your tenant\n.\nKey highlights\nMonitor adoption and use\n: Use data to work toward your goals over a period of time. You can identify your most active users, the number and types of operations they're performing, number of pages requests, most-used entities, workflows, plug-ins, and more.\nManage storage and performance\n: Optimize performance by monitoring storage quotas, storage use, and top tables by size.\nTroubleshoot effectively\n: Quickly diagnose and troubleshoot errors by drilling down into the details of your top failing workflows and API calls.\nHome (default) dashboard\nThe home (default) dashboard shows you information on the number of active Dataverse users, storage usage, the most active workflows, and more.\nHome dashboard details\nChart element\nDescription\nActive Users\nNumber of active users (unique users) who performed an operation that caused one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\n.\nAPI Calls\nNumber of API calls made by the environment with a Dataverse database for a selected time period.\nAPI Pass Rate\nPercentage of API calls pass rate out of total API calls made in the environment with a Dataverse database over a specified time period.\nExecutions\nNumber of plug-ins were executed in the environment with a Dataverse database over a specified time period.\nTotal Operations\nNumber of operations (\nCreate\n,\nUpdate\n,\nDelete\n,\nRead\n) occurred in the environment with a Dataverse database over a specified time period.\nMost Active Users Performing Operations\nList of most active users who performed an operation that caused a\nCreate\n,\nUpdate\n,\nRead\n, or\nDelete\nSDK call in the Dynamics 365 environment over a selected time period.\nTop Plug-ins by Failures\nNumber of 10 most failing plug-ins in the environment with a Dataverse database over a specified time period.\nActive users dashboard\nThe Active users dashboard shows you how many Dynamics 365 users there are, how many licenses are in use, what custom entities are used most frequently, and more.\nActive users dashboard details\nNote\nExports are limited to a maximum of 3000 records.\nChart element\nDescription\nTotal Active Users\nTotal number of active users (unique users) who performed an operation that caused one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\n.\nMost Used Entities\nTen Entities which had the most\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate SDK Calls\n.\nTotal Page Requests\nThe number of page load requests for forms, dashboards, and reports. This is the count of requests received by the Dynamics 365 server. Pages that are cached while browsing won't be counted.\nTotal Operations\nThis chart shows how many operations (create, update, deletes, reads) have occurred in the environment with a Dataverse database for the selected time period.\nActive Users Performing Specific Operations\nTotal number of active users (unique users) over time who performed an operation that caused one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\n.\nActive Users\nNumber of active users (unique users) in your environment who performed an operation that caused one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\nover time.\nMost Active Users Performing Operations\nList of most active users (unique users) over time who performed an operation that caused one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\n.\nMost Used Custom Entities\nList of custom entities which had the most\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate SDK Calls\n.\nMost Used OOB Entities\nList of out-of-box entities which had the most\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate SDK Calls\n.\nUsage Active Users by OS\nThe number of active users by operating system.\nActive Users by Device Type\nThe number of active users by device type.\nActive Users by Browser\nThe number of active users by browser.\nActive Users by Security Roles\nThe number of active users by security roles.\nUsers by Business Unit\nThe number of active users by business unit.\nNumber of Creates by Entity\nHow many create operations are performed by the selected user in the environment with a Dataverse database for the selected time period.\nNumber of Updates by Entity\nHow many update operations are performed on different entities by the selected user in the environment with a Dataverse database for the selected time period.\nNumber of Reads by Entity\nHow many read operations are performed on different entities by the selected user in the environment with a Dataverse database for the selected time period.\nNumber of Deletes by Entity\nHow many delete operations are performed on different entities by the selected user in the environment with a Dataverse database for the selected time period.\nTotal Operations Over Time\nThe total operations performed by the selected user in the environment with a Dataverse database over the selected time period.\nTotal Operations by Entity\nThe total operations performed on different entities by the selected user in the environment with a Dataverse database for the selected time period.\nActive Users by Entities\nShow the active users distributed over different entities\nNote\nRetrieve\nand\nRetrieveMultiple\nSDK calls are reported as\nReads\n.\nActive usage chart update frequency\nThis table details the frequency of different active usage chart updates.\nChart\nUpdate frequency\nTotal Active Users\n24 hours\nMost Used Entities\n24 hours\nMost Active Users (Reads)\n24 hours\nTotal API Calls\n24 hours\nTotal Page Requests\n24 hours\nMost Active Users (Changes)\n24 hours\nTotal Operations\n24 hours\nActive Users Performing Specific Operations\n24 hours\nActive Users\n24 hours\nMost Active Users Performing Operations\n24 hours\nMost Used Custom Entities\n24 hours\nMost Used OOB Entities\n24 hours\nSystem Jobs dashboard\nThis dashboard helps you monitor and troubleshoot workflows.\nSystem jobs dashboard details\nChart element\nDescription\nWorkflow Executions\nThis chart shows the number of workflows executed in a environment with a Dataverse database over a specified time.\nSystem Jobs Pass Rate\nThis chart shows the system job's pass rate as percentage of system jobs executed in the environment with a Dataverse database over a specified time.\nSystem Jobs Throughput/Minute\nThis chart shows the average of system jobs executed per hour in the environment with a Dataverse database over a specified time.\nExecutions and Backlog\nThis chart shows the number of executions and the backlog for system jobs in the environment with a Dataverse database over a specified time.\nMost Active Workflows\nThis chart shows the top-10 most executed workflows in the environment with a Dataverse database over a specified time.\nTop Workflows by Failures\nThis chart shows the top-10 most failing workflows in the environment with a Dataverse database over the specified time. Select a workflow to see the failures and their number of occurrences.\nSystem jobs chart update frequency\nThis table details the frequency of different system jobs chart updates:\nChart\nUpdate frequency\nWorkflow Executions\n24 hours\nSystem Jobs Pass Rate\n24 hours\nSystem Jobs Throughput / Hour\n24 hours\nMost Active Workflows\n24 hours\nSystem Jobs Executions and Backlog\n24 hours\nTop Workflows by Failures\n24 hours\nPlug-ins dashboard\nThis dashboard helps you monitor and troubleshoot plug-ins.\nPlug-in dashboard details\nChart element\nDescription\nPlug-in Success Rate\nThis chart shows the plug-in pass rate as percentage of total plug-in executions executed in the environment with a Dataverse database over a specified time.\nPlug-in Executions\nThis chart shows how many plug-ins executed in the environment with a Dataverse database over a specified time.\nAverage Plug-in Execution Time\nThis chart shows average time taken to successfully execute a plug-in in the environment with a Dataverse database over a specified time.\nMost Active Plug-ins\nThis chart shows the top-10 most executed plug-ins in the environment with a Dataverse database over a specified time.\nTop Plug-ins by Failures\nThis chart shows the top-10 most failing plug-ins in the environment with a Dataverse database over a specified time.\nPlug-in chart update frequency\nThis table details the frequency of different plug-in chart updates:\nChart\nUpdate frequency\nPlug-in Success Rate\n24 hours\nMost Active Plug-ins\n24 hours\nPlug-in Executions\n24 hours\nAverage Plug-in Execution Time\n24 hours\nTop Plug-ins by Failures\n24 hours\nAPI calls statistics dashboard\nThis dashboard helps you monitor and troubleshoot API calls.\nAPI calls statistics dashboard details\nChart element\nDescription\nAPI Success Rate\nThis chart shows the API success rate as percentage of total API calls made in the environment with a Dataverse database over a specified time.\nTop API by Failures\nThis chart shows top-10 failing API calls in the environment with a Dataverse database over a specified time.\nTotal API Calls\nThis chart shows total number of API calls made in the environment with a Dataverse database over a specified time.\nMost Used API\nThis chart shows top-10 most executed API calls in the environment with a Dataverse database database. Adding the individual counts provide the total of the top-10 API calls. This is not be the same as the all-up Total API Calls metric.\nAPI Calls\nThis chart shows the number of API calls made over time in the environment with a Dataverse database over a specified time. Adding up the individual counts equals the Total API Calls count.\nAPI peak call rate\nThis chart shows capacity consumption relative to the API call limit. More information:\nAPI peak call rate report\nAPI calls statistics chart update frequency\nThis table details the frequency of API calls statistics chart updates:\nChart\nUpdate frequency\nAPI Success Rate\n24 hours\nTop API by Failures\n24 hours\nMost Used API\n24 hours\nTotal API Calls\n24 hours\nAPI Calls\n24 hours\nAPI peak call rate\n24 hours\nAPI peak call rate report (preview)\nImportant\nThis is a preview feature.\nPreview features aren't meant for production use and may have restricted functionality. These features are available before an official release so that customers can get early access and provide feedback.\nThe API peak call rate report shows API usage graph with the number of requests per user/application for the selected interval. This report helps you monitor the API usage, and avoid hitting the\nservice protection limits\n.\nChart element\nDescription\nSDSService and OData\nThe bars show the max number of API requests by app/users within 5-min interval. The maximum is the number of requests per user per five minutes that is based on your licenses and capacity add-ons.\nAPI Peak limit\nThe peak requests per second recorded by the request count API limit. This is a measure of request count per unit time.\nAnalyze API peak call rate\nTo help interpret and act on the capacity, the graph shows the API peak limit. The bars show the max number of API requests by app/users within a 5-minute interval. The maximum is the number of requests per user per five minutes that is based on your licenses and capacity add-ons.\nYou can also have a direct view of where your actual use of capacity is relative to the limit so you can be sure that you are within the limit.\nWhen the graph shows that your requests per user/app are beyond the peak limit (identified with a red line), it means that you have reached a peak and your requests are being throttled. The report shows data using a single unit of measure to make it easy to get an overview of API utilization.\nAPI peak call rate is calculated as the maximum of one of the following:\nThe peak requests per second (RPS) recorded by the request count API limit. This is a measure of request count per unit time.\nThe peak cumulative execution time recorded by the time API limit. Each 150 ms of request execution time is counted as one API call, and then summed up for every 5-minute interval. This is a measure of compute time, converted to an equivalent number of API calls per unit time.\nFor more information about the API count and time limits, refer to\nservice protection API limits\n.\nAPI peak call rate example scenarios\nAPI peak call rate is based on either the number of requests or execution time measured by the service protection limits, whichever is greater. One request is equivalent to 150ms of execution time measured by the time limit.\nThe scenarios below show how the peak call rate is derived based on either request count or execution time using 150ms as the conversion factor from time to count.\nScenario 1\n: Client sends 150,000 web API calls in 5 minutes that each execute for 50ms.\nCount is 500 requests per second (150,000 per 5 minutes is 30,000 per minute)\nTime is equivalent to 17 requests per second (750,000ms total time, or 5000 calls per 5 minutes (750,000ms / 150ms))\nRequest count is higher in this case, so the peak rate displayed is 500 requests per second.\nScenario 2\n: Client sends 300 web API calls in 5 minutes that each execute for 10 seconds.\nCount is 1 request per second (there are 300 seconds in 5 minutes)\nTime is equivalent to 67 requests per second (3,000,000ms total time, or 20,000 API calls per 5 minutes (3,000,000ms / 150ms)).\nExecution time converts to a higher request count in this case, so the peak rate displayed is 67 API calls per second.\nOptimize API peak call rate\nThe usage graph can help you identify what users/applications are approaching or exceeding the service protection limits and take actions to mitigate it as necessary.\nTo optimize limit, consider reducing the number of API requests by user/app or increase the limit by adding more capacity and bring the peak limit (identified with a red line) higher.\nMailbox Usage dashboard\nThis dashboard helps you monitor email mailbox usage.\nMailbox usage dashboard details\nChart element\nDescription\nMailbox Details by GEO\nThis chart shows mailbox details like:\nthe number of server-side synch configured mailboxes.\nthe number of server-side synch enabled mailboxes.\nthe number of server-side synch Appointments, Contacts, and Tasks enabled mailboxes.\nthe number of server-side synch incoming enabled mailboxes.\nthe number of server-side synch outgoing enabled mailboxes categorized by the geo location the mailbox is hosted in.\nMailboxes by Server Type\nThis chart shows the mailbox distribution by server type.\nActive Email Server Profiles by Geo\nThis chart shows active server-side synch enabled mailboxes distributed over the geo location they are hosted in.\nMailboxes by Exchange Configuration\nThis chart shows the number of mailboxes categorized by their Exchange configuration.\nNumber of Mailbox Configuration Errors\nThis chart shows the number of mailboxes configuration errors which occurred over the user-selected time frame.\nMailbox Usage\nThis chart shows the number of server-side synch mailboxes over the time range selected by the user.\nNumber of Outlook Mailboxes\nThis chart shows the number of Outlook mailboxes configured for the organization.\nNumber of Active Email Server Profiles\nThis chart shows the number of active email server profiles for the time range configured by the user.\nMailbox usage chart update frequency\nThis table details the frequency of mailbox usage chart updates:\nChart\nUpdate frequency\nMailbox Details by Geo\n24 hours\nActive Email Server Profiles by Geo\n24 hours\nMailboxes by Server Type\n24 hours\nMailbox Usage\n24 hours\nNumber of Mailbox Configuration Errors\n24 hours\nNumber of Active Email Server Profiles\n24 hours\nNumber of Outlook Mailboxes\n24 hours\nMailboxes by Exchange Configuration\n24 hours\nDownload reports\nSelect\nDownload\nto view available downloads and then select any of the reports to download them into Microsoft Excel.\nAll the download reports, except\nActive Dynamics 365 Customer Engagement Plan Users by Application\n, show data for an environment and per the timeline in the filters for the out-of-box Dataverse analytics reports. If you select a certain date range for the out-of-box Dataverse reports, the same time filter applies to the downloads. The maximum duration for data availability is 30 days.\nThe\nActive Dynamics 365 Customer Engagement Plan Users by Application\nreport always shows the last 30 days of data at the tenant level.\nDownload reports dashboard details\nChart element\nDescription\nActive users by device type\nList of active users by device type used to access Dynamics 365.\nActive users by business unit\nList of active users by their business unit.\nNOTE\n: This is not specific to UI calls, and includes system calls in the context of the user.\nActive users by security role\nList of active users by their security roles.\nNOTE\n: This is not specific to UI calls, and includes system calls in the context of the user.\nActive users by client\nList of active users, by client type used to access Dynamics 365.\nActive users by entities\nList of active users distributed by entity.\nMost active users performing operations\nList of most active users (unique users) over time who perform an operation that causes one of these SDK calls:\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate\n.\nMost used custom entities\nList of custom entities that had the most\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate SDK Calls\n.\nMost used OOB entities\nList of out-of-box entities that had the most\nRetrieve\n,\nRetrieve Multiple\n,\nDelete\n,\nCreate\n, and\nUpdate SDK Calls\n.\nMost active workflows\nList of top-10 most executed workflows in the environment with a Dataverse database over a specified time.\nMost active plug-ins\nList of top-10 most executed plug-ins in the environment with a Dataverse database over a specified time.\nMost used API\nList of top-10 most executed API calls in the Dataverse environment database.\nActive Dynamics 365 Customer Engagement Plan Users by Application\nActive Dynamics 365 Customer Engagement plan users by application. Helps customers to know usage across different apps so that when it is time to renew their subscription, they can choose the individual apps to be bought (for example Dynamics 365 for Sales, Dynamics 365 for Customer Service, and more). The Customer Engagement plan, which was a suite of all Customer Engagement applications, is no longer being sold and people need to choose the individual apps to be bought.\nNon-conformant usage by users with Team Member license\nShows customers how their users (with team-member licenses) are using the product in ways that are deemed not conformant with the use rights entitled to this license, as per licensing guide.\nEnvironment and date-time range data\nYou can view data for different environment and date-time ranges. Take these steps to get started:\nSelect\nChange filters\n.\nSelect the desired\nenvironment\nand\ntime-period\nfrom the drop-down lists.\nSelect\nApply\nto save the changes. All Dataverse analytics reports are available using this selection process.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Analytics",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/self-service-analytics": {
      "content_hash": "sha256:d2722e2471dadbaf092ad71ffe2b019ceae033836cb991c61204083e8837211c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSet up Microsoft Power Platform self-service analytics to export inventory and usage data (preview)\nFeedback\nSummarize this article for me\n[This article is pre-release documentation and is subject to change.]\nWith the Power Platform admin center, you can export Power Platform inventory and usage data directly into Azure Data Lake Storage for your organization's business needs. Having the data in your own data lake means you can store data for the durations specified in your organization's data retention policies.\nYou can also create custom reports with Power BI, with views at the business unit level and detailed app reports at the tenant and environment level.\nImportant\nThis is a preview feature.\nPreview features arenât meant for production use and might have restricted functionality. These features are available before an official release so that customers can get early access and provide feedback.\nDuring this preview, the user experience displaying the list of established subscriptions is limited to show only first 50 subscriptions created within the tenant.\nData Lake Storage seamlessly integrates with Azure Synapse Analytics, Power BI, and Azure Data Factory. Data Lake Storage offers a comprehensive cloud platform designed for handling large-scale data and advanced analytics.\nArchitected from the ground up for cloud scale and performance, Data Lake Storage is a cost-effective solution to run big data workloads. With Data Lake Storage, your organization can analyze all its data in a single place with no artificial constraints.\nThe enablement of data export is limited to customers with a paid, premium Microsoft Dataverse license available for the tenant. Details of other licensing requirements are provided in admin documentation and in general availability\nrelease plans\n. More details about minimum Dataverse capacity requirements to access the data export features are announced in advance of general availability.\nGovernment Community Cloud (GCC) customers who need to configure integration to Data Lake Storage hosted in an Azure Government subscription should open a\nsupport request\n.\nPrerequisites\nTo access data export in the\nPower Platform admin center\n, you must have one of these roles: Power Platform admin, Dynamics 365 admin, or Microsoft 365 Global admin.\nCreate a storage account\nto use with Azure Data Lake Storage Gen2. Make sure you select the same location for the Data Lake Storage account as your Power BI tenant. To learn more about how to determine your Power BI tenant location, go to\nWhere is my Power BI tenant located\n?\nThis preview feature supports the following Azure Data Lake Storage Gen2 configurations:\nStorage Account Types: Standard general-purpose v2 or Premium block blobs.\nHierarchical Namespace:\nEnable hierarchical namespace\nmust be selected.\nNetwork Connectivity, Network Access:\nEnable public access from all networks\nmust be selected.\nNetwork Routing, Routing Preference:\nMicrosoft network routing\nis recommended.\nSecurity:\nRequire secure transfer for REST API operations\nmust be selected.\nSimplify data with Data Lake Storage\nData Lake Storage\nenables you to store captured data of any size, type, or ingestion speed in one single, secure location for operational and exploratory analytics. You can use Microsoft Power Platform self-service analytics to export Power Apps inventory and usage data directly to your\nData Lake Storage Gen2\nlocations.\nYou can store exported data for extended durations, and you can move data to data warehouses. To learn more about building custom reports at tenant and environment levels across business units, see\nCreate custom dashboards by using Power Platform inventory and usage data\n.\nExtensible analytics with Data Lake Storage\nYou can use self-service options in the Power Platform admin center with Data Lake Storage to extend Power Apps remote monitoring using data from various sources. You can also use cloud analytics and AI to take advantage of predictive analytics within service monitoring solutions. The diagram illustrates an example of how to derive intelligence from Power Platform data collection.\nA diagram of limitless extensibility options through using cloud analytics and AI is divided into three areas. Microsoft Power Platform apps - Power BI, Power Apps, and Power Automate - are shown collectively supplying governance, monitoring, and management to the middle area, the customer's Data Lake Storage. The data lake includes Power Platform admin center analytics and organizational datasets, all informed by cloud intelligence. On the right, the customer's dashboard is the core of an app workspace where data lake data is analyzed and acted on.\nData\nThe amount of data that you can export depends on your app and flow usage. The initial export includes inventory data of all the Power Apps and Cloud flows across your environment. After the initial export, an incremental data push occurs daily.\nFor example, an enterprise customer with two years' worth of inventory data might have 300 MB of data to export. After the initial export, approximately five MB to 10 MB of that data is pushed daily.\nSet up the data export process for your tenant\nAdmins should use the Power Platform admin center to set up the data export. Before you export data, make sure that your Data Lake Storage Gen2 account is set up as described in this section. Make sure that the admin who sets up the data export already has access to your storage account.\nFollow these steps to set up your data lake:\nSign in to the\nPower Platform admin center\nas a Microsoft Entra Global Admin, and then select\nManage\n>\nData export\n.\nOn the command bar, select\nNew data export\n.\nSelect either\nPower Apps\nor\nPower Automate\n. If not already enabled, set\nEnable tenant-level analytics\nto\nOn\n, and then select\nNext\n.\nNote\nThe Global Admin user must have specific roles described in\nFirst-time setup of data export\n.\nChoose a subscription to associate with the Azure storage account.\nIn the list of resource groups under this subscription, select a resource group.\nSelect the Azure storage account, in the list of storage accounts under the selected resource group.\nSelect\nCreate\nto set up the connection to Data Lake Storage Gen2.\nAllow up to 12 hours after you set up the data export for resource inventory and 30 days of historical usage data to be exported to the Azure Data Lake Storage account.\nFirst-time setup of a data export\nWhen setting up the first data export to your organization's data lake, Microsoft requires your Microsoft Entra global admin be the one to create the connection.\nImportant\nTo enable principal access to your organization's property, specifically a\nData Lake Storage Gen2 account\n, a connection with Microsoft's tenant service is necessary. A one-time connection setup must be performed by a user who is a member of your organization's Microsoft Entra (Microsoft Entra ID) Global Admin built-in role\nwith elevated access\nto subscriptions. Or a Global Admin who has at least a \"Contributor\" Azure role-based access control (RBAC) on the Azure Subscription with a \"User Access Administrator\" and \"Contributor\" Azure RBAC role on the target Azure Storage account. This is required because the tenant must allow the service to access and assign specific permissions on the Data Lake Storage account.\nRelated articles\nCreate custom dashboards by using Power Platform inventory and usage data\nAzure Data Lake Storage\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Export Analytics to Azure",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/tenant-wide-agent-inventory": {
      "content_hash": "sha256:a123b8491f01bc6c2c18cd6d35e2c1e763612e2240df8c8645687d367f3909e4",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nView agent inventory (preview)\nFeedback\nSummarize this article for me\n[This article is prerelease documentation and is subject to change.]\nThe Power Platform admin center now offers an enhanced, agent inventory experience that provides IT administrators with comprehensive visibility into all Microsoft Copilot Studio agents created across their tenant. With this new agent inventory page, administrators can effortlessly discover, search, filter, and sort the entire inventory of agents by owner, creation date, region, and other key attributes, streamlining common administrative tasks.\nThe inventory allows administrators to:\nAccelerate support\n: Quickly locate agents referenced in support tickets to improve response times.\nPrevent orphaned agents\n: Identify agents owned by departing users to proactively transfer ownership and maintain continuity.\nEnforce compliance standards\n: Easily detect agents created in nonapproved regions, ensuring adherence to organizational compliance policies.\nImportant\nThis is a preview feature.\nPreview features arenât meant for production use and might have restricted functionality. These features are subject to\nsupplemental terms of use\n, and are available before an official release so that customers can get early access and provide feedback.\nPrerequisites\nYou mustâ¯\nturn on tenant-level analytics\nâ¯to access the inventory.\nView your tenant-wide, agent inventory\nTo view your inventory of custom agents:\nSign in to the\nPower Platform admin center\nas a tenant administrator.\nSelect\nManage\nin the navigation pane.\nIn the\nManage\npane, select\nCopilot Studio\n. The\nCopilot Studio\npage appears, listing custom agents that were created by makers within your tenant.\nApply filters and sorts\nYou can filter by:\nEnvironment type\n: Select the\nEnvironment type\ncolumn and select the default environment. You see all custom agents in the default environment.\nOwner\n: Select the\nOwner\ncolumn and type the name of the person who created the custom agent. You see all agents owned by this person in the default environment.\nCreation date\n: Select the\nCreated on\ncolumn and apply the date filters of your choice. For example, you can filter from January 2024 to today's date. You see all agents owned by this person, in the default environment, that they created in the year 2024.\nYou can also sort by creation date. Select the\nCreated on\ncolumn and select the\nSort descending\nsort order. You see the user's most recently created agents, in the default environment, for the year 2024.\nYou can apply filters and sorts on any column, offering numerous possibilities.\nSearch the inventory\nYou can search, filter, and sort the agent inventory. Keep in mind that you search across the records that have been displayed in the user interface (UI). For example, consider the following scenarios:\nIf you apply a filter and get 400 records returned, the search operation searches across those 400 records.\nIf you apply a filter that returns more than 500 records, you only see 500 records displayed in the UI at this time due to a\nknown limitation\n. The search operation searches across just those 500 records.\nYou can add more filters to narrow down your results, if needed.\nDisplay more columns\nThe\nCopilot Studio\npage provides the option to display more columns to help you better manage your custom agents. To customize displayed columns:\nSelect the\ncolumn chooser\nicon, located next to the search box on the right side of the page.\nSelect the columns you wish to display or hide.\nSelect\nSave\n.\nView agent or environment details\nTo view details about an agent:\nSelect an item, then select the\nDetails\noption, under the page name.\nSelect the agent's display name to be redirected to its details page in the Copilot Studio portal.\nNote\nYou must have edit permissions on the selected agent to access its details page. If you don't have sufficient permissions, you see a \"This link is broken\" error.\nTo view details about an environment, select the environment name to view the environment details.\nReset all searches, filters, and sorts\nTo clear all filters and sorts, select any column and select\nClear all filters\n.\nKnown limitations\nLimited scope\n: This experience supports only agents built directly in Copilot Studio. Agents that were created in the Microsoft 365 Copilot app, aren't supported in this release.\nData refresh frequency\n: Inventory data updates once every 24 hours. Newly created agents might take up to 24 hours to appear, and deleted agents might remain visible for up to 48 hours after removal.\nItem display limit\n: The inventory page displays a maximum of 500 agents at one time. If more than 500 agents match your search or filter criteria, only the first 500 are displayed. Use more filters to narrow down your results. The primary search box, at the top of the page, only searches across those 500 agents.\nFrequently asked questions\nWhy am I seeing multiple agents with identical namesâfor example,\nCopilot in Power Apps\nâacross different environments?\nPower Apps has been creating a platform-owned agent, named\nCopilot in Power Apps\n, in each environment. This agent is no longer being created in new environments. This agent will be removed in the future. It can be manually removed now, or you can wait for the removal in an upcoming solution update.\nThe admin setting\nCopilot in Power Apps (Preview)\nhas no impact on the creation of this agent. Learn more in\nAdd copilot chat to your app\n.\nWhy can't I find an agent on the Copilot Studio page?\nOccasionally, you might not be able to locate a specific agent on the\nCopilot Studio\npage. Use the following steps to resolve the issue.\nStep 1: Clear all filters and sorts\nYou may inadvertently have filters or sorts applied that are hiding the agent.\nSelect any column header.\nSelect\nClear all filters\n.\nReapply appropriate filters and sorts to help locate your agent.\nStep 2: Check the refresh date\nThe agent inventory refreshes once every 24 hours. Keep in mind:\nNewly created agents may take up to 24 hours to appear.\nDeleted agents may remain visible for up to 48 hours after deletion.\nCheck the inventory refresh timestamp at the top-right corner of the page.\nIf your agent was created after the last refresh, wait until the next refresh cycle completes.\nIf your agent was created before the last refresh and is still not visible, proceed to\nstep 3\n.\nIf you're uncertain of the creation time, wait for the next refresh cycle before proceeding.\nStep 3: Verify that the agent exists in the Copilot Studio portal.\nConfirm the agent's existence and your access permissions by verifying directly in the Copilot Studio portal:\nNavigate to the Copilot Studio portal.\nSelect the appropriate environment where the agent should exist.\nEnsure you have appropriate permissions to view the agent:\nIf you see the agent in Copilot Studio, but it's still missing from the Power Platform\nCopilot Studio\npage after the refresh cycle, open a support ticket.\nIf you can't see the agent in Copilot Studio (and you have verified permissions), it likely no longer exists.\nNext steps\nIf you have completed these troubleshooting steps and are still unable to locate your agent, contact Microsoft Support for further assistance.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent Inventory",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/monitoring/monitor-copilot-studio": {
      "content_hash": "sha256:79d9f3b4c410bab0723c491476f51dc3d65a855e99faac70c1355f96f63ea334",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMetrics and recommendations for Copilot Studio\nFeedback\nSummarize this article for me\nCopilot Studio operational health metrics are available in the Power Platform admin center.\nView Copilot Studio metrics\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nMonitor\n.\nIn the\nMonitor\npane, under\nProducts\n, select\nCopilot Studio\n.\nThe\nCopilot Studio\npage displays the metrics for conversational and autonomous agents created in Copilot Studio.\nCopilot Studio metrics and recommendations\nMetric definitions\nType\nMetric\nDefinition\nSupport\nAgents\nAgent session success rate\nA percentage that describes how often an autonomous agent is able to successfully execute its task, or how often a conversational agent's session was successfully resolved.\nPreview\nAgents\nAgent session success rate\nThe number of distinct user sessions in an agent in one day. A session begins when a user opens the agent and ends after a period of inactivity or when the agent is closed.\nPreview\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Monitor Copilot Studio",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/admin-activity-logging": {
      "content_hash": "sha256:b47f44ca39781d7e2be3c20afd6717a474666a25cbffd9f6f4896641bece5898",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nView Power Platform admin logs in Microsoft Purview\nFeedback\nSummarize this article for me\nAdministration of Microsoft Power Platform products and services can affect various capabilities such as environment settings and operations, data policies, and integration-related settings. It's important to monitor such actions to:\nhelp mitigate failures\nhelp contain systems of security constraints\nadhere to compliance requirements\nact on security threats.\nThis article explains how you can monitor activities in Microsoft Purview that are performed on Power Platform environments by those who have admin access across user experiences and programmable interfaces. The activities fall within these categories:\nEnvironment lifecycle operations\nEnvironment property and setting change activities\nThe activities include actions made by Power Platform administrators, Dynamics 365 administrators, members of the System Administrator role (for Power Platform environments with Dataverse), the environment creator or owner (for Power Platform environments without Dataverse), and impersonated users that map to any of these roles.\nEach activity event consists of a common schema defined at\nOffice 365 Management Activity API schema\n. The schema defines the payload of metadata that's unique for each activity.\nPrerequisites\nTo view Power Platform admin activity logs in Microsoft Purview, make sure you:\nReview and complete the\nprerequisites\nin the overview article.\nConfirm either the\nAudit Logs\nor\nView-Only Audit Logs\nrole is assigned to you in Microsoft Purview.\nLearn more:\nManage Dataverse auditing\nAuditing overview\nLearn about auditing solutions in Microsoft Purview\nPermissions in the Microsoft Purview portal\nNote\nAdmin activities for Power Platform environments are enabled by default on all tenants and you can't disable the activity collection.\nAccess the logs\nTake these steps to sign in to the Microsoft Purview portal:\nSign in to the\nMicrosoft Purview portal\nIn the Microsoft Purview portal, you can access the Audit page two ways:\nOn the left navigation pane, select\nSolutions\nand then select\nAudit\n.\nOr, on the\nHome\npage, select the\nAudit\nsolution card. If the Audit solution card isn't displayed, select\nView all solutions\nand then select\nAudit\nfrom the\nCore\nsection.\nThe audit solution lets you search activities or create audit retention policies. On the\nSearch\npage, you can filter for different Power Platform activities in the\nActivities\nlist. Activities are mapped to event types and categories, which are listed in the tables in this article for you to reference.\nThe logs are also accessible to developers via the\nOffice 365 Management API\n.\nSee\nGet started with search\nto learn more about searching the audit logs in Microsoft Purview.\nActivity category: Environment lifecycle operations\nEach activity event contains a payload of metadata that's specific to the individual event. Microsoft Purview receives the\nenvironment lifecycle operation\nactivities listed in this table.\nEvent\nDescription\nProvisioned environment\nThe environment was created.\nDeleted environment\nThe environment was deleted.\nRecovered environment\nAn environment that was deleted was recovered within seven days.\nHard-deleted environment\nThe environment was hard deleted.\nMoved environment\nThe environment was moved to a different tenant.\nCopied environment\nThe environment, including specific attributes such as application data, users, customizations, and schemas, were copied.\nBacked up environment\nThe environment that was backed up.\nRestored environment\nThe environment was restored from a back up.\nConverted environment type\nThe environment was converted to a different environment type, such as production or sandbox.\nReset environment\nA sandbox environment was reset.\nUpgraded environment\nA component of an environment was upgraded to a new version.\nCMK-Renewed environment\nThe customer-managed key (CMK) was renewed on the environment.\nCMK-Reverted environment\nThe environment was removed from enterprise policy and encryption was returned to Microsoft-managed key.\nActivity category: Environment property and setting change activities\nEach activity event contains a payload of metadata that's specific to the individual event. Microsoft Purview receives the\nenvironment property and setting\nactivities listed in this table.\nEvent\nDescription\nChanged property on environment\nCommunicates when a property on an environment changes. In general, properties are metadata (names) that are associated with an environment. This event includes changes to:\nDisplay name\nDomain name\nSecurity group ID\nAdmin mode\nBackground operations state\nActivity category: Environment groups and rules\nAll activities for environment groups and rules are recorded under the\nPowerPlatformAdministratorActivity\nrecord type.\nEach activity event contains a payload of metadata that's specific to the individual event. The environment group activities listed in this table are sent to Microsoft Purview.\nEvent\nDescription\nNewEnvironmentGroup\nA new environment group is created.\nDeleteEnvironmentGroup\nAn environment group is deleted.\nUpdateEnvironmentGroup\nAn environment group's name or description is updated.\nEnvironmentAddedToEnvironmentGroup\nAn environment is added to an environment group.\nEnvironmentRemovedFromEnvironmentGroup\nAn environment is removed from an environment group.\nThese nine rules activities are sent to Microsoft Purview:\nAI-generated descriptions (preview)\nBackup retention\nGenerative AI settings\nSharing agents with Editor\nSharing agents with Viewer\nSharing controls for canvas apps\nSharing controls for solution-aware cloud flows\nSolution checker enforcement\nUsage insights\nEvent\nDescription\nCreateRuleSetOperation\nA rule is added to an environment group for the first time.\nUpdateRuleSetOperation\nA rule is edited in an environment group.\nDeleteRuleSetOperation\nAn environment group is deleted.\nThe remaining rules activities listed in this table are sent to Microsoft Purview.\nEvent\nDescription\nCreateRuleBasedPolicyOperation\nA rule is added to an environment group for the first time.\nCreateRuleBasedPolicyAssignmentOperation\nA rule is added to an environment group for the first time.\nUpdateRuleBasedPolicyOperation\nA rule is added, edited, or removed from an environment group.\nDeleteRuleBasedPolicyOperation\nAn environment group is deleted.\nDeleteRuleBasedPolicyAssignmentOperation\nAn environment group is deleted.\nActivity category: Business model and licensing\nEach activity event contains a payload of metadata that's specific to the individual event. The business model and licensing activities listed in this table are sent to Microsoft Purview.\nCategory\nEvent\nDescription\nBilling Policy\nBillingPolicyCreate\nA new billing policy is created.\nBilling Policy\nBillingPolicyDelete\nA billing policy is deleted.\nBilling Policy\nBillingPolicyUpdate\nThe environments linked to a billing policy change (added, removed).\nISV\nIsvContractConsent\nA tenant admin consents to an ISV contract.\nLicense Auto-claim\nAssignLicenseAutoClaim\nA license is assigned to a user automatically via an auto-claim policy.\nLicense Auto-claim\nAssignLicenseAutoClaimPolicyCreate\nA new auto-claim policy is created.\nCurrency\nCurrencyEnvironmentAllocate\nCurrency (add-on) is allocated or deallocated to an environment.\nTrials\nTrialConvertToProduction\nA trial plan is converted to a production plan.\nTrials\nTrialEnforce\nA customer attempts to provision environments beyond the trial limit.\nTrials\nTrialProvision\nA new trial plan is provisioned.\nTrials\nTrialSignUpEligibilityCheck\nPrior to trial provisioning, a check occurs to determine trial eligibility.\nTrials\nTrialViralConsent\nA tenant changes their consented plan types, and reflects the new state.\nTrials\nAssignLicenseToUser\nA trial license is assigned to a user.\nEnvironment Lifecycle\nEnvironmentDisabledByMiser\nAn environment is automatically disabled due to insufficient database capacity.\nActivity category: Admin actions\nEach activity event contains a payload of metadata that's specific to the individual event. The admin activities listed in this table are sent to Microsoft Purview.\nEvent\nDescription\nApplyAdminRole\nA tenant admin requests the system administrator role in Dataverse in the environment.\nActivity category: Lockbox operations\nAll the lockbox activities fall under the\nLockboxRequestOperation\nactivity. Each activity event contains a payload of metadata with these properties when you create or update the lockbox request:\nLockbox request ID\nLockbox request state\nLockbox support ticket ID\nLockbox request expiration time\nLockbox data access duration\nEnvironment ID\nUser who performed the operation (when the lockbox request is created)\nYou send the events listed in this table to Microsoft Purview.\nCategory\nEvent\nDescription\nCreate lockbox request\nLockboxRequestOperation\nA new lockbox request is created.\nUpdate Lockbox request\nLockboxRequestOperation\nA lockbox request is approved or denied.\nLockbox request access ended\nLockboxRequestOperation\nA lockbox request expired or access ended.\nHere's an example of the payload of metadata you can expect from one of the events listed in the table.\n[\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.lockbox.data_access.duration\",\n \"Value\": \"8\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.lockbox.support_ticket.id\",\n \"Value\": \"MSFT initiated\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.lockbox.request.state\",\n \"Value\": \"Created\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.lockbox.request.expiration_time\",\n \"Value\": \"[DATE] 11:59:15 PM +00:00\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.lockbox.request.id\",\n \"Value\": \"dfdead68-3263-4c05-9e8a-5b61ddb5878c\"\n },\n {\n \"Name\": \"version\",\n \"Value\": \"1.0\"\n },\n {\n \"Name\": \"type\",\n \"Value\": \"PowerPlatformAdministratorActivityRecord\"\n },\n {\n \"Name\": \"powerplatform.analytics.activity.name\",\n \"Value\": \"LockboxRequestOperation\"\n },\n {\n \"Name\": \"powerplatform.analytics.activity.id\",\n \"Value\": \"cb18351c-fa1c-4f34-a6d9-f8cb91636009\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.environment.id\",\n \"Value\": \"ed92c80e-89ef-e0c8-a9eb-98559ca07809\"\n },\n {\n \"Name\": \"enduser.id\",\n \"Value\": \"\"\n },\n {\n \"Name\": \"enduser.principal_name\",\n \"Value\": \"Test user\"\n },\n {\n \"Name\": \"enduser.role\",\n \"Value\": \"Admin\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.id\",\n \"Value\": \"3a568f62-11ff-4e89-bee8-4d47041b0003\"\n }\n]\nActivity category: Data policy events\nNote\nActivity logging for data policies isn't currently available in sovereign clouds.\nTo access data policy logs, you need the appropriate Microsoft licenses. Go to\nMicrosoft Purview service description\nand\nMicrosoft Purview licensing guidance\nto learn more.\nAll the data policy events appear under the\nGovernanceApiPolicyOperation\nactivity. Each activity event contains a property collection with the following properties:\nOperation name\nPolicy ID\nPolicy display name\nAdditional resources (if applicable)\nThe data policy events listed in this table are sent to Microsoft Purview.\nCategory\nDescription\nCreate Data Policy\nA new data policy is created.\nUpdate Data Policy\nA data policy is updated.\nDelete Data Policy\nA data policy is deleted.\nCreate Custom Connector Patterns\nA new custom connector URL pattern is created.\nUpdate Custom Connector Patterns\nA custom connector URL pattern is updated.\nDelete Custom Connector Patterns\nA custom connector URL pattern is deleted.\nCreate Connector Configurations\nA connector configuration is created for the data policy.\nUpdate Connector Configurations\nA connector configuration is updated for the data policy.\nDelete Connector Configurations\nA connector configuration is deleted for the data policy.\nCreate Policy Scope\nA new policy scope is created.\nUpdate Policy Scope\nA policy scope is updated.\nDelete Policy Scope\nA policy scope is deleted.\nCreate Exempt Resources\nAn exempt resources list is created for the data policy.\nUpdate Exempt Resources\nAn exempt resources list is updated for the data policy.\nDelete Exempt Resources\nAn exempt resources list is deleted for the data policy.\nCreate connector blocking policy\nA new connector blocking policy is created.\nUpdate connector blocking policy\nA connector blocking policy is updated.\nDelete connector blocking policy\nA connector blocking policy is deleted.\nHere's an example payload of metadata that you can expect from one of the events in the table.\n[\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.governance.api_policy.additional_resources\",\n \"Value\": \"<<json>>\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.display_name\",\n \"Value\": \"ConnectorBlockingPolicy\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.governance.api_policy.operation_result\",\n \"Value\": \"True\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.id\",\n \"Value\": \"ConnectorBlockingPolicy\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.type\",\n \"Value\": \"ApiPolicy\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.governance.api_policy.operation_name\",\n \"Value\": \"DeleteDlpPolicy\"\n },\n {\n \"Name\": \"version\",\n \"Value\": \"1.0\"\n },\n {\n \"Name\": \"type\",\n \"Value\": \"PowerPlatformAdministratorActivityRecord\"\n },\n {\n \"Name\": \"powerplatform.analytics.activity.name\",\n \"Value\": \"GovernanceApiPolicyOperation\"\n },\n {\n \"Name\": \"powerplatform.analytics.activity.id\",\n \"Value\": \"99ac5d50-a0f4-4878-8ff4-e02b7da3a510\"\n },\n {\n \"Name\": \"enduser.id\",\n \"Value\": \"888c1bf5-3127-4c8c-84ee-b6a9c684e315\"\n },\n {\n \"Name\": \"enduser.principal_name\",\n \"Value\": admin@contosotest.onmicrosoft.com\n },\n {\n \"Name\": \"enduser.role\",\n \"Value\": \"Admin\"\n },\n {\n \"Name\": \"powerplatform.analytics.resource.tenant.id\",\n \"Value\": \"ce65293a-e07d-4638-9dfa-79483fcd5136\"\n }\n]\nRelated content\nMicrosoft Purview\nMicrosoft Purview portal\nAuditing solutions in Microsoft Purview\nOffice 365 Management Activity API schema\nDetailed properties in the audit log\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Admin Activity Logging",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/business-continuity-disaster-recovery": {
      "content_hash": "sha256:28537857df05161525afe1e7a6a75fc6d5f1ecd2fd15f4a8f1d17b78a746f4f7",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nBusiness continuity and disaster recovery\nFeedback\nSummarize this article for me\nNote\nAs of September 3, 2025, the self-service disaster recovery feature supports failover for\nDynamics 365 Contact Center\n. With this enhancement, organizations can seamlessly initiate failover for their contact center environments, ensuring smooth execution of disaster recovery drills or continued operations from an alternate region when needed.\nSelf-service disaster recovery for finance and operations applications is now available in preview. Sign up\nusing this form\nif you're interested in participating in the preview.\nBusinesses expect their applications and customer data to be protected and resilient during unavoidable outages and disruptions. It's important to document a business continuity plan that minimizes the effects of outages. To recover and resume operations, make sure the plan lists stakeholders, processes, and specific steps.\nMicrosoft provides business continuity and disaster recovery capabilities to all\nproduction type environments\nin Dynamics 365 and Power Platform software as a service (SaaS) applications. This article describes how Microsoft keeps your production data resilient during outages.\nThe diagram shows a typical architecture of a geography that serves one or more countries or regions. Power Platform admins only need to know the geography location, but within each geography, Microsoft deploys more infrastructure to provide scale and extra protection for your data.\nA geography has at least one Azure region, which usually includes three\navailability zones\nbut never has fewer than two availability zones.\nBuilt-in disaster recovery in-region with Azure availability zones\nInfrastructure components like network, power, or cooling can fail unexpectedly, for example, because of a lightning strike, and can affect one or more data centers. To ensure resilience, Microsoft deploys availability zones, so your environment is replicated across at least two distinct zones.\nMicrosoft automatically detects availability zone-level failures and switches to other availability zones in the region almost instantly to protect you from data loss while keeping downtime near zero in most cases. This in-region capability is for production environments that host business-critical application processes and data. To avoid disruption, don't deploy production processes and data in nonproduction types like sandbox, developer, or trial environments.\nAvailability zones provide built-in resilience for seamless disaster recovery without manual intervention. Zone-redundant data services replicate data across multiple zones, so a failure in one zone doesn't affect data availability. The recovery point objective is near zero, and the recovery time objective is less than five minutes. If one zone fails, traffic is automatically rerouted to the remaining zones with minimal service disruption.\nBackup of production environments\nThe transition to availability zones significantly improves backup and failover processes for Dynamics 365 and Power Platform workloads. These workloads typically require contacting customer support for manual intervention. Your data and services stay highly available within the primary region, with built-in real-time redundancy across multiple zones.\nKey improvements include:\nAlways-on resilience\n: Your environments automatically replicate across multiple availability zones, so you don't need separate geo-secondary backups.\nFaster recovery\n: Synchronous replication across zones enables failover within a region to happen almost instantly, minimizing disruptions and data loss.\nSeamless experience\n: Unlike traditional backups that require restoration, availability zones keep your environment continuously active.\nReduced support dependency\n: Automated failover within the primary region means you don't need to contact Microsoft support for most disaster recovery scenarios.\nA limited number of customers in certain regions are transitioning to the improved architecture. Whether the region transitioned or is transitioning, the service always keeps a backup of environment data in more than one data center.\nAvailability zones are far enough apart to reduce the chance of an outage affecting more than one zone, but close enough to maintain low-latency connections to other availability zones. Availability zones are typically separated by several kilometers and are usually within 100 kilometers.\nCustomers who need greater distance within a geography can use self-service disaster recovery to keep a copy in a secondary region. With this feature, customers control failover operations and run disaster recovery drills as described in the following section.\nCross-region self-service disaster recovery\nMost geographies have region pairs separated by at least 300 miles when possible, to help protect your data in large-scale disasters.\nSelf-service disaster recovery is a Power Platform infrastructure capability that lets you replicate your environment across long distances and start environment failover between regions yourself.\nYou usually have multiple environments of different types in your tenant. This capability is available only for production environments.\nTo turn on self-service disaster recovery, make sure your environment is managed and linked to a\npay-as-you-go billing plan\n. For more information about managed environments, go to\nManaged Environments\n.\nAllow Virtual Network pairing for self-service disaster recovery in Dynamics 365\nIf you deploy your Dynamics 365 environment within a Virtual Network and plan to use self-service disaster recovery, you need to configure a\nVirtual Network pair\n. This pairing ensures that your primary and secondary environments can communicate securely during failover and failback operations. Without a Virtual Network pair, disaster recovery operations fail because network connectivity between regions can't be established.\nFor setup instructions, go to\nSet up virtual network support for Power Platform\n.\nTurn on self-service disaster recovery\nThis action sets up resources and starts replicating data between the primary and secondary locations. The process can take up to 48 hours to finish. Admins get a notification when the process finishes.\nTurning on disaster recovery in an environment doesn't affect the environment or its data.\nTo turn on disaster recovery, follow these steps.\nSign in to the\nPower Platform admin center\nas a system administrator.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n. The\nEnvironments\npage appears.\nSelect the production environment where you want to turn on self-service disaster recovery.\nSelect\nDisaster Recovery\nin the command bar at the top of the page. The\nDisaster Recovery\npane appears.\nSelect the checkbox to turn on\nDisaster Recovery\n.\nSelect\nSave\n.\nThe environment briefly displays the\nEdit details\npage.\nThe\nEnvironment details\npage displays that the process of turning on the feature has started.\nYou might also want to turn on disaster recovery for other events, like:\nDisaster recovery drill\nEmergency response for a major regional outage\nDisaster recovery drills\nYour company might have disaster recovery drills documented as a requirement in your internal business continuity plans. Some industries and companies might be required by government regulations to perform audits on their business continuity disaster recovery capabilities. In these cases, you can run a disaster recovery drill on an environment. A disaster recovery drill lets you do self-service disaster recovery without losing any data. The duration of the failover action can be slightly longer while all remaining data is replicated to the secondary region.\nWe recommend doing drills on a copy of a production environment, since this process involves downtime when failing over to remote region that can last for minutes. For example, you might want to copy a production environment to a sandbox environment and then change the type from sandbox to production.\nEmergency response failover\nChoose this option during an emergency, when the primary region has an outage and you can't use environments or data. If you select this option, the environment fails and doesn't copy any more data except for data that's already replicated before the outage.\nWhen you start an emergency response, you see the amount of data loss shown in time. Compare this data loss to your recovery point objective to check if it's acceptable before you continue. The environment stays in a Running state until disaster recovery finishes and normal operation resumes from the secondary region.\nNote\nDatabase backups are\nnot replicated to secondary regions\nfor scenarios supported by self-service disaster recovery, unless you explicitly allow self-service disaster recovery. Without self-service disaster recovery, backups remain in the primary region only, which means cross-region failover can't be guaranteed. To ensure business continuity and compliance with your disaster recovery strategy, configure self-service disaster recovery for your environment.\nSwitch back to primary region\nAfter you fix an outage or finish your drill, switch the environment back to its primary region. The environment can operate with limited resources in the paired region. You don't lose data during this action.\nEnvironment disaster recovery status\nAdmins check the current disaster recovery state and location of an environment in the\nEnvironment details\npage. Admins also select\nDisaster Recovery\nin the command bar to open the\nDisaster Recovery\npane.\nTo check data replication latency at any time, select\nDisaster Recovery\n, and then select\nEmergency response\nas the disaster recovery reason. This action opens a confirmation dialog that shows the last replication time between regions for that environment. You can select\nCancel\nif your only purpose is to check the potential loss of data if there's a failover operation. Remember, the last sync time always changes because data is replicated continuously.\nDocument your business continuity plan\nWe recommend that you perform disaster recovery drills or an emergency response before a real disaster strikes, so you can document all steps required for any integration points that are external to Power Platform. Your company is then more prepared for recovery if there's a real disaster.\nFrequently asked questions (FAQs)\nWhy use self-service disaster recovery?\nSuper storms, natural calamities, and unforeseen political uncertainties that have the potential to bring an entire region down are becoming more common. To minimize the impact of a disaster that brings an entire region down, maintain an asynchronous copy in a remote region. You might also want to maintain a copy in a remote region for compliance audits.\nSelf-service disaster recovery gives you control to fail over to a secondary region with the push of a button and failback with the push of a button when the primary region is restored to ensure business continuity. You can also simulate the primary region being down to run a real failover and failback to the secondary region to test a real compliance drill. Run drills with a copy of the production environment to avoid any downtime.\nWhy do I need self-service disaster recovery if I already have a secondary copy maintained in a remote, secondary region?\nFor the public cloud, the system doesn't maintain secondary copies in a remote, secondary region unless you turn on self-service disaster recovery.\nThe system maintains at least twoâand in some cases, threeâsynchronous copies of production environments within a region, at no extra cost to you. These copies are hosted in availability zones in physically separated data centers with independent power, cooling, and networking, in compliance with legislated data residency regulations.\nWith the implementation of\navailability zones\n, these cross-region copies became redundant. Recovering from these copies was a complex and manual process that affected recovery times.\nWhat are the costs associated with using self-service disaster recovery?\nYou must turn on\npay-as-you-go\nfor the environment as a prerequisite to turning on self-service disaster recovery on that environment.\nThe selected environment must be a\nManaged Environment\n. This environment is a premium license tier.\nCapacity charges are based on the storage consumption of the environment's paired secondary region for database, file, and log storage types.\nCapacity consumption is reflected in the familiar licensing experience within the Power Platform admin center. Learn more in\nView usage and billing information\n.\nFor example, suppose a user has 10-GB capacity consumption in the primary location. When self-service disaster recovery is turned on, a copy of data is created in the remote secondary region and this copy consumes another 10 GB. You can pay for this 10 GB in the secondary region through storage entitlements. Only if you exceed your available free storage or available entitlements does a pay-as-you-go plan actively start billing.\nPay-as-you-go is designed to generate various alerts and warnings at various thresholds to warn administrators of depleting storage. Use the alert mechanism to your advantage.\nPay-as-you-go links the selected environment to the Azure subscription by using a billing policy. Once you link an environment to an Azure subscription, the usage of apps and any Dataverse or Power Platform usage that goes above the included storage amounts are billed against the Azure subscription by using Azure meters. For more information, go to\nPay-as-you-go meters\n. If you acquire more storage entitlements, the pay-as-you-go plan stops running the meters and consuming from available free storage and entitlements take precedence.\nHow does billing work for self-service disaster recovery?\nIf you configure your environment to draw capacity from your tenant's Dataverse capacity entitlement, the system consumes the entitled capacity first. You still need a pay-as-you-go billing plan to avoid capacity overages.\nThe pay-as-you-go plan generates multiple warnings at various thresholds to ensure that you're well-informed and can take appropriate action to avoid pay-as-you-go charges.\nAdmins can allocate capacity to the environment, after which the pay-as-you-go plan is billed.\nYou can't turn off the pay-as-you-go plan in the billing experience if you turn on self-service disaster recovery.\nCan I switch regions during a regional outage?\nIf there's a regional outage, the system supports failover only to the designated secondary region as part of self-service disaster recovery. It doesn't support switching to any other arbitrary region.\nIs my region supported for self-service disaster recovery?\nSelf-service disaster recovery depends on Azure region pairs. Regions that don't have a regional Azure pair aren't supported. For more information, go to\nAzure supported regions\n.\nAs of November 2025, Austria East, Belgium Central, Chile Central, Indonesia Central, Israel Central, Italy North, Malaysia West, Mexico Central, New Zealand North, and Poland Central are single regions and aren't supported. Once a region gets a regional pair, it's on our roadmap for Power Platform geo build-out and for supporting self-service disaster.\nNote\nUAE, Brazil, and South Africa have regional pairs in constrained regions and are on the roadmap for Power Platform geo buildout followed by self-service disaster recovery support. Geo build-out prioritization is influenced by impact, opportunity, and resource constraints.\nWhat should I know about the capacity experience?\nWhen you allow self-service disaster recovery, you see more storage consumption displayed in the Dataverse capacity graph, clearly indicating the extra capacity used by the cross-region backup.\nWhen you don't allow self-service disaster recovery, the capacity graph shows standard usage without the extra storage for replication.\nWhen self-service disaster recovery is active, the capacity graph displays the extra consumption from cross-region replication, with a\nDisaster recovery active\ntag in the Dataverse capacity summary.\nHow do I disable self-service disaster recovery?\nTo disable self-service disaster recovery, go to the\ndisaster recovery pane\nin Power platform admin center and uncheck the\nTurn on disaster recovery\ncheckbox.\nWhat happens when I disable self-service disaster recovery?\nDisabling self-service disaster recovery deletes all replicated environment data in the paired region. You're prompted to confirm the environment's name before proceeding.\nCan I disable self-service disaster recovery while in a paired region (in a failed over state)?\nNo, you can't disable self-service disaster recovery while the environment is in a failed over state. You must switch to the primary region first.\nAre Power Apps and Power Pages supported with self-service disaster recovery?\nYes, self-service disaster recovery is supported for Power Apps and Power Pages.\nIs Power Automate supported with self-service disaster recovery?\nAs of October 2025:\nPower Automate desktop flows are fully supported for failover and failback with self-service disaster recovery.\nPower Automate cloud flows are now available in preview. Don't use features in preview with production workloads.\nHow can I find out where my data is being replicated to? Can I change my secondary destination region?\nMicrosoft reserves the rights to disclose the exact details of where the customer's data is residing for security and if it may need to be moved or replicated for various, high availability and resiliency scenarios. Customers can be assured that their data at rest respects geographical boundaries and abides by legislated residency laws. Even if self-service disaster recovery isn't turned on, Microsoft reserves the right to replicate, move, and relocate the data within a region for high availability and operational needs. The location of customer data within a geography (for example,\nAPAC\n) isn't disclosed and may change based on Azure capacity constraints.\nIs Field service supported for self-service disaster recovery?\nField service now supports self-service disaster recovery. You can now manage work orders, scheduling, inventory, and customer communications in one unified platform and in a disaster, fail over your automated service workflows, orders, inventory, and dispatching to a remote region for business continuity.\nAre there any known limitations during a region-wide outage that self-service disaster recovery can't mitigate?\nCopilot Studio conversation runtime requests fail until Microsoft restores the service in the primary region. Custom agents successfully failover and failback since they're saved on Dataverse.\nIn Dynamics 365, analytics and automation in sales observe latency impact. Relationship analytics KPIs aren't computed and new models for scoring aren't created during an outage.\nIn Dynamics 365 Customer Insights - Data, real-time updates are impacted. It doesn't support self-service disaster recovery today.\nIn Dynamics 365 Customer service, basic scenarios that are 100% dependent on Dataverse, such as case creation, or Knowledge Base articles work. Case knowledge base access in customer service is unavailable.\nDynamics 365 Project Operations features aren't yet supported.\nData lake failover has known issues. Self-service disaster recovery isn't supported yet.\nConnectors may have recovery issues when dependent on external systems, like SharePoint, SQL Server or third-party applications.\nFor Dynamics 365 Sales, analytics, reporting, and functions dependent on automation, such as sales forecasting, are unavailable.\nFinance and operations products aren't currently supported for self-serve disaster recovery during regional outages.\nAI Builder may see latency impact.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Business Continuity",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/backup-restore-environments": {
      "content_hash": "sha256:345fdf4a8ff1cd1123dbb8cc1f07cbbbfa0ca640cd3f6ad12185546dabde59b3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nBack up and restore environments\nFeedback\nSummarize this article for me\nIt's important to protect your data on Microsoft Power Platform and in Dataverse and to provide continuous availability of service through system or manual backups.\nSystem backups are automatically created for environments that have a database. System backups of production environments that have a database and Dynamics 365 applications are retained for up to 28 days. By default, backups of production environments without Dynamics 365 applications and other nonproduction environments are retained for seven days. However, for managed production environments without Dynamics 365 applications, the retention period can be extended up to 28 days using PowerShell.\nManual backups are backups that the user initiates. It's recommended for creating manual backups before performing major customizations, applying a version update, or making significant changes to the environment. You can create these backups for production and sandbox environments, but not for the default environment. Manual backups of production environments that have Dynamics 365 applications are kept for up to 28 days. Backups of environments that don't have Dynamics 365 applications are kept for seven days.\nSupported retention period\nEnvironment types\nSystem backup\nManual backup\nProduction with Dynamics 365 apps\n28 days\n28 days\nProduction without Dynamics 365 apps*\n7 days\n7 days\nSandbox\n7 days\n7 days\nDeveloper\n7 days\n7 days\nTeams\n7 days\n7 days\nDefault**\n7 days\nNot supported\nTrial\nNot backed up\nNot supported\nTrial (subscription-based)\nNot backed up\nNot supported\n* For managed production environments that don't have Dynamics 365 applications, we allow you to extend the retention period beyond seven days, to a maximum of 28 days, through PowerShell. Learn more in\nChange the backup retention period for production environments without Dynamics 365 applications\n.\n** We don't support restoring a system backup of the default environment through the Power Platform admin center. Learn more in\nBackup and restoration of the default environment\n.\nSystem backup and restore operations aren't supported for trial-type environments. To use the full set of features, including system backup and restore options, go to\nConvert either type of trial environment to a production environment\n.\nSystem backups\nEnvironments that have a database are automatically backed up and can be restored. All your environments, except trial environments (both standard and subscription-based), have system backups. System backups are created continuously using the Azure SQL Database automated backup feature. Learn more in\nAutomated backups\n.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, then in the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, select an environment.\nIn the command bar, click\nBackup & Restore\n, then select\nRestore or manage\n.\nOn the\nSystem\ntab, select an available system backup by choosing a date and time.\nClick\nContinue\n.\nThe\nBackup retention\nside panel displays the backup details.\nAbout system backups\nSystem backups aren't counted toward storage capacity. To restore an environment, you need\n1 gigabyte (GB)\nof free capacity. If you're over capacity, learn more in:\nIs there a database size restriction for backing up or restoring an organization through the user interface or API?\n.\nCopying and restoring data might take more than one day, depending on the size of the data, especially if you must copy\naudit data\n.\nBackup and restore operations include only apps (created by using Power Apps) and flows (created by using Power Automate) in a Dataverse solution.\nDownloading a copy of a database backup for offline use isn't supported.\nChange the backup retention period for production environments without Dynamics 365 applications\nFor environments without Dynamics 365 applications, the default backup retention period is seven days. Admins who run production\nManaged Environments\nof this type can use PowerShell to change the retention period to 7, 14, 21, or 28 days. To change this setting, you must have an admin role, such as Power Platform admin or Dynamics 365 admin in Microsoft Entra ID.\nKeep the these points in mind:\nIf you adjust the backup retention period, the new setting applies to all future backups and existing backups within the retention period. The change may take up to 24 hours to apply, and some older backups may be removed earlier than expected. Because the change might take up to 24 hours to affect existing backups, some backups might be removed earlier than you expect.\nFor all other nonproduction environments, including default-type environments, the backup retention period is seven days by default.\nFor example, you create an environment on January 1. On that day, the system starts to make backups of your environment, and it stores those backups for a default period of seven days. Therefore, on January 8, backups from January 1 to January 8 are available for restoration. If you change the retention period to 14 days on January 8, the system starts to keep the backups for a longer time. Therefore, on January 16, backups from January 3 to January 16 are available for restoration. In this way, you have more flexibility and control over your backup data.\nPrepare your environment for PowerShell\nThe PowerShell module for Power Platform Administrators is the recommended tool for managing administrative capabilities in Power Platform environments. For information that helps you get started with the PowerShell for Power Platform Administrators module, go to\nGet started with PowerShell for Power Platform Administrators\n.\nNote\nYou can extend the backup retention period only for production environments where Dynamics 365 applications aren't enabled. For production environments where Dynamics 365 applications are enabled, a retention period of 28 days is used. For all other nonproduction environments, the default backup retention period of seven days is used, regardless of the setting's value.\nSet the retention period\nSet-AdminPowerAppEnvironmentBackupRetentionPeriod\nSupply values for the following parameters:\nSet the\nEnvironmentName\nparameter to the environment ID of your environment.\nSet the\nNewBackupRetentionPeriodInDays\nparameter to\n7\n,\n14\n,\n21\n, or\n28\n.\nVerify the retention period\nGet-AdminPowerAppEnvironment -EnvironmentName \"Environment ID\"\nSet the\nEnvironmentName\nparameter to the environment ID of your environment.\nRestore system backups\nYou can't directly restore backups to production environments. To restore a backup to a production environment, you must first change the environment type to sandbox, perform the restore, and then switch the environment type back to production. If you want to restore a system backup to a production environment, you must first\nchange the environment type\nto sandbox. Then, after the restore is completed, you can then switch the environment type back to production. Learn more in:\nCan I restore to a production environment?\n.\nYou must restore an environment in the same region where it was backed up. The target and source environments should be in the same region. When an environment is restored onto itself, audit logs aren't deleted. For example, when an environment is restored onto itself to a past time (t1), full audit data for the environment is available. This data includes any audit logs that were generated after t1.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, then in the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, select an environment.\nIn the command bar, click\nBackup & Restore\n, then select\nRestore or manage\n.\nUnder the\nSystem\ntab, select an available system backup by choosing a date and time.\nSelect\nContinue\n.\nOn the\nBackup retention\nside panel, select the target environment to overwrite.\nSelect\nRestore\n, then select\nConfirm\nto proceed with overwriting the environment.\nNote\nOnly sandbox environments can be restored to. For information about the effects of changing the environment type, go to the section:\nCan I restore to a production environment?\n.\nUnder\nEdit details\n, you can change the environment name.\nIf you don't see the environment that you want to restore to\nThese restrictions apply to restoration from both system backups and manual backups:\nYou must restore an environment in the same region where it was backed up. The target and source environments should be in the same region.\nThe source environment can be a production, sandbox, or developer environment. No other types of environments are supported.\nThe target environment can be a sandbox or developer environment. If the target is a developer environment, the source must also be a developer environment.\nA Managed Environment can be restored only to another Managed Environment. A non-Managed Environment can't be restored to a Managed Environment.\nIf the source environment has a customer-managed encryption key applied, the target environment must also have the same customer-managed encryption key applied.\nBackup and restore operations work only with source and target environments that have Dataverse.\nIf there are any enterprise policies applied to the source environment, then the target environment should also have the same set of policies applied.\nSandbox, Teams, and developer environments support self-restore backups.\nSource type\nTarget type\nProduction\nSandbox\nSandbox\nSandbox\nDeveloper\nSandbox, Developer\nTeams\nTeams (self-restore only)\nDefault\nDeveloper\nFor more information about how to restore to a production environment, go to the section:\nCan I restore to a production environment?\n.\nManual backups\nAlthough automated system backups are great, you should create your own backups before you do major customization or apply a version update. Manual backups might take up to 10 minutes to process before they're available for restoration. It's recommended to wait at least 10â15 minutes before attempting to restore from a manual backup. Therefore, wait at least 10 to 15 minutes before you try to restore your data from a manual backup.\nAbout manual backups\nYou can create backups of production, sandbox, Teams, and developer environments.\nYou can't create backups of the default environment.\nManual backups of production environments that have a database and Dynamics 365 applications are kept for up to 28 days. Manual backups for production environments that don't have Dynamics 365 applications are kept for seven days.\nSandbox backups are kept for up to seven days.\nCheck your expiration date.\nThe label of the backup file that is created reflects the restore point timestamp. The restore point timestamp is the closest available time to the time when the manual backup was created. The timestamp label can't be edited.\nThere's no limit on the number of manual backups that you can create.\nManual backups don't count against your storage capacity limits, but restoring an environment requires at least 1 GB of available capacity.\nYou must restore an environment in the same region where it was backed up.\nIf you don't see your target environment, refer to the\nIf you don't see the environment that you want to restore to\nsection for possible reasons and troubleshooting steps.\nCreate a manual backup\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, then in the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, select an environment.\nIn the command bar, click\nBackup & Restore\n, then select\nRestore or manage\n.\nSelect the\nManual\ntab, then click\nCreate a manual backup\n.\nFill in the information, then select\nCreate\nto proceed.\nThere's no real-time status indicator while the backup is being processed. However, you receive a confirmation message once the backup is successfully created. When the backup is completed, you receive the following message: \"The <\nbackup name\n> backup was successfully created.\"\nRestore a manual backup\nYou can restore backups only to sandbox environments. You can't restore them to production environments. If you want to restore a manual backup to a production environment, you must first change the environment type to sandbox. Then, after the restore is completed, you can switch the environment type back to production.\nImportant\nChanging the environment type to sandbox affects database retention. For more information about the effects of changing the environment type, go to the section:\nCan I restore to a production environment?\n.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, then in the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, select an environment.\nIn the command bar, select\nBackup & Restore\n, then select\nRestore or manage\n.\nOn the\nManual\ntab, select a manual backup to restore, then select\nRestore\nin the command bar.\nOn the\nBackup retention\nside panel, select the target environment to overwrite.\nSelect whether you want to include audit logs. The inclusion of audit logs can significantly increase the time that's required to restore an environment. Therefore, audit logs are excluded by default. Learn more in\nRestore audit logs\n.\nSelect\nRestore\n, then select\nConfirm\nto proceed with overwriting the environment.\nRestore audit logs\nRestoration of audit logs can significantly increase the time that is required to restore an environment. Therefore, audit logs are excluded by default. Follow these steps to include audit logs when you restore a manual backup.\nComplete steps 1 through 6 of the previous procedure.\nUnder\nAudit logs\n, select\nClick here\n.\nEnable copying of audit logs.\nContinue with step 8 of the previous procedure.\nDelete a manual backup\nYou can delete manual backups. You can't delete system backups.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n, then in the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, choose an environment.\nIn the command bar, select\nBackup & Restore\n, then select\nRestore or manage\n.\nNavigate to the\nManual\ntab. Select the backup to delete, then select\nDelete\nin the command bar.\nSelect\nContinue\nto confirm the deletion.\nApp-specific backups\nFor information about backup and restore for specific apps, refer to the documentation for the appropriate app:\nDynamics 365 Marketing\nDynamics 365 Finance\nDynamics 365 Customer Service\nAzure Synapse Link for Dataverse\nPower Apps portals\nFAQ\nHow are system backups made?\nIn the current version of the product, system backups occur continuously. The underlying technology is Azure SQL Database. Learn more in\nAutomated backups\n.\nHow are manual, on-demand backups made?\nIn the current version of the product, system backups occur continuously. The underlying technology is Azure SQL Database. Learn more in\nAutomated backups\n.\nBecause Azure SQL Database continuously makes backups, there's no need to make other backups. Your on-demand backup is just a timestamp and a label that reflects that timestamp. We store this information in our system and use it during restore requests. This behavior differs from the behavior in previous versions that took a full backup during an on-demand backup.\nWhy can't I see the status of the manual backup?\nThere's no real-time status indicator while the backup is being processed. However, you receive a confirmation message once the backup is successfully created. When the backup is completed, you receive the following message: \"The <\nbackup name\n> backup was successfully created.\"\nShould I open a support ticket to make a full backup?\nNo. In the current version of the product, system backups occur continuously. This behavior differs from the behavior in previous versions, where backups were made once a day. The underlying technology is Azure SQL Database. For more information, see\nAutomated backups\n.\nBecause Azure SQL Database continuously makes backups, and there's no specific way to make other, on-demand backups, we recommend that you use the on-demand backup capabilities for labeled backups in Power Platform admin center.\nHow long are my manual, on-demand backups and system backups retained?\nSystem and manual backups for some production-type environments are retained for up to 28 days. Backups for other environment types are retained for only up to seven days. Learn more in the section:\nHow do I determine if backups of a production environment are retained for 28 days?\n.\nHow do I determine if backups of a production environment are retained for 28 days?\nProduction environments that have been created with a database give you the option to enable one or more Dynamics 365 applications (for example, Dynamics 365 Sales or Dynamics 365 Customer Service). However, you must purchase licenses that entitle you to deploy those applications. Backups of production environments that have a database and Dynamics 365 applications are retained for up to 28 days. By default, backups of production environments that don't have Dynamics 365 applications are retained for seven days. However, for Managed Environments, you can increase the retention period beyond seven days.\nCan I move my data from an online environment to an on-premises version?\nIt isn't possible to obtain a copy of your database backup. If you want to move your online data to Dynamics 365 Customer Engagement (on-premises), data migration is required. For smaller data sets, consider\nexporting data to Excel\n. For larger data sets, find a third-party data migration solution on\nMicrosoft Marketplace\n.\nHow can I download a copy of my backup?\nIt isn't possible to obtain a copy of your database backup. Moving your online data requires data migration. For smaller data sets, consider\nexporting data to Excel\n. For larger data sets, find a third-party data migration solution on\nMicrosoft Marketplace\n.\nIs there a database size restriction for backing up or restoring an organization through the user interface or API?\nThere are no restrictions on database size (or storage capacity/entitlement) for backups that are made through the user interface (UI) or API. However, if an organization's storage capacity usage exceeds the entitled capacity, the following admin operations are blocked:\nRestore an environment (requires minimum 1-GB capacity available)\nCreate new environment (requires minimum 1-GB capacity available)\nCopy an environment (requires minimum 1-GB capacity available)\nTo comply with storage usage requirements, customers can always\nfree up storage\n,\narchive data\n,\ndelete unwanted environments\n, or buy more capacity. To learn more about capacity add-ons, refer to the add-ons section in the\nMicrosoft Dynamics 365 Licensing Guide\nor the\nMicrosoft Power Platform Licensing Guide\n. You can work through your organization's standard procurement process to purchase capacity add-ons.\nCan I restore to a production environment?\nYou can't directly restore to a production environment. This restriction helps prevent accidental overwrites.\nIf you want to restore to a production environment, you must first change the environment type to sandbox. Learn more in\nSwitch an environment\n.\nIf you want to restore a system backup or a restore point from the past seven days, you can safely switch the environment type. If you think you might have to restore to a backup that is older than seven days, we strongly recommend that you keep the environment a production environment and consider restoring to a different environment of the sandbox type.\nIf you do switch a production environment to a sandbox environment for a manual restore, you can choose a backup only from the past seven days. After the restore is completed, be sure to change the environment back to a production environment\nas soon as possible\n, to help prevent the loss of any backups that are older than seven days.\nWhy is my organization in administration mode after a restore, and how do I disable it?\nThe newly restored environment is put in administration mode. To turn off administration mode, go to\nSet administration mode\n. You can set administration mode in sandbox or production environments.\nAfter a restore, what steps are needed to ensure that flows work as expected?\nFlows\nâ In the target environment, existing solution flows are deleted, but existing nonsolution flows remain. Review the flows in the target environment to ensure that triggers and actions point to the correct locations. Solution flows are turned off. Therefore, enable flows as required. Solution flows must be enabled or turned on for the PowerShell and API commands to work with them.\nConnection references\nâ Connection references require new connections. Create and set connections on connection references.\nCustom connectors\nâ Custom connectors should be reviewed and, as required, deleted and reinstalled.\nDo apps that are shared with Everyone continue to be shared with Everyone in a restored environment?\nNo. Apps that are shared with Everyone in an environment that is backed up aren't shared with Everyone in the restored environment. Alternatively, a canvas app can be shared with a security group. In this case, the app in the restored environment is shared with that security group.\nAre app identifiers the same after backup and restore operations?\nNot for canvas apps. The app ID for a canvas app in a restored environment differs from the app ID when an environment was backed up.\nIf I restore my environment, do previous backups remain available?\nYes, all backups within the organization's retention period remain available.\nHow can I restore records after a bulk deletion without restoring over an organization?\nTo restore records after a bulk deletion without restoring over an organization, follow these steps.\nCreate a new, empty organization.\nRestore the backup from the current organization to the new organization.\nThis approach keeps the original organization together with all the records that were added since the backup. At the same time, it creates a new organization that has the records that were deleted.\nHow can I restore a deleted environment?\nYou can recover a recently deleted environment (within seven days of deletion) by using the Power Platform admin center or the Recover-AdminPowerAppEnvironment Power Apps cmdlet. Production environments that have Dynamics 365 applications are available for up to 28 days.\nFor more information about the recovery environment, go to\nRecover environment\n.\nTroubleshooting\nThe restore operation failed. What action can I take?\nThe restore process, especially for environments with large amounts of data, is a complex backend operation. If the restore operation fails, the target environment is left in a disabled state. To retry the restore process, the failed environment must be the target environment for the operation. Wait 30 minutes and retry the operation again. The other actions you can take for the disabled, target environment are reset, delete, or copy to as a target environment.\nYou don't see the environment that you want to restore to\nThe source environment can be a production, sandbox, or developer environment. No other types of environments are supported.\nThe target environment can be a sandbox or developer environment. If the target is a developer environment, the source must also be a developer environment.\nThe target and source environments should be in the same region.\nA Managed Environment can be restored only to another Managed Environment. Learn more in\nManaged Environments overview\n.\nIf the source environment has a customer-managed encryption key applied, the target environment must also have a customer-managed encryption key applied. Learn more in\nManage your customer-managed encryption key\n.\nIf an environment is enabled for\nVirtual Network support\n, the target environment must be in the same enterprise policy as the source environment.\nRestoration of an environment requires\n1 GB of available capacity\n. Learn more in the section:\nIs there a database size restriction for backing up or restoring an organization through the user interface or API?\n.\nBackup and restore operations work only with source and target environments that have Dataverse. Learn more in\nAdd a Microsoft Dataverse database\n.\nIf you don't have enough storage, go to\nAdd Microsoft Dataverse storage capacity\nto request more storage.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Backup and Restore",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/regions-overview": {
      "content_hash": "sha256:7745b8b28e5fc1a3485ecfa91a40f0b782545157b09ab2d36d7e3e83d3cfdaf3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRegions overview\nFeedback\nSummarize this article for me\nFor multinational companies with employees and customers distributed around the world, you can create and manage environments specific to your global regions. You can create an environment in a different region than where your tenant resides. Local environments can provide quicker data access for users in that region. Be sure to read\nA multi-environment deployment\nto understand the features of multiple environments.\nHow do I find out where my app is deployed?\nYour app is deployed in the region that hosts the environment. For example, if your environment is created in the Europe region, then your app is deployed in Europe data centers.\nUsing Power Platform admin center\nIf you're an administrator, you can determine the region of each environment in the Power Platform admin center.\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nManage\n.\nIn the\nManage\npane, select\nEnvironments\n.\nOn the\nEnvironments\npage, locate the\nRegion\ncolumn.\nWhat regions are available?\nRefer to the\nMicrosoft Dynamics 365 and Power Platform data residency documentation\n.\nWho can create environments in these regions?\nWith Power Apps, you can create environments in various regions across the globe, which benefits your business in these ways:\nStore your data closer to your users\nMaintain the compliance requirement of your geography\nYou can create a database for an environment in one region (for example, United States) even if the Microsoft Entra tenant is in another region (for example, Canada or Europe). Note the following:\nTax laws prevent you from creating a database for an environment in India and Australia, if your Microsoft Entra tenant is not in India and Australia respectively. You can get an exception for Australia.\nOnly a US Government associated organization can create an environment in US Government (GCC).\nYour Microsoft Entra tenant's home location\nRegions where you can create a database\nIndia\nAny region except Australia\nAustralia\nAny region except India\nAny other location\nAny region except India and Australia\nWhat features are specific to a given region?\nEnvironments can be created in different regions, and are bound to that geographic location. When you create an app in an environment, that app is deployed in datacenters in that geographic location. This applies to any items you create in that environment, including databases in the Microsoft Dataverse, apps, connections, gateways, and custom connectors.\nFor optimal performance, if your users are in Europe, create and use the environment in the Europe region. If your users are in the United States, create and use the environment in the U.S.\nNote\nOn-premises data gateways aren't available in the India region.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Regions Overview",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/capacity-storage": {
      "content_hash": "sha256:4d67025daf5ebd70b89ca3e822254fb4b6ff9e9c4e14217042081e7f60c90214",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nDataverse capacity-based storage details\nFeedback\nSummarize this article for me\nIf you purchased storage after April 2019, or if you have a mix of storage purchases made before and after April 2019, you see your storage capacity entitlement and usage by database, file, and log as it appears in the Microsoft Power Platform admin center today.\nData volume continues to grow exponentially as businesses advance their digital transformation journey and bring data together across their organization. Modern business applications need to support new business scenarios, manage new data types, and help organizations with the increasing complexity of compliance mandates. To support the growing needs of today's organizations, data storage solutions need to evolve continuously and provide the right solution to support expanding business needs.\nNote\nFor licensing information, see the\nPower Platform Licensing Guide\n.\nIf you purchased your Dynamics 365 subscription through a Microsoft partner, contact them to manage storage capacity. The following steps don't apply to partner-based subscriptions.\nLicenses for Microsoft Dataverse capacity-based storage model\nThe following licenses provide capacity by using the new storage model. If you have any of these licenses, you see the new model report:\nDataverse for Apps Database Capacity\nDataverse for Apps File Capacity\nDataverse for Apps Log Capacity\nTo check whether you have any of these licenses, sign in to the Microsoft 365 admin center and then go to\nBilling\n>\nLicenses\n.\nNote\nIf you have a mix of\nlegacy model licenses\nand new model licenses, a new model report is displayed.\nIf you have none of the\nlegacy model licenses\nnor the new model licenses, a new model report is displayed.\nVerifying your Microsoft Dataverse capacity-based storage model\nTo view the Capacity add-ons summary page, you need one of the following roles:\nTenant administrator\nPower Platform administrator\nDynamics 365 administrator\nAlternatively, a user with any of the preceding roles can grant permissions to the environment administrator to view the\nCapacity summary\ntab within the\nTenant setting\npage.\nFollow these steps to verify you have the Microsoft Dataverse capacity-based storage model:\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nLicensing\n.\nIn the Licensing pane, select\nCapacity add-ons\nto go to the Capacity add-ons summary page where you can see your tenant's storage, add-ons, and Microsoft Power Platform requests.\nLearn more in\nDataverse capacity-based storage overview\n.\nCapacity page details\nThe tabs\nSummary\n,\nDataverse\n,\nMicrosoft Teams\n,\nAdd-ons\n, and\nTrial\nare available on the Capacity add-ons page.\nSummary tab\nOn the Capacity page,\nSummary\nis the default view where you see a tenant-level view of where your organization is using storage capacity. You can view:\nStorage capacity usage\nStorage capacity, by source\nTop storage usage, by environment\nAll Dataverse tables, including system tables, are included in the storage capacity reports. Files such as .pdf (or any other file attachment type) are stored in file storage. However, the database stores certain attributes needed to access the files.\nStorage capacity usage\nIn the\nstorage capacity usage\nsection, you can see:\nFile and database\n: The following tables store data in file and database storage:\nAttachment\nAnnotationBase\nAny custom or out-of-the-box table that has columns of datatype file or image (full size)\nAny table that is used by one or more install Insights applications and\nends in -\nAnalytics\nWebResourceBase\nRibbonClientMetadataBase\nLog\n: The following tables are used:\nAuditBase\nPlugInTraceLogBase\nElastic tables\nDatabase only\n: All other tables count for your database\nStorage capacity, by source\nIn the\nstorage capacity, by source\nsection, you can see:\nOrg (tenant) default\n: The default capacity given at the time of sign up\nUser licenses\n: More capacity added for every user license purchased\nAdditional storage\n: Any extra storage you bought\nTotal\n: Total storage available\nView self-service sources\n: Learn more at\nView self-service license amounts and storage capacity\nTop storage usage, by environment\nIn the\ntop storage usage, by environment\nsection, you can see the environments that consume the most capacity.\nAdd-ons\nIn the\nadd-ons\nsection, you can see the details of add-ons that your organization purchased. Learn more at\nView capacity add-ons in Power Platform admin center\n.\nIn the\nadd-ons\nsection, you can also select\nManage\nto assign add-ons to environments or\nDownload reports\nto view a downloaded report. Add-on reports expire after 30 days.\nDataverse tab\nOn the Capacity page, select\nDataverse\n. This page provides similar information as the summary tab, but with an environment-level view of where your organization is using capacity.\nNote\nThere's no technical limit on the size of a Dataverse environment. The limits mentioned on this page are entitlement limits based on product licenses you purchase.\nThis table highlights some of the features you can see on the Dataverse page.\nFeature\nDescription\nDownload\nSelect\nDownload\nabove the list of environments to download an Excel .CSV file with high-level storage information for each environment that the signed-in admin has permission to see in the Power Platform admin center.\nSearch\nUse\nSearch\nto search by the environment name and the environment type.\nDetails\nSelect the\nDetails\nbutton (\n) to see an environment-level detailed view of where your organization is using capacity, in addition to the three types of capacity consumption.\nDefault environment tip\nThe calculated storage usage in this view only displays what is\nabove\nthe default environment's included capacity. Tool tips indicate how to view actual usage in the\nDetails\nsection.\nNote\nThe following environments don't count against capacity and show as 0 GB:\nMicrosoft Teams\nTrial\nPreview\nSupport\nDeveloper\nThe default environment has the following included storage capacity: 3 GB Dataverse database capacity, 3 GB Dataverse file capacity, and 1 GB Dataverse log capacity.\nYou can select an environment that's showing 0 GB and then go to its environment capacity analytics page to see the actual consumption.\nFor the default environment, the list view shows the amount of capacity consumed beyond the included quota. Select the\nDetails\nbutton (\n) to see usage.\nThe capacity check - conducted before creating new environments - excludes the default environment's included storage capacity when calculating whether you have sufficient capacity to create a new environment.\nEnvironment storage capacity details\nSelect the\nDetails\nbutton (\n) associated with the environment you want to see more information about.\nThe following details are provided:\nActual database usage\nTop database tables and their growth over time\nActual file usage\nTop files tables and their growth over time\nActual log usage\nTop tables and their growth over time\nNote\nRefer to the\nstorage capacity reports\nunder\nDataverse long term retention\nto understand details on storage capacity with the retention feature.\nMicrosoft Teams tab\nOn the Capacity page, select\nMicrosoft Teams\n. This tab shows the capacity storage used by your Microsoft Teams environments. Teams environment capacity usage doesn't count towards your organization's Dataverse usage.\nFeature\nDescription\nDownload\nSelect\nDownload\nabove the list of environments to download an Excel .CSV file with high-level storage information for each environment that the signed-in admin has permission to see in the Power Platform admin center.\nSearch\nUse\nSearch\nto search by the environment name and the environment type.\nAdd-ons tab\nOn the Capacity page, select\nAdd-ons\n. This tab shows your organization's add-on usage details and lets you assign add-ons to environments. For more information, see\nView capacity add-ons in Power Platform admin center\n.\nNote\nThis tab only appears if your tenant includes add-ons.\nTrial tab\nOn the Capacity page, select\nTrial\n. This tab shows the capacity storage used by your trial environments. Trial environment capacity usage doesn't count towards your organization's Dataverse usage.\nFeature\nDescription\nDownload\nSelect\nDownload\nabove the list of environments to download an Excel .CSV file with high-level storage information for each environment that the signed-in admin has permission to see in the Power Platform admin center.\nSearch\nUse\nSearch\nto search by the environment name and the environment type.\nDataverse page in Licenses (preview)\nImportant\nThis is a preview feature.\nDon't use preview features in production environments. Preview features might have restricted functionality. They're subject to\nsupplemental terms of use\n. Microsoft makes preview features available before an official release so that customers can get early access and provide feedback.\nThis feature is being gradually rolled out across regions and might not be available in your region yet.\nTrack tenant usage\nYou can track and manage Dataverse capacity in the\nLicenses\nsection of Power Platform admin center.\nSign in to the\nPower Platform admin center\n.\nOn the navigation pane, select\nLicensing\n.\nOn the Licensing pane, select\nDataverse\nunder\nProducts\n.\nUsage per storage type\nIn the\nUsage per storage type\ntile, you can view the consumption of your database, log, and file storage. This section displays your prepaid entitled capacity along with the corresponding usage. Additionally, it indicates if any part of your Dataverse usage is billed under a pay-as-you-go plan.\nTop environment consuming storage\nThe\nTop environment consuming storage\ntile displays the environments using the most capacity. It also indicates whether any of these top-consuming environments are in overage and provides a breakdown of prepaid versus pay-as-you-go usage. You can select\nDatabase\n,\nFile\n, or\nLog\nto view the corresponding consumption details.\nDataverse environment usage\nIn the\nTop environments consuming storage\ntile, select\nSee all environments\nto view capacity consumption across all your Dataverse environments. The following details are provided:\nName of the environment\nOverage status if capacity is allocated to the environment\nWhether capacity is preallocated to the environment\nEnvironment type\nManaged Environment status\nPay-as-you-go plan linkage status\nAbility to draw capacity from available tenant pool\nDatabase, file, and log consumption\nTrack environment usage\nOn the\nDataverse\npage, select\nEnvironment\nand choose an environment from the list.\nAlternatively, in the\nTop environment consuming storage\ntile, select\nSee all environments\nand select an environment name.\nUsage per storage type tile\nIn the\nUsage per storage type\ntile, you can view the consumption of your database, log, and file storage. This section displays your prepaid allocated capacity, if any, along with the corresponding usage. Additionally, it indicates if any part of your Dataverse usage is billed under a pay-as-you-go plan.\nConsumption per table\nIn the\nConsumption per table\nsection, you can view the amount of storage consumed by each Dataverse table. To see table consumption for a specific storage type, select\nDatabase\n,\nFile\n, or\nLog\nin the\nUsage per storage type\ntile. Select the table name for the consumption trend, with the option to track daily usage trends, for up to the past three months.\nDataverse search consumption and reporting\nIn addition to database and file storage, Dataverse search includes the indexes that power different experiences. These indexes support search and generative AI across structured or tabular data and unstructured data stored in Dataverse, such as files.\nStorage consumed by Dataverse search is reported at the environment-level as a table called\nDataverseSearch\n. It was previously named\nRelevanceSearch\n.\nDataverse search can also be monitored at the Dataverse Environment report in the Power Platform admin center\nThe Dataverse Environment report is located at\nLicensing\n>\nDataverse\n>\nEnvironments\ntab (consumption per table reporting).\nHow much does the indexed Dataverse search data cost?\nAll Dataverse indexes are reported at the Dataverse database capacity rate. Turning on Dataverse search doesn't turn on any other experience automatically. For more information, see\nWhat is Dataverse search?\nAllocate capacity for an environment\nWhen you select the\nDataverse\ntab, you can allocate capacity to a specific environment. After you allocate capacity, you can view the status of your environments to see whether they're within capacity or in an overage state.\nSign in to the\nPower Platform admin center\n.\nOn the navigation pane, select\nLicensing\n.\nOn the\nLicensing\npane, select\nDataverse\nin the\nProducts\nsection.\nOn the\nSummary\npage, select\nManage capacity\n.\nSelect the environment for which you want to allocate capacity.\nIn the\nManage capacity\npanel, view the currently allocated and consumed capacity for the environment.\nAllocate capacity by entering the desired value in the\nDatabase\n,\nFile\n, and\nLog\nfields. Make sure the capacity values are positive integers and don't exceed the available capacity displayed at the top of the panel.\nOpt in to receive daily email alerts sent to tenant and environment admins when the consumed capacity (database, log, or file) reaches a set percentage of the allocated capacity.\nSelect\nSave\nto apply the changes.\nManage capacity overage\nWhen an environment's capacity consumption exceeds the preallocated capacity, you have two options to manage the overage:\nIn the\nManage capacity\npane, use capacity available from the tenant's overall capacity pool.\nIn the\nManage capacity\npane, link the environment to a pay-as-you-go billing plan, where any overage is charged to the associated Azure subscription.\nChanges for exceeding storage capacity entitlements\nMicrosoft is making changes for what happens when an organization's storage capacity is close to or exceeds the capacity entitled or purchased through add-ons.\nNotifications for capacity approaching storage limits are triggered when any of the three storage capacities (database, file, or log) have less than 15% of space available. Another warning notification that admin operations could be impacted is sent when any of the three storage capacities have less than 5% of space available. The final tier of notification triggers when the tenant is \"in overage\" (storage usage exceeds capacity entitlements), which alerts the admin that the following operations aren't available until the overage is resolved:\nCreate a new environment (requires minimum 1-GB capacity available)\nCopy an environment\nRestore an environment\nConvert a trial environment to paid (requires minimum 1-GB capacity available)\nRecover an environment (requires minimum 1-GB capacity available)\nAdd Dataverse database to an environment\nNote\nThe storage driven capacity model calculation of these thresholds also considers the overflow usage allowed in the storage driven model. For example, extra database capacity can be used to cover log and file overuse and extra log capacity can be used to cover file overuse. Therefore, overflow usage is taken into consideration to reduce the number of emails a tenant admin receives.\nTenant admins, Power Platform admins, and Dynamics 365 admins receive these notifications on a weekly basis. At this time, there's no option for a customer to opt out of these notifications or delegate these notifications to someone else. All admin types listed earlier automatically receive these notifications.\nAdditionally, there's a notification banner in the Power Platform admin center when a tenant exceeds storage capacity.\nThe\nUniversal License Terms for Online Services\napply to your organization's use of the online service, including consumption that exceeds the online service's documented entitlements or usage limits.\nYour organization must have the right licenses for the storage you use:\nIf you use more than your documented entitlements or usage limits, you must buy more licenses.\nIf your storage consumption exceeds the documented entitlements or usage limits, Microsoft might suspend use of the online service. Microsoft provides reasonable notice before suspending your online service.\nExample storage capacity scenarios and overage enforcement\nStay within the limits for your entitled capacity for database, log, and file storage. If you use more capacity than you're entitled to, buy more capacity or free up some space. However, if you overuse database, log, or file capacity, review the following scenarios to understand when enforcement applies.\nScenario 1: Database storage is over capacity, overage enforcement\nType\nEntitled\nConsumed\nDatabase\n100 GB\n110 GB\nLog\n10 GB\n5 GB\nFile\n400 GB\n200 GB\nThis tenant uses 10 GB more than the database capacity. Even though the tenant has 200 GB of extra file storage, the tenant is in deficit. This tenant should free up storage or purchase more capacity.\nScenario 2: Log storage is over capacity, overage enforcement\nType\nEntitled\nConsumed\nDatabase\n100 GB\n95 GB\nLog\n10 GB\n20 GB\nFile\n400 GB\n200 GB\nThis tenant uses 10 GB more than the log capacity and has only 5 GB available in database capacity. Therefore, the tenant is in deficit and should free up storage or purchase more capacity.\nScenario 3: File storage is over capacity, overage enforcement\nType\nEntitled\nConsumed\nDatabase\n100 GB\n20 GB\nLog\n10 GB\n5 GB\nFile\n200 GB\n290 GB\nThis tenant is 90 GB over in file usage. Despite having 85 GB available (80-GB database + 5-GB log) in storage capacity, the tenant is considered to be in deficit. This tenant should free up storage or purchase more capacity.\nExample storage capacity scenario, no overage\nScenario 4: Log storage is over capacity\nType\nEntitled\nConsumed\nDatabase\n100 GB\n80 GB\nLog\n10 GB\n20 GB\nFile\n400 GB\n200 GB\nThis tenant is 10 GB over in log usage but has 20 GB available in database capacity. Therefore, the tenant isn't in deficit. File storage excess entitlement can't be used to compensate deficits in log or database storage.\nActions to take for a storage capacity deficit\nYou can always\nfree up storage\n,\ndelete unwanted environments\n, or buy more capacity to be compliant with storage usage. To learn more about capacity add-ons, go to the\nDynamics 365 Licensing Guide\nor the\n\"Add-ons\" section of the Power Apps and Power Automate Licensing Guide\n.\nYou can work through your organization's standard procurement process to purchase\ncapacity add-ons\n.\nFrequently asked questions (FAQ)\nWhy does my storage consumption decrease in the database and grow in the file storage?\nMicrosoft constantly optimizes Dataverse for ease of use, performance, and efficiency. Part of this ongoing effort is moving data to the best possible storage with the lowest cost for customers. File-type data such as \"Annotation\" and \"Attachment\" is moving from database to file storage. This change leads to decreased usage of database capacity and an increase in file capacity.\nWhy could my database table size decrease while my table and file data sizes remain the same?\nAs part of moving file-type data such as \"Annotation\" and \"Attachment\" out from database and into file storage, Microsoft periodically reclaims the freed database space. This change leads to decreased usage of database capacity, while the table and file data size computations remain unchanged.\nDo indexes affect database storage usage?\nDatabase storage includes both the database rows and index files used to improve search performance. Indexes are created and optimized for peak performance. The system frequently updates them by analyzing data use patterns. No user action is needed to optimize the indexes, as all Dataverse stores have tuning enabled by default. A fluctuation in database storage can be represented by an increased or decreased number of indexes. Dataverse is continually being tuned to increase efficiency and incorporate new technologies that improve user experience and optimize storage capacity. Common causes for an increase in index size are:\nAn organization makes use of new functionality. This functionality can be custom, out-of-the-box, or part of an update or solution installation.\nData volume or complexity changes.\nA change in usage patterns that indicate new indexes need reevaluation.\nIf you configure Quick Find lookups for data that's frequently used, this configuration also creates more indexes in the database. Admin-configured Quick Find values can increase the size of the indexes based on:\nThe number of columns chosen and the data type of those columns.\nThe volume of rows for the tables and columns.\nThe complexity of the database structure.\nBecause an admin creates custom Quick Find lookups in the org, these indexes can be user-controlled. Admins can reduce some of the storage used by these custom indexes by taking the following action:\nRemove unneeded columns or tables.\nEliminate multiline text columns from inclusion.\nNote\nThe Dataverse search indexed data is the data that improves the search quality for the global search and generative AI experiences, as well as interpreting the content by using natural language. This index data accrues to the overall Dataverse search consumption.\nWhat is the DataverseSearch table and how can I reduce it?\nThe\nDataverseSearch\ntable (previously known as\nRelevanceSearch\n) stores indexed data for the global search and generative AI experiences. It includes data from all searchable, retrievable, and filterable fields of the tables you indexed for your environment and Copilot semantic indexes.\nFor more information, see\nManaging Dataverse search\n.\nCan I manage Dataverse search?\nAn admin can manage Dataverse search through the three states associated with this setting: On, Default, and Off. Learn more in\nConfigure Dataverse search for your environment\n.\nNote\nDataverse search is set to\nOn\nfor any new production, sandbox, or default environment type. It's set to\nDefault\nfor any new other type of environment.\nIf you turn on Dataverse search as\nOn\nor\nDefault\n, no other setting is turned on.\nWhat actions can makers take?\nDepending on the experience that leverages Dataverse search and its usage, the consumption size might increase. Learn more in\nWhat is Dataverse search?\n.\nImportant\nDon't turn off Dataverse search. Turning off Dataverse search directly impacts all dependent generative AI experiences in your different applications and all users using them.\nTurning off Dataverse search\nWhen you turn off Dataverse search, the system deletes its indexed Dataverse data. All experiences that depend on this data, including search and generative AI conversational capabilities, become limited or unusable for all users.\nEnvironment admins have 12 hours to turn the feature back on without losing indexed data.\nDuring 12 hours:\nYou can turn Dataverse search back on without losing indexed data.\nAfter 12 hours:\nThe system permanently deletes all indexed Dataverse data.\nTurning Dataverse search back on re-triggers the indexing of Dataverse data.\nImportant\nTurning off Dataverse search deprovisions and removes the index within a period of 12 hours. If you turn on Dataverse search after it's been off for 12 hours, it provisions a fresh index that needs to go through a full sync. Syncing might take up to an hour or more for average size organizations, and a couple of days for large organizations. Be sure to consider these implications when you turn off Dataverse search temporarily.\nIndex removal (or provisioning) can take multiple days to complete, depending on the amount of Dataverse search consumption. For example, an organization with 10 GB of indexed data might take one day to clean up all indexes, while an organization with 500 GB might take multiple days to see it reflected in Dataverse search reporting. Please wait a few days or a week before submitting a support ticket, to ensure a complete removal of Dataverse search indexed data.\nWhat happens if I turn off Dataverse search?\nAll experiences that use Dataverse search become limited. For more information, see\nFrequently asked questions about Dataverse search\n.\nTurning on Dataverse search again\nSelecting On\n:\nWhen you set Dataverse search to\nOn\nafter setting it to\nOff\n, the system immediately re-triggers all indexes across all enabled experiences for them to work accordingly, and Dataverse search costs resume.\nSelecting Default\n:\nWhen you set Dataverse search to\nDefault\nafter setting it to\nOff\n, the system only regenerates the indexes when triggered. Examples include when a Copilot Studio agent uses a fileâsuch as a local file, OneDrive file, SharePoint file upload, or Dataverse tableâor if a prompt is submitted to an agent or Copilot. When the indexes are triggered, Dataverse search costs resume.\nNote\nYou can't turn Dataverse search\nOn\nor\nOff\nfor different applications in the same environment. The status of the setting applies to all applications in the environment that use Dataverse search.\nI just bought the new capacity-based licenses. How do I provision an environment by using this model?\nYou can provision environments through the Power Platform admin center. Learn more in\nCreate and manage environments in the Power Platform admin center\n.\nI'm a new customer and I recently purchased the new offers. My usage of database, log, or file is showing red. What should I do?\nConsider buying more capacity by using the\nLicensing Guide\n. Alternatively, you can\nfree up storage\n.\nI'm an existing customer, and my renewal is coming up. Will I be affected?\nCustomers who renew existing subscriptions can choose to continue to transact by using the existing offers for a certain period of time. Contact your Microsoft partner or Microsoft sales team for details.\nI'm a Power Apps or Power Automate customer and have environments with and without database. Do they consume storage capacity?\nYes. All environments consume 1 GB, regardless of whether they have an associated database.\nDo I get notified through email when my organization is over capacity?\nYes, tenant admins receive email notifications on a weekly basis if their organization is at or over capacity. Additionally, tenant admins get notified when their organization reaches 15% of available capacity, and when their organization reaches 5% of available capacity.\nWhy am I no longer getting storage notifications?\nCapacity email notifications are sent weekly to tenant admins based on three different thresholds. If you're no longer getting storage notifications, check your admin role. It could also be the case that your organization is over the three predefined capacity thresholds. In that case, you don't receive an email notification.\nI'm an existing customer. Should I expect my file and log usage to change?\nLog and files data usage isn't expected to be exactly the same size as when the same data is stored by using database, due to different storage and indexing technologies. The current set of out-of-the-box tables stored in file and log storage might change in the future.\nThe capacity report shows the entitlement breakdown per license, but I have more licenses in my tenant and not all of them are listed in the breakdown. Why?\nNot all licenses give per-user entitlement. For example, the Team Member license doesn't give any per-user database, file, or log entitlement. So in this case, the license isn't listed in the breakdown.\nWhich environments are counted in the capacity report?\nDefault, production, and sandbox environments count for consumption. Trial, preview, support, and developer environments don't count.\nWhat are tables ending in \"- analytics\" in my capacity report?\nTables ending in \"â Analytics\" are tables used by one or more Insights applications, for example Sales Insights, Customer Service Hub, or Field Service and resource scheduling and optimization analytics dashboard to generate predictive insights or analytics dashboards. The data is synched from Dataverse tables. Go to the section\nMore information\nfor documentation covering the installed Insights applications and the tables used to create insights and dashboards.\nWhy can't I see the Summary tab in my capacity report?\nIn April 2023, Microsoft changed the roles that can see the\nSummary\ntab in the capacity report. Now, only users with the tenant admin, Power Platform admin, or Dynamics 365 admin roles can see the\nSummary\ntab. Users with other roles, such as environment admins, no longer see this tab and are redirected to the\nDataverse\ntab when accessing the report. If you need access to the\nSummary\ntab, ask your admin to assign one of the required roles.\nMore information:\nSales Insights\nField Service and resource scheduling optimization (RSO)\nCustomer Service Insights\nField Service\nWho can allocate capacity?\nUsers with global admin, Power Platform admin, and Dynamics 365 admin roles can allocate Dataverse capacity.\nDoes this change affect the total available capacity in my tenant?\nThis change doesn't affect the overall capacity available at the tenant level. Admins can choose to preallocate capacity from the tenant pool to an environment. When they preallocate capacity, it reduces the tenant level's total available capacity for use by other environments.\nWhat happens if capacity consumption goes beyond the allocated capacity?\nCurrently, only\nsoft enforcement\nthrough email notification is turned on. Admins (Power Platform admins and environment admins) start receiving notifications when capacity usage exceeds 85% of the allocated capacity.\nWhat types of Dataverse capacity can be allocated?\nYou can allocate database, file, and log capacity.\nDo I need to allocate capacity to every environment like other supported currencies?\nNo, admins can select specific environments to allocate capacity.\nRelated information\nAdd Microsoft Dataverse storage capacity\nCapacity add-ons\nAutomatic tuning in Azure SQL Database\nWhat's new in storage\nFree up storage space\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Capacity Storage",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/powerapps-powershell": {
      "content_hash": "sha256:1cdc885e99ef30bca795044e1e6e4b27b9c6377ea58c486ff9d8824d72603dca",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nPowerShell support for Power Apps and Power Automate\nFeedback\nSummarize this article for me\nWith\nPowerShell\ncmdlets for Power Platform creators and administrators, you can automate many monitoring and management tasks. Tasks that are only possible\nmanually\ntoday in\nPower Apps\n,\nPower Automate\n, or the\nPower Platform admin center\n.\nCmdlets\nCmdlets\nare functions written in the\nPowerShell\nscript language that execute commands in PowerShell. Running these Power Apps cmdlets allows you to interact with your Business Application Platform without having to go through the admin portal in a web browser.\nYou can combine cmdlets with other PowerShell functions to write complex scripts that can optimize your workflow. You can still use the cmdlets if you're not an admin on the tenant, but you're limited to the resources you own. Administrative user account use cmdlets that start with\nAdmin\n.\nCmdlets are available on the PowerShell gallery as two separate modules:\nAdministrator\nMaker\nFor information on the Power Apps admin module, see\nGet started using the Power Apps admin module\nand\nMicrosoft.PowerApps.Administration.PowerShell\n.\nGet started with PowerShell\nIf you're new to PowerShell and need help with finding and launching it, go to\nGetting Started with PowerShell\n. If you need help with using PowerShell or the cmdlets, go to\nThe PowerShell Help System\n.\nPrerequisites for PowerShell\nPowerShell in this article requires\nWindows PowerShell\nversion 5.x. To check the version of PowerShell running on your machine, run the following command:\n$PSVersionTable.PSVersion\nIf you have an outdated version, go to\nUpgrading existing Windows PowerShell\n.\nImportant\nThe modules described in this document use .NET Framework, which is incompatible with PowerShell 6.0 and later. These later versions use .NET Core.\nModule installation and sign in\nTo run PowerShell cmdlets for app creators:\nRun PowerShell as an administrator.\nImport the necessary modules.\nInstall-Module -Name Microsoft.PowerApps.Administration.PowerShell\nInstall-Module -Name Microsoft.PowerApps.PowerShell -AllowClobber\nAlternatively, if you don't have admin rights on your computer, use the\n-Scope CurrentUser\nparameter for installation.\nInstall-Module -Name Microsoft.PowerApps.Administration.PowerShell -Scope CurrentUser\nInstall-Module -Name Microsoft.PowerApps.PowerShell -AllowClobber -Scope CurrentUser\nIf you're prompted to accept the change to the\nInstallationPolicy\nvalue of the repository, accept\n[A] Yes\nto all modules by typing\nA\n, then press\nEnter\nfor each module.\nOptionally, before accessing the commands, you can provide your credentials. Credentials are refreshed for up to eight hours before you're required to sign in again. If credentials aren't provided before a command is executed, then a prompt for credentials appears.\n# Opens a prompt to collect credentials (Microsoft Entra account and password).\nAdd-PowerAppsAccount\n# Here is how you can pass in credentials (to avoid opening a prompt).\n$pass = ConvertTo-SecureString \"password\" -AsPlainText -Force\nAdd-PowerAppsAccount -Username user@contoso.com -Password $pass\nOptionally, a specific endpoint can be targeted. The default endpoint is\nprod\n. If a user wants to run a PowerShell script targeting an environment in a nonproduction region, such as GCC, the\n-Endpoint\nparameter can be changed to\nusgov\nfor GCC Moderate, or\nusgovhigh\nfor GCC High, or\ndod\nfor GCC DOD. The full list of endpoints supported is: \"prod,preview,tip1,tip2,usgov,usgovhigh,dod,china\".\n# An environment in another region, such as GCC, can be targeted using the -Endpoint parameter.\nAdd-PowerAppsAccount -Endpoint \"usgov\"\nModule updates\nYou can check the version of all your PowerShell modules using\nGet-Module\n.\nGet-Module\nAnd you can update all your PowerShell modules to the latest using\nUpdate-Module\n.\nUpdate-Module\nAlternately, check the Power Platform modules version, using\nGet-Module\nand the\n-Name\nparameter.\nGet-Module -Name \"Microsoft.PowerApps.Administration.PowerShell\"\nGet-Module -Name \"Microsoft.PowerApps.PowerShell\"\nUpdate the Power Platform PowerShell modules, using\nUpdate-Module\nand the\n-Name\nparameter.\nUpdate-Module -Name \"Microsoft.PowerApps.Administration.PowerShell\"\nUpdate-Module -Name \"Microsoft.PowerApps.PowerShell\"\nPower Apps cmdlets for app creators\nPrerequisites for Power Apps cmdlets\nUsers with a valid Power Apps license can perform the operations in these cmdlets. However, they only have access to resources, like apps and flows, that are created or shared with them.\nCmdlet list - Maker Cmdlets\nNote\nWe updated some of the cmdlets function names in the latest release in order to add appropriate prefixes to prevent collisions. For an overview of what changed, refer the following table.\nPurpose\nCmdlet\nAdd a canvas app to a Microsoft Dataverse solution\nSet-PowerAppAsSolutionAware\nRead and update environments\nGet-AdminPowerAppEnvironment\n(previously Get-PowerAppsEnvironment)\nGet-FlowEnvironment\nRestore-PowerAppEnvironment\n(previously Restore-AppVersion)\nRead, update, and delete a canvas app\nGet-AdminPowerApp\n(previously Get-App)\nRemove-AdminPowerApp\n(previously Remove-App)\nPublish-AdminPowerApp\n(previously Publish-App)\nRead, update, and delete canvas app permissions\nGet-AdminPowerAppRoleAssignment\n(previously Get-AppRoleAssignment)\nRemove-AdminPowerAppRoleAssignment\n(previously Remove-AppRoleAssignment)\nRead, update, and delete a flow\nGet-AdminFlow\nEnable-AdminFlow\nDisable-AdminFlow\nRemove-AdminFlow\nRead, update, and delete flow permissions\nGet-AdminFlowOwnerRole\nSet-AdminFlowOwnerRole\nRemove-AdminFlowOwnerRole\nRead and respond to flow approvals\nGet-AdminFlowApprovalRequest\nRemove-AdminFlowApprovals\nRead and delete connections\nGet-AdminPowerAppConnection\n(previously Get-Connection)\nRemove-AdminPowerAppConnection\n(previously Remove-Connection)\nRead, update, and delete connection permissions\nGet-AdminPowerAppConnectionRoleAssignment\n(previously Get-ConnectionRoleAssignment)\nSet-AdminPowerAppConnectionRoleAssignment\n(previously Set-ConnectionRoleAssignment)\nRemove-AdminPowerAppConnectionRoleAssignment\n(previously Remove-ConnectionRoleAssignment)\nRead, and delete connectors\nGet-AdminPowerAppConnector\n(previously Get-Connector)\nRemove-AdminPowerAppConnector\n(previously Remove-Connector)\nAdd, read, update, and delete custom connector permissions\nGet-AdminPowerAppConnectorRoleAssignment\n(previously Get-ConnectorRoleAssignment)\nGet-PowerAppConnectorRoleAssignment\n(previously Set-ConnectorRoleAssignment)\nRemove-PowerAppConnectorRoleAssignment\n(previously Remove-ConnectorRoleAssignment)\nRead, add, and remove policy URL patterns\nGet-PowerAppPolicyUrlPatterns\nNew-PowerAppPolicyUrlPatterns\nRemove-PowerAppPolicyUrlPatterns\nRead, register, and remove management apps\nGet-PowerAppManagementApp\nGet-PowerAppManagementApps\nNew-PowerAppManagementApp\nRemove-PowerAppManagementApp\nRead, create, update, and import protection keys\nGet-PowerAppRetrieveAvailableTenantProtectionKeys\nGet-PowerAppGenerateProtectionKey\nGet-PowerAppRetrieveTenantProtectionKey\nNew-PowerAppImportProtectionKey\nSet-PowerAppTenantProtectionKey\nPower Apps cmdlets for administrators\nFor more information on Power Apps and Power Automate cmdlets for admins, see\nGet started with PowerShell for Power Platform Administrators\n.\nTips\nUse\nGet-Help\nfollowed by a\nCmdletName\nto get a list of examples.\nAfter you type dash\n-\n, you can press\nTab\nto cycle through the input tags. Place this flag after the cmdlet name.\nExample commands:\nGet-Help Get-AdminPowerAppEnvironment\nGet-Help Get-AdminPowerAppEnvironment -Examples\nGet-Help Get-AdminPowerAppEnvironment -Detailed\nOperation examples\nFollowing are some common scenarios that show how to use new and existing Power Apps cmdlets.\nEnvironments Commands\nPower Apps Commands\nPower Automate commands\nAPI connection commands\nData policy commands\nData resource exemption cmdlets\nBlock trial licenses commands\nEnvironments commands\nUse these commands to get details on and update environments in your tenant.\nDisplay a list of all environments\nGet-AdminPowerAppEnvironment\nReturns a list of each environment across your tenant, with details of each (for example, environment name (guid), display name, location, creator, and more).\nDisplay details of your default environment\nGet-AdminPowerAppEnvironment âDefault\nReturns the details for only the default environment of the tenant.\nDisplay details of a specific environment\nGet-AdminPowerAppEnvironment âEnvironmentName 'EnvironmentName'\nNote\nThe\nEnvironmentName\nfield is a unique identifier, which is different from the\nDisplayName\n(see first and second fields in the output in the following image).\nPower Apps commands\nThese operations are used to read and modify Power Apps data in your tenant.\nDisplay a list of all Power Apps\nGet-AdminPowerApp\nReturns a list of all Power Apps across the tenant, with details of each (for example, application name (guid), display name, creator, and more).\nDisplay a list of all Power Apps that match the input display name\nGet-AdminPowerApp 'DisplayName'\nThis command lists all Power Apps in your tenant that match the display name.\nNote\nUse quotations around input values that contain spaces. For example, use \"My App Name\".\nFeature an application\nSet-AdminPowerAppAsFeatured âAppName 'AppName'\nFeatured applications are grouped and pushed to the top of the list in the Power Apps mobile player.\nNote\nLike environments, the\nAppName\nfield is a unique identifier, which is different from the\nDisplayName\n. If you want to perform operations based on the display name, some functions will let you use the pipeline (see next function).\nMake an application a Hero app, using the pipeline\nGet-AdminPowerApp 'DisplayName' | Set-AdminPowerAppAsHero\nA Hero app appears at the top of the list in the Power Apps mobile player. There can only be one Hero app.\nThe pipe\n|\ncharacter between two cmdlets takes the output of the first cmdlet and passes it as the input value of the second, if the function is written to accommodate the pipe.\nNote\nAn app must already be a featured app before it's changed to a Hero.\nDisplay the number of apps each user owns\nGet-AdminPowerApp | Select âExpandProperty Owner | Select âExpandProperty displayname | Group\nYou can combine native PowerShell functions with the Power Apps cmdlets to manipulate data even further. Here we use the Select function to isolate the Owner attribute (an object) from the Get-AdminApp object. We then isolate the name of the owner object by pipelining that output into another Select function. Finally, passing the second Select function output into the Group function returns a nice table that includes a count of each owner's number of apps.\nDisplay the number of apps in each environment\nGet-AdminPowerApp | Select -ExpandProperty EnvironmentName | Group | %{ New-Object -TypeName PSObject -Property @{ DisplayName = (Get-AdminPowerAppEnvironment -EnvironmentName $_.Name | Select -ExpandProperty displayName); Count = $_.Count } }\nDownload Power Apps user details\nGet-AdminPowerAppsUserDetails -OutputFilePath '.\\adminUserDetails.txt' âUserPrincipalName 'admin@bappartners.onmicrosoft.com'\nThe previous command stores the Power Apps user details (basic usage information about the input user via their user principal name) in the specified text file. It creates a new file if there's no existing file with that name, and overwrites the text file if it already exists.\nExport a list of assigned user licenses\nGet-AdminPowerAppLicenses -OutputFilePath '<licenses.csv>'\nExports all the assigned user licenses (Power Apps and Power Automate) in your tenant into a tabular view .csv file. The exported file contains both self-service, sign-up, internal trial plans and plans sourced from Microsoft Entra ID. The internal trial plans aren't visible to admins in the Microsoft 365 admin center.\nThe export can take a while for tenants with a large number of Microsoft Power Platform users.\nNote\nOutput of the Get-AdminPowerAppLicenses cmdlet only includes licenses for users who accessed Power Platform services (for example, Power Apps, Power Automate, or Power Platform admin center). Users who had licenses assigned in Microsoft Entra ID (typically via the Microsoft 365 admin center) but never accessed Power Platform services don't have their licenses included in the generated .csv output. Furthermore, since the Power Platform licensing services caches the licenses, updates made to license assignments in Microsoft Entra ID can take up to seven days to reflect in the output for users who didn't access the service recently.\nSet logged in user as the owner of a canvas app\nSet-AdminPowerAppOwner âAppName 'AppName' -AppOwner $Global:currentSession.userId âEnvironmentName 'EnvironmentName'\nChanges the owner role of a Power App to the current user, and replaces the original owner as a \"can view\" role type.\nNote\nThe AppName and EnvironmentName fields are the unique identifiers (guids), not the display names.\nDisplay a list of deleted canvas apps in an environment\nGet-AdminDeletedPowerAppsList -EnvironmentName 'EnvironmentName'\nThis command displays all canvas apps recently deleted, as they might still be recovered. The restorable duration is 28 days. Any app deleted after 28 days isn't returned in this list and can't be recovered.\nRecover a deleted canvas app\nGet-AdminRecoverDeletedPowerApp -AppName 'AppName' -EnvironmentName 'EnvironmentName'\nThis command recovers a canvas app discoverable through the\nGet-AdminDeletedPowerAppsList\ncmdlet. Any canvas app that isn't displayed in the\nGet-AdminDeletedPowerAppsList\nisn't recoverable.\nDesignate SharePoint custom form environment\nThe following cmdlets can be used to specify and verify which environment SharePoint custom forms are saved to, instead of the default environment. When the designated environment for SharePoint custom forms changes, this environment is where newly created custom forms are saved. Existing custom forms don't automatically migrate to different environments as these cmdlets are used. The ability for a user to create a custom form in a designated environment requires that user to have the Environment Maker role. Users can be granted the Environment Maker role in the\nPower Platform admin center\n.\nAny environment that isnât the default environment can be deleted. If the designated SharePoint custom form environment is deleted, the custom forms are deleted with it.\nGet-AdminPowerAppSharepointFormEnvironmentâ¯\nThis command returns the\nEnvironmentName\nfor the environment currently designated for newly created SharePoint custom forms. If an environment has never been designated, the default environment is returned.\nSet-AdminPowerAppSharepointFormEnvironmentâ¯âEnvironmentName 'EnvironmentName'\nThis command designates the environment newly created SharePoint custom forms save to, instead of the default environment. Existing custom forms don't automatically migrate to the newly designated environment. Only production environment can be designated for SharePoint custom forms.\nReset-AdminPowerAppSharepointFormEnvironment\nThis resets the default environment as the designated environment to save SharePoint custom forms.\nDisplay tenant setting for ability to share apps with\nEveryone\n$settings = Get-TenantSettings \n$settings.PowerPlatform.PowerApps.disableShareWithEveryone\nThis setting controls whether users with the Environment Maker security role can share canvas apps with\nEveryone in an organization\n. When the setting is set to\ntrue\n, only users with an admin role (Dynamics 365 admin, Power Platform Service admin, Microsoft Entra tenant admin) can share apps with\nEveryone in an organization\n.\nRegardless of this tenant settings value, makers with the sharing privilege can share apps with security groups of any size. This control only determines whether the\nEveryone\nshorthand can be used when sharing.\nChange tenant setting for ability to share apps with\nEveryone\n$settings = Get-TenantSettings \n$settings.powerPlatform.powerApps.disableShareWithEveryone = $True \nSet-TenantSettings -RequestBody $settings\nSurface your organizationâs governance error message content\nIf you specify governance error message content to appear in error messages, the content in the error message is displayed when makers observe they donât have permission to share apps with\nEveryone\n. See\nPowerShell governance error message content commands\n.\nAssociate in context flows to an app\nAssociate flows in context of an app to the app to create a dependency between the app and flows. To learn more about context flows, see\nWhat Power Automate capabilities are included in Power Apps licenses?\nAdd-AdminFlowPowerAppContext -EnvironmentName <String> -FlowName <String> -AppName <String> [-ApiVersion <String>] [<CommonParameters>]\nEnvironmentName and FlowName can be found in the flow url:\nFor a Non-Solution flow, the URL looks like this:\nhttps://preview.flow.microsoft.com/manage/environments/839eace6-59ab-4243-97ec-a5b8fcc104e7/flows/6df8ec2d-3a2b-49ef-8e91-942b8be3202t/details\nThe GUID after\nenvironments/\nis the EnvironmentName and the GUID after\nflows/\nis the FlowName\nFor Solution flow, the URL looks like this:\nhttps://us.flow.microsoft.com/manage/environments/66495a1d-e34e-e330-9baf-0be559e6900b/solutions/fd140aaf-4df4-11dd-bd17-0019b9312238/flows/53d829c4-a5db-4f9f-8ed8-4fb49da69ee1/details\nThe GUID after\nenvironments/\nis the EnvironmentName and the GUID after\nflows/\nis the FlowName\nThe AppName for a canvas app can be found on the canvas app details page.\nThe AppName for a model driven app can be found in solution explorer.\nTo see the examples, type:\nget-help Add-AdminFlowPowerAppContext -examples\n.\nTo get more information, type:\nget-help Add-AdminFlowPowerAppContext -detailed\n.\nTo get technical information, type:\nget-help Add-AdminFlowPowerAppContext -full\n.\nRemove in context flows of an app\nRemove the dependency between flows and an app with this PowerShell command. The Remove-AdminFlowPowerAppContext removes app context from the specific flow.\nRemove-AdminFlowPowerAppContext -EnvironmentName <String> -FlowName <String> -AppName <String> [-ApiVersion <String>] [<CommonParameters>]\n\n - To see the examples, type: \"get-help Remove-AdminFlowPowerAppContext -examples\".\n - For more information, type: \"get-help Remove-AdminFlowPowerAppContext -detailed\".\n - For technical information, type: \"get-help Remove-AdminFlowPowerAppContext -full\".\nPower Automate commands\nUse these important commands to perform administration related to Power Automate.\nFor a full list of Power Automate and Power Apps cmdlets for admins, see\nGet started with PowerShell for Power Platform Administrators\n.\nDisplay all flows\nGet-AdminFlow\nReturns a list of all flows in the tenant.\nDisplay flow owner role details\nGet-AdminFlowOwnerRole âEnvironmentName 'EnvironmentName' âFlowName 'FlowName'\nReturns the owner details of the specified flow.\nNote\nLike\nEnvironments\nand\nPowerApps\n,\nFlowName\nis the unique identifier (guid), which is different from the display name of the flow.\nDisplay flow user details\nGet-AdminFlowUserDetails âUserId $Global:currentSession.userId\nReturns the user details regarding flow usage. In this example, we're using the user ID of the current logged in user of the PowerShell session as input.\nRemove flow user details\nRemove-AdminFlowUserDetails âUserId 'UserId'\nDeletes the details on a flow user completely from the Microsoft database. All flows the input user owns must be deleted before the flow user details can be purged.\nNote\nThe UserId field is the Object ID of the user's Microsoft Entra record, which can be found in the\nAzure portal\nunder\nMicrosoft Entra ID\n>\nUsers\n>\nProfile\n>\nObject ID\n. You must be an admin to access this data from here.\nExport all flows to a CSV file\nGet-AdminFlow | Export-Csv -Path '.\\FlowExport.csv'\nExports all the flows in your tenant into a tabular view .csv file.\nAdd flows into Dataverse solutions\nAdd-AdminFlowsToSolution -EnvironmentName <String>\nMigrates all the nonsolution flows in the environment.\nParameter variations can be used to migrate only specific flows, add into a specific solution, or migrate only a set number of flows at a time.\nFor technical details, see\nAdd-AdminFlowsToSolution\n.\nList HTTP Action flows\nGet-AdminFlowWithHttpAction -EnvironmentName <String>\nLists flows with HTTP actions.\nDisplayName\nFlowName\nEnvironmentName\nGet Invoice HTTP\nflow-1\nenvironment-1\nPay Invoice from App\nflow-2\nenvironment-2\nReconcile Account\nflow-3\nenvironment-3\nAPI connection commands\nView and manage API connections in your tenant.\nDisplay all native Connections in your default environment\nGet-AdminPowerAppEnvironment -Default | Get-AdminPowerAppConnection\nDisplays a list of all API connections you have in the default environment. Native connections are found under the\nDataverse\n>\nConnections\ntab in\nPower Apps\n.\nDisplay all custom connectors in the tenant\nGet-AdminPowerAppConnector\nReturns a list of all custom connector details in the tenant.\nNote\nGet-AdminPowerAppConnector\ndoesn't list custom connectors that are in a solution. This is a known limitation.\nData policy commands\nThese cmdlets control the data policies on your tenant.\nCreate a data policy\nNew-DlpPolicy\nCreates a new data policy for the signed-in admin's tenant.\nRetrieve a list of data policy objects\nGet-DlpPolicy\nGets policy objects for the signed-in admin's tenant.\nNote\nWhen you view a data policy using PowerShell, the display name of connectors are from when the data policy was created or when the connectors were last moved within the policy. New changes to the display names of connectors aren't reflected.\nWhen you view a data policy using PowerShell, new connectors in the default group that weren't moved aren't returned.\nFor both of these known issues, a workaround is to move the affected connector to another group within the policy and then move it back to the correct group. After doing this, each of the connectors is visible with their correct name.\nUpdate a data policy\nSet-DlpPolicy\nUpdates details of the policy, such as the policy display name.\nRemove a policy\nRemove-DlpPolicy\nDeletes a data policy.\nData resource exemption cmdlets\nThese cmdlets allow you to exempt or unexempt a specific resource from a policy.\nRetrieve existing exempt resource list for a data policy\nGet-PowerAppDlpPolicyExemptResources -TenantId -PolicyName\nCreate a new exempt resource list for a data policy\nNew-PowerAppDlpPolicyExemptResources -TenantId -PolicyName -NewDlpPolicyExemptResources\nUpdate the exempt resource list for a data policy\nSet-PowerAppDlpPolicyExemptResources -TenantId -PolicyName -UpdatedExemptResources\nRemove the exempt resource list for a data policy\nRemove-PowerAppDlpPolicyExemptResources -TenantId -PolicyName\nTo exempt a resource from a data policy, you need the following information:\nTenant ID (GUID)\nData policy ID (GUID)\nResource ID (ends with a GUID)\nResource type\nYou can retrieve the resource ID and type using PowerShell cmdlets Get-PowerApp for apps and Get-Flow for flows.\nExample removal script\nTo exempt flow with ID\nf239652e-dd38-4826-a1de-90a2aea584d9\nand app with ID\n06002625-7154-4417-996e-21d7a60ad624\n, we can run the following cmdlets:\n1. PS D:\\> $flow = Get-Flow -FlowName f239652e-dd38-4826-a1de-90a2aea584d9 \n2. PS D:\\> $app = Get-PowerApp -AppName 06002625-7154-4417-996e-21d7a60ad624 \n3. PS D:\\> $exemptFlow = [pscustomobject]@{ \n4. >> id = $flow.Internal.id \n5. >> type = $flow.Internal.type \n6. >> } \n7. PS D:\\> $exemptApp = [pscustomobject]@{ \n8. >> id = $app.Internal.id \n9. >> type = $app.Internal.type \n10. >> } \n11. PS D:\\> $exemptResources = [pscustomobject]@{ \n12. >> exemptResources = @($exemptFlow, $exemptApp) \n13. >> } \n14. PS D:\\> New-PowerAppDlpPolicyExemptResources -TenantId aaaabbbb-0000-cccc-1111-dddd2222eeee -PolicyName bbbbcccc-1111-dddd-2222-eeee3333ffff -NewDlpPolicyExemptResources $exemptResources \n15. \n16. exemptResources \n17. --------------- \n18. {@{id=/providers/Microsoft.ProcessSimple/environments/Default-aaaabbbb-0000-cccc-1111-dddd2222eeee/flows/f239652e-dd38-4826-a1de-90a2aea584d9; type=Microsoft.ProcessSimple/environments/flows}, @{id=/providers/Microsoft.PowerApps/apps/06002625-7154-4417-996e-21d7a60ad..\nData policy exemption experience in the following scenarios\n#\nScenario\nExperience\n1\nUser launches an app thatâs not data policy compliant but data policy exempt.\nApp launch proceeds with or without data policy enforcement.\n2\nMaker saves an app thatâs not data policy compliant but data policy exempt\nWith or without data policy exemption, data policy compliance doesn't block the app save operation. The data policy noncompliance warning is shown regardless of data policy exemption.\n3\nMaker saves a flow thatâs not data policy compliant but data policy exempt\nWith or without data policy exemption, data policy compliance doesn't block the flow save operation. The data policy noncompliance warning doesn't appear.\nGovernance error message content commands\nThe following cmdlets can lead your end users to your organizationâs governance reference material. The command includes a link to governance documentation and a governance contact for when they're prompted by governance controls. For instance, when governance error message content is set, it appears in Power Apps data policy runtime enforcement messages.\nSet governance error message content\nNew-PowerAppDlpErrorSettings -TenantId 'TenantId' -ErrorSettings @{ \n ErrorMessageDetails = @{ \n enabled = $True \n url = \"https://contoso.org/governanceMaterial\" \n } \n ContactDetails= @{ \n enabled = $True \n email = \"admin@contoso.com\" \n } \n}\nThe governance error message URL and email can be shown independently or together. You can enable or disable the governance error message with the\nenabled\nfield.\nGovernance error message content scenarios\n#\nScenario\nAvailability\n1\nUser launches an app created using Power Apps thatâs not data policy compliant\nGenerally available\n2\nMaker shares a Power Apps canvas app but doesnât have share privilege\nGenerally available\n3\nMaker shares a Power Apps canvas app with\nEveryone\nbut doesnât have privilege to share with\nEveryone\nGenerally available\n4\nMaker saves an app created using Power Apps thatâs not data policy compliant\nGenerally available\n5\nMaker saves a Power Automate flow thatâs not data policy compliant\nGenerally available\n6\nUser launches an app without security group membership to the security group associated to Dataverse environment\nGenerally available\nDisplay governance error message content\nGet-PowerAppDlpErrorSettings -TenantId 'TenantId'\nUpdate governance error message content\nSet-PowerAppDlpErrorSettings -TenantId 'TenantId' -ErrorSettings @{ \n ErrorMessageDetails = @{ \n enabled = $True \n url = \"https://contoso.org/governanceMaterial\" \n } \n ContactDetails= @{ \n enabled = $True \n email = \"admin@contoso.com\" \n } \n}\nEnforce data policy for violating connections - environment\nThese cmdlets allow you to enforce data policy for violating connections at environment or tenant level.\nEnforce data policies for violating connections\nYou can enforce data policies on connections in an environment. Enforcing disables existing connections that violate data policies and enables any previously disabled connections that no longer violate data policies.\nStart-DLPEnforcementOnConnectionsInEnvironment -EnvironmentName [Environment ID]\nExample environment enforcement script\nStart-DLPEnforcementOnConnectionsInEnvironment -EnvironmentName c4a07cd6-cb14-e987-b5a2-a1dd61346963\nEnforce data policies for violating connections - tenant\nYou can enforce data policies on connections in the tenant. Enforcing disables existing connections that violate data policies and enables any previously disabled connections that no longer violate data policies.\nStart-DLPEnforcementOnConnectionsInTenant\nBlock trial licenses commands\nCommands:\nRemove-AllowedConsentPlans\nAdd-AllowedConsentPlans\nGet-AllowedConsentPlans\nThe allowed consent plans cmdlets can be used to add or remove access to a particular type of consent plan from a tenant. \"Internal\" consent plans are either trial licenses or developer plans that users can sign themselves up for via Power Apps/Power Automate portals/Power Automate for desktop. \"Ad-hoc subscription\" or \"Viral\" consent plans are trial licenses that users can sign themselves up for at\nhttps://signup.microsoft.com\n. Admins can assign users through Microsoft Entra ID or the Microsoft 365 admin portal.\nBy default, all types of consent plans are allowed in a tenant. However, a Power Platform admin might want to block users from assigning themselves trial licenses, but retain the ability to assign trial licenses on behalf of users. This rule can be accomplished by using the\nRemove-AllowedConsentPlans -Types \"Internal\"\ncommand and by not allowing the setting\nUpdate-MgPolicyAuthorizationPolicy -AllowedToSignUpEmailBasedSubscriptions\nin Microsoft Entra ID.\nImportant\nWhen you use\nRemove-AllowedConsentPlans\n, all existing plans of the specified type are removed from all users in the tenant and aren't recoverable. This command blocks all future assignments of that type. If the Power Platform admin wishes to re-enable plans of that type, they can use\nAdd-AllowedConsentPlans\n. If they want to view the current state of allowed consent plans, they can use\nGet-AllowedConsentPlans\n.\nIf you have questions\nIf you have comments, suggestions, or questions, post them on the\nAdministering Power Apps community board\n.\nRelated information\nGet started using the Power Apps admin module.\nMicrosoft.PowerApps.Administration.PowerShell\nPreview: Programmability and extensibility overview\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "PowerShell",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/powershell-getting-started": {
      "content_hash": "sha256:b3fa6fffb6dd7d30334c34b631294abf61f5eb86448fd73b4754aeea10fe8b51",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGet started with PowerShell for Power Platform Administrators\nFeedback\nSummarize this article for me\nPowerShell for Power Platform Administrators cmdlets are designed for managing and administering Microsoft Power Platform environments, Power Apps, and Power Automate flows. Use PowerShell for Power Platform Administrators when you want to build automated tools that interact with these resources.\nThis article helps you get started with the PowerShell module and teaches the core concepts behind it.\nInstallation\nThe easiest way to get started with the PowerShell module is by installing it on your local machine. Follow the instructions in\nInstallation\nto import the module, or to update an outdated version you might have installed previously.\nSign in to Microsoft Power Platform\nSign in interactively with the Add-PowerAppsAccount cmdlet.\nAdd-PowerAppsAccount -Endpoint prod\nAlternatively, you can sign in with a client ID and secret or certificate. To do this, you need to\nCreate a service principal\n.\n$appId = \"CLIENT_ID_FROM_AZURE_APP\"\n$secret = \"SECRET_FROM_AZURE_APP\"\n$tenantId = \"TENANT_ID_FROM_AZURE_APP\"\n\nAdd-PowerAppsAccount -Endpoint prod -TenantID $tenantId -ApplicationId $appId -ClientSecret $secret -Verbose\nPrerequisite\nTo perform the administration operations in the cmdlets, you'll need the following:\nAny of these roles from Microsoft Entra ID, Tenant admin, Power Platform administrator, Dynamics 365 Service Administrator, can access the Power Apps admin PowerShell cmdlets. These roles no longer require a Power Apps plan for administrative access to the Power Apps admin PowerShell cmdlets. However, these administrators need to sign in to the Power Platform admin center at least once before using the PowerShell cmdlets. If this isn't done, the cmdlets fail with an authorization error.\nPower Platform administrator or Dynamics 365 administrator permissions are required if you need to search through another user's resources. Note that environment admins only have access to those environments and environment resources for which they have permissions.\nFor Dataverse for Teams environments, you must be a Power Platform administrator to manage environments from which you aren't the owner of the team in Microsoft Teams.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "PowerShell Getting Started",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/guidance/adoption/dlp-strategy": {
      "content_hash": "sha256:770524e94d57068d38b1b603e130613dde48a50336faa7333ce7b0468f85cc65",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nImplement a data policy strategy\nFeedback\nSummarize this article for me\nData policies, including data loss prevention (DLP) policies, act as guardrails to help prevent users from unintentionally exposing organizational data and to protect information security in the tenant. Data policies enforce rules for which connectors are enabled for each environment, and which connectors can be used together. Connectors are classified as either\nbusiness data only\n,\nno business data allowed\n, or\nblocked\n. A connector in the business data only group can only be used with other connectors from that group in the same app or flow. Learn more in\nData policies\n.\nEstablishing your data policies goes hand in hand with your\nenvironment strategy\n.\nQuick facts\nData policies\nact as guardrails to help prevent users from unintentionally exposing data.\nData policies can be scoped at the environment level and tenant level, offering flexibility to craft policies that are sensible and don't block high productivity.\nEnvironment data policies can't override tenant-wide data policies.\nIf multiple policies are configured for one environment, the most restrictive policy applies to the combination of connectors.\nBy default, no data policies are implemented in the tenant.\nPolicies can't be applied at the user level, only at the environment or tenant level.\nData policies are connector aware, but they don't control connections made using the connector. In other words, data policies can't determine whether the connector is used to connect to a development, test, or production environment.\nPowerShell and admin connectors can manage policies.\nUsers of resources in environments can view policies that apply.\nConnector classification\nBusiness and non-business classifications draw boundaries around what connectors can be used together in a given app or flow. Connectors can be classified across the following groups using data policies:\nBusiness\n: A given Power App or Power Automate resource can use one or more connectors from a business group. If a Power App or Power Automate resource uses a business connector, it can't use any non-business connector.\nNon-business\n: A given Power App or Power Automate resource can use one or more connectors from a non-business group. If a Power App or Power Automate resource uses a non-business connector, it can't use any business connector.\nBlocked\n: No Power App or Power Automate resource can use a connector from a blocked group. All Microsoft-owned premium connectors and third-party connectors (standard and premium) can be blocked. Microsoft-owned standard connectors and Common Data Service connectors can't be blocked.\nNote\nThe names \"business\" and \"non-business\" don't have any special meaningâthey are simply labels. The grouping of the connectors themselves is of significance, not the name of the group they're placed in.\nLearn more:\nConnector classification\nGranular control\nYou can achieve more granular control by configuring\nconnector action control\n. Through action control, you can choose which actions on a connector are allowed or not allowed. This option is for blockable connectors that you have added to a policy's non-business or business data group. Using it, you might allow makers to use the \"read\" actions but not the \"modify\" actions on the connector. Connectors get new actions when they're updated. You can set whether to allow or block new actions.\nAnother way to get more granular control is by configuring\nconnector endpoint filtering\n. Endpoint filtering allows admins to govern which specific endpoints makers can connect to when building apps, flows, or chatbots. Connector endpoint filtering applies to six connectors: HTTP, HTTP with Microsoft Entra ID, HTTP Webhook, SQL Server, Azure Blob Storage, and SMTP. The rules only apply when a maker uses a static value to specify an endpoint.\nPower Platform allows makers to create and share\ncustom connectors\n. You can manage\ncustom connectors for tenant and environment level data policies\n.\nSpecifically:\nEnvironment admins can use the Power Platform admin center to classify individual, custom connectors by name for environment-level data policies.\nTenant admins can use the Power Platform admin center and PowerShell to classify custom connector by their Host URL endpoints using a pattern matching construct for tenant-level data policies.\nData policies for Copilot Studio\nData policies let you govern how agents connect and interact with data and services, within and outside your organization. Learn more in\nConfigure data policies for agents\n.\nData policies for desktop flows\nPower Automate allows you to create and enforce data policies that classify desktop flow modules and individual module actions as business, non-business, or blocked. This categorization prevents makers from combining modules and actions from different categories into a desktop flow or between a cloud flow and the desktop flows it uses. Learn more in\nData policies for desktop flows\n.\nStrategies for creating data policies\nAs an administrator taking over an environment or starting to support use of Power Platform, data policies should be one of the first things you set up. With a base set of policies in place, you can then focus on handling exceptions and creating targeted data policies that implement these exceptions once approved.\nWe recommend the following starting point for data policies for\nshared user and team productivity environments\n:\nCreate a policy spanning all environments except selected ones (for example, your production environments), keep the available connectors in this policy limited to Microsoft 365 and other standard microservices, and block access to everything else. This policy applies to the default environment, and to training environments you have for running internal training events. Additionally, this policy also applies to any new environments that are created.\nCreate appropriate and more permissive data policies for your\nshared user and team productivity environments\n. These policies could allow makers to use connectors like Azure services in addition to the Microsoft 365 services. The connectors available in these environments depend on your organization, and where your organization stores business data.\nWe recommend the following starting point for data policies for\nproduction (business unit and project) environments\n:\nExclude those environments from shared user and team productivity policies.\nWork with the business unit and project to establish which connectors and connector combinations they use and create a tenant policy to include the selected environments only.\nUse environment policies to categorize custom connectors as business-data only, as necessary.\nWe also recommend to:\nCreate a minimal number of policies per environment. There's no strict hierarchy between tenant and environment policies. At design and runtime, all policies that are applicable to the environment in which the app or flow resides are evaluated together to decide whether the resource is in compliance or in violation of data policies.\nMultiple data policies\napplied to one environment will fragment your connector space in complicated ways and might make it difficult to understand issues your makers are facing.\nCentrally manage data policies using tenant level policies, and use environment policies only to categorize custom connectors or in exception cases.\nWith a base strategy in place, plan how to handle exceptions. You can:\nDeny the request.\nAdd the connector to the default data policy.\nAdd the environments to the All Except list for the global default data policy and create a use case-specific policy with the exception included.\nExample: Contoso's data strategy\nLet's look at how Contoso Corporation, our sample organization for this guidance, set up their data policies. The setup of their data policies ties in closely with their\nenvironment strategy\n.\nContoso admins want to support user and team productivity scenarios, business applications, and Center of Excellence (CoE) activity management.\nThe environment and data policy strategy that Contoso admins apply includes:\nA tenant-wide restrictive data policy that applies to all environments in the tenant except some specific environments that they exclude from the policy scope. Admins intend to keep the available connectors in this policy limited to Microsoft 365 and other standard micro-services by blocking access to everything else. This policy also applies to the default environment.\nContoso admins create another shared environment for users to create apps for user and team productivity use cases. This environment has an associated tenant-level data policy that isn't as risk-averse as a default policy and allows makers to use connectors like Azure services in addition to the Microsoft 365 services. Because this environment isn't the default environment, admins actively control the environment maker list for it. This strategy takes a tiered approach to shared user and team productivity environment and associated data settings.\nBusiness units create development, test, and production environments for their tax and audit subsidiaries across various countries and regions to build line-of-business applications. Access for environment makers is carefully managed, and appropriate first- and third-party connectors are made available using tenant-level data policies in consultation with business unit stakeholders.\nSimilarly, development, test, and production environments are created for Central IT to develop and roll out relevant applications. These business application scenarios typically have a well-defined set of connectors that need to be available for makers, testers, and users in these environments. Access to these connectors is managed using a dedicated tenant-level policy.\nContoso also has a special purpose environment dedicated to their Center of Excellence activities. In Contoso, the data policy for the special purpose environment remains high touch given the experimental nature of the theory teams book. In this case, tenant admins delegate data management for this environment directly to a trusted environment admin of the CoE team and exclude it from all tenant-level policies. This environment is managed only by the environment-level data policy, which is an exception rather than the rule at Contoso.\nAs expected, any new environments that are created in Contoso map to the original all-environments policy.\nThis setup of tenant-centric data policies doesn't prevent environment admins from coming up with their own environment-level policies, if they want to introduce more restrictions or to classify custom connectors.\nSet up data policies\nCreate your policy in the\nPower Platform admin center\n. Learn more in\nManage data policies\n.\nUse the\nDLP SDK\nto add custom connectors to a data policy.\nClearly communicate your organization's data policies to makers\nSet up a\nSharePoint site or a wiki\nthat clearly communicates:\nTenant-level and key environment-level (for example, default environment, trial environment) data policies enforced in the organization, inclusive of lists of connectors classified as business, non-business, and blocked.\nYour admin group's email ID so makers can contact them for exception scenarios. For example, admins can help makers comply by editing an existing data policy, moving the solution to a different environment, creating a new environment and a new data policy, and moving the maker and resource to this new environment.\nAlso clearly\ncommunicate your organization's environment strategy\nto makers.\nNext steps\nReview the detailed articles in this series to further enhance your security posture:\nDetect threats to your organization\nEstablish data protection and privacy controls\nConfigure identity and access management\nMeet compliance requirements\nSecure the default environment\nAfter reviewing the articles, review the security checklist to ensure Power Platform deployments are robust, resilient, and aligned with best practices.\nReview the security checklist\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Power Platform Governance",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/guidance/adoption/environment-strategy": {
      "content_hash": "sha256:3f6fa9ac3a20405450ddfd99144b0bc3df14fc11e66023e71700c14c45e2bc17",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nDevelop a tenant environment strategy to adopt Power Platform at scale\nFeedback\nSummarize this article for me\nEvery organization's journey to adopt Microsoft Power Platform is unique. A tenant environment strategy lays the foundation to help accelerate usage in a manageable and secure fashion.\nThis article shows you how to align your Power Platform tenant environment strategy with the product capabilities and vision. You learn how to best use the latest features of the platform to implement a strategy that can allow your adoption of Power Platform to reach enterprise scale.\nIntroduction\nPower Platform empowers organizations to build low-code solutions for rapid innovation. These solutions can focus on productivity for individuals and small teams, or apply across the organization. They can also extend to business processes, including external customers and partners. Supporting these solutions are Power Platform environments where the low-code resources are built, tested, and used. As an organization increases its adoption of Power Platform, implementing a good tenant environment strategy is essential to make it manageable and secure as the number of environments grows.\nTo help you be more successful, this article guides you on how best to use the features available to establish your first environment strategy or evolve your current plans. We also outline our vision for how these features are intended to work together and how they'll evolve for managing Power Platform at scale. In this guidance, we establish how to properly route new users to environments and group environments to consistently apply governance, security rules, and other important aspects of a tenant environment strategy. We also provide detailed steps to secure your default environment, which is a critical first step in implementing an environment strategy.\nWhile many perspectives are available for managing Power Platform environments, the approach in this article aligns with Microsoft's latest product direction and uses current features and near-term planned enhancements. This updated guidance can help you ensure that you use only the environment features and options that are strategic to how Microsoft intends for you to manage environments at scale.\nMicrosoft's tenant environment strategy vision\nMany organizations start their Power Platform journey with personal productivity apps and automations built and running in a shared central environment called the\ndefault environment\n. These resources often use only the basic capabilities included with Microsoft 365 and don't use the full capabilities of Power Platform. As this initial adoption accelerates, Microsoft provides organizations with an on-ramp to an environment strategy for enterprise scale adoption of the full Power Platform capabilities. These premium governance capabilities become available when users have a premium Power Platform (Power Apps, Power Automate, Microsoft Copilot Studio, and Dynamics 365) license. The\nPower Platform adoption maturity model\nprovides more insights to help organizations define their roadmap to achieve enterprise scale adoption beyond their environment strategy. This approach can help organizations mature from basic personal productivity to enterprise-scale adoption of Power Platform.\nPower Platform administrative, governance, and security features allow organizations to adopt and manage Power Platform for enterprise productivity and enterprise app usage at scale. Using Managed Environments activates a set of premium capabilities that enable greater visibility and control and reduce the manual effort to administer and secure environments. Using these capabilities, you can ensure consistent application of your governance and security policies. Admins can transition into an enterprise-scale, environment strategy using these capabilities. Spending less time and effort on the administration helps reduce the overall total cost of ownership (TCO) of the platform as your organization scales usage.\nA key element of the transition to enterprise scale is to enhance the shared, central environment strategy for makers by making it easier for them to use personal, development environments. In a shared, central environment strategy, makers build, use, and share apps in the default environment. This strategy can result in lack of isolation and makers encroaching on each other. Imagine if everyone in the company shared a single OneDrive folder for all their documents. Instead, use environment features to guide makers to their own, personal environment where they can safely build their apps protected from makers working on unrelated assets, with simplified governance for admins. Coworkers can be added as more makers to these environments to collaborate on building solutions.\nFigure: Illustration of a shared, central environment (left) and an environment routing strategy (right).\nNewly created maker environments can be automatically added to a group that applies rules to ensure that the environments have consistent governance and security policies. Admins can handle exceptions by moving a maker's environment to a group with relaxed rules.\nLow-code resources created by the makers represent the initial stage in a resource's application lifecycle management (ALM) journey. As part of this initial stage, it's important to capture each version of a resource and be able to recreate it, if necessary. When the resource is ready to be shared, the maker can use the continuous integration attached to the developer environment to promote it to a production environment. Users can then run the resource, isolated from any ongoing maker activity.\nPrioritize the built-in features of the platform for managing environments when possible, instead of building your own tools. If the built-in features don't meet your organization's unique requirements, use platform admin tooling to create custom tools. You should evaluate any custom tooling against new features as they become available. Monitoring Microsoft's platform roadmap and aligning it with your own roadmap makes this process easier.\nEstablish your environment strategy using the recommended environment capabilities tailored for your organization's unique needs. Don't think of creating your environment strategy as a one-time activity. It should evolve over time to incorporate new environment features as they become available.\nFeatures that support an enterprise-scale, environment strategy\nEnvironments\nare a building block for Power Platform administration, governance, and security. A complete feature overview is out of the scope of this article; however, this section highlights the features that support implementation of an environment strategy at enterprise scale.\nTypes of environments\ndescribes the different uses of environments as part of your strategy.\nManaged Environments\nprovides a set of premium capabilities that make environments easier to manage at scale.\nLicense auto-claim\nsimplifies license assignment by allowing users to claim Power Apps per user licenses when they're needed, instead of requiring an admin to identify users who need licenses in advance.\nEnvironment groups and rules\nexplains how to manage environments as groups and apply rules to groups to automate consistent governance policies.\nDefault environment routing\nautomatically moves makers away from creating resources in the default environment to their own personal environment.\nMicrosoft Dataverse\nprovides enhanced security and ALM.\nPreferred solutions\nhelps makers ensure that all the assets they build are in a Dataverse solution, making it easier to promote them to other environments.\nPipelines in Power Platform\nprovides a simplified process for promoting assets from development to test and production environments, making continuous integration and deployment (CI/CD) available to all makers.\nCatalog in Power Platform\nallows makers to share components, like apps and flows, and more advanced starting points such as templates.\nTypes of environments\nThe following table describes the types of environments you can create, their characteristics, and their intended uses.\nType\nCharacteristics and uses\nDefault\nThe environment that comes with every tenant. Many Microsoft 365 experiences use this environment for customizations and automations. This environment isn't intended for long-term or permanent work beyond the Microsoft 365 personal, productivity scenarios.\nProduction\nThis environment is intended to be used for permanent work in an organization. Production environments support extended, back-up retention, from seven days to up to 28 days.\nSandbox\nThese nonproduction environments support environment actions like copy and reset. Sandboxes are best used for testing and ALM build environments.\nDeveloper\nThese special environments are intended as makers' personal development workspaces, which isolate low-code assets from users and other makers. Makers can have up to three developer environments. They don't count against your tenant capacity. Developer environments that haven't been used for 90 days are automatically turned off and then removed from your tenant if the owner doesn't respond to notifications. Dynamics 365 apps aren't available in developer environments.\nTrial\nThese environments are intended to support short-term testing and proofs of concept. They're limited to one per user. Trial environments are automatically removed from your tenant after a short period of time.\nMicrosoft Dataverse for Teams\nThese environments are automatically created when you create an app in Teams or install an app from the app catalog. The security model for these environments aligns with the team they're associated with.\nSupport\nThese are special environments created by Microsoft Support to allow engineers to troubleshoot problems. These environments don't count against your tenant capacity.\nWhen creating an overall tenant environment strategy, consider the different types to support your recommendations.\nManaged Environments\nEnvironments have a base set of features and characteristics depending on the environment type. Managed Environments expand on the base features to provide a suite of premium capabilities that allow admins to more easily manage Power Platform at scale with more control, less effort, and more insights. These capabilities are unlocked when you set an environment as managed.\nThe following table lists the features of Managed Environments that are available, as of this writing. New features are added often, so check the\ndocumentation\nfor the latest list. Although all the features can help you build an environment strategy, the features in italics are more relevant for the strategy that's outlined in this article.\nMore visibility\nMore control\nLess effort\nUsage insights\nAdmin digest\nLicense reports\nData policy view\nExport data to Azure Application Insights\nAI-generated descriptions for all apps\nSharing limits\nData policies for desktop flows\nSolution checker\nMaker welcome content\nIP firewall\nIP cookie binding\nCustomer-managed keys\nCustomer Lockbox\nExtended back-ups\nEasy activation\nPower Platform pipelines\nEnvironment routing\nEnvironment groups and rules\nActions page\nLicense auto-claim\nAuto-claim policies\nautomate the assignment of Power Apps and Power Automate licenses to users when they need one to use certain apps or features. Automation can help reduce the number of licenses consumed and avoid the overhead of manually assigning licenses.\nAfter a policy is configured, any user in the organization who needs an individual Power Apps license is automatically granted one under the following conditions:\nIf a user without a standalone Power Apps license launches an app that demands a premium license, the system automatically assigns the user a Power Apps per user license.\nIf a user without a standalone Power Apps license launches an app in a Managed Environment, the system automatically assigns the user a Power Apps per user license.\nSimilarly, after a policy is configured, any user in the organization who needs an individual Power Automate license is automatically granted one under the following conditions:\nThe user triggers, saves, or turns on a premium cloud flow with attended RPA (Robotic Process Automation).\nThe user requests a Power Automate premium license.\nWe recommend configuring license auto-claim if your environment strategy includes Managed Environments. Users of apps and flows encounter the least amount of licensing friction, and you only consume licenses for users who are actively running apps or using Power Automate.\nEnvironment groups and rules\nAs Power Platform adoption in your tenant increases, so can the number of environments that require administration and governance. As the number of environments increases, the more challenging it becomes to ensure that you've applied consistent settings and governance policies on the environments. The\nenvironment groups feature\nmakes this easier, by allowing you to create named groups and associate environments with them, like placing related documents in a file folder.\nKeep the following considerations in mind as you think about using environment groups:\nAn environment must be managed to be included in a group.\nAn environment can be in only one group at a time.\nAn environment can be moved from one group to another.\nEnvironments in a group can be from multiple geographic regions.\nGroups can't contain other groups.\nTo help you apply consistent settings and governance, environment groups can have one or more of the following rules configured and turned on:\nSharing controls for canvas apps\nUsage insights\nMaker welcome content\nSolution-checker enforcement\nBack-up retention\nAI-generated descriptions\nA rule becomes active when it's published. Active rules are applied to all environments that are associated with the group.\nWhen a group rule is managing a setting, individual environment settings are locked. The only way to change them is to modify the rule. If the environment is removed from the group, it keeps the group settings, but an environment admin can change them. This approach is important for an environment strategy because it ensures that an environment admin can't override the policies set for the group.\nUsing environment groups allows you to organize your environments in logical ways, similar to your organization structure, product service hierarchy, or other frameworks that we explore later. The following diagram is a conceptual example of how the Contoso organization might think about organizing its environment groups.\nFigure: Conceptualization of an environment strategy for a Contoso tenant.\nWhen you're planning the rules to configure, think through what you could apply at each level of the conceptual hierarchy. Although you can't configure the group hierarchy yet, you can use a combination of naming conventions and rule configuration to implement your conceptual design. For example, given the Contoso tenant conceptualization shown earlier, the following illustration represents the environment groups the organization could use to implement its design.\nFigure: Example of implementing the conceptual environment groups into the actual tenant\nLater in this article, we explore more ways to use environment groups as part of a tenant environment strategy.\nDefault environment routing\nA key part of the environment strategy that we outline in this article is to move makers away from creating resources in the default environment. The\nenvironment routing feature\nredirects makers into their personal development environment and creates new developer environments, as needed.\nFigure: A maker is automatically redirected to a personal, developer environment instead of the default environment when building apps.\nThe developer environments that are created by routing are managed by default. Users with Developer Plan licenses are limited to creating and previewing resources in the environment. To run the resources as a user, they need an appropriate\nlicense\n.\nYou can use environment routing by itself, but the recommended way is to use it with environment groups. When used this way, any environment that's created is associated with the group that you designate to contain all new developer environments, ensuring that it's immediately covered by your governance policies.\nMakers are automatically assigned a security role that makes them an environment admin of their developer environment. When the environment is a part of an environment group, the makerâas the environment adminâcan't change the environment settings because they're managed by the environment group rules. Only admins, who can modify the group rules, can make any changes.\nYou can impose even more control in two ways. First, you can disallow manual creation of developer environments in your tenant settings. When this option is set, makers can't create environments themselves in the admin portal. They also won't get one automatically created by the routing policy. Second, you can specify a security group, in the routing policy, to limit who can automatically get an environment created.\nInitially, environment routing supports routing new and existing makers away from the default environment when they use\nmake.powerapps.com\n. Over time, other Power Platform services will support the environment routing feature.\nMaker welcome content\nProvide\ncustomized welcome content\nto help makers get started with Power Apps and Copilot Studio. When you add your own help content, it replaces the default Power Apps first-time help experience for makers. The custom welcome message can inform makers about the company rules and what they can do in each environment or group of environments.\nHere are some suggestions for how your organization might use the welcome message in each type of environment. Include an image that identifies the environment type or owners to help with user adoption and error prevention.\nDefault environment\nThe default environment is often the most restricted, with data policies and sharing controls. Create a welcome message that warns your makers about restrictions and possible limitations, and include a link to your organization's policy website or document.\nFor example, you might want to inform makers to use the default environment only for solutions that are related to Microsoft 365 applications, avoid using production applications in the default environment, and to share their canvas apps only with a limited number of individuals. The following example shows how to create such a message in Managed Environments settings:\nExample Markdown input:\n![Contoso](https://i.ibb.co/SNSTCx3/something.png)\n## Welcome to Contoso Personal Productivity Environment\n\n### Before you start, here are some considerations\n\nUse this environment if you plan to build apps that integrate with Office 365.\n\nBefore you start, be aware of these limitations:\n\n1. You can't share your apps with more than five users.\n1. The data in Dataverse is shared with everyone in the organization.\n1. You can only use Office 365 connectors.\n\nIf you're not sure you're in the right place, follow **[this guidance](#)**.\nHere's the rendered welcome message:\nProduction environments\nProduction environments are typically used for deploying solutions that support the enterprise and team productivity. It's important that apps and data comply with organizational policies. Since you need to control which users have access to the production environment, it's a good idea to inform users if you have a policy of refreshing access. You might allow more connectors and increase the sharing limits in a production environment. You can also use the welcome message to inform makers of the right team to reach out to for support. The following example shows how to create such a message:\n![Contoso](https://i.ibb.co/SNSTCx3/something.png)\n## Welcome to HR Europe Environment\n\n### Before you start, here are some considerations\n\nUse this environment if you're on the HR team and your data is located in Europe.\n\nBefore you start, be aware of these limitations:\n\n1. You can only share apps with security groups. [Follow this process](#) to share your apps.\n1. The data in Dataverse is stored in Europe.\n1. You can only use social media connectors with read actions.\n1. If you need more connectors, [submit a request](#).\n\nIf you're not sure you're in the right place, follow **[this guidance](#)**.\nHere is sample output:\nDeveloper environments\nDeveloper environments are most often where developers build their solutions. Since the developers are working on the applications, they aren't in production, and scalability is limited. Normally, dev environments have more relaxed data policies due to the nature of the makers. To avoid developers using production assets in their dev environments, limit sharing capabilities and use a specific data policy for this type of environment. Here's an example of a welcome message for a development environment:\n![Contoso](https://i.ibb.co/SNSTCx3/something.png)\n## Welcome to a Developer Environment\n\n### Before you start, here are some considerations\n\nUse this environment if you're a developer and you're building solutions.\n\nBefore you start, be aware of these limitations:\n\n1. You can only share resources with up to two members of your team. If you need to share with more people, [submit a change request](#).\n1. Use resources only while you're developing a solution.\n1. Be mindful of the connectors and data you're using.\n1. If you need more connectors, [submit a request](#).\n\nIf you're not sure you're in the right place, follow **[this guidance](#)**.\nHere is sample output for a developer environment:\nSandbox environments\nTypically, sandbox environments are used to test solutions. Because some tests involve a significant number of users, these environments scale, up to a point, and have more capacity than a developer environment. Sandbox environments are also commonly used as development environments and are typically shared by multiple developers. Here's an example of a welcome message for such an environment:\n![Contoso](https://i.ibb.co/SNSTCx3/something.png)\n## Welcome to a Test Environment\n\n### Before you start, here are some considerations\n\nUse this environment only if you're testing solutions.\n\nBefore you start, be aware of these limitations:\n\n1. You can only share resources with your team. If you need to share with more people, [submit a change request](#).\n1. You're not allowed to edit or import solutions directly in this environment.\n1. Be mindful of the test data and compliance.\n1. If you need help from a security export or IT support, [submit a request](#).\n\nIf you're not sure you're in the right place, follow **[this guidance](#)**.\nHere is sample output for a sandbox or test environment:\nLimit sharing\nAdmins can\nlimit how broadly users can share canvas apps, flows, and agents\n. The limit only applies to future sharing, however. If you apply a sharing limit of 20 to an environment with resources that are already shared with more than 20 users, those resources continue to work for all users the resources were shared with. Create a process to inform makers of apps, flows, and agents shared with more than the new limit so they can reduce the number of users their resources are shared with. In some cases, you might decide to move the solution to another environment. Sharing limits apply to canvas apps, flows, and agents.\nAdmins typically need to control how makers share their apps, flows, and agents when:\nResources are shared in a personal productivity environment\n. If you have an environment where users can create resources for their own work, resources without global business value, or resources without support from IT, it's important that you don't allow makers to share them across the organization. If resources start as personal productivity but later become popular and are widely used, be mindful about the limit you set on sharing. A common limit is between 5 and 50 users.\nResources are shared with security groups or everyone\n. Resources that are shared with a security group can be run by all members of the group. In a developer environment, you might want the developer to control how resources are shared instead of relying on group membership. In other scenarios, you might want to allow sharing with everyone. If your organization's policy is that resources are shared with a security group that includes all users who are authorized to run the resource and is managed by the IT department, you might want to restrict makers from sharing with other security groups.\nHere are common sharing limits for each environment type:\nDefault\n: Select\nExclude sharing with security groups\n, select\nLimit total individuals who can share to\n, and select 20 for the value.\nDeveloper\n: Select\nExclude sharing with security groups\n, select\nLimit total individuals who can share to\n, and select 5 for the value.\nSandbox\n: Select\nExclude sharing with security groups\nand leave\nLimit total individuals who can share to\nunselected. Use this option if apps are shared with an IT-managed security group that includes the users who are authorized to run the application. If the maker, user, or team can manage which users are permitted to test a solution, select\nDon't set limits\n(default).\nProduction\n: Select\nDon't set limits\n(default). To control sharing based on a specific security group, select\nExclude sharing with security groups\nand leave\nLimit total individuals who can share to\nunselected.\nMicrosoft Dataverse\nDataverse securely stores and manages data that's used by applications. In the context of an environment strategy, the\nDataverse solution feature\nlets you transport apps and components from one environment to another. Makers build their assets in containersâsolutionsâthat track what they build. Solutions can easily be transported to other environments. Using this approach, you can separate developer environments, where makers build resources, from the production environments where they're used. Both makers and users benefit. Makers can continue to evolve their resources, and users aren't surprised by sudden changes. When makers are ready to publish their changes, they can request to promote the updated resource to the production environment.\nDataverse solutions are the mechanism for implementing ALM in Power Platform products like Power Apps and Power Automate. Pipelines in Power Platform use solutions to automate CI/CD of assets that makers build. Solutions can be exported from Dataverse and stored in a source control tool like Azure DevOps or GitHub. The solution in source control becomes the source of truth if you need to recreate the development environment. For example, if a maker built a popular app and then deleted the developer environment, an exported solution stored in source control could be used to recreate a viable development environment.\nAnother important consideration when you create an environment with Dataverse is whether any Dynamics 365 applications will be deployed to the environment. If the potential exists, you must enable Dynamics 365 when you create the environment or you won't be able to install Dynamics 365 apps later.\nWe recommended that you provision Dataverse in any environment where makers create assets that will be shared with other users. This strategy makes it easier for the assets to be ALM ready.\nPreferred solutions\nWhen a maker creates a Dataverse asset in a Dataverse environmentâand doesn't start from a custom solutionâthe asset is associated with the default solution and may also be associated with the Common Data Service default solution. The default solution is shared by all makers who create assets in the environment. Identifying which maker created specific components or which assets belong to specific apps is challenging, making it harder to promote a popular app to another environment for sharing with a larger audience. To do so, you need to promote all the assets in the default solution, which isn't ideal.\nTo support your environment strategy and make it easier to work with, makers should create a custom solution in their development environment, and then set it as the\npreferred solution\nin the environment. Makers set the preferred solution in an environment to indicate which solution an asset they created should be associated with. Preferred solutions can help ensure that when makers use pipelines to promote their resources to other environments, the promoted solution contains all the required assets. Think of this as preparing the assets to be ALM-ready.\nPipelines in Power Platform\nAs we've seen, a key tenet of a good environment strategy is to isolate where an asset is built from where it's deployed and used. This separation ensures that users who are trying to use an asset don't encounter downtime because a maker is updating it. However, it requires assets to be promoted to a production environmentâideally, as part of a Dataverse solutionâbefore they can be used.\nDataverse solutions can be manually transported between environments. However, you can automate the processâand put policies in place to ensure that proper change management occursâusing\npipelines\n. Depending on the environment rules that you set in the\nsolution checker\n, pipelines automatically enforce all the rules before the solution is deployed, preventing further deployment errors. The following diagram illustrates how pipelines can automate the promotion of an asset from development to production.\nFigure: A pipeline automates promoting an asset that's stored in source control from development, through test, to production.\nYou can configure the number of environments and processes, like approvals, that need to be included in a pipeline.\nPipelines work together with environment groups. They can be preconfigured for development environments to allow makers to easily start the promotion process by responding to a prompt when they try to share their assets with other users. As part of a deployment request using pipelines, makers can propose whom to share their assets with and the required security roles. A pipeline admin can approve or reject the request before deployment by ensuring least privileges for the maker who originated it.\nPipelines in Power Platform store the definitions of each pipeline in a host environment that Microsoft manages by default. However, you can define multiple host environments in your tenant that you manage, allowing you to handle unique requirements.\nSolution checker enforcement\nIt's common for a Center of Excellence (CoE) team to set up guardrails to reduce the risk of users importing noncompliant solutions into an environment. Admins can easily\nenforce rich static analysis checks of solutions\nagainst a set of best practice rules to identify problematic patterns. Organizations with decentralized CoEs often find it necessary to activate solution checker enforcement along with proactively reaching out to makers by email to offer support.\nSolution checker enforcement offers three levels of control, None, Warn, and Block. Administrators configure the effect of the check, whether it provides a warning but allows the import or blocks the import altogether, while also providing the result of the import to the maker.\nOrganizations that use this feature configure it differently depending on the environment type. It's normal to have exceptions, and this guidance should always be aligned with your needs. However, here are the most common settings for solution checker enforcement in each environment type:\nDefault: Select\nBlock\nand\nSend emails\n.\nDeveloper: Select\nWarn\nand leave\nSend emails\nunselected.\nSandbox: Select\nWarn\nand leave\nSend emails\nunselected.\nProduction: Select\nBlock\nand\nSend emails\n.\nTeams Environment: Select\nBlock\nand\nSend emails\n.\nCatalog in Power Platform\nOrganizations where developers and makers build and share components like apps, flows, and templatesâadvanced starting pointsâtend to get more value from Power Platform.\nThe Power Platform catalog\nmakes it easy for makers to share their components and templates across environments.\nThe catalog is installed in an environment and can be installed with the pipeline host in the same environment. It's also possible to handle unique resource segmentation requirements by having multiple environments with a catalog installed.\nOrganizations that encourage developers and makers to build and share components and templates in the catalog derive more value from their investment in Power Platform. Simply building isn't enough. Sharing the artifacts, at scale, fosters communities and supports groups that can unlock value from a diverse set of personnel in the organization. In fact, organizations that are most successful with Power Platform adopt a fusion team model, where pro developers, makers, and admins work together to help their fellow employees derive the highest value possible from the platform by reusing solutions, templates, and components.\nFeature roadmap\nAs Microsoft continues to evolve the features of Power Platform that support governance and administration, you can follow along in the\nrelease planner\n. You learn what's planned, what's in the upcoming release wave, and what you can try now. You can even create your own release plan by saving the items you want to follow.\nFoundation of an enterprise-scale environment strategy\nWe discussed our vision for a tenant environment strategy at enterprise scale and key environment features that support it. Now, we look at how you can use those features together as part of an environment strategy. Your strategy should be based on your organization's unique requirements, so let's start with a basic example before we tailor a strategy to meet your needs.\nIn this example, Contoso leadership wants to empower employees to take advantage of Power Platform and have identified the following high-level requirements:\nEmployees need to be able to build automated, document approval processes and other Power Platform customizations with Microsoft 365.\nEmployees should be able to build Power Apps and Power Automate automations to improve their personal productivity.\nThe makers who are working on the company's Compliance Tracker app must be able to develop and maintain it.\nTo support these requirements, the Contoso admin and governance team developed the following environment topology:\nFigure: Proposed environment topology for Contoso's Power Platform at scale project.\nLet's explore this environment topology diagram in detail.\nThe default environment is used to build Microsoft 365 productivity customizations. Data policies and restrictions on sharing limit other types of maker activity and place guardrails around what makers can build in this environment.\nOnly admins are able to create trial, sandbox, and production environments. Makers use a custom Microsoft Form or another process to request a new environment. The\nMicrosoft Power Platform Center of Excellence (CoE) Starter Kit\nincludes\nan environment request\nthat could be used.\nFour environment groups are created: Development, Shared Development, UAT (user acceptance testing), and Production.\nAn environment routing policy set for the Development group routes makers away from the default environment into their own developer environments. As new development environments are created, they're automatically associated with the Development group and its rules are applied.\nThe Shared Development group supports environments that contain projects with multiple makers.\nThe UAT group contains environments that are used to test resources before they're promoted to production.\nThe Production group contains environments that host apps, flows, and other artifacts for production use.\nThis proposed topology is missing pipelines to automate promotion between development, test, and production environments. Let's add them now.\nFigure: The same environment topology with pipelines connecting a pipeline host environment to development, test, and production environments.\nIn the revised environment topology diagram, we've added a pipeline host environment and two pipelines. One pipeline moves resources from development to test and then to production environments. The pipeline rule on the Development group will be modified to use this pipeline. The other pipeline moves resources from the shared dev environment to test and then to production. The pipeline rule on the Shared Development group will be modified to use this pipeline.\nThis basic environment strategy provides a foundation that you can build on for other use cases, which we explore next.\nEnvironment strategies for specific scenarios\nHere are some common use cases that you might need to incorporate in the foundation tenant environment strategy.\nControl which makers can create developer environments\nBy default, anyone who has a Power Platform Premium license, a Developer Plan license, or a Power Platform tenant admin role can create a developer environment from the admin portal.\nIn the foundation environment strategy, environment routing ensures that makers are directed away from the default environment, to a new developer environment that's created in the designated group. However, makers can still manually create developer environments that aren't placed in an environment group and don't have its rules applied.\nTo refine which makers are eligible for environment routing, specify a security group in the routing configuration. When a security group is configured, only members of the security group are routed. All others fall back to the default environment.\nProvide more flexibility to advanced makers\nIn the foundation environment strategy, all new maker environments are routed to a designated developer environment group. Typically, this group of environments has a fairly restrictive set of governance rules applied.\nAs makers become more advanced, you can allow them to request access to more capabilities. Instead of removing them from the original environment group and manually managing the exception, you can use another environment group to track these advanced makers.\nFigure: Add more capable makers to an environment that has relaxed governance rules.\nOrganize developer environments by region or business unit\nIn the current implementation of environment routing, all new developer environments are created in a single environment group. What if you want to organize your makers' developer environments by region, for example, or business unit?\nUse routing to direct makers into a new developer environment that's created in the designated group. Then you can move it to another group that's based on region, organizational unit, or other criteria, where you can apply more granular governance rules.\nFigure: After environment routing creates developer environments in the designated group, move them to more structurally specific groups.\nMoving environments is a manual action today, but you'll be able to automate it when the Power Platform admin connector supports the group feature in a future update.\nDevelop an app for enterprise use\nA team in your organization might be developing an app for enterprise-wide use. The team might be IT-driven or include both IT and business users (what's known as a fusion team).\nIn the simplest environment strategy, the project team builds in a shared environment that's either a sandbox or a production type. A developer environment type isn't the best way to support multiple makers collaborating on a resource. Makers need to communicate with one another to avoid collisions and conflicts in the shared environment.\nDedicated testing and production environments aren't required. The app could be tested in and deployed to organization-wide testing and production environments that host multiple applications.\nFigure: Two enterprise apps under development in dedicated environments, then tested and deployed in environments that are shared with other apps.\nIn a more advanced variation, each maker has an individual developer environment. This strategy has the benefit of providing greater isolation to the maker, but can make combining individual work in an integration environment more complicated. Although working in isolation can be helpful for larger, sophisticated teams, it can add unnecessary overhead to smaller teams that can be more successful collaborating in a shared development environment.\nFigure: Two makers working on the same app in individual developer environments must combine their work in a shared integration environment before it moves to testing and production.\nThis variation commonly incorporates a source control strategy, with each development environment represented as a branch in source control that gets merged when changes are ready to be promoted. It's important to account for how the application will be maintained after the initial release.\nFor example, version 1.0 of the app might be in production while the team moves on to building version 2.0. Your environment strategy must support fixing a problem in version 1.0, while development of version 2.0 is underway.\nFigure: Version 1.0 must be patched, tested, and deployed while version 2.0 is being developed, tested, and deployed.\nEnvironment groups offer multiple approaches to handling this enterprise app scenario. For example, this could be a single app group or could involve having separate groups for each development stage. In the best practices section, we explore how to evaluate the options.\nMinimize use of developer environments\nIndividual developer environments are the recommended way to provide makers a workspace to build low-code solutions. They offer the highest level of isolation from other makers. If your organization wants to minimize the number of developer environments, multiple shared environments are better than encouraging makers to build assets in the default environment.\nIn this scenario, you would restrict the creation of developer environments and create shared production-type development environments. You could organize these shared environments by organization structure, region, or other criteria. An environment group could contain them to ensure that they have consistent governance rules applied. Grant makers permission to create low-code assets in the environment that's assigned to them.\nSecurity as part of your environment strategy\nEnvironments are a key component of using Power Platform securely. They represent security boundaries within your tenant that help protect apps and data. As part of your environment strategy, you must consider how your security requirements influence the number and purpose of the environments in your tenant.\nEnvironments enable you to create multiple security boundaries within your tenant to protect apps and data. The protection provided by the environment can be adjusted to meet the necessary security protection by applying a configurable set of security features on the environment. A detailed discussion of individual environment security features is beyond the scope of this article. However, in this section we offer recommendations for how to think of security as part of your tenant environment strategy.\nSecurity at the tenant level\nMost security settings that affect environments are configured for each environment individually. However, you can make some changes at the tenant level to help support your environment strategy.\nConsider\nturning off the Share with Everyone feature\nin Power Platform. Only admins would be able to share an asset with everyone.\nConsider\nsecuring integration with Exchange\n.\nApply cross-tenant isolation\nto help minimize the risk of data exfiltration between tenants.\nRestrict the creation of net-new production environments to admins.\nLimiting environment creation\nis beneficial to maintain control in general, both to prevent unaccounted capacity consumption and to reduce the number of environments to manage. If users have to request environments from central IT, itâs easier to see what people are working on if admins are the gatekeepers.\nSecure the default environment\nThe default environment has a role in supporting Microsoft 365 productivity customizations. As part of the recommended environment strategy, though, it's best to minimize its use as much as possible. Instead, makers should build in their own isolated environments. Although you can't block access to the default environment, you can minimize what can be done in it.\nFirst, use environment routing to direct makers to their own workspace to build low-code assets.\nReview who has admin access to the default environment and limit it to roles that need it.\nConsider renaming the default environment to something more descriptive, like \"Personal Productivity.\"\nEstablish a data policy for the default environment that blocks new connectors and restricts makers to using only basic, unblockable connectors. Move all the connectors that can't be blocked to the business data group. Move all the blockable connectors to the blocked data group.\nCreate a rule\nto block all URL patterns used by custom connectors.\nSecuring the default environment is a priority. Implement it with tenant-level security as part of the first step in your environment strategy. Without these measures, makers can add more assets to the default environment. With these measures and environment routing in place, makers are encouraged to use their own environment.\nLearn more:\nSecure the default environment\nSecure other environments\nIf your organization is like most, you have several environments in addition to the default environment. The level of security each one requires can vary depending on the apps and data it contains. Developer environments typically have more relaxed rules than production environments. Some production environments require the most protection possible.\nAs part of establishing your environment strategy, identify common levels of security for your environments and the features that protect each level, as in the following example.\nFigure: An example of three tiers of environment security and the security features that apply to environments in each tier.\nIncorporate the security levels you identify into your group strategy, and where possible, use rules to enable the security features in your environments. In this example, a rule limits sharing in all the environments that are designated as normal or medium security.\nAlign environments to your data policy strategy\nData policies are another important part of an overall governance effort to control the services used by low-code resources in an environment. Environment groups don't have a rule to apply a data policy to an environment. However, you can align your data policy strategy with your environment groups. For example, you could create a data policy with the same or a similar name as an environment group and apply it to environments in that group.\nLearn more about how to implement a data policy strategy\n.\nFigure: In this example, environments in the Personal Dev group follow a data loss prevention (DLP) policy that blocks all non-Microsoft connectors.\nTailor an environment strategy for your organization\nIn earlier sections, we described our vision for how organizations can manage environments at scale. We explored essential features, how they contribute to an environment strategy, and what a foundation environment topology that uses them might look like. We gave examples of how to build on that foundation to accommodate common scenarios. Because every organization is unique, the next step is for you to tailor an environment strategy that meets your organization's needs.\nStart where you are\nWhether your organization is new to Power Platform or has been using it for years, the first step is to evaluate your situation. Assess, at a high level, what's in your default environment, what other environments you have, and what they're being used for. Often an environment strategy is done as part of an overall effort to establish governance of Power Platform in an organization. If that is the case, you might already have established some of the governance vision that is required to tailor a strategy for your organization.\nOrganization information you should know includes:\nWhat is the vision for how Power Platform will be used in the organization?\nWho in the organization will be building low-code assets?\nYou need to make some key decisions:\nHow will makers get new environments?\nWill you group your environments, and if so, how?\nWhat security levels are required for different environments, and how do environments get classified?\nHow will you decide whether an app, automation, or Copilot will use an existing environment or a new one?\nAre there any gaps between the baseline features of the platform and your requirements that require a custom governance process?\nHow will you handle any existing assets in the default environment?\nDo you have a tenant and environment data policy strategy, and if so, how does it align with the environment strategy you're creating?\nYou might find inspiration in the\ncloud operating models\nthat are part of the Cloud Adoption Framework for Azure.\nFill gaps using the platform\nYou'll almost always find requirements that the platform's built-in capabilities don't satisfy. As you evaluate these gaps, consider the following possible outcomes of your evaluation:\nThe gap is acceptable.\nThe gap can be filled using the Power Platform Center of Excellence Starter Kit.\nThe gap can be filled using the platform's capabilities, such as APIs, connectors and custom apps, or automations.\nThe gap can be filled using a third-party tool or app.\nCoE Starter Kit\nThe\nPower Platform Center of Excellence Starter Kit\nis a collection of components and tools that are designed to help your organization adopt and support the use of Power Platform. A key aspect of the starter kit is its ability to collect data about platform usage across your environments, which can be helpful as you develop and evolve your environment strategy.\nFor example, the Environments Power BI dashboard offers an overview that helps you understand which environments exist in your tenant, who created them, and what assets they contain.\nFigure: The Environments dashboard in Power BI.\nThe kit includes starting points or inspiration, such as a process that makers can use to\nrequest new environments\nand changes to data policies for their environments.\nFigure: Flow diagram illustrating an environment management process in the CoE Starter Kit.\nPlatform programmability and extensibility\nOne of the great things about a low-code platform is that you can use it to build apps, automations, portals, and copilots to help you manage it. You also have access to lower-level tools that can be used to fill gaps in support of your environment strategy.\nYou can use the following connectors to build apps and flows:\nPower Platform for Admins\nand\nPower Platform for Admins V2\nPower Apps for Admins\nand\nPower Apps for Makers\nPower Automate Management\nYou can use the\nPower Platform command-line interface (CLI)\nto develop automations to help you manage the environment lifecycle and other tasks related to DevOps practices.\nWith\nPowerShell cmdlets for Power Platform creators and administrators\n, you can automate many monitoring and management tasks.\nThe\nPower Platform DLP SDK\ncan help you manage your tenant and environment data loss prevention policies.\nBest practice recommendations\nIn this section of the article, we build on the recommendations in the foundation and scenario-specific sections.\nNew environments\nAs part of developing your strategy, consider when to create environments to support a workload. Your evaluation must balance the benefits of isolation that an environment provides, such as locking down particular environments for better security, with the disadvantages, like the friction users face when sharing data across apps.\nWhen you're evaluating whether an app or an automation belongs in its own environment, assess the different stages of the app's life cycle separately. During development, isolation from other apps is important. When multiple apps are developed in a single environment, you risk creating cross-app dependencies.\nAs a general recommendation, when possible, development environments should be single-purpose, disposable, and easily recreated.\nTesting multiple apps in the same environment makes sense if they run together in production. In fact, if you don't test with the apps that will be running in production, you risk not discovering compatibility problems.\nWhen you evaluate the production environment for an app, keep the following considerations in mind:\nIs the app compatible with existing apps in the environment?\nFor example, two apps that both use the Dataverse Contact table for different purposes might not be compatible. Are the apps compatible from a data policy perspective?\nAre there special compliance or regulatory requirements for separation of data?\nFor example, does the sensitivity of the data require it to be isolated? Is there a requirement that data can't be included with other data?\nIs the data highly confidential or sensitive? Would exfiltration cause monetary or reputational damage to the organization?\nIsolating in a separate environment can allow for more control over security.\nDoes the app need data from other apps and need to be collocated with them?\nFor example, two apps that both use your Customer table should be hosted together. Separating them would create redundant data copies and create problems with maintaining the data.\nDoes the data require regional data residency?\nIn some scenarios, the same app or automation can be deployed to regional environments to ensure appropriate data isolation and residency.\nAre most users in the same region as the environment?\nIf the environment is in EMEA, but most of the app's users are US-based, sharing an environment might not provide the best performance.\nWill new admins be needed, or will the existing admins be sufficient?\nIf the new app requires more admins, are they compatible with the existing admins (since all will have admin permissions on all apps in the environment)?\nWhat's the life expectancy of the app?\nIf the app or automation is temporary or short-lived, it might not be a good idea to install it in an environment with more permanent apps.\nWill users have difficulty having to use multiple environments for different apps?\nThis can affect everything from finding an app on their mobile device to self-service reporting that has to pull data from multiple environments.\nCapacity\nEach environment, except trial and developer environments, uses 1 GB to provision initially. Capacity is shared across the tenant so it needs to be allocated to those who need it.\nConserve capacity by:\nManaging shared test and production environments. Unlike shared development environments, permissions in test and production environments should be limited to user access for testing.\nAutomate cleanup of temporary development environments and encourage use of trial environments for testing or proof-of-concept work.\nEnvironment groups\nEnvironment groups are flexible and allow you to accommodate various use cases unique to your organizations. Here are a few ways you could consider grouping environments as part of your environment strategy:\nBy service or component; for example, a ServiceNow service tree\nDevelopment, test, and production\nDepartments, business groups, or cost centers\nBy Projects\nBy location, if most environments in a location have similar governance needs; this can also help meet similar regional regulatory and legal compliance\nFigure: Environment groups for two different departments with different rules.\nNaming environments and groups\nAs part of your strategy, consider how environments and groups are named.\nEnvironment names are visible to admins, makers, and users. Only admins typically use environment groups, but makers may encounter them if they have privileges to create environments.\nDeveloper environments that are automatically created follow the pattern\n<user name>'s Environment\n; for example, \"Avery Howard's Environment.\" Environment groups aren't named automatically.\nEnvironment and environment group names aren't required to be unique. However, to avoid confusion, it's a best practice to avoid duplicate names.\nNames are limited to 100 characters. Shorter names are easier to use.\nNaming conventions\nEstablish consistent naming conventions.\nConsistent names help admins know what the group's purpose is and what environments it manages. Consistent names also make automation and reporting easier.\nA common practice is to include the lifecycle stage in the name of an environment; for example, Contoso Dev, Contoso Test, Contoso Prod. The goal is to clearly separate environments that have the same content, but different purposes.\nAnother common practice is to include the department or business unit in the name when the environment is dedicated to that group of users.\nFor example, you might decide that all environment or environment group names must follow the pattern\n<lifecycle stage>-<region>-<business unit>-<purpose>\n(Prod-US-Finance-Payroll).\nKeep names short, meaningful, and descriptive.\nAvoid including confidential information in names. They can be visible to anyone who has access to the admin center.\nThink about how your groups will evolve and grow over time, and make sure your naming convention can accommodate these evolving needs.\nAssets in the default environment\nYour environment strategy should encourage (or enforce) the use of personal, development environments to reduce what gets created in the default environment. However, you should look at what makers have already created in the default environment and evaluate how to handle each use case. Is it appropriate to leave in the default environment, or should it be migrated to another environment?\nA key part of this hygiene effort is identifying widely used applications in your organization that need a protected development environment separate from the production environment.\nThe following table lists example use cases and migration actions. Ultimately, your organization needs to identify its own use cases and risk factors associated with leaving assets in the default environment. Learn more about when to\nmove assets from the default environment\n.\nDefault environment\nMigration action\nMicrosoft 365 personal productivity\nStay in the default environment.\nAssets with a single maker that have been used recently but aren't shared\nMove to the owner's individual, developer environment.\nAssets with a single maker that have been used recently and are shared\nMove to the owner's individual developer environment and run from a shared production environment.\nAssets with multiple makers that have been used recently and are shared\nMove to a shared developer environment and run from a shared production environment.\nAssets that haven't been used recently\nNotify the owner and move to quarantine if no response.\nAssets in Dataverse for Teams environments\nMicrosoft Dataverse for Teams\nempowers users to build custom apps, bots, and flows in Microsoft Teams by using Power Apps, Microsoft Copilot Studio, and Power Automate. When a team owner adds this capability to their team, a Microsoft Power Platform environment with a Dataverse for Teams database is created and linked to their team. Learn how to\nestablish governance policies to manage Microsoft Dataverse for Teams environments\n.\nEnvironment strategy internally at Microsoft\nMicrosoft considers itself \"Customer Zero\" because it internally adopts Power Platform to drive automation and efficiency for its employees. The following numbers show the scale of use across Microsoft's internal tenant.\n50,000-60,000 active makers each month\nOver 250,000 applications and over 300,000 flows\nOver 20,000 environments\nMicrosoft is shifting from its prior environment strategy to one using the latest Power Platform governance features, including Managed Environments, environment groups, and rules.\nAs part of the enhanced strategy Microsoft plans to group together scenarios based on development type, organizational ownership, and risk level. Because so much is being built across the company, it's hard to focus on every possible scenario and to customize for each use case. Given the scale of innovation and change, automation is required, together with as many out-of-the-box controls as possible.\nMicrosoft is structuring its Power Platform environments into three broad categories that cover seven use cases, reflecting varying degrees of risk and control: personal productivity, team collaboration, and enterprise development.\nPersonal productivity\n: For users who just want to build an app or flow for themselves, without collaborating with others. These users are routed to personal development environments. These locked-down environments use Managed Environment features, including restricting sharing and controlling other actions. Connectors and actions in these environments are heavily restricted. These environments are the least risky. Using locked-down personal environments allows users to avoid the more rigorous compliance process required to build personal productivity apps and flows.\nTeam collaboration\n: For users who are building tooling, automation, and processes for their team. For this scenario, Microsoft recommends using Dataverse for Teams environments. Lifecycle, access management, and data labeling are controlled at the Microsoft 365 group-level, eliminating the need to spend time managing these users from a Power Platform governance perspective. This level of use is the next step up in the risk spectrum.\nEnterprise development/production-level used by all employees\n: For users building tooling or solutions used more broadly across the company. These environments may store the most sensitive data, use more powerful connectors, and require more governance. This level carries the highest risk and, therefore, significant effort is spent on governance. ALM is required, with preproduction work happening in sandbox environments and only managed solutions allowed in production environments. These environments must be linked to ServiceTree, which enforces reoccurring security and privacy reviews. The environment group rules are customized based on ServiceTree metadata and signals. Many environment groups and rules are used to manage and control these environments.\nMicrosoft's governance strategy isn't static. It's fluid and changes to adapt to new challenges and incorporate new Power Platform features.\nEvolve your tenant environment strategy\nIn this article, we described how to establish an enterprise-scale tenant environment strategy. The strategy grows with your business, regardless of where you're starting on the journey. Organizations of any size can benefit from the strategy we present; however, for organizations that are already at higher scale, the benefits are greater.\nDeveloping a tenant environment strategy isn't a one-time activity. It's a journey. Evolve your strategy over time as your needs change. Your strategy must also adjust to adopt new capabilities of the platform and to address new challenges.\nLike all journeys, different organizations join at different points along the way, but all have the same destination in mind. What follows are possible on-ramps that represent where your organization is today.\nStart\nYour organization is at the beginning of its journey to adopt Power Platform. This stage is often referred to as\ngreenfield\n. You're starting your journey at the best place because you don't have to worry about existing environments or the impact that new policies might have on how people in your organization are using Power Platform. This is the best time to implement an enterprise-scale environment strategy that's aligned with product features and best practices.\nExplore the key environment features and strategies that are outlined in this article. Take the time to understand the key themes and the considerations and decisions that you need to make to design and implement a tenant environment strategy that best fits your requirements.\nEstablishing a solid foundation now is essential to avoid having to wrangle an out-of-control situation that can occur later if you start without a defined strategy. Plan for rapid acceleration of your use of Power Platform, but avoid the temptation to over-engineer your environment strategy by adding complexity that isn't required. Remember, this is a journey, and you can continue to evolve your strategy as your needs change.\nAlign\nYour organization has and is executing an environment strategy that needs to be modified to align with new Power Platform features and best practices. This stage is often referred to as\nbrownfield\n. Unlike organizations just starting out, you need to consider the impact on your organization of changing your environment strategy.\nExplore the key environment features and strategies that are outlined in this article and evaluate what's required to evolve your strategy to be more in line. Usually all that's needed are incremental adjustments. When possible, plan the roll-out of changes to minimize the impact on your users.\nThe following suggestions are common incremental changes you could implement:\nTo start your alignment without affecting existing environments, create an environment group that contains new developer environments and establish rules for how you want to govern them. Turn on environment routing to ensure that all new developer environments are created in the designated group.\nEvaluate your grouping strategy and, if needed, create groups to support your existing environments. Establish rules on those groups that align with existing restrictions and exceptions. Move existing environments into those groups.\nIdentify broadly popular applications that are built and used in the default environment. Use pipelines to publish them to a production environment where users in your organization can run them. Then work on migrating development of those apps to either an individual developer environment or a dedicated development environment.\nCreate a plan to identify, quarantine, and remove assets in the default environment that aren't being used.\nEnhance\nThe environment strategy you're executing is already in line with the latest features and best practices, but your organization wants to add more controls or features.\nCommunicate your environment strategy to your organization\nYou implement your tenant environment strategy more successfully if your Power Platform users understand and are aligned with what you're trying to achieve. If you simply activate your strategy without any communication, users see the changes as restrictions and look for ways to work around them.\nAs part of developing or evolving your strategy, decide how you inform users of key elements of the strategy that affect their use of Power Platform. They don't need all the technical details of your strategyâonly the essentials that help them stay productive. For example, communicate:\nThe purpose of the default environment\nWhere they should build new low-code assets\nHow they should use their personal developer environment\nHow to request custom environments for specific business units or projects\nGeneral connector usage policies, and how to request more connector privileges for their environments\nHow to share what they build with others\nThe responsibilities of a maker; for example:\nKeep the tenant clean. Delete your environments, apps, and flows if they're no longer needed. Use test environments if experimenting.\nShare wisely. Watch out for oversharing of your environments, apps, flows, and shared connections.\nProtect organization data. Avoid moving data from highly confidential or confidential data sources to unprotected or external storage.\nWhen your strategy changes, share how the changes affect your users so that they know what to do differently\nA good start is to\nturn on the maker welcome content\nin the environment group where new makers are added.\nFigure: Use the welcome content to help new makers be successful.\nAnother effective approach to communicating with your users is establishing an internal Power Platform hub. The hub can be a place for people to collaborate on projects, share ideas, and discover new ways to apply technology to achieve more. The hub is where you might also share detailed information about your environment strategy that's relevant to your users. Learn how to\ncreate an internal Power Platform hub\n.\nConclusion\nIn this article, we explored features that are designed to help your organization manage Power Platform environments at enterprise scale and incorporate them into your tenant environment strategy.\nAs your organization adopts Power Platform and usage accelerates, the need for environments can change rapidly. You need an agile approach that helps your environment strategy keep up with changes and continue to meet your organization's evolving governance requirements.\nA key factor for success with a tenant environment strategy is communicating with your makers and users and gaining their support. Make sure that the people who build low-code applications and automations know how to follow your organization's environment strategy and where they should be building their low-code assets.\nEvery organization's journey to adopting Power Platform is unique. We presented some ideas to help you get started. Your Microsoft account team or Power Platform partner can help you create a more customized tenant environment strategy for your organization.\nRelated information\nEnvironment groups\nEnvironment routing\nEnterprise security with Power Platform (white paper)\nLow-code security and governance\nSolution concepts in ALM\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Environment Strategy",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/guidance/coe/power-bi-monitor": {
      "content_hash": "sha256:55fe25228ecc5e400242105b5ebf2958b9d8c6fa16a849fa8fe33b3077aa3ca0",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMonitor with the CoE Power BI dashboard\nFeedback\nSummarize this article for me\nWith the\nMonitor\nsection of the Center of Excellence (CoE) Power BI dashboard, you can query basic inventory (environments, apps, flows, makers, connectors, and audit logs) to monitor usage across your entire tenant and within each environment. These reports also support drill-downs and filtering, for example by maker department/country/city, connector usage, or premium feature usage.\nOverview\nThe\nOverview â Power Apps, Power Automate and Chatbots\npage provides you with a tenant-wide overview of resources:\nTotal number of environments (and environments created this month)\nTotal number of environment makers\nTotal number of custom connectors\nTotal number of apps, app makers, and apps created this month\nTotal number of flows, flow makers, and flows created this month\nTotal number of bots, bot makers, and bots created this month\nThe visualizations highlight environments and makers that have the most resources, and show a map of where your makers are based.\nEnvironments\nThe\nEnvironments\npage shows you how many environments, environment makers, and Microsoft Dataverse instances you have.\nThe graphs visualize:\nThe environment creation trend by date\nThe number of resources per environment\nThe number of environments by type\nTop environment creators\nThe number of Managed Environments\nThe filters allow you to drill down and analyze specific environment types, maker trends, and changes over time.\nTeams Environments\nThe\nTeams Environments\npage shows you the number of Microsoft Teams environments, environment makers, and resources in those environments.\nThe graphs visualize:\nThe environment creation trend\nThe number of resources per environment\nThe tables of environments shows:\nEnvironment Name\nLink to the Environment in the Admin Center\nLink to the connected Microsoft Teams\nOwner\nLatest App launch in the environment\nNumber of apps and flows\nA red icon if no apps or flows exist in the environments\nCreated On date\nThe table of apps shows:\nApp name\nOwner\nLast launched\nCreated on date\nModified on date\nNote\nLast launched\ninformation is only available if the\nAudit Log\nhas been configured.\nInformation about bots created via Microsoft Copilot Studio in Microsoft Teams environments is currently not available in the CoE Starter Kit.\nThe filters allow you to filter by Owner as well as Created date.\nApps\nThe\nApps\npage provides an overview of apps in your environment:\nTotal number of apps\nTotal number of apps created this month\nTotal number of app makers\nTotal number of canvas apps and model-driven apps\nThe number of production apps (a\nproduction app\nhas had 50 active sessions, or active sessions by five unique users, in a month)\nOn the graphs, you can see your app creation trend, your makers over time, your top environments, and top connectors used in apps.\nFilters on this page can help you narrow down this view by app owner, app plan classification, app type, environment name and type, or connector used.\nThe hamburger menu on this page helps you navigate to other reports relevant to Power Apps.\nSharePoint form apps\nThe\nSharePoint Form Apps\npage provides an overview of apps created to customize SharePoint lists or document library forms.\nNavigate directly to the SharePoint site and view how many connectors are being used in a customized form.\nCloud flows\nThe\nCloud flows\npage provides an overview of cloud-based API automation flows in your environment:\nTotal number of flows\nTotal number of flows created this month\nTotal number of flow makers\nTotal number of started, suspended and stopped flows\nThrough visuals, you can see your flow creation trend, your top active departments, and top environments and top connectors used in flows.\nFilters on this page can help you narrow down this view by flow owner, flow state, flow display name, environment, maker department, or connector used.\nCustom connectors\nThe\nCustom Connectors\npage helps you understand what\ncustom connectors\nyou have, what endpoints they're connecting to, and which resources are using the custom connector.\nNext to the total number of custom connectors and number of test connectors (those that have the word\nTest\nin the display name), you'll also see a connector creation trend, which environments have the most custom connectors, and which flows and apps are using custom connectors.\nFilters help you narrow down the view by connector creator, environment, or created date.\nDesktop flows\nThe\nDesktop flows\npage provides an overview of UI-based robotic process automation (RPA) flows in your environment:\nTotal number of desktop flows\nTotal number of desktop flows created this month\nTotal number of desktop flow makers\nThrough visuals, you can see your flow creation trend and top environments with desktop flows. Use the list view of all flows to sort your flows by type and flow state.\nFilters on this page can help you narrow down this view by flow owner, flow display name, environment, maker department, or desktop flow type.\nBots\nThe\nBots\npage provides an overview of Microsoft Copilot Studio bots in your environment:\nTotal number of bots\nTotal number of bots created this month\nTotal number of bot makers\nTotal number of published bots\nThrough visuals, you can see your bot creation trend and top environments with bots. Use the list view of all bots to sort your bots by bot maker or bot state.\nFilters on this page can help you narrow down this view by environment and by maker.\nAI Builder models\nThe\nAI Builder Models\npage provides an overview of AI Builder Models in your environment:\nTotal number of AI Builder models\nTotal number of AI Builder models created this month\nTotal number of AI Builder models makers\nThrough visuals, you can see your AI Builder model creation trend and top environments with AI Builder models. Use the list view of all AI Builder models to sort your AI Builder models by maker or template.\nFilters on this page can help you narrow down this view by environment and by maker.\nPower Pages\nThe\nPower Pages\npage provides an overview of Power Pages in your environment:\nTotal number of Power Pages\nTotal number of Power Pages created this month\nTotal number of Power Pages makers\nThrough visuals, you can see your Power Pages creation trend and top environments with Power Pages. Use the list view of all Power Pages to sort your Power Pages by maker, website, website status, and table permission.\nFilters on this page can help you narrow down this view by environment and by maker.\nSolutions\nThe\nSolutions\npage provides an overview of Power Platform solutions in your environment:\nTotal number of solutions\nTotal number of solutions created this month\nTotal number of solution makers\nThrough visuals, you can see your solution creation trend and top environments with solutions. Use the list view of all solutions to sort your solutions by publisher, maker, or environment.\nFilters on this page can help you narrow down this view by environment, publisher, and maker.\nBusiness process flows\nThe\nBusiness Process Flows\npage provides an overview of Business process flows in your environment:\nTotal number of business process flows\nTotal number of business process flows created this month\nTotal number of business process flows makers\nThrough visuals, you can see your business process flow creation trend and top environments with business process flows. Use the list view of all business process flows to sort by state, maker, and environment.\nFilters on this page can help you narrow down this view by environment, state, and maker.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "CoE Power BI Monitor",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/release-plan/2025wave2/": {
      "content_hash": "sha256:2f5b9aa03419cbcf23b130779b78d2db6b6bc96289b649c2e5f1755efb46d3cf",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Power Platform 2025 release wave 2 plan\nFeedback\nSummarize this article for me\nThe Microsoft Power Platform release plan for the 2025 release wave 2 announces the latest updates to customers as features are prepared for release. You can browse the release plan here\nonline\n(updated throughout the month), view it in the\nRelease planner\n, or download the document as a\nPDF file\n, which is updated with every publish. The plan for 2025 release wave 2 covers new features for Dynamics 365 releasing from\nOctober 2025\nthrough\nMarch 2026\n.\nDownload the 2025 release wave 2 PDF for Power Platform\nor select the option at the bottom of the table of contents.\nThe Dynamics 365 features coming in the 2025 release wave 2 have been summarized in a separate\nrelease plan\nand a downloadable\nPDF\n.\nThe role-based Copilot offerings features coming in the 2025 release wave 2 have been summarized in a separate\nrelease plan\nas well as a downloadable\nPDF\n.\n2025 release wave 2 overview\nMicrosoft Power Platform enables users and organizations to analyze, act on, and automate data to digitally transform their businesses. Microsoft Power Platform today is comprised of: Power Apps, Power Pages, Power Automate, Microsoft Copilot Studio, Microsoft Dataverse and Microsoft Power Platform governance and administration. The 2025 release wave 2 contains hundreds of new features across Power Platform applications, including Power Apps, Power Pages, Power Automate, and Microsoft Copilot Studio, as well as Microsoft Dataverse and Power Platform capabilities for governance and administration.\nPower Apps\nPower Apps\nenables human and agent collaboration. They include an agent feed to supervise the work of agents and extensible built-in agents for common tasks like entering, exploring, visualizing, and summarizing data. Bring business problems to Plan Designer and a team of agents will help you build enterprise solutions that include apps, agents, Power BI reports and more. Vibe-code with the App Agent to create data-connected experiences. Just describe what you need or provide an image, and it will be done!\nPower Pages\nPower Pages\nenables businesses to build secure, data-driven portals effortlessly. In this wave, we will further expedite site building for low-code makers and pro developers to build intelligent sites for your employees, customers, and partners. Introduction of enhanced security agent features will further empower low code makers, pro developers, and admins with actionable insights and abilities for securing their websites.\nPower Automate\nPower Automate\nis transforming how enterprises automate complex business processes; through new human in loop experiences such as advanced approvals, AI native capabilities such as Generative Actions and Intelligent Document processing. To manage complex automations at scale there is a comprehensive suite of governance, observability, and security controls coming to Automation Center and Power Platform Admin Center.\nMicrosoft Copilot Studio\nMicrosoft Copilot Studio\ncontinues its journey to make agent creation and operation even easier and more powerful with autonomous agents in Microsoft 365 Copilot, the ability to build complete teams of agents that work seamlessly together, and improved governance for enterprise scalability. Copilot Studio will offer even deeper integration with Azure AI Foundry and the Microsoft Graph, ensuring your agents can use the latest AI technology in coordination with your data in the Microsoft Graph.\nMicrosoft Dataverse\nMicrosoft Dataverse\ncontinues to serve as a trusted low-code data platform, enabling the creation of scalable agents, Copilot applications, and automations. This update introduces enhancements to core agentic capabilities - including Dataverse for Agents and Dataverse Search - to support smarter, AI-ready experiences. New features such as Dataverse MCP Server and AI-powered business logic tools further expand the ability to build dynamic, intelligent solutions grounded in enterprise data.\nGovernance and administration\nMicrosoft Power Platform governance and administration\nwill become the unified governance hub for managing intelligent agents, agent-driven apps, and automated workflows across the Microsoft ecosystem in this release wave. This will provide the most secure, governable, reliable platform for agent development.\nKey dates for the 2025 release wave 2\nThese release plans describe functionality that may not have been released yet. Delivery timelines and projected functionality may change or may not ship (see\nMicrosoft policy\n).\nHere are the key dates for the 2025 release wave 2.\nMilestone\nDate\nDescription\nRelease plans available\nJuly 16, 2025\nLearn about the new capabilities coming in the 2025 release wave 2 (October 2025 - March 2026) across Microsoft Powerâ¯Platform, Dynamicsâ¯365, and role-based Copilot offerings.\nEarly access available\nAugust 4, 2025\nTest and validate new features and capabilities that will be part of 2025 release wave 2, coming in October, before they are enabled automatically for your users. You can view the Dynamics 365\n2025 release wave 2 early access features\nnow\n.\nRelease plans available in additional languages\nJuly 30, 2025\nThe Microsoft Powerâ¯Platform, Dynamics 365, and role-based Copilot offerings release plans are published in 11 additional languages: Danish, Dutch, Finnish, French, German, Italian, Japanese, Norwegian, Portuguese (Brazilian), Spanish, and Swedish.\nGeneral availability\nOctober 1, 2025\nProduction deployment for the 2025 release wave 2 begins.\nRegional deployments will start on October 1, 2025.\nJust like the previous release waves, we continue to call out how each feature will be enabled in your environment:\nUsers, automatically\n: These features include changes to the user experience for users and are enabled automatically.\nAdmins, makers, or analysts, automatically\n: These features are meant to be used by administrators, makers, or business analysts and are enabled automatically.\nUsers by admins, makers, or analysts\n: These features must be enabled or configured by the administrators, makers, or business analysts to be available for their users.\nYou can get ready with confidence knowing which features will be enabled automatically.\nWeâve done this work to help youâour partners, customers, and usersâdrive the digital transformation of your business on your terms. Weâre looking forward to engaging with you as you put these new services and capabilities to work, and weâre eager to hear your feedback as you dig in to the 2025 release wave 2 plans.\nLet us know your thoughts. Share your feedback in the\nMicrosoft Power Platform community forum\n. We'll use your feedback to make improvements.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Release Plans",
      "section": "Power Platform Administration"
    },
    "https://learn.microsoft.com/en-us/power-platform/alm/pipelines": {
      "content_hash": "sha256:15d1b6b384f12f53b8a87c8bd9403d4b4fea25a8ef44aba896835e2e88a77669",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of pipelines in Power Platform\nFeedback\nSummarize this article for me\nPipelines in Power Platform aim to democratize application lifecycle management (ALM) for Power Platform and Dynamics 365 customers by bringing ALM automation and continuous integration and continuous delivery (CI/CD) capabilities into the service in a manner that's more approachable for all makers, admins, and developers.\nPipelines significantly reduce the effort and domain knowledge previously required to realize the ROI from adopting healthy, automated ALM processes within your team or organization.\nAdmins easily configure automated deployment pipelines in minutes rather than days or weeks.\nMakers have an intuitive user experience for easily deploying their solutions.\nProfessional developers can (optionally)\nextend pipelines\nand run them using the Power Platform command line interface (CLI).\nAdmins centrally manage and govern pipelines\nPipelines enable admins to centrally govern citizen-led and pro-dev-led projects at scale with less effort. Admins set up the appropriate safeguards that govern and facilitate solution development, testing, and delivery across the organization. Other admin benefits include:\nLower total cost of ownership:\nPipelines significantly improve maker, developer, and admin productivity. Pipelines enable your business solutions to come to market faster, with higher quality, through a safe and governed process.\nMinimal effort to implement a secure and custom-tailored change management processes across your organization or team.\nSave time and money:\nThe system handles the heavy lifting and ongoing maintenance so you don't have to.\nScale ALM at your own pace:\nRegardless of where you're at in your ALM journey, you can extend pipelines to accommodate your evolving business needs. We aim for this upward transition to be as seamless and effortless as possible. More information:\nMicrosoft Power Platform CLI\npac pipeline\ncommand group\nAchieve compliance, safety, monitoring, and automation goals with:\nSecure production environments with approval based\ndelegated deployments\n.\nCustomizations and audit log saved automatically and are easily accessible.\nOut-of-the-box analytics provides better visibility within a central location.\nThe ability to view out-of-the-box Power BI reports within the pipelines app or create your own. More information:\nReporting overview for model-driven apps\nCustom tailor pipelines to the needs of your organization with\npipelines extensibility\nand Power Automate.\nMakers run preconfigured pipelines\nOnce pipelines are in place, makers can initiate in-product deployments with a few clicks. They do so directly within their development environments. Other benefits to makers include:\nNo prior knowledge of ALM processes or systems required. Citizen developers often view pipelines as a guided change management process.\nSolution deployments are prevalidated against the target environment to prevent mistakes and improve success rates. For example, missing dependencies and other issues are detected before deployment and makers are immediately guided to take the appropriate action.\nConnections and environment variables are provided upfront and validated before the deployment begins.\nThis helps ensure applications and automation are deployed without needing manual post-processing steps, and are connected to the appropriate data sources within each environment.\nAdmins can even preconfigure certain connections that will be used.\nDevelopers can use and extend pipelines\nProfessional developers are more productive with pipelines now handling the complex background operations. Developers can tell the system what they want to accomplish instead of executing the various underlying tasks necessary to accomplish the same goal. Using the Power Platform CLI, developers can:\nList pipelines to view pertinent details such as which stages and environments are ready to deploy their solutions to.\nDeploy a solution with a single command:\nWith pipelines, developers simply provide the required parameters and the system orchestrates all the end-to-end deployment operations in compliance with the organizational policies.\nNo need to connect to multiple environments, export solutions, download solution files, manually create connections and populate deployment settings files, import solutions, or handle various other tasks that were required previously.\nAdditionally, developers can\nextend pipelines\nand integrate with other CI/CD tools.\nFrequently asked questions\nWhat do pipelines deploy?\nPipelines deploy solutions as well as configuration for the target environment such as connections, connection references, and environment variables. Any Power Platform customization contained in your solution can be deployed using pipelines. Pipelines, or solutions in general, don't contain data stored within Dataverse tables.\nImportant\nPower BI Dashboards (preview) and Power BI Datasets (preview) are not currently supported in pipelines.\nWhy can't I see my pipeline from my environment?\nFirst, ensure that your source and target environments are linked properly. You'll only be able to view your pipeline in the assigned source environments, such as your development environments. When linking each of your environments to your pipeline during configuration, you have an option of\nDevelopment Environment\nor\nTarget Environment\nenvironment type. If your pipeline-associated environments are assigned their proper type, your pipeline appears as an option in your source development environment.\nDoes pipelines automatically store solution backups?\nYes. Both managed and unmanaged solutions are automatically exported and stored in the pipelines host for every deployment.\nCan customization bypass a deployment stage such as QA?\nNo. Solutions are exported as soon as a deployment request is submitted (when the maker selects\nDeploy\nfrom within their development environment), and the same solution artifact will be deployed. Similarly, the system doesn't re-export a solution for deployments to subsequent stages in a pipeline. The same solution artifact must pass through pipeline stages in sequential order. The system also prevents any tampering or modification to the exported solution artifact. This ensures customization can't bypass QA environments or your approval processes.\nAre standalone licenses required to use pipelines?\nDeveloper environments aren't required to be Managed Environments. They can be used for development and testing with the developer plan.\nThe pipelines host should be a production environment, but the pipelines host doesn't have to be a Managed Environment.\nAll other environments used in pipelines must be enabled as Managed Environments.\nLicenses granting premium use rights are required for all Managed Environments.\nA common setup example:\nEnvironment purpose\nEnvironment type\nStandalone license required\nHost\nProduction\nNo\nDevelopment\nDeveloper\nNo\nQA\nDeveloper\nNo\nProduction\nProduction\nYes\nCan I ensure pipeline targets are Managed Environments?\nYes. Tenant admins can automatically convert pipeline target environments to Managed Environments, ensuring compliance with Microsoft standards.\nTo enable an environment as a Managed Environment, go to the Power Platform admin center\nDeployments\n>\nSettings\n. Turn on the automatic managed environment setting for each pipeline host.\nImportant\nStarting February 2026, Microsoft will start enabling Managed Environments for any pipeline target environments that arenât already enabled. Customers will be notified via Microsoft 365 Message center.\nWe recommend you review and enable Managed Environments for all pipeline targets now. You can do this manually now or set it to occur automatically:\nManually:\nGo to enable\nManaged Environments\n.\nAutomatically:\nConfigure the setting for new pipelines as described above.\nCan I configure approvals for deployments?\nYes. See\ndelegated deployments\n.\nCan I use different service principals for different pipelines and stages?\nYes. More information:\nDeploy with a service principal\nWhat connections can be used?\nSimilar to authoring experiences, makers running pipelines can either provide their own connections or connections they have access to. Service principal connections can also be used for connectors that support service principal authentication, including custom connectors.\nWhy can't I update existing connection references?\nCurrently, connection references without a value in the solution or targeted environment can't be updated during deployment. If a value was deployed previously, it can be updated in the targeted environment.\nWho owns deployed solution objects?\nThe deploying identity. For standard deployments, the owner is the requesting maker. For delegated deployments, the owner is the delegated service principal or user.\nCan pipelines deploy to a different tenant?\nNo. We recommend using Azure DevOps or GitHub for this scenario.\nWhy can't I access the \"Manage pipelines\" button in the command bar?\nIf the user has the \"Deployment Pipeline Administrator\" security role the \"Manage pipelines\" button will be enabled and it will open the \"Deployment Pipeline Configuration\" app. The button will also not be enabled if there is no platform host or custom host available. More information:\nAccessing the \"Deployment Pipeline Configuration\" app\nWhat should I do if my development or target environment is reset or deleted?\nYou should delete the environment record and update the pipeline configuration when needed. If an environment is reset, you re-create the environment record then associate it with your pipeline.\nCan I use pipelines in the default environment?\nYes. However, using the default environment as the pipelines host isn't recommended for all customers.\nCan I deploy using my own service principal?\nYes. More information:\nDeploy pipelines as a service principal or pipeline owner\n.\nCan pipelines be used with Azure DevOps, GitHub, or the ALM Accelerator?\nYes, together these tools are powerful while keeping maker experiences simple. More information:\nextend pipelines\nCan I roll back to a previous version?\nYes. If the pipeline setting is enabled, you can\nredeploy previous solution versions\nfrom the run history view on the Pipelines page. If the setting is disabled, only higher solution versions can be deployed or imported. As a work-around, admins can download the artifact from the pipelines host, increment the solution version in the solution.xml file, then manually import it into the target environment.\nCan I set retention policies for pipelines data?\nYes. You can configure bulk delete jobs in the Dataverse pipelines host to delete data on a defined schedule.\nCan I specify advanced solution import behaviors such as update versus upgrade?\nNot currently. Pipelines default import behavior is\nUpgrade\nwithout\nOverwrite customizations\n.\nCan an environment be associated with multiple hosts?\nNo. However, one environment can be linked to multiple pipelines within the same host. In order to associate an environment with a different host, add it to a pipeline in the new host. Then delete the environment record from the original host and verify everything works as expected.\nCan I customize or extend the first-party deployment pipeline app and tables?\nNot currently. However, intentional extension hooks are available to customize pipelines logic. More information:\nextend pipelines\n.\nWhere can I view and run pipelines?\nNavigate to an unmanaged solution in development to an environment associated with your pipeline. Pipelines can't be viewed or run from the default solution, managed solutions, or in target environments. Notice you can also retrieve and run pipelines from the Power Platform CLI.\nCan I deploy across regions?\nYes, but only if the\nCross-Geo Solution Deployments\nsetting is enabled in the host. If the setting is disabled, the host and all environments associated with pipelines in a host must be located within the same geographic location (as specified when creating environments). For example, if the setting is disabled, a pipeline can't deploy from Germany to Canada and a host in Germany can't manage environments in Canada. In a case where the tenant administrator would like to prevent cross-geo solution deployments, separate hosts should be used for Germany and Canada.\nCan I deploy the same solution using different pipelines?\nYes, this is possible, although we recommend starting with the same pipeline for a given solution. This helps avoid confusion and inadvertent mistakes. Pipeline run information is displayed in the context of one pipeline and one solution (within the solution experience). Therefore other pipelines might not show the latest deployed solution version or other important run information associated with different pipelines. Notice that the Deployment Pipeline Configuration app shows run information across all pipelines and all solutions for the current host.\nCan the host environment also be used as a development or target environment?\nUsing the same environment for development and the host isn't supported; other combinations aren't recommended as a best practice.\nHow can I view what changed between different versions?\nWithin the target environment, you can see layers of deployed objects as well as what changed between layers. Additionally, you can see XML diffs between layers for model-driven apps, site maps, and forms. Pipelines can also be extended to integrate with GitHub and other source control systems to compare granular diffs.\nShould my host environment be the same as where I installed the COE toolkit?\nThis is a valid configuration and should be evaluated based on the needs and policies within your organization.\nCan I deploy unmanaged solutions?\nNo. We recommend that you always deploy managed solutions to nondevelopment environments. Notice unmanaged solutions are automatically exported and stored in the pipelines host so you can download and import them to other development environments or put them in source control.\nCan I deploy multiple solutions at once?\nNot currently. You'll need to submit a different deployment for each solution. However, the same pipeline can be used for multiple solutions.\nDo pipelines publish unmanaged customizations before exporting the solution?\nNot currently. We recommend you publish individual objects as they're saved. Note that only certain solution objects require publishing.\nCan I use pipelines for multi-developer teams working in isolated development environments?\nThe current implementation uses a single development environment for a given solution.\nHow are pipelines different from the ALM Accelerator?\nBoth offer many valuable capabilities and the owning teams work together closely in developing the pipelines and broader ALM vision for Power Platform. Pipelines are more simplistic in nature and can be set up and managed with less effort. Access to other products and technologies isn't required as everything is managed in-house. The ALM Accelerator, on the other hand, is sometimes a better fit for more advanced ALM scenarios.\nWhile there are many additional functional differences, the fundamental difference is that pipelines are an official Microsoft Power Platform product featureâmeaning it's designed, architected, engineered, tested, maintained, and supported by Microsoft product engineering. Pipelines are built into the product and can be accessed within native product experiences.\nWhen should I use pipelines versus another tool?\nWe encourage customers to use pipelines for core deployment functionality, and when needed, extend pipelines to integrate with other CI/CD tools. When used together, the workloads required within CI/CD tools often become less complicated and costly to maintain.\nNext steps\nSet up pipelines\nExtend pipelines\nRelated information\nDeploy solutions using Pipeline in Power Apps (video)\nSimplify Microsoft Power Platform deployments by using pipelines - Learning Path\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Pipelines Overview",
      "section": "Power Platform ALM"
    },
    "https://learn.microsoft.com/en-us/power-platform/alm/set-up-pipelines": {
      "content_hash": "sha256:4697dac5b6f1f0c92a150b1874e18af614d56eceb2cf8cfc7ef33dd27faa46ee",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSet up pipelines in Power Platform\nFeedback\nSummarize this article for me\nCreate and run pipelines to easily deploy solutions to environments. There are two different ways to set up pipelines:\nPlatform host\n. The default tenant-wide platform host, which can be configured by makers.\nCustom host\n. Admins configure a custom host to centrally govern citizen-led and pro-dev-led projects.\nInformation within each section of this article pertains to the specified host method for setting up pipelines.\nFrequently asked questions\nWill personal pipelines conflict with any pipelines that I have already set up?\nNo. Thanks to the host separation dynamic that we have in place, there's no way for a maker creating a personal pipeline (in the platform host) to associate an environment that is already associated with a custom host. By default, makers don't have permissions to create lightweight personal pipelines in environments already associated with a custom host. This means that your current pipelines UX, if in place, won't change.\nImportant\nMakers also don't receive elevated access to environments as a result of this feature. Selectable target environments are filtered to include only environments that a maker can already import to. This feature ensures that all personal pipelines are stored in the platform host that is accessible to administrators, and provides an easier way for makers to self-service their application lifecycle management (ALM).\nWhy can't I select or view certain environments when I create a pipeline?\nThe target environment picker filters out any environments that:\nThe current user doesn't have import-access to, or\nare outside of the geographical region that the pipelines host is located in if host-wide setting is disabled. More information:\nEnable cross-geo solution deployments\nYou also can't create a pipeline with a target environment that's already associated to the host as a development environment. To change an environment's type distinction in a host, you must\nplay the Deployment Pipeline Configuration app\n, delete the environment record, and re-create the environment record with the desired type.\nWhy am I seeing an error that states \"this environment is already associated with another pipelines host?\"\nThis error indicates that another host already contains an active environment record that you're trying to associate with the current host. To resolve this, go to\nUsing Force Link to associate an environment with a new host\nor\nDisassociating environments from one host and associating them with another host\n.\nDo the pipelines and data within the platform host count towards my Dataverse capacity?\nNo. The data consumption in the\nplatform host\ndoesn't count against your current plan since the pipelines data for the platform host is stored in Power Platform infrastructure. This data is stored within your tenant and accessible by administrators, but due to its implementation details, doesn't consume data capacity within a plan.\nHowever, capacity does apply to a\ncustom host\n, which isn't an implementation in the platform but is instead in a customizable environment.\nCan I enable makers to create personal pipelines in a custom host?\nYes. As an administrator, you can assign the\nDeployment Pipeline Default\nrole to anyone you want to grant lightweight pipeline creation permissions to. Administrators can also add users to the\nDeployment Pipeline Maker\nteam via the\nSecurity Teams\npage in the Deployment Pipeline Configuration app.\nThis Deployment Pipelines Default role isn't assigned to anyone by default in the case of custom host, so the lightweight personal pipeline creation experience is only visible by default in environments that aren't already associated with a custom host.\nAs an admin, how do I prevent makers from creating personal pipelines by default?\nBecause custom hosts don't grant pipeline create-access by default like the platform host does. You can\nset up a custom host\nand then\nuse force link\n, if necessary, to associate development environments with a custom host.\nIf there's already a custom host available skip this step. If not, you have to create one following the steps to\ncreate a pipeline using a custom pipelines host\n.\nOnce there's a custom host available, as an admin, navigate to the Deployment Pipeline Configuration app for the custom host. The app is located in the environment that you installed the Power Platform Pipelines package in.\nGo to\nEnvironments\nfrom the side navigation pane, and\ncreate new environment record(s)\nfor the development environments that you would like to prevent makers from creating new personal pipelines from. If the environment was already linked to another host, such as the platform host, the validation fails. If this occurs, select\nForce Link\non the command bar after validation failure to override the current link to the other pipelines host.\nFollowing these steps effectively disables the\ncreate pipeline\ncapability for any makers who access in pipelines feature in these development environments because they don't have pipelines permissions. Existing pipelines in the custom host, if any, are also not shared with any users by default. Admins are able to apply with workaround with any existing custom host as well.\nWhy am I not seeing the latest features for pipelines?\nThe pipelines package is always being updated to give you the latest and greatest for your ALM processes. Ensure that you have the latest Power Platform pipelines package in your\ncustom host\n:\nGo to the\nPower Platform admin center\n,\nSelect your pipelines host environment.\nSelect\nDynamics 365 apps\n, and locate\nPower Platform Pipelines.\nNotice if there's an update available.\nFor\nplatform hosts\n, the pipelines package is updated automatically, and might not be available as soon as the manual package update is made available for custom hosts.\nHow can I recover unmanaged solutions from Power Platform Pipelines past deployment history?\nThe\nImport Solutions from a Pipelines Host\nfeature in Power Platform allows users to recover unmanaged and managed solutions from past deployments. This capability is particularly useful in scenarios where a solution is accidentally lost or needs to be restored to a development environment. Alternatively, Pipelines admins can also use the pipeline configuration management app to download the unmanaged solution from the deployment history record easily.\nNext steps\nExtend pipelines in Power Platform\nRun pipelines in Power Platform\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Set Up Pipelines",
      "section": "Power Platform ALM"
    },
    "https://learn.microsoft.com/en-us/power-platform/alm/run-pipeline": {
      "content_hash": "sha256:11d59098f3049faa8816d77fefb3c2d8f679b38bf3f50c6d2964a9746897f021",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRun pipelines in Power Platform\nFeedback\nSummarize this article for me\nPipelines automate solution deployments between Power Platform environments and facilitate healthy application management practices with minimal effort.\nPrerequisites\nOne or more pipelines must already be created and associated with the environment that's used for development.\nThe development environment must have Microsoft Dataverse or Dataverse plus Dynamics 365 customer engagement apps.\nYou must have access to run a pipeline. More information:\nGrant access to edit or run pipelines\nYou must have privileges to import solutions to the target environments associated with a pipeline.\nThe\nPower Platform Pipelines\napplication must be installed in your pipeline host environment. More information:\nInstall the pipelines application in your host environment\nFor more information about these prerequisites, go to\nSet up pipelines\n.\nRun a pipeline\nSign in to a Power Platform environment using Power Apps (\nmake.powerapps.com\n) or Power Automate (\nmake.powerautomate.com\n) and select your development environment.\nTo deploy a solution using a pipeline, go to\nSolutions\nand create or select an unmanaged solution to deploy.\nFrom the\nSolutions\narea, choose between two options to include the solution in the pipeline:\nSelect\nPipelines\nfrom the left navigation pane.\nSelect\nOverview\nfrom the left navigation pane, and then select\nDeploy\non the command bar.\nSelect the stage to deploy to, such as\nDeploy to Test\n, select\nDeploy here\n, and the deployment pane appears on the right.\nChoose to deploy\nNow\nor schedule for\nLater\n, and then select\nNext\non the right pane. This initiates validation of the solution against the test environment. This validation can also be referred to as preflight checks. Missing dependencies and other common issues are checked that might cause a deployment to fail.\nIf connection references or environment variables are present, youâre prompted to provide these (just as you would when manually importing solutions).\nReview the summary of the deployment and optionally add deployment notes.\nSelect\nDeploy\n. This initiates an automated deployment to the target environment.\nNote\nPipelines aren't visible within the default solution, managed solutions, or target environments.\nYou must complete the deployment stages in order. For example, you can't deploy version 1.0.0.1 to production before it has been deployed to test. After you deploy to test, the same solution that was deployed will then be deployed to production, even if afterward you made changes to the solution without incrementing the version.\nA message stating your request to deploy here is pending, which means your admin attached\nbackground processes or approvals\nthat run before your deployment can proceed.\nCancel a scheduled deployment\nIf you have a scheduled deployment, you can cancel it through three different methods:\nIn the pipeline\nDetails\nsection where you began your deployment, there's an option to\nCancel deployment\nbefore the scheduled deployment time.\nIn\nRun history\n, selecting\n...\non a scheduled deployment displays a\nCancel deployment\noption.\nIn the\nInformation\npane, select a deployment record in\nRun history\n, and then select\nCancel deployment\nunder the\nStatus\nof a scheduled deployment.\nChange the time of a scheduled deployment as a pipeline admin\nIn the Deployment Pipeline Configuration app, perform the following steps:\nNavigate to\nRun history\nunder\nDeployments\n.\nSelect the record for the scheduled deployment that you want to change.\nChange the\nScheduled Time\n(shown in UTC, which might differ from your time zone) as desired.\nMonitor pipeline deployments\nThe\nPipelines\npage in the\nSolutions\narea displays all deployment activity for the current pipeline and solution.\nSelect a pipeline, then select\nRun history\nto view more detail and error information if there was a failure.\nRelated articles\nCreate a pipeline in Microsoft Power Platform - Learn Module\nSolution concepts\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Run Pipelines",
      "section": "Power Platform ALM"
    },
    "https://learn.microsoft.com/en-us/power-platform/alm/solution-concepts-alm": {
      "content_hash": "sha256:4693111c2cb23e75400e793d84a4096010ef063b616badd02e1ff5be67242928",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSolution concepts\nFeedback\nSummarize this article for me\nSolutions are the mechanism for implementing application lifecycle management (ALM) in Power Apps and Power Automate. This article describes the following key solution concepts:\nTwo types of solutions (managed or unmanaged)\nSolution components\nLifecycle of a solution\nSolution publisher\nSolution and solution component dependencies\nManaged and unmanaged solutions\nA solution is either\nmanaged\nor\nunmanaged\n.\nUnmanaged solutions\nare developed. Unmanaged solutions are used in development environments while you make changes to your application. Unmanaged solutions can be exported either as unmanaged or managed. Exported unmanaged versions of your solutions should be checked into your source control system. Unmanaged solutions should be considered your source for Microsoft Power Platform assets. When an unmanaged solution is deleted, only the solution container of any customizations included in it's deleted. All the unmanaged customizations remain in effect and belong to the default solution.\nManaged solutions\nare deployed. Managed solutions are deployed to any environment that isn't a development environment for that solution. These environments include test, user acceptance testing (UAT), system integration testing (SIT), and production environments. Managed solutions can be serviced independently from other managed solutions in an environment. As an ALM best practice, managed solutions should be generated by exporting an unmanaged solution as managed and considered a build artifact. Additionally:\nYou can't edit components directly within a managed solution. To edit managed components, first add them to an unmanaged solution.\nWhen you edit a managed component, you create a dependency between your unmanaged customizations and the managed solution. When a dependency exists, the managed solution can't be uninstalled until you remove the dependency.\nSome managed components canât be edited. To verify whether a component can be edited, view the\nManaged properties\n.\nYou can't export a managed solution. But you can export an unmanaged solution as managed.\nWhen a managed solution is deleted (uninstalled), all the customizations and extensions included with it are removed.\nImportant\nYou can't import a managed solution into the same environment that contains the originating unmanaged solution. To test a managed solution, you need a separate environment to import it into.\nWhen you delete a managed solution, the following data is lost: data stored in custom tables that are part of the managed solution and data stored in custom columns that are part of the managed solution on other tables that aren't part of the managed solution.\nMakers and developers work in development environments using unmanaged solutions, then import them to other downstream environmentsâsuch as testâas managed solutions.\nNote\nWhen you customize in the development environment, you're working in the unmanaged layer. Then, when you export the unmanaged solution as a managed solution to distribute to another environment, the managed solution is imported into the environment in the managed layer. More information:\nSolution layers\nSolution components\nA component, also known as objects, represents something that you can potentially customize. Anything that can be included in a solution is a component. To view the components included in a solution, open the solution you want. The components are listed in the\nComponents\nlist.\nNote\nA solution can be up to 95 MB in size.\nYou can't edit components directly within a managed solution.\nTo view a list of component types that can be added to any solution, go to\nComponentType Options\n.\nSome components are nested within other components. For example, a table contains forms, views, charts, columns, tables relationships, messages, and business rules. Each of those components requires a table to exist. Except for choice columns, all other columns canât exist outside of a table. We say that the column is dependent on the table. There are twice as many types of components as shown in the preceding list, but most of them are nested within other components and not visible in the application.\nThe purpose of having components is to keep track of any limitations on what can be customized using managed properties and all the dependencies so that it can be exported, imported, and (in managed solutions) deleted without leaving anything behind.\nSolution lifecycle\nSolutions support the following actions that help support application lifecycle\nprocesses:\nCreate\n. Author and export unmanaged solutions.\nUpdate\n. Create updates to a managed solution that are deployed to the parent managed solution. You can't delete components with an update.\nUpgrade\n. Import the solution as an upgrade to an existing managed solution, which removes unused components and implements upgrade logic. Upgrades involve rolling up (merging) all patches to the solution into a new version of the solution. Solution upgrades delete components that existed but are no longer included in the upgraded version. You can choose to upgrade immediately or to stage the upgrade so that you can do some additional actions prior to completing the upgrade.\nPatch\n. A patch contains only the changes for a parent managed solution, such as adding or editing components and assets. Use patches when making small updates (similar to a hotfix). When patches are imported, they're layered on top of the parent solution. You can't delete components with a patch.\nSolution publisher\nEvery app and other solution components such as tables you create or any customization you make is part of a solution. Because every solution has a publisher, you should create your own publisher rather than use the default. You specify the publisher when you create a solution.\nNote\nBy default, if you don't use a custom solution you'll be working in the default system solutions, which are known as the\nCommon Data Service Default Solution\nand the\nDefault\nsolutions. More information:\nDefault Solution and Common Data Service Default Solution\nThe preferred solution is a solution you specify that becomes your default solution. More information:\nSet the preferred solution\nThe publisher of a solution where a component is created is considered the owner of that component. The owner of a component controls what changes other publishers of solutions including that component are allowed to make or restricted from making. It's possible to move the ownership of a component from one solution to another within the same publisher, but not across publishers. Once you introduce a publisher for a component in a managed solution, you canât change the publisher for the component. Because of this restriction, it's best to define a single publisher so you can change the layering model across solutions later.\nThe solution publisher specifies who developed the app. For this reason, you should create a solution publisher name that's meaningful.\nSolution publisher prefix\nA solution publisher includes a prefix. The publisher prefix is a mechanism to help avoid naming collisions. This allows for solutions from different publishers to be installed in the same environment with few conflicts. For example, the Contoso solution displayed here includes a solution publisher prefix of\ncontoso\n.\nNote\nWhen you change a solution publisher prefix, you should do it before you create any new apps or metadata items because you can't change the names of metadata items after they're created.\nMore information:\nCreate a solution publisher prefix\nChange a solution publisher prefix\nSolution dependencies\nBecause of the way that managed solutions are layered, some managed solutions can be dependent on solution components in other managed solutions. Some solution publishers take advantage of this to build solutions that are modular. You might need to install a \"base\" managed solution first and then install a second managed solution that further customizes the components in the base managed solution. The second managed solution depends on solution components that are part of the first solution.\nThe system tracks these dependencies between solutions. If you try to install a solution that requires a base solution that isnât installed, you wonât be able to install the solution. You get a message saying that the solution requires another solution to be installed first. Similarly, because of the dependencies, you canât uninstall the base solution while a solution that depends on it's still installed. You have to uninstall the dependent solution before you can uninstall the base solution. More information:\nRemoving dependencies\nSolution component dependencies\nA solution component represents something that you can potentially customize. Anything that can be included in a solution is a solution component and some components are dependent on other components. For example, the website column and account summary report are both dependent on the account table. More information:\nDependency tracking for solution components\nSee also\nSolution layers\nCreate and manage environments in the Power Platform admin center\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Solution Concepts",
      "section": "Power Platform ALM"
    },
    "https://learn.microsoft.com/en-us/power-platform/alm/admin-deployment-hub": {
      "content_hash": "sha256:11d91e750da283b97a0f039df50cf41aee97a570d8de1c6647f307d2ccc38f67",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAdmin deployment page\nFeedback\nSummarize this article for me\nThe\nDeployment\npage in the Power Platform admin center provides a streamlined experience to help administrators navigate the complexities of managing Power Platform application lifecycle management (ALM) workloads, including managing pipelines deployments at enterprise scale. Admins have visibility to all the deployments in their tenant and can approve deployment requests and troubleshoot issues.\nNote\nCurrently the deployment page doesn't have all the capabilities available within the\nDeployment Pipelines Configuration app\n.\nUse the deployment page\nSign in to the\nPower Platform admin center\n.\nIn the navigation pane, select\nDeployment\n.\nSelect the desired pipelines host. Deployment data isn't currently aggregated across hosts.\nLearn about the ALM process in Power Platform\nThe\nGet started\nsection provides helpful learning content and guidance to set up deployments using best practices.\nManage deployments from one central location\nPipelines in Power Platform allow you to manage the end-to-end deployment process across your organization. The deployment page makes it easy to view all the pipelines and deployment activity within the tenant.\nAdmins can view all\npipelines host\nenvironments in the tenant, including the platform host, and\nselect a host\nto view all the pipelines and deployment history managed by that host.\nSelect\nPipelines\non the left navigation pane to view all active pipelines within the pipelines host.\nNote\nYou can view up to the last 365 days by changing the filter.\nAdditional information and advanced pipeline configuration can be accessed by navigating to the pipelines host environment and opening the\nDeployment Pipelines Configuration app\n.\nThe\nRun history\nview shows all deployment activity managed by the selected pipelines host including:\nThe\nStart time\nand\nEnd time\nfor every deployment.\nPipeline\nthat facilitated each deployment.\nSource\nis the development environment where the solution was developed and exported from.\nTarget\nis the destination environment where the pipeline is deployed. For example, for integration testing, user acceptance testing (UAT), production, and so on.\nStatus\nindicates whether the deployment is in-progress, succeeded, failed, or canceled.\nSolution\nis the name of the artifact and the\nVersion\ndeployed to the target environment.\nImportant\nAll target environments used in a pipeline must be enabled as\nManaged Environments\n.\nTenant admins can enable automatic conversion of pipelines environments to\nManaged Environments\n.\nManage deployment settings\nAdmins can manage these\nSettings\nwithin the selected pipelines host (settings are managed separately for each host):\nEnable automatic conversion of pipelines environments to\nManaged Environments\n. This ensures pipelines environments meet Microsoft compliance standards automatically. When makers deploy to this environment, it gets automatically converted to a Managed Environment.\nSolution deployments across regions\n: Admins can opt in to allow deployments between environments in different geographic locations. For example, when the host and production environments are in North America but the development environment is in India.\nImportant\nThis setting enables data to be shared across geographical regions within your tenant.\nAllow makers to import shared solution deployments\n: Deployed solution backups are stored in the pipelines host. This setting allows nonadmins to import solutions that were shared with them, in addition to the ability to import solutions that they deployed.\nUse a custom pipelines host\n: Allows you to set one default host for the entire tenant. This replaces\npersonal pipelines\n- meaning admins control who can access pipelines and makers can no longer create personal pipelines in the platform host. It's also useful when a central team manages deployments for the entire tenant. This setting is only visible when the\nPlatform host\nis selected in the host picker.\nReview and approve deployment requests\nOn the deployment page, admins approve or reject deployment requests assigned to them. Youâll first need to\nsetup delegated deployments\nwith service principals, which is recommended as the secure way to securely deploy to production environments.\nItâs important admins review changes in the solution and the sharing request. Once approved, the solution is deployed, and solution objects and security roles are shared automatically. Notice other types of approvals within the pipelines host environment can also be managed.\nRetry failed deployments\nA dedicated\nFailed deployments\nview helps admins quickly identify and troubleshoot failures. Deployments shown as\nFailed\nin the run history view can be retried by selecting\nRetry\nin the details panel if the operation was\nDeploy\n. A confirmation message appears when you confirm the retry.\nFAQ\nAre Managed Environments required for deployment pipelines, and what does this mean for my organization?\nYes. All target environments used in Power Platform deployment pipelines have always been required to be Managed Environments for compliant usage. This requirement helps your organization benefit from enhanced governance, improved security, and streamlined license management.\nHow can I ensure pipelines targets are Managed Environments automatically?\nTenant admins (Power Platform and Dynamics 365 admins) can enable a setting that automatically converts pipelines target environments to Managed Environments, ensuring compliance with Microsoft standards. Managed Environments are then enabled on the target during the next deployment.\nTo enable the setting, go to the Power Platform admin center\nDeployments\n>\nSettings\n. Turn on the automatic managed environment setting for each pipeline host.\nWhy did I receive Message Center notification âPower Platform â Automatic enablement of Managed Environments for Deployment Pipelinesâ?\nYou receive a notification when you have environments that aren't managed and are target of a pipeline and used for deployment in the last six months.\nThe notification lists specific environments that need action.\nImportant\nStarting February 2026, Microsoft starts enabling Managed Environments for any pipeline target environments that arenât already enabled.\nWe recommend that you review and enable Managed Environments for all pipeline targets now or set it to occur automatically.\nHow do I verify pipelines target environments requiring Managed Environments?\nGo to the Power Platform admin center\nDeployments\n>\nPipelines\n>\nRun History\n. Then select a host and change the filter to\nLast 180 days\n. If multiple hosts exist, review deployments in each. Environments listed under\nTarget\nrequire Managed Environments.\nNote\nAdditional run history information and the ability to export data and generate reports is available within the\nDeployment Pipelines Configuration app\n.\nDoes this automatic enablement affect end users or licensing, and how can I prepare?\nThere's no expected disruption for end users or their applications because of this automatic enablement. The changes focus on environment governance and compliance, so your users and apps continue to function as usual.\nImportant\nManaged Environments come with an\nautoclaim policy\n, which is applied automatically. The autoclaim policy ensures users who access apps in Managed Environments automatically receive the necessary licenses. Ensure you have appropriate license capacity in the tenant to utilize autoclaim.\nWill Microsoft enable unmanaged pipelines target environments in February 2026 if the automatic enablement setting is turned off?\nYes. We also recommend you enable the setting to ensure future compliance.\nCan I restrict access to personal pipelines?\nYes. Go to the Power Platform admin center >\nDeployments\n>\nSettings\n>\nUse a custom pipelines host\n, and then select a custom pipelines host. If there's no existing custom host, create one. Save the setting.\nThis overrides the platform host behavior, and nonadmins can't use pipelines unless you\ngrant access\nin the custom host environment.\nRelated articles\nOverview of pipelines in Power Platform\nView solutions on the deployment page for makers\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Admin Deployment Hub",
      "section": "Power Platform ALM"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/fundamentals-what-is-copilot-studio": {
      "content_hash": "sha256:45c9be19fdfd335cfb156fa15f12b9793a4f4dd2a5f6edac65035d99409336f6",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCopilot Studio overview\nFeedback\nSummarize this article for me\nCopilot Studio is a graphical, low-code tool for building agents and agent flows.\nOne of the standout features of Copilot Studio is its ability to connect to other data sources by using prebuilt or custom connectors. With this flexibility, you can create and orchestrate sophisticated logic, ensuring that your agent experiences are powerful and intuitive.\nThe platform's low-code experience puts the power of AI at your fingertips, making it accessible even if you don't have an extensive technical background.\nWhat is an agent?\nAn agent is a powerful AI companion that can handle a range of interactions and tasks. It can resolve issues that require complex conversations and autonomously determine the best action to take based on its instructions and context. It coordinates language models, along with instructions, context, knowledge sources, topics, tools, inputs, and triggers to accomplish your goals.\nAgents can engage with customers and employees in multiple languages across websites, mobile apps, Facebook, Microsoft Teams, or any channel supported by the Azure Bot Service. They can also improve productivity by performing tasks as part of a conversation or in reaction to a trigger to assist users and organizations.\nYou can easily create agents in Copilot Studio without the need for data scientists or developers. Some of the ways you might use agents include:\nSales help and support issues\nOpening hours and store information\nEmployee health and vacation benefits\nPublic health tracking information\nCommon employee questions for businesses\nUse agents on their own or to extend Microsoft 365 Copilot with enterprise data and scenarios.\nWhat is an agent flow?\nAgent flows offer a powerful way to automate repetitive tasks and integrate your apps and services. Agent flows can be triggered manually, by other automated events or agents, or based on a schedule.\nWith Copilot Studio, you can create agent flows by using natural language or a visual editor.\nYou can run agent flows as standalone automations. You can also configure an agent flow to trigger from an agent as a tool, and return results to the same agent.\nHow does an agent conversation work?\nCopilot Studio agents use customized NLU model and AI capabilities to understand what a user types or says, then respond with the best topic. A topic is a portion of a conversational thread between a user and the agent. For more information, see\nCreate and edit topics\n.\nFor example, you might create an agent for your customers to ask common questions about your business. Your agent reduces support overhead by deflecting support calls. In the agent, you can create a topic about your store's opening hours and name the topic\nStore hours\n.\nWhen a customer asks a question such as \"When do you open?\" or \"What are your opening hours?\", the agent uses natural language understanding (NLU) to understand the\nintent\nbehind the question. The agent matches that intent to the best topic, the\nStore hours\ntopic.\nThe agent follows the\nconversation flow\nâwhich is a group of connected nodesâthat you define in the\nStore hours\ntopic. Some nodes can ask questions, while others use conditions (if/else) to determine which store the customer wants. The final output of the topic shows the hours and contact information for that specific store.\nHowever, you can't anticipate all the types of questions your customers ask. To help mitigate this issue, Copilot Studio incorporates powerful AI-powered capabilities that use the latest advancements in NLU models. Once your agent is linked to knowledge sources, it can automatically generate responses. These responses are conversational, plain language, and you don't need to create topics for every eventuality.\nYou can also choose to let your agent access information outside its knowledge sources.\nCopilot Studio can use AI powered by the Azure OpenAI GPT model, also used in Bing, to create topics from a simple description of your needs. Similarly, you can modify and update any topic in your agent by describing the changes you want to make.\nAccess Copilot Studio\nAccess Copilot Studio as a standalone web app or as a discrete app within Teams. The Copilot Studio app for Teams supports classic chatbots only.\nWeb app\nUse cases:\nYou're an IT admin who wants to create agents to perform tasks or interact with customers.\nYou're familiar with agent services and want to trial or test Copilot Studio.\nYou want to explore advanced agent concepts, such as entities and variables, and create complex agents.\nGo to the web app at\nhttps://copilotstudio.microsoft.com\nExplore the Copilot Studio demo\nTeams app\nUse cases:\nYou're an employee or member of an organization who wants to use chatbots to answer common employee questions.\nYou want to use advanced concepts, such as entities and variables, and have a chatbot internally available in Teams.\nYou want to create and distribute a chatbot quickly.\nOpen or add the Copilot Studio app in Teams\nPlan your agent\nConsider the following points when planning your agent.\nExtend Microsoft 365 Copilot with an agent\nConsider extending Microsoft 365 Copilot with an agent if:\nYou want to craft your own agent by declaring instructions, tools, and knowledge to customize Microsoft 365 Copilot for specific tasks and domain knowledge.\nYou wish to utilize the existing Copilot orchestrator.\nYou want a standalone custom version of the Microsoft 365 Copilot chat experience.\nCreate an agent\nCopilot Studio makes it easy to create agents. You only need to describe the agent you want in plain language. Tell Copilot Studio what specific instructions, triggers, knowledge sources, and tools you want for your agent. Then test your agent before you deploy it. Publish your agent when you're ready across multiple channels.\nConsider creating an agent if:\nYou want an agent that can:\nIntegrate company data and documents\nRetrieve real-time data from external APIs\nTake actions in response to external events\nBe embedded in company applications\nYou require a customized end-to-end solution for your web or mobile app or automation workflow that meets specific business needs and allows for complete control over product branding.\nYou want to surface your agent to other agents as their supported agent extension.\nYou're a proficient developer looking to create a customized end-to-end solution to cater to your business needs, and want:\nFull control on product branding\nChoice of language models and orchestration\nOr, if you're building products like:\nA customer service chatbot for your e-commerce site\nA virtual assistant to schedule appointments for your healthcare service\nGaming experiences that incorporate generative AI\nAccessibility\nThe agent authoring canvas is built for accessibility in accordance with\nMicrosoft accessibility guidelines\nand supports standard navigational patterns.\nImportant information\nImportant\nMicrosoft Copilot Studio (1) is not intended or made available as a medical device for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of disease, or otherwise to be used as a component of any clinical offering or product, and no license or right is granted to use Microsoft Copilot Studio for such purposes, (2) is not designed or intended to be a substitute for professional medical advice, diagnosis, treatment, or judgment and should not be used as a substitute for, or to replace, professional medical advice, diagnosis, treatment, or judgment, and (3) should not be used for emergencies and does not support emergency calls. Any agent you create using Microsoft Copilot Studio is your own product or service, separate and apart from Microsoft Copilot Studio. You are solely responsible for the design, development, and implementation of your agent (including incorporation of it into any product or service intended for medical or clinical use) and for explicitly providing end users with appropriate warnings and disclaimers pertaining to use of your agent. You are solely responsible for any personal injury or death that may occur as a result of your agent or your use of Microsoft Copilot Studio in connection with your agent, including (without limitation) any such injuries to end users.\nRelated content\nAI-based agent authoring overview\nCreate and delete agents\nCreate and edit topics\nKey concepts - Publish and deploy your agent\nAnalytics overview\nAgent flows overview\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Copilot Studio Overview",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/security-and-governance": {
      "content_hash": "sha256:423251bc6a7ddd1f5c0550dd4e47189cf2c17d5aef310e2f92afa95cbd058728",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nKey concepts - Copilot Studio security and governance\nFeedback\nSummarize this article for me\nCopilot Studio follows a number of security and governance controls and processes, including geographic data residency, data loss prevention (DLP), multiple standards certifications, regulatory compliance,\nenvironment routing\n, and regional customization. For more information and details on how Copilot Studio agent handle data, see\nGeographic data residency in Copilot Studio\n.\nThis article provides an overview of the security practices followed by Copilot Studio, a list of security and governance controls and features, and examples and suggestions for employing safety and security within Copilot Studio for your agent makers and users.\nSecurity and governance controls\nControl\nCore scenario\nRelated content\nAgent runtime protection status\nMakers can see the security status of their agents from the Agents page.\nAgent runtime protection status\nData policy controls\nAdmins can use data policies in the Power Platform admin center to govern the use and availability of Copilot Studio features and agent capabilities, including:\nMaker and user authentication\nKnowledge sources\nActions, connectors, and skills\nHTTP requests\nPublication to channels\nAppInsights\nTriggers\nConfigure data policies for agents\nMakers audit logs in Microsoft Purview for admins\nAdmins have full visibility into maker audit logs in Microsoft Purview.\nView audit logs\nAudit logs in Microsoft Sentinel for admins\nAdmins can monitor and receive alerts on agent activities through Microsoft Sentinel.\nView audit logs\nRun tools with user credentials\nAgent makers can configure tools to use the userâs credentials by default.\nUse tools with custom agents\nSensitivity label for Knowledge with SharePoint\nAgent makers and users can see the highest sensitivity label applied to sources used in the agent's response and individual reference labels in the chat.\nView sensitivity labels for Sharepoint data sources\nUser authentication with certificates\nAdmins and makers can configure agents to use Entra ID manual authentication with certificate provider.\nConfigure user authentication\nMaker security warning\nMakers can see security alerts for their agent before publishing it when security and governance default configurations are modified.\nAutomatic security scan in Copilot Studio\nEnvironment routing\nAdmins can configure environment routing to provide their makers a safe space to build agents.\nWork with Power Platform environments\nMaker welcome message\nAdmins can configure a maker welcome message to inform makers about important privacy and compliance requirements.\nWork with Power Platform environments\nAutonomous agents governance with data policies\nAdmins can manage agent capabilities with triggers using data policies, ensuring protection against data exfiltration and other risks.\nConfigure data policies for agents\nCMK\nAdmins can enable customer-managed encryption keys (CMK) for their Copilot Studio environments.\nConfigure customer-managed encryption keys\nSecurity Development Lifecycle\nCopilot Studio follows the Security Development Lifecycle (SDL). The SDL is a set of strict practices that support security assurance and compliance requirements. Learn more at\nMicrosoft Security Development Lifecycle Practices\n.\nData processing and license agreements\nThe Copilot Studio service is governed by your commercial license agreements, including the\nMicrosoft Product Terms\nand the\nData Protection Addendum\n. For the location of data processing, refer to the\ngeographical availability documentation\n.\nCompliance with standards and practices\nThe\nMicrosoft Trust Center\nis the primary resource for Power Platform compliance information.\nLearn more at\nCopilot Studio compliance offerings\n.\nData loss prevention and governance\nCopilot Studio supports an extensive set of\ndata loss prevention features\nto help you manage the security of your data, along with\nPower Platform data policies\n.\nAdditionally, to further govern and secure Copilot Studio using generative AI features in your organization, you can:\nDisable agent publishing: Your admin can use the Power Platform admin center to turn off the ability to publish agents that use generative AI features for your tenant.\nDisable data movement across geographic locations\nfor Copilot Studio generative AI features outside the United States.\nUse the Microsoft 365 admin center to govern the conversational and AI actions and agents that show in Microsoft 365 Copilot\n.\nFinally, Copilot Studio supports securely accessing customer data using\nCustomer Lockbox\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Security and Governance",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/publication-fundamentals-publish-channels": {
      "content_hash": "sha256:3913216076c607081e4a42060b55bd4907fb87a538f42ef4ec644f55b67f9d8f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nKey concepts - Publish and deploy your agent\nFeedback\nSummarize this article for me\nWith Copilot Studio, you can publish agents to engage with your customers on multiple platforms or channels, such as live websites, mobile apps, Microsoft 365 Copilot or messaging platforms like Teams and Facebook.\nEach time you update your agent, you can publish it again from within Copilot Studio. Publishing your agent applies to all the channels associated with your agent.\nWeb app\nTeams\nYou need to publish your agent before your customers can engage with it. You can publish your agent on multiple platforms, or\nchannels.\nAfter you publish your agent to at least one channel, you can connect it to more channels. Remember to publish your agent again after you make any changes to it.\nWhen you publish your agent, this agent updates on all connected channels. If you make changes to your agent but don't publish after doing so, your customers won't be engaging with the latest content.\nThe agent comes with the\nAuthenticate with Microsoft\noption turned on. The agent automatically uses Microsoft Entra ID authentication for Teams, Power Apps, and Microsoft 365 Copilot without requiring any manual setup.\nIf you want to allow anyone to chat with your agent, select\nNo authentication\n.\nCaution\nSelecting the\nNo authentication\noption allows anyone who has the link to chat and interact with your bot or agent.\nWe recommend you apply authentication, especially if you are using your bot or agent within your organization or for specific users, along with\nother security and governance controls\n.\nIf you want to use other channels and still have authentication for your agent, select\nAuthenticate manually\n.\nImportant\nIf you select\nNo authentication\n, your agent can't use\nAgent actions\nwith\nuser credentials\n.\nPublish the latest content\nWith your agent open for editing, in the navigation menu, select\nPublish\n.\nSelect\nPublish\n, and then confirm. Publishing can take a few minutes.\nTest your agent\nTest your agent after you publish. You can\nmake the agent available to users in Teams and Microsoft 365 Copilot\nwith the installation link or from various places in the Microsoft Teams app store.\nYou can share your agent later by selecting\nMake the agent available to others\nfrom the\nPublish\npage, in Teams.\nYou can also install the agent for your own use in Microsoft Teams by selecting\nOpen the agent in Teams\n.\nIf you selected\nNo authentication\nor\nAuthenticate manually\n, select the\nDemo website\nlink to open a prebuilt website in a new browser tab, where you and your teammates can interact with the agent.\nThe demo website is also useful to gather feedback from stakeholders before you roll your agent out to customers. Learn how to\nconfigure the demo website and add the agent to your live website\n.\nTip\nWhat's the difference between the test chat and the demo website?\nUse the test chat (the\nTest agent\npane) while you're building your agent to make sure conversation flows as you expect and to spot errors.\nShare the demo website URL with members of your team or other stakeholders to try out the agent. The demo website isn't intended for production use. You shouldn't share the URL with customers.\nConfigure channels\nAfter publishing your agent at least once, you can add channels to make it reachable by your customers.\nTo configure channels for your agent:\nOn the top menu bar, select\nChannels\n.\nSelect the desired channel from the list of available channels.\nThe connection steps are different for each channel. For more information, see the article for the desired channels, in the following list:\nTeams and Microsoft 365 Copilot\nSharePoint\nWhatsApp\nDemo Website\nCustom Website\nMobile App\nFacebook\nAzure Bot Service channels\n, including:\nCortana\nSlack\nTelegram\nTwilio\nLine\nKik\nGroupMe\nDirect Line Speech\nEmail\nChannel experience reference table\nDifferent channels have different user experiences. The following table shows a high-level overview of the experiences for each channel. Take the channel experiences into account when optimizing your agent content for specific channels.\nExperience\nWebsite\nTeams and Microsoft 365 Copilot\nFacebook\nDynamics Omnichannel for Customer Service\nCustomer satisfaction survey\nAdaptive card\nText-only\nText-only\nText-only\nMultiple-choice options\nSupported\nSupported up to six (as hero card)\nSupported up to 13\nPartially Supported\nMarkdown\nSupported\nPartially Supported\nPartially supported\nPartially Supported\nWelcome message\nSupported\nSupported\nNot supported\nSupported for\nChat\n. Not supported for other channels.\nDid-You-Mean\nSupported\nSupported\nSupported\nSupported for\nMicrosoft Teams\n,\nChat\n, Facebook, and text-only channels (short message service (SMS) via\nTeleSign\nand\nTwilio\n,\nWhatsApp\n,\nWeChat\n, and\nTwitter\n).\nSuggested actions are presented as a text-only list; users must retype an option to respond.\nNext steps (Web app)\nArticle\nDescription\nPublish an agent to a live or demo website\nPublish your agent on your live website, or use a demo website to share internally.\nConnect and configure an agent for Teams and Microsoft 365 Copilot\nUse Teams and Microsoft 365 Copilot to distribute your agent.\nPublish an agent to Facebook\nAdd your agent to Facebook Messenger.\nPublish an agent to mobile or custom apps\nAdd your agent to mobile or custom native apps (developer coding required).\nPublish an agent to Azure Bot Service channels\nAdd your agent to Azure Bot Service channels (developer coding required).\nSee the\nweb app instructions for publishing latest content\nas they're the same in the Teams app.\nWhen publication is successful, you can\nmake the agent available to users in Microsoft Teams\nwith the installation link or from various places in the Microsoft Teams app store. You can share your agent later by selecting\nMake the agent available to others\nfrom the\nPublish\npage.\nYou can also install the agent for your own use in Microsoft Teams by selecting\nOpen the agent in Teams\n.\nTip\nTo prevent disrupting users who are having an existing conversation with the agent, they don't receive the latest published content until a new conversation starts. A new conversation starts after it has been idle for more than 30 minutes.\nYou might want to try out the latest published content in Microsoft Teams right away. You can do so by entering\nstart over\nin an existing conversation. This restarts the conversation with the latest content you published.\nKnown limitations\nCustomer satisfaction survey is a text-only version in Microsoft Teams instead of an adaptive card.\nMicrosoft Teams can only render up to six suggested actions for user in one question node.\nA user can't send or upload attachments to the chat. If they try to send an attachment, the agent replies:\nLooks like you tried to send an attachment. Currently, I can only process text. Please try sending your message again without the attachment.\nThis limitation applies to all channels, even if the channel or user-facing experience supports attachments (for example, if you're using the Direct Line API or Microsoft Teams).\nAttachments can be supported if the message is sent to a skill, where the skill bot supports the processing of attachments.\nFor more information on skills, see\nUse Microsoft Bot Framework skills in Copilot Studio\n.\nNext steps (Teams)\nArticle\nDescription\nConnect and configure an agent for Teams and Microsoft 365\nMake your agent available to users in Microsoft Teams and Microsoft 365.\nCreate a privacy statement and terms of use in Microsoft Teams\nCreate and link to a privacy statement and terms of use for agents you create.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent Publishing",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/admin-share-bots": {
      "content_hash": "sha256:abe6cdcd998cfc79f48ac8d8f093377f776020b2349b015e6947534a7f8d754e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nShare agents with other users\nFeedback\nSummarize this article for me\nYou can share your agents with others in either of the following ways:\nGrant security groups, or your whole organization, permission to chat with the agent.\nInvite users to collaborate on your agent project. Collaborators always have permission to chat with the agent.\nPrerequisites\nUser authentication\nfor the agent must be configured to\nAuthenticate manually\n, with\nAzure Active Directory\nor\nMicrosoft Entra ID\nas the provider.\nRequired user sign-in\nmust be enabled to manage who can chat with the agent in your organization.\nShare an agent for chat\nWeb app\nTeams\nCollaborators\n, who have authoring permissions for a shared agent, can always chat with it. However, you can also grant users permission to chat with an agent in Copilot Studio without granting them authoring permissions.\nTo grant users permission to only chat with the agent, you can either:\nShare your agent with a security group.\nShare your agent with everyone in your organization.\nNote\nWhen sharing an agent for\nchat\nyou can't share it with:\nMicrosoft 365 groups.\nIndividual users directly. To manage individual user access, add or remove users from the security group.\nTo author agents in Copilot Studio, makers need at least the\nEnvironment Maker\nrole. The\nBot Author\nrole is deprecated. When a maker shares an agent for co-authoring, the other user is granted the\nBot Contributor\nand\nEnvironment Maker\nroles. Users in these roles can only access agents they created or that have been shared with them. Additionally, makers must have the\nprvAssignRole\nprivilege, included in the\nSystem Administrator\nand\nSystem Customizer\nroles, to share an agent for co-authoring. If the new co-author holds the\nEnvironment Maker\nrole, the original maker doesn't need the\nprvAssignRole\nprivilege.\nShare an agent with security groups\nYou can share an agent with security groups so their members can chat with it.\nOpen the agent you want to share in Copilot Studio.\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nEnter the name of every security group that you would like to share the agent with.\nReview the permissions for each security group.\nIf you want to let the users know you shared the agent with them, select\nSend an email invitation to new users\n.\nNote\nUsers can only receive an email invitation if their security group has email enabled. Alternatively, select\nCopy link\nand then share the link directly with the users to inform them they can now chat with your agent.\nSelect\nShare\nto share the agent with the security groups you specified.\nShare an agent with everyone in the organization\nYou can share your agent to allow everyone in the same organization as the agent to chat with it.\nOpen the agent you want to share in Copilot Studio.\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nSelect\nEveryone in <OrganizationName>\n(where\n<OrganizationName>\nis your organization's name).\nSelect\nUser - can use the agent\n.\nNote\nCopilot Studio doesn't send email invitations to everyone in an organization. You can select\nCopy link\nand then share the link directly with the users to inform them they can now chat with your agent.\nSelect\nShare\nto share the agent with everyone in the organization.\nShare your agent with other users so they can chat with the agent or collaborate to author it.\nA user can always chat with an agent if it was created in the same team. You can also share agents with users outside of a team.\nShare an agent with security groups\nYou can share an agent with security groups so their members can chat with it.\nOpen the agent you want to share in Copilot Studio for Teams.\nSelect\nShare\nat the top of the\nOverview\npage.\nEnter the security group name that you would like to share the agent with.\nNote\nYou can only share an agent with security groups. You can't share with individual users directly.\nYou can manage individual user access by adding or removing users from the security group.\nTo make a security-enabled group, please refer to\nMicrosoft Graph documentation\n.\nReview the security group's permissions.\nIf you want to let users know you shared the agent with them, select\nSend an email invitation to new users\n.\nNote\nUsers can only receive an email invitation if their security group has email enabled. Alternatively, select\nCopy link\nand then share the link directly with the users to inform them they can now install the agent in Microsoft Teams and chat with it.\nSelect\nShare\nto share the agent with the security group you specified.\nShare an agent with everyone in the organization\nYou can share your agent to allow everyone in the same organization as the agent to chat with it.\nOpen the agent you want to share in Copilot Studio for Teams.\nSelect\nShare\nat the top of the\nOverview\npage.\nSelect\nEveryone in <OrganizationName>\n(where\n<OrganizationName>\nis your organization's name).\nSelect\nUser - can use the chatbot\n.\nNote\nCopilot Studio doesn't send email invitations to everyone in an organization. You can select\nCopy link\nand then share the link directly with the users to inform them they can now install the agent in Microsoft Teams and chat with it.\nSelect\nShare\nto share the agent with everyone in the organization.\nShare an agent for collaborative authoring\nWeb app\nTeams\nSharing an agent with individual users gives them permission to view, edit, configure, share, and publish the agent. They can't delete the agent.\nNote\nYou can only share an agent with users who have a Microsoft Copilot Studio per user license. Users who don't have a license can\nsign up for a trial\n.\nOpen the agent you want to share in Copilot Studio.\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nEnter the name or email address of each user that you would like to share the agent with.\nNote\nWhen sharing an agent for\ncollaborative authoring\nyou can only share it with individual users in your organization.\nReview the permissions for each user.\nIf you want to let your new collaborators know you shared the agent with them, select\nSend an email invitation to new users\n.\nSelect\nShare\nto share the agent with the users you specified.\nImportant\nIf a user wasn't already a\nmember of the environment\nfor the shared agent, it can take up to 10 minutes before the agent becomes available in Copilot Studio for this user.\nYou can always collaborate with others when building agents in the Copilot Studio app for Teams. This means other members of your team can make changes, and you can see who else is editing a topic.\nYour\nMicrosoft Teams roles\ndetermine your permissions in the team where you create an agent:\nTeam Owners can create, view, edit, and configure all agents in teams they own.\nTeam Members can create, edit, and configure their own agents. They can view the other team members' agents.\nNote\nIf you are an owner for a Microsoft Entra ID group associated with a team, without being a member of that team, you might not be able to see the team in the Power Apps and Copilot Studio apps in Microsoft Teams. To resolve this issue, add yourself to the team. It can take a few minutes before the team becomes visible to you.\nTo share an agent with other users for collaboration, you must\nadd them to your team\n. It can take up to 15 minutes before a new team member sees the team in the Copilot Studio app for Teams.\nWhen you select the\nAgents\ntab on the top menu bar, you can see a list of your teams. Select a team to see the agents in that team.\nTip\nMy agents\nshows all the agents you created and is an easy way for you to find your agent across multiple teams. You can find agents created by other team members by selecting the team.\nSelect the name of an agent to open it for editing.\nIf you select the check mark next to the name of an agent, a secondary menu bar appears. From this menu bar, you can go straight to the\nTopics\nor\nAnalytics\npage for your agent. You can also select\nEdit\nto go to the\nOverview\npage.\nIf you select the three dots (\nâ¦\n) next to the name of an agent you can then select\nEdit\nto go to the\nOverview\npage, or go to the\nTopics\nor\nAnalytics\npages.\nIf you rename, restore, or delete a team, it could take up to 2 hours for the changes to be reflected in the Copilot Studio app.\nCollaborate on agents\nAfter you shared an agent with other users, they can all edit its topics.\nOn the\nTopics\npage, the\nEditing\ncolumn shows who's working on topics. Select a person's icon to quickly chat with them in Teams or send them an email.\nThis information can help prevent conflicts when multiple authors are working on the same topic.\nNote\nThe list of authors in the\nEditing\ncolumn is only refreshed when the page is loaded.\nWhen a topic is open for editing, icons at the top of the authoring canvas also show who's currently working on this topic.\nIf an author doesn't make any changes to the topic, disconnects their computer, or closes the browser window, they're considered to have abandoned the topic. After 30 minutes of inactivity, the user isn't identified as editing the topic.\nOccasionally, multiple authors might make changes to a topic and attempt to save their changes concurrently. For example, you might open and start editing a topic. Your coworker opens the same topic, makes a small change, and saves it. Then, when you've finished editing the topic, and attempt to save it, Copilot Studio detects a conflict. When a conflict happens Copilot Studio prevents you from overwriting your coworker's changes, by offering you two options:\nSelect\nDiscard changes\nto reload your agent with the latest changes (discarding your work).\nSelect\nSave copy\nto save a copy of the topic (keeping your changes in a copy of the topic).\nIf you save your changes as a new topic, you can then review your coworker's changes, merge the two topics, and delete the copy once you're done.\nStop sharing an agent\nWeb app\nTeams\nYou can stop sharing an agent with individual users, a security group, or everyone in your organization.\nStop sharing with security groups\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nSelect the\nX\nicon next to each security group you want to stop sharing the agent with.\nSelect\nShare\nto stop sharing the agent with these security groups.\nStop sharing with everyone in the organization\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nSelect\nEveryone in <OrganizationName>\n(where\n<OrganizationName>\nis your organization's name).\nSelect\nNone\n.\nSelect\nShare\nto stop sharing the agent with everyone in the organization.\nStop sharing an agent with individual users\nYou can stop sharing an agent with a user, and any shared user can stop the agent from being shared with other users, except for the owner. Owners always have access to their agents.\nOn the top menu bar, select the three dots (\nâ¦\n) and then select\nShare\n.\nSelect the\nX\nicon next to each user you want to stop sharing the agent with.\nSelect\nShare\nto stop sharing the agent with these users.\nYou can stop sharing an agent with security groups or everyone in your organization.\nNote\nWhen you stop sharing an agent, affected users can't access the agent after their current conversation has timed out (after 30 minutes of idle time).\nStop sharing with security groups\nSelect\nShare\nat the top of the\nOverview\npage.\nSelect the\nX\nicon next to each security group you want to stop sharing the agent with.\nSelect\nShare\nto stop sharing the agent with these security groups.\nStop sharing with everyone in the organization\nSelect\nShare\nat the top of the\nOverview\npage.\nSelect\nEveryone in <OrganizationName>\n(where\n<OrganizationName>\nis your organization's name).\nSelect\nNone\n.\nSelect\nShare\nto stop sharing the agent with everyone in the organization.\nShare Power Automate flows used in an agent\nYou can\nadd actions to an agent using flows in Power Automate\n. However, sharing an agent doesn't automatically share the flows in the agent.\nUsers who don't have access to flows in a shared agent can still run these flows by using the Test panel in Copilot Studio.\nTest your agents to make sure users who chat with them have the required permissions to run the\nPower Automate flows\n.\nTo let other users edit or add flows, you must share them in Power Automate. You can open flows directly from the topic where the flow is used.\nSelect\nView flow details\nto go to the flow's details page in Power Automate.\nSelect\nEdit\nin the\nOwners\nsection.\nEnter the name or email address of the user you want to give editing permissions to.\nAssign environment security roles\nIf you're a\nSystem Administrator\n, you can assign and manage environment security roles when sharing an agent.\nThe\nEnvironment security roles\nsection shows when you share an agent and only if you're a\nSystem Administrator\n. It lets you share agents with users who don't have sufficient environment permissions to use Copilot Studio.\nYou must be a\nSystem Administrator\nof the environment where the agent is located to view and add security roles.\nNote\nYou can only\nassign\nsecurity roles when sharing an agent. You can't remove security roles when sharing. For full security role management, use the\nPower Platform admin center\n.\nLearn more about\nsecurity roles\nand\npredefined security roles\nin the Power Platform admin documentation.\nAssign the Environment Maker security role during agent sharing\nWhen sharing an agent, if a user doesn't have sufficient permissions to use Copilot Studio in the environment, you're notified that the\nEnvironment Maker\nsecurity role is assigned to the user so they can use the agent.\nAssign the Bot Transcript Viewer security role during agent sharing\nWhen sharing an agent, you can assign the\nBot Transcript Viewer\nsecurity role to users who don't have conversation transcript access.\nDepending on the content and target audience of the agent, consider granting transcript access only to users who have the appropriate privacy training.\nImportant\nConversation transcript access is managed by environment security roles. After assigning the\nBot Transcript Viewer\nsecurity role to a user, that user can access conversation transcripts for all agents that they create or are shared with them in the environment.\nBy default, only admins have the\nBot Transcript Viewer\nrole. We recommend you\ncreate a new environment for your agents\nto control which users can view conversation transcripts.\nInsufficient environment permissions\nUsers in an environment must have the\nEnvironment Maker\nsecurity role before an agent can be shared with them.\nA system administrator for the environment must assign the\nEnvironment Maker\nsecurity role to a user before you share an agent with them. If you have the\nSystem Administrator\nsecurity role, you can\nassign the Environment Maker role\nto users when you share agents.\nLearn more about\nsecurity roles\nand\npredefined security roles\n.\nManage security roles\nYou can\nmanage environment security roles at the Power Platform admin center\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Share and Manage Agents",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/analytics-overview": {
      "content_hash": "sha256:2a5c0bf0628d62c91c1f68af29cbda18915977765e16d2e4e8a9f1190b6e8fa1",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAnalytics overview\nFeedback\nSummarize this article for me\nUse analytics to understand how well your agent is performing and to identify areas for improvement.\nThe\nAnalytics\ntab in Copilot Studio shows you comprehensive data for your agent, from an overview of key metrics to in-depth usage analytics for your agent's components. You can drill down into each piece of data to get more details.\nThe analytics experience is tailored for\nconversational agents\nand for\nautonomous agents\n.\nAnalytics are available in all geographies. Time and date stamps in analytics are in Coordinated Universal Time (UTC). This includes day start and end times, session times, and any other time markers in your agent's data.\nNote\nAnalytics aren't available on the\nAnalytics\npage for activity completed when you test your agent in Copilot Studio using the\ntest panel\n.\nTo access analytics:\nOpen your agent in Copilot Studio.\nSelect\nAnalytics\non the top menu bar.\nThe\nSummary\narea uses Copilot to generate an AI summary of key analytics insights about your agent. Select\nView More\nto see the full summarized list of insights.\nYou can provide feedback to Microsoft about this section with the\nThumbs up\nand\nThumbs down\nicons\n. Use the\nSubmit feedback to Microsoft\npanel to add a comment and share related files. By providing descriptive feedback like this, we can work together to continuously improve our product.\nOn the\nSubmit feedback to Microsoft\npanel, describe in natural language your likes or dislikes, depending on which icon you selected to open the panel.\nChoose whether to share prompt, generated response, relevant content samples, and additional log files.\nSelect\nSubmit\n.\nYou can also check a high-level performance summary in the\nOverview\narea, then dive deeper into its performance.\nConversational sessions only\nAnalytics for conversational agents\nin Copilot Studio track user engagement with your agent and try to capture how well your agent handles user tasks.\nConversational analytics uses the following concepts and terms:\nConversations\nare an ongoing interaction between a specific user, or group of users, on a\nchannel\nand your agent.\nConversations can pause and resume later, or be\ntransferred to a customer service representative\n. The conversation might be one-way, either from the customer to the agent, or from the agent to the customer, but is more commonly a back-and-forth interaction between the customer and the agent.\nA conversation times out after 30 minutes of inactivity.\nA single conversation can contain one or more analytics sessions.\nAn analytics session in classic mode is associated with the last custom topic triggered by a user. If the session doesnât include custom topics, it's the last system topic triggered directly by the user.\nEvent trigger sessions only\nAn autonomous agent is an agent with an event trigger. Only\nanalytics for agents with triggers\nare available for these agents.\nAn\nanalytics session\nfor agents with triggers tracks from when an agent receives a payload from a trigger through any actions the agent runs in response. These analytics sessions capture what your agent is responding to, and how well your agent performs.\nNote\nIf a trigger fails and the agent doesn't receive a trigger payload, an analytics session can't begin. Only successfully triggered runs are tracked in analytics.\nHybrid view - both conversational and event-triggered sessions\nWhen your agent's data includes sessions for at least one conversation and at least one trigger-based run in the report's period, then a\nhybrid\nview of relevant metrics for both conversational and autonomous sessions are displayed on the\nAnalytics\ntab. In this view, the\nOverview\nand\nEffectiveness\nsections show metrics side by side for both the conversational and event-triggered sessions. The\nUse\nsection allows you to select between\nConversations\nor\nRuns\n, which displays only relevant data. Selecting\nAll\nshows all use-related data. The\nSatisfaction\nsection displays satisfaction metrics for conversational sessions.\nFor more information about:\nDisplayed metrics relevant to conversation sessions, see\nAnalyze conversational agent effectiveness\n.\nDisplayed metrics relevant to event-triggered sessions, see\nAnalyze autonomous agent health\n.\nDownload conversational transcripts\nConversation transcripts are available for download a few minutes after the conversation times out. You can download any time period within the last 29 days. You can download them in\nDataverse via the Power Apps portal\nand as\nsession chat transcripts via the Copilot Studio app\n. It can take up to an hour after the analytic session ends before the related data appears on the analytics dashboard.\nNote\nConversation transcripts in Dataverse are unavailable for download on the Copilot Studio app in Teams. To review and export transcripts in Dataverse, you need to sign up for the\nCopilot Studio web app\n. Session chat transcripts can be downloaded via the\nCopilot Studio app\n. For more information, see\nDownload agent session transcripts\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Analytics",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/analytics-csat": {
      "content_hash": "sha256:0e9e495c2d6707b2b66d6956110f81671ec3fe785873a1e135eca7ca54a60f85",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAnalyze conversational agent effectiveness\nFeedback\nSummarize this article for me\nThe\nAnalytics\npage in Copilot Studio provides an aggregated insight into the overall effectiveness of your agent across\nanalytics sessions\n. The page is divided into core areas that focus on different performance contexts. The page also displays an\nOverview\narea that provides high-level, key performance indicator (KPI) metrics for your agent, a\nSavings\narea that analyzes time and cost savings attributable to your agent or your agent's tools, and a\nSummary\narea that provides key analytic insights into your agent's performance.\nFor more information about:\nThe\nSummary\nand\nOverview\nareas, see\nAnalytics overview\nThe\nSavings\narea, see\nAnalyze time and cost savings for agents\nThere are six core areas to focus on when reviewing and improving conversational agent effectiveness:\nThemes\n:\nThemes\nhelp you gain analytics insights by clustering user questions into AI-suggested categories.\nConversation outcomes\n: Knowing the end result of a conversation helps you begin to identify where your agent is succeeding and where it needs improvement.\nAgents\n: See call volume metrics, success rates, and current status for child and connected agents.\nGenerated answer rate and quality\n: Understanding when agent struggles to provide answers to user questions and how it uses knowledge sources can help you find ways to improve your agent's answer rate and quality.\nTool use\n: Learning how often tools are used and how often they succeed can help you understand if those tools are useful and successful for users.\nSatisfaction\n: Reviewing user feedback helps you identify new user scenarios and issues, and making improvements based directly on what your users are asking for.\nYou can view analytics for events that occurred in the last 90 days.\nConversation outcomes\nThe\nConversation outcomes\nsection shows a chart that tracks the type of outcome for each session between your agent and users.\nThe chart, whether displayed as a stacked histogram or stacked area chart, visualizes the relative volumes of outcomes, color-coded and stacked by type. Each of\nResolved\n,\nEscalated\n,\nAbandoned\n, and\nUnengaged\nare represented by their respective colors for each data point. The y-axis indicates the number of sessions.\nTo see metrics about individual outcomes specific to one data point (a specific day), hover over an area representing the color of an outcome of interest (for example, teal for Abandoned) on the day you're interested in. In the example, there were 90 abandoned sessions representing 35.6% of all session outcomes on November 24.\nIn the legend below the chart, hover over any of the outcome labels to highlight that outcome in the chart.\nSelect (on or off) one or several of the legend labels to either show or hide outcomes from the stacked area chart. Do this to add more clarity to the outcomes that remain when:\nIndividual outcome lines appear visually close together.\nYou want to see more clearly when trend lines are trending positive or negative but the aggregate of stacked outcomes on the chart is flattening these trend lines.\nNote\nWhen you remove an outcome from the chart in this way, you remove that outcome from the larger pool of displayed outcomes. Removing displayed outcomes changes the displayed percent value of any remaining outcome against the pool because it changes the denominator of the ratio.\nIn the following example, the\nEscalated\nand\nUnengaged\nlabels were removed from the chart. The tooltip shows there were 95 abandoned sessions on November 23, which represents 60.5% of the remaining visible outcomes on the chart (being the sum of\nResolved\n+\nAbandoned\noutcomes).\nTo download conversation outcome data (data visualized in the graph), select the menu icon\nand select\nDownload CSV\n.\nNote\nIf you have any outcomes removed from the chart when you download, their data doesn't appear in the CSV.\nTo open a side panel with detailed information about conversation outcomes, select\nSee details\non the chart. The\nConversation outcomes\nside panel includes:\nA pie chart breakdown of\nsession\noutcomes, showing relative weighting (expressed as a percent) of\nResolved\n,\nEscalated\n, and\nAbandoned\noutcomes.\nA stacked bar graph showing the relative weighting (expressed as a percent) of\nResolved confirmed\nand\nResolved implied\noutcome reasons describing all resolved session outcomes.\nA stacked bar graph showing the relative weighting (expressed as a percent) of\nSystem intended\n,\nSystem unintended\n, and\nUser requested\noutcome reasons describing all escalated session outcomes.\nThe top topics that led to each outcome.\nNote\nTo see a tooltip with raw count information, hover over any of the pie chart or stacked bar chart segments.\nA\nsession\nfalls into one of the following two states:\nUnengaged\n: A session starts when a user interacts with your agent or the agent sends a proactive message to the user. The session begins in an\nunengaged\nstate.\nEngaged\n: The user actively interacts with the agent. There's a difference in behavior based on the\nagent's orchestration mode\n.\nClassic orchestration: A session becomes engaged when one of the following topics is triggered:\nCustom topic directly triggered by the user\nEscalate topic\nFallback topic\nConversational boosting topic\nGenerative AI orchestration: A session becomes engaged when a user directly triggers a plan and includes one of the following elements:\nNonsystem topic\nEscalate topic\nFallback topic\nA Knowledge Source\nA tool\nAn engaged session has one of the following outcomes:\nOutcome category\nOutcome\nDescription\nResolved\nA session ends successfully. There are two types of resolved sessions:\nResolved confirmed\nand\nResolved implied\n.\nResolved confirmed\nA session is considered\nResolved confirmed\nwhen the\nEnd of Conversation\ntopic is triggered and the user confirms that the interaction was a success.\nResolved implied\nA session is\nResolved implied\nwhen the session is completed without user confirmation but instead based on the agent's logic. The\nResolved implied\nstate depends on whether your agent uses Classic or Generative AI orchestration:\n- Classic orchestration: A session is considered\nResolved implied\nwhen the\nEnd of Conversation\ntopic is triggered, and the user lets the session time out without providing a confirmation.\n- Generative AI orchestration: A session is considered\nResolved implied\nwhen a session times out and there are no remaining active plans. An active plan is a plan that's waiting for a user's input.\nEscalated\nA session ends but is considered Escalated when the\nEscalate\ntopic is triggered or a\nTransfer to agent\nnode is run (the current analytics session ends, whether the conversation transfers to a live agent or not). There are three types of escalated sessions:\nSystem intended\n,\nSystem unintended\n, and\nUser requested\n.\nSystem intended\nA session is escalated automatically as a result of an automatic business rule set by a maker. The escalation is an expected outcome of the conversation and isn't something needing investigation or change.\nExample: A user would like to transfer more than $25,000 to a third party. This amount exceeds a threshold in a business rule and the session is automatically escalated as a result.\nSystem unintended\nAn escalation occurs automatically as a result of a session exceeding one or more thresholds set by a maker. Usually, this outcome indicates that the user is stuck in the conversation and needs assistance.\nExample: A session is escalated after three failures to do a particular task.\nUser requested\nA session is escalated because there was an explicit user request during the conversation.\nExample: A user enters\nTransfer me to an agent\n.\nAbandoned\nA session ends and is considered\nAbandoned\nwhen an engaged session times out after 30 minutes and didn't reach a resolved or escalated state.\nYou can also set the outcome for tools with the\nconversationOutcome\nparameter using the tool code editor. For example,\nconversationOutcome: ResolvedConfirmed\nfor confirmed success or\nconversationOutcome: ResolvedImplied\nfor implied success.\nSee the guidance documentation on\nmeasuring engagement\nfor suggestions and best practices on how to measure and improve engagement.\nAgents\nThe\nAgents\nlist displays high-level volume, performance, and status metrics for\nconnected and child agents\nof your main agent. The list identifies the relationship type the listed agent has to your main agent in the\nType\ncolumn. If an agent is a child agent, its type is\nChild\n. Connected agents have a listed type that reflects where they were created (for example,\nCopilot Studio\n,\nAzure AI Foundry\n). The\nCalls\nmetric for each listed agent describes the volume of calls from the main agent to the connected or child agent.\nSuccess rate\nreflects the proportion of calls (as a % of all calls) that completed successfully.\nStatus\nindicates the individual administrative status for each connected and child agent.\nBy default, the\nAgents\nlist displays the top five (5) connected and child agents of your main agent, ranked from highest to lowest total number of questions. If there are more than five agents, select\nSee all\nto display all agents.\nNote\nThe\nSee all\nbutton is visible only if there are more than five connected or child agents to your main agent.\nGenerated answer rate and quality (preview)\nImportant\nThis article contains Microsoft Copilot Studio preview documentation and is subject to change.\nPreview features aren't meant for production use and may have restricted functionality. These features are available before an official release so that you can get early access and\nprovide feedback\n.\nIf you're building a production-ready agent, see\nMicrosoft Copilot Studio Overview\n.\nWith generative answers, your agent can use AI to generate answers to user queries using knowledge sources and the instructions you provide. However, your agent might not be able to answer all user queries. The\nGenerated answer rate and quality\nsection tracks, organizes, and analyzes unanswered queries and answer quality to give you guidance for improving your agent's answering performance.\nThe\nAnswer rate\nshows the number of answered and unanswered questions within the selected time period and the percentage change over time.\nAnswer quality\nmeasures the quality of answers using AI. Copilot Studio looks at a sample set of answered question and analyzes different quality, including completeness, relevance, and level of groundedness of a response. If the answer meets a set standard, Copilot Studio labels the answer as\nGood\nquality. Copilot Studio labels answers that don't meet that standard as\nPoor\nquality. For\nPoor\nanswers, Copilot Studio assigns a reason for the quality rating, and shows the percentage of answers assigned to each category.\nHover over any segment of a bar in the chart to see the relative weighting of an individual reason for either a\nGood\nor\nPoor\nquality label. The tooltip also indicates the number of answers sampled to arrive at the calculated percent value.\nIn the legend below the chart, hover over any of the quality label reasons to highlight that reason in the chart.\nYou can provide feedback to Microsoft about this section with the\nThumbs up\nand\nThumbs down\nicons\n. Use the\nSubmit feedback to Microsoft\npanel to add a comment and share related files. By providing descriptive feedback like this, we can work together to continuously improve our product.\nOn the\nSubmit feedback to Microsoft\npanel, describe in natural language your likes or dislikes, depending on which icon you selected to open the panel.\nChoose whether to share prompt, generated response, relevant content samples, and additional log files.\nSelect\nSubmit\n.\nSelect\nSee details\nto open a side panel with question answer rates, knowledge source usage, and error rates over your selected time period. You can use these charts to identify which knowledge sources work well to help users, and which to target for improvements.\nIf your agent has child agents, on the side panel, select\nAll\nto display metrics for both the main agent and child agents,\nMain agent\nfor metrics about the main agent only, or\nChild agent\nfor metrics about child agents only.\nUnanswered questions\nshows the reasons why the agent didn't answer a user query.\nKnowledge source use\nshows the percentage of sessions that used each knowledge source the agent has access to.\nAll sources\nshows the percentage of questions that used each knowledge source.\nErrors\nshows the percentage of queries that resulted in a knowledge-related error for each knowledge source type (for example, SharePoint).\nUnder\nAll sources\n, to see more information at the level of any one of the listed knowledge sources, select an individual source. The tooltip includes:\nThe total number of questions that referenced this knowledge source as well as the number of\nthumbs up\nand\nthumbs down\nreactions.\nA stacked bar chart showing the breakdown of the quality of response relative weightings for questions referencing this knowledge source. Hover over any segment of the bar chart to see the value of that segment's relative weighting and the number of questions sampled to arrive at that value.\nTool use\nThe\nTool use\nsection shows a chart and metrics that track how often your tools are started over time, and how often your agent used those tools successfully. It also shows trend indicators for how often your agent uses each tool and the percentage of called tools used successfully.\nThe chart displays the top five tools used over the date period defined at the top of the\nAnalytics\npage.\nIn the legend below the chart, hover over any of the tools to highlight that tool in the chart.\nTo open a side panel with a list of all tools used in the specified time period, along with trend indicators, select\nSee details\non the chart. On the\nTool use\npanel, you can display calculations of the percentage of questions used for each tool. If your agent has child agents, you can choose to display calculations for both the main agent and child agents (\nAll\n), the\nMain agent\nonly, or the\nChild agent\nonly.\nSatisfaction\nThe\nSatisfaction\nsection shows user feedback gathered from reactions to agent responses, survey results, and sentiment score for a session. Satisfaction is split into two sub-sections: a\nReactions\nsection, which displays thumbs up, thumbs down feedback and user comments for specific agent responses, and a\nSurvey results\nsection, which displays the explicit customer satisfaction (CSAT) score and AI-based sentiment analysis for the entire session.\nFeedback data is stored in the conversation transcript table in Dataverse. For a list of channels that support this feature, see\nFeature details\n.\nReactions\nThe\nReactions\nsection shows user feedback gathered from reactions to agent responses and survey results for a session. The chart counts the number of times users selected either the thumbs up (positive) or thumbs down (negative) buttons available on each response they received from your agent.\nAfter a user provides a reaction, they can leave a comment. To view comments, select\nSee details\n. On the\nReaction comments\npanel, select\nAll\n,\nThumbs up\n, or\nThumbs down\nto filter comments.\nNote\nAgents published to the Microsoft 365 Copilot channel don't support reactions.\nTo view comments, you must have the\nBot Transcript Viewer\nsecurity role.\nFor each reaction, to see the associated user query and agent response, select the toggle beside the comment. The\nAnalytics\npage stores user queries and agent responses for up to 28 days.\nUser feedback is\nOn\nby default. You can turn off this feature, if desired. You can also add or edit a disclaimer for users about how their feedback is used:\nOpen the agent, then go to\nSettings\n, and find the\nUser feedback\nsection.\nTurn\nLet users give feedback when using this agent\neither\nOn\nor\nOff\n.\nAdd or edit a disclaimer so users know how their feedback is used. You can also provide privacy information and tips.\nUser satisfaction for sessions\nThe\nUser satisfaction for sessions\nsection shows information about user satisfaction based on user survey results and AI analysis of sentiment in a sample of sessions:\nSurvey satisfaction score\n: A score out of 5 calculated from the average customer satisfaction (CSAT) scores for sessions in which users responded to end-of-session requests to take a survey.\nNote\nScores of\n1\nand\n2\nmap to\nDissatisfied\n, a score of\n3\nis considered\nNeutral\n, and scores of\n4\nand\n5\nmap to\nSatisfied\n.\nSatisfaction by session\n: A stacked bar chart that visualizes the relative weighting for each of the survey's score categories, being\nDissatisfied\n,\nNeutral\n, and\nSatisfied\n. Hover over each segment of the chart to see the size of the sample and the numerical value of the weighting of each score category.\nSentiment analysis (preview)\n: A complementary metric to the survey score. This metric uses AI to analyze user messages from a sample of sessions to evaluate an overall user sentiment for the agent. The numerical value represents the percentage of sessions with negative user sentiment.\nSelect\nSee details\nto drill down into the sentiment data for the relative weighting of each of the sentiment categories (being\nPositive\n,\nNeutral\n, and\nNegative\n), and to see how the satisfaction metrics trend over the report's configured time period.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Customer Satisfaction",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/advanced-connectors": {
      "content_hash": "sha256:a44eb0963223bad372780340c9e57f4f3b9e3658c9144e30a2df42dac7842ae8",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nUse Power Platform connectors as tools\nFeedback\nSummarize this article for me\nConnectors from Microsoft Power Platform\nare proxies or \"wrappers\" around APIs that allow Copilot Studio, Power Automate, Power Apps, and Azure Logic Apps to talk to other apps and services. Connectors let you connect your accounts and use prebuilt tools and triggers to build your apps and workflows.\nWith connectors, you can access various services (both within the Microsoft ecosystem and outside it) to perform a wide array of tasks automatically.\nThere are\nmany connectors\navailable. Connectors include connections between and to Microsoft services like Office 365, SharePoint, and Dynamics 365, as well as connections to non-Microsoft services like Twitter, Google services, Salesforce, and more. Connectors are categorized as:\nPrebuilt connectors\n, which are built-in connections to popular services available to use in Copilot Studio agents. These include:\nStandard connectors\n, such as SharePoint, which are included with all Copilot Studio plans.\nPremium connectors\n, which are available in select\nCopilot Studio plans\n.\nCustom connectors\n, which let you connect to any publicly available API for services not covered by existing connectors.\nIntegration with Copilot Studio\nConnectors are useful tools that greatly extend the functionality of Copilot Studio agents. Connectors connect you to various external services and applications to perform a wide range of tasks. With these connectors you can create more dynamic, responsive, and useful agents, tailored to specific business needs and processes.\nYou can call connectors as tools in your agent, at the agent level, or in a\ntopic\n.\nNote\nFor more information on adding connectors as a knowledge source, see\nAdd Power Platform connectors as knowledge (preview)\n.\nAdd tools from a prebuilt connector to your agent\nYou can select and add tools from prebuilt connectors directly to your agent. Connector tools represent specific actions or operations you want your agent to perform using that connector.\nFor some connectors, you add tools one at a time.\nFor some connectors, you can add multiple related tools at once as a\ntool group\n.\nAdd a single tool from a prebuilt connector\nSelect\nAgents\nand select the agent you want to add a connector to.\nGo to the\nTools\npage of your agent and select\nAdd a tool\n.\nSelect\nConnector\n. The different services with connectors available are displayed.\nSelect the service you want to connect to, or search for the service by name in the search box. You can see a list of tools available for the service connector.\nSelect the tool you want to add. The\nAdd tool\npane opens.\nIf the connection doesn't already exist, select\nCreate new connection\n. The details of setting up the connection depend on the connector you selected.\nSelect\nSubmit\nor\nCreate\nas applicable when you're done.\nSelect\nAdd and configure\n. The configuration page for the new tool opens, showing the new tool and its details.\nBy default, the connection is configured to use user credentials. For more information about the supported authentication modes, see\nConfigure user authentication for tools\n. To change this behavior, see the following section.\nAdd multiple tools from a prebuilt connector as a tool group\nSome connectors let you add multiple related tools at once to an agent as a\ntool group\n.\nBenefits of using tool groups\nTool groups let you quickly equip your agents with multiple related tools at once, streamlining configuration and improving efficiency. Instead of adding and configuring individual tools manually, you can add entire groups and apply shared configurations across them.\nThere are several benefits to using tool groups:\nFaster Setup: Add multiple tools in one step instead of configuring each individually.\nConsistency: Shared inputs are applied across all tools in the group.\nFlexibility: Inputs can be dynamically filled by AI or customized manually.\nConnectors that support tool groups\nCurrently, two connectors let you add multiple related tools at once as a\ntool group\n:\nOffice 365 Outlook connector\nSharePoint connector\nOffice 365 Outlook tool groups\nGroup\nTools in group\nManage emails\nSend an email\nGet emails\nDraft an email message\nSend a Draft message\nManage calendar\nGet calendar view of events\nCreate event\nFind meeting times\nGet calendars\nManage contacts\nCreate contact\nGet contact\nUpdate contact\nSharePoint tool groups\nGroup\nTools in group\nManage files and folders\nCreate file\nGet file content\nList folder\nGet files (properties only)\nManage lists and items\nGet items\nCreate item\nGet item\nUpdate item\nManage sites and permissions\nGet lists\nGet files (properties only)\nGet file content using path\nGet file properties\nSteps to add a tool group\nSelect\nAgents\nand select the agent you want to add a connector to.\nGo to the\nTools\npage of your agent and select\nAdd a tool\n.\nSelect a connector that supports tool groups.\nSelect the service you want to connect to, or search for the service by name in the search box. You can see a list of tools available for the service connector, presented in two sections:\nAdd multiple tools\nAdd a single tool\nUnder\nAdd multiple tools\n, select the tool group to add.\nIf the connection doesn't already exist, select\nCreate new connection\nand set up the connection.\nBy default, the connection is configured to use user credentials. For more information about the supported authentication modes, see\nConfigure user authentication for tools\n. To change this behavior, see the following section.\nSelect\nAdd and configure\n.\nConfigure inputs for the tool group. You can leave an input set as\nDynamically fill with AI\nif you would like AI to fill those inputs at run time.\nTo add all tools in the selected group to the tools list for your agent, select\nCreate\n.\nAdd a tool from a prebuilt connector in a topic\nSelect\nAgents\nand select the agent you want to add a connector to.\nGo to the\nTopics\npage and select the topic you want to add a connector to.\nSelect\nAdd node\n(\n+\n) on the authoring canvas.\nIn the node selection window, select\nAdd a tool\n>\nConnector\n, and search for the connector tool you want to add.\nSet up connection details as needed for the connector.\nSelect\nSubmit\n.\nBy default, the connection is configured to use user credentials. For more information about the supported authentication modes, see\nConfigure user authentication for tools\n. To change this behavior, see the following section.\nCreate a custom connector to add to an agent\nSelect\nAgents\nand select the agent you want to add a connector to.\nGo to the\nTools\npage and select\nAdd a tool\n.\nSelect\nNew tool\n>\nCustom connector\n. You're taken to the Power Apps portal under the\nCustom connectors\nsection.\nSelect\nNew custom connector\nand select the method you want to use to create the connector.\nUse connectors with maker-provided credentials\nConnectors require a valid set of credentials. By default, connectors are configured to ask users (users of your agent) to provide their credentials for the associated service, when the tool is invoked. To have your agent use the maker's credentials, perform the following steps:\nConfigure your agent to use an\nauthenticated channel\n.\nAdd a connector tool to your agent, and configure it.\nGo to the connector tool\nOverview\npage.\nUnder\nDetails\n>\nAdditional details\n>\nCredentials to use\n, select\nMaker-provided credentials\n.\nPublish and test the experience in the\nTest your agent\npane, or in the desired channel.\nShare connection\nTo share your connection with others:\nGo to\nmake.powerapps.com\n.\nSelect\nConnections\nin the left navigation bar.\nSelect the connection and select\nShare\n.\nIn the\nShare\ndialog, search for the desired user and select the user.\nUnder\nPermission\n, next to the user, select\nCan use + share\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Connectors",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/knowledge-copilot-studio": {
      "content_hash": "sha256:d999ee23574973f40fbbdc24e0a4b00f48b5c1702f479142c30b739ee74bc2ef",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nKnowledge sources summary\nFeedback\nSummarize this article for me\nIn Copilot Studio, knowledge sources work together with generative answers. When knowledge sources are added, agents can use enterprise data from Power Platform, Dynamics 365 data, websites, and external systems. Knowledge sources allow your agents to provide relevant information and insights for your customers.\nPublished agents that contain knowledge use the configured knowledge sources to ground the published agent. Knowledge can be incorporated at the agent level, in the\nKnowledge\npage, or at the topic level, with a\ngenerative answers node\nin an agent topic.\nKnowledge sources can be incorporated into agents during their initial creation, added after the agent is created, or added to a generative answers topic node.\nAdd and manage knowledge for generative answers\nGenerative answers allow your agent to find and present information from multiple sources, internal or external, without having to create specific topics. Generative answers can be used as primary information sources or as a fallback source when authored topics can't answer a user's query. As a result, you can quickly create and deploy a functional agent. Makers don't need to manually author multiple topics, which might not address all customer questions.\nBy default, when you create an agent, Copilot Studio automatically creates the\nConversational boosting\nsystem topic. This topic contains a generative answers node, which allows you to begin utilizing knowledge sources immediately. All knowledge sources that are added at the agent level are added to generative answers node in the\nConversational boosting\nsystem topic.\nFor prerequisites and information on limitations, see\nGenerative answers\n.\nFor information on analytic metrics on a per knowledge source basis, see:\nGenerated answer rate and quality\nfor conversational agents.\nKnowledge source use\nfor autonomous agents.\nDrill down on a theme\nfor knowledge source metrics in the context of themes.\nSupported knowledge sources\nName\nSource\nDescription\nNumber of inputs supported in generative answers\nAuthentication\nPublic website\nExternal\nSearches the query input on Bing, only returns results from provided websites\nGenerative mode: 25 websites\nClassic mode: Four public URLs (for example,\nmicrosoft.com\n)\nNone\nDocuments\nInternal\nSearches documents uploaded to Dataverse, returns results from the document contents\nGenerative mode: All documents\nClassic mode: Limited by the Dataverse file storage allocation\nNone\nSharePoint\nInternal\nConnects to a SharePoint URL, uses GraphSearch to return results\nGenerative mode: 25 URLs\nClassic mode: Four URLs per generative answers topic node\nAgent user's Microsoft Entra ID authentication\nDataverse\nInternal\nConnects to the configured Dataverse environment and uses a retrieval-augmented generative technique in Dataverse to return results\nGenerative mode: Unlimited\nClassic mode: Two Dataverse knowledge sources (and up to 15 tables per knowledge source)\nAgent user's Microsoft Entra ID authentication\nEnterprise data using connectors\nInternal\nConnects to connectors where your organization data is indexed by Microsoft Search\nGenerative mode: Unlimited\nClassic mode: Two per custom agent\nAgent user's Microsoft Entra ID authentication\nNote\nAgent user authentication for knowledge sources means that when a specific user asks a question of the agent, the agent only surfaces content that the specific user can access.\nKnowledge sources in generative answers nodes currently don't support Bing Custom Search, Azure OpenAI, or Custom Data. Instead, from the generative answers node properties, use the\nClassic data\noption for\nBing Custom Search\n,\nAzure OpenAI\n, or\nCustom Data\nsources.\nFor websites, you need to confirm which website(s) your organization owns that Bing will search through Copilot Studio.\nYou can perform language-agnostic querying across all supported file types and languages.\nIf you're using unstructured data, such as individual SharePoint files and folders, OneDrive files and folders, or connectors, there are different limits and limations. For more information, go to\nLimits and limitations\n.\nCurrently, citations returned from a knowledge source can't be used as inputs to other tools or actions.\nKnowledge search in classic and generative modes\nHow knowledge sources are searched depends on which\norchestration mode\nthe agent uses:\nclassic\nor\ngenerative\n.\nClassic orchestration\nWhen an agent is configured to use classic orchestration, the following applies:\nIn the\nConversational boosting\nsystem topic, the number of knowledge sources the agent can search is limited, and depends on the type of knowledge source. Your agent can search any combination of knowledge sources, up to the maximum number indicated for each type in the following table:\nType of knowledge source\nLimit\nAzure OpenAI Service connection\n5\nBing Custom Search Custom Configuration IDs\n2\nCustom data sources\n3\nDataverse knowledge sources\n2 sources with up to 15 tables each\nSharePoint URLs\n4\nUploaded files\nUnlimited\nWebsite URLs\n4\nYou can also embed a\ngenerative answers node\nin a topic, so that a search is performed for specific intents, and not only as a fallback. The preceding knowledge source limits apply.\nClassic orchestration supports\ncustom data sources\n, in addition to the other knowledge sources.\nGenerative orchestration\nWhen an agent is configured to use generative orchestration, the following applies:\nIf there are more than 25 different knowledge sources, the agent filters the knowledge sources using an internal GPT based on the description given to the knowledge source. More information:\nAuthoring descriptions\nNote\nFiles uploaded\nto the agent aren't part of the 25 knowledge source search limit.\nGenerative orchestration doesn't support\ncustom data\nor\nBing Custom Search\nas knowledge sources. To use those knowledge sources, you must embed them inside a\ngenerative answers node\nin a topic.\nEnable Web Search for your agent\nThe\nWeb Search\nsetting on the\nGenerative AI\nsettings page lets your agent access broad, real-time, and up-to-date information beyond what is available in predefined or enterprise-specific knowledge bases. This setting requires that the agent has generative orchestration turned on.\nWhen turned on,\nWeb Search\ntriggers when a user's question might benefit from information on the web. It searches all public websites indexed by Bing. This type of search happens in parallel with any searches of public websites you added as knowledge sources. Results from\nWeb Search\nare interleaved with results from your configured public website knowledge sources.\nNote\nWeb Search\nuses\nGrounding with Bing Search\nto return information from the web.\nAllow the agent to use general knowledge\nThe\nUse general knowledge\nsetting on the\nGenerative AI\nsettings page configures your agent to use\ngenerative AI\n. This setting requires that the agent has generative orchestration turned on.\nGenerative AI includes general knowledge, which refers to the foundational knowledge that the generative AI is trained on. When this setting is turned on, it allows your agent to use this general knowledge in its answers. This general knowledge setting means that the agent answers questions unrelated to the domain of your agent. If you prefer that your agent is grounded with your specific knowledge sources only, turn off this setting.\nTenant graph grounding with semantic search\nThe\nTenant graph grounding with semantic search\nsetting on the\nGenerative AI\nsettings page determines whether your agent uses\nsemantic search\nto improve search results. This setting requires that the agent has generative orchestration turned on.\nThis feature requires the agent to share a tenant with a Microsoft 365 Copilot license. It also requires that a semantic index is configured for use. To use a semantic index, the Microsoft 365 Copilot license must be assigned to at least one user in the enterprise.\nImportant\nThe\nTenant graph grounding with semantic search\nfeature requires that the agent's\nuser authentication\nis set to\nAuthenticate with Microsoft\n.\nWhen the feature is turned on and the maker has a Microsoft 365 license in the same tenant, the agent supports SharePoint and connectors containing files up to 200 MB. The feature is turned on by default.\nNote\nFor agents grounded in SharePoint knowledge sources, turning on\nTenant graph grounding with semantic search\nprovides significantly better knowledge retrieval and response quality. This feature uses cutting-edge internal retrieval tools that allow the agent to obtain a greater volume of context, with greater precision. However, due to the increased system complexity, certain users and queries might experience a small increase in latency.\nIf you don't have a Microsoft 365 Copilot license in the same tenant as your agent, or you experience lower response quality, turn off the feature.\nThe agent maker doesn't need to have a Microsoft 365 Copilot license to create an agent with a semantic index.\nSharePoint and Microsoft Copilot connectors support files up to 512 MB if they have PDF, PPTX, or DOCX extensions. For more information on supported file types, see\nSupported content types\n.\nThe\nTenant graph grounding with semantic search\nfeature is a separate feature from the\nDataverse search\nfeature. For more information about how Dataverse search works, see\nFrequently asked questions about Dataverse search\n.\nSource authentication\nIf you're using SharePoint, Dataverse, or enterprise data using Microsoft Copilot connectors, you need to incorporate authentication. For more information, see\nConfigure user authentication in Copilot Studio\n, and for individual generative answers nodes, see\nAuthentication\n.\nIn addition, you might need to account for\nURL considerations\nthat require extra authentication for your sources.\nContent moderation\nThe content moderation settings allow your agent to provide more answers. However, the increase in answers might affect the allowance of\nharmful content\nfrom the agent.\nThe following areas allow you to configure the content moderation settings:\nThe setting in the\nGenerative AI\nsettings page sets the moderation at the agent level.\nThe setting in the generative answers node sets the moderation at the topic level.\nThe setting in the prompt tool sets the moderation at the prompt level.\nAt runtime, the setting at the topic level takes precedence. If content moderation isn't set at the topic level, it defaults to the\nGenerative AI\nsettings configuration.\nTo override agent or topic content moderation for prompt tools, configure the\nCompletion\nsetting of the prompt tool to\nsend a specific response\n.\nTo adjust the\ncontent moderation settings at the agent level\n, change your agent's\nGenerative AI\noption to\nGenerative\n.\nSelect the desired moderation level for your agent.\nThe moderation levels range from\nLowest\nto\nHighest\n. The lowest level generates the most answers, but they might contain harmful content. The highest level of content moderation generates fewer answers, and applies a stricter filter to restrict harmful content. The default moderation level is\nHigh\n.\nSelect\nSave\n.\nTo adjust the\ncontent moderation settings at the topic level\n, change the setting in your generative answers node.\nTo adjust the\ncontent moderation settings for the prompt tool\n, change the setting in the prompt builder.\nOfficial sources\nWhen adding knowledge sources to your agent, you might not always control how the information evolves over time, or you might not fully trust this information. It's important to let your users know that they should consider answers with caution, and they should verify them when appropriate.\nHowever, when you know that information from a specific knowledge source goes through a strict verification process and is highly trusted, you can mark this knowledge source as an official source that can be used directly, without verification.\nTo mark a knowledge source as official, on the\nKnowledge\npage, select the three dots (\nâ®\n) for the knowledge source, point to\nOfficial source\nand select\nYes\n.\nNote\nThis feature isn't yet compatible with\ngenerative orchestration\n. If you want your agent to use official knowledge sources and mark them as such, turn off generative orchestration.\nWhen an agent uses authoritative knowledge sources, the response starts with a distinctive indication.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Knowledge Sources",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/nlu-gpt-overview": {
      "content_hash": "sha256:75acbd1228b7600aef93df31d344e1c9b6177a6f5467b9b510b397e8fc307331",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAI-based agent authoring overview\nFeedback\nSummarize this article for me\nCopilot Studio offers generative AI features to reduce manual authoring and dramatically expand the scope of an agent's knowledge and its ability to interact with users.\nGenerative AI is an artificial intelligence technology that uses language models to generate original content and provide natural language understanding and responses. Learn more about\nGenerative AI\nin the Artificial Intelligence (AI) playbook.\nIn Copilot Studio, you can use the following generative AI features to retrieve and create content, either individually or all together.\nCreate an agent\n. With no manual authoring of topics required, an\nempty\nagent can generate answers based on knowledge sources you specify such as websites and files. See\nGenerative answers\nand the\nQuickstart\n.\nHarness AI general knowledge\n. When this option is enabled, the agent can answer general questions unrelated to your specific knowledge sources or topics. See\nAI general knowledge\n.\nAuthor topics using natural language\n. Describe what you want your topic to do, and Copilot Studio creates it for you. Your agent includes conversational responses and multiple types of nodes. Use the suggested default topic or as a starting point for further development. See\nCreate and edit topics with Copilot\n.\nAuthor prompts using natural language\n. Describe the prompt you want to create, and Copilot Studio generates it for you. You can use the suggested default prompt or as a starting point for further development. See\nCreate and edit prompts with Copilot\n.\nCreate agent flows using natural language\n. Describe the overall flow you want your agent to follow, and Copilot Studio generates it for you. You can use the suggested default flow or as a starting point for further development. See\nBuild an agent flow with natural language\n.\nTurn on generative orchestration\n. Let the agent select the most appropriate topics, tools, agents, and knowledge sources at runtime. See\nOrchestrate agent behavior with generative AI\n.\nUsing generative AI in Copilot Studio transforms how you build agents, significantly reducing manual work and configuration.\nGenerative answers\nGenerative answers in Copilot Studio let your agent find and present information from multiple sources, internal or external, without created topics. Generative answers can be used as primary information sources or as a fallback source when authored topics can't answer a user's query. As a result, you can quickly create and deploy a functional agent. You don't need to manually author multiple topics that might not address all customer questions.\nWhat changed?\nIn traditional chatbots, when an agent can't determine a user's intent, it asks the user to rephrase their question. If after two prompts, the agent still can't determine the user's intent, the agent escalates to a live agent, using the\nEscalate\nsystem topic.\nWith generative answers, before escalating to a live agent, the agent uses natural language processing (NLP) to:\nParse what a user types to determine what they're asking.\nFind, collate, and parse relevant information from a specified source. This source can be your company's website, or from multiple sources, including Sharepoint.\nSummarize search results into plain language delivered to the agent user.\nYour workflow might look like this:\nYou create an agent and enable the\nGenerative\noption in the\nGenerative AI\npage of Settings. You test the agent thoroughly.\nAfter testing, you publish your agent to instantly provide answers, help, and guidance to your agent users.\nYou create individual topics for frequently asked questions. These topics might develop from\nanalytics from previous agents\nor existing support issues.\nAI general knowledge\nIn addition to generative answers, you can use AI general knowledge to allow your agent to find and present information in response to your customer's questions. General knowledge saves you from needing to manually author multiple topics, which might not address all your customer's questions. It can also help when a user's intent can't be addressed by existing agent topics.\nWhat is AI general knowledge?\nAI general knowledge applies the capabilities of AI to access and provides information, insights, and assistance across a wide range of topics.\nWhy use it?\nAccessibility\n: The agent can instantly access a vast repository of information and expertise across a wide range of subjects.\nVersatility\n: It's capable of addressing diverse topics and tasks, making it a versatile resource for various needs.\nNote\nWhile AI general knowledge can provide valuable information and assistance, you need to critically evaluate the information it provides and consider consulting other sources for verification or further clarification when necessary.\nPrerequisites\nAn account for Copilot Studio. If you don't have an account, follow the instruction in\nSign up for a Copilot Studio trial\n.\nThe current version of Copilot Studio. The agent type must not be Classic. Classic agents have (classic) added to their name, for example \"Contoso store hours (classic).\"\nReview AI response generation training, model, and usage in the\nFAQ for generative answers\nand\nLearn more about Azure OpenAI\n.\nWhat's supported?\nAI-based authoring might be subject to usage limits or capacity throttling.\nQuotas\nQuotas are default constraints applied to agents that limit how often messages can be sent to an agent. The purpose of quotas is to throttle the client's service load, which protects a service from being overloaded and the client from unexpected resource usage.\nAgents with generative answers enabled have a limit on the number of queries they can make derive answers from the URL you specified. Normal conversations that use agent topics follow the\nusual quotas and limitations\n.\nLanguages\nSee\nLanguage support\nfor the list of supported languages.\nRelated content\nGet up and running with\nQuickstart: Create and deploy an agent\n.\nAdd\nknowledge sources\nto your agent.\nHave a conversation to\nauthor topics using natural language\n.\nUse\ngenerative orchestration\nto call your actions automatically at runtime.\nBuild an agent flow with natural language\n.\nCreate prompts with Copilot\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Generative AI",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/advanced-plugin-actions": {
      "content_hash": "sha256:01cefbccd7a68b48db2d925bde81d155d623396e82476d197b8c58b0daa0235d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAdd tools to custom agents\nFeedback\nSummarize this article for me\nTools are the building blocks that enable your agent to interact with external systems. Tools expand the functionality of your agent, allowing it to perform various actions in response to user requests or autonomous triggers. Each tool represents a specific capability that your agent can perform. For example, you can equip your agent with tools that do things like:\nSend emails using the Office 365 Outlook connector\nCheck the current weather conditions and forecasts\nRead and write data from Dataverse\nRead and post messages to Teams\nMechanisms for adding tools\nYou can extend the capabilities of your custom agent by adding one or more\ntools\n. Your agent can use tools to respond to users automatically, using\ngenerative orchestration\n. You can also call tools explicitly from within a topic.\nWith\ngenerative orchestration\n(active by default), your agent can automatically select the most appropriate tool or topic, or search across knowledge, to respond to a user. This orchestration mode creates a more dynamic and intelligent conversation experience.\nIn classic mode (generative orchestration turned off), an agent can only use topics to respond to the user. However, you can still design your agent to call tools explicitly from within topics.\nThere are several mechanisms available to you to add tools to your agent:\nConnector\n: Connect to proprietary APIs and services using Power Platform Connectors to pull in data or carry out actions.\nPrebuilt connector: Choose from a selection of preset connections to thousands of popular APIs from both Microsoft and non-Microsoft services.\nCustom connector: Define a connection to a custom service or system to enable custom tool options using Power Platform Connectors. The connector needs view and share permissions for the organization for the agent to use the connector.\nAgent flow\n: Define an agent flow, including one or more actions to carry out.\nPrompt\n: Single turn model-based prompt that can reference knowledge you provide and generate code to analyze data.\nREST API\n: Define a connection to a REST API, and select one or more API endpoints and methods to add as tools.\nModel Context Protocol\n: Connect to an MCP server to access tools and resources.\nComputer use\n: Lets your agent interact with any system that has a graphical user interface, for websites and desktop apps, selecting buttons, choosing menus, and entering text into fields on the screen.\nThere are two other mechanisms you can use to add tool-like behavior to your agent:\nSkills: Container for a set of related tools.\nClient tool: Send an event activity to the client so that the client carries out an action and returns a response.\nFor more information on skills and client tools, see the links in the\nRelated content\nsection.\nCreate and add a new tool at agent level\nCreating new tools directly within Copilot Studio streamlines the development process and ensures proper integration with your agent. Tools added to an agent are available for automatic orchestration throughout your agent's conversations.\nOpen your agent by choosing\nAgents\nin the left hand navigation pane and selecting your agent from the list.\nGo to the\nTools\npage for the agent.\nSelect\nAdd a tool\n.\nIn the\nAdd tool\npane, select\nNew tool\n.\nSelect the type of tool you want to add from the list that appears:\nPrompt\nAgent flow\nComputer use\nCustom connector\nModel Context Protocol\nREST API\nPerform the configuration steps specific to the type of tool you selected. For example, if you select\nPrompt\n, you must perform the following steps:\nDefine the prompt template and instructions\nSpecify input parameters\nConfigure knowledge sources\nSet response format and constraints\nSelect\nSave\nor\nPublish\n, as applicable, to create the new tool.\nSelect\nAdd and configure\n. The tool is added to your agent. The configuration page for your tool appears. You can\nview and make changes to your tool configuration\nhere.\nYou can see the new tool on the\nTools\npage for the agent.\nView and make changes to your tool configuration\nYou can view and edit the configuration of your tool at any time: go to the\nTools\npage for your agent, and select the tool from the list of tools.\nThe configuration page for your tool opens. The details are displayed in three sections:\nDetails\nInputs\nCompletion\nFor MCP servers connected as agent tools, the configuration page is different from other tool types. The\nDetails\nsection is similar, but instead of\nInputs\nand\nCompletion\n, there are\nTools\nand\nResources\nsections with information about available tools and resources for the MCP server. For more information, see\nView tools and resources in an existing MCP server\n.\nDetails\nThe\nDetails\nsection lets you configure basic details about your tool.\nHere, you can view and update:\nName\n: The name of the tool. This name appears in the list of tools for your agent. Choose a name that clearly indicates the tool's function.\nDescription\n: A description of the tool. Generative orchestration relies on this description to determine when your agent should use the tool. Write clear, specific descriptions including what the tool does and when it should be used.\nAdditional details\n:\nAllow agent to decide dynamically when to use the tool\n: When this option is selected, the agent can use generative orchestration to determine when to use the tool. If this option isn't selected, the agent only uses the tool when it's explicitly called from a topic. (By default, this option is selected when generative orchestration is enabled.)\nAsk the end user before running\n: In the end user chat experience, ask the agent for confirmation before running the tool. This option is set to\nNo\nby default.\nAuthentication\n: Select whether to use the user's (\nEnd user\n) or maker's (\nMaker-provided\n) credentials for the tool. By default, user authentication applies.\nDescription\n: Optionally, you can add a description of the tool the agent shows to the user when it wants to run the tool. This description lets the user know what they're being asked to authenticate.\nInputs\nHere, you can view and configure the inputs for your tool. The inputs are used to gather information from the user to fill the required inputs for the tool. The information is displayed as a table, one line for each input.\nBy default, the\nFill using\ncolumn value for each input is set to\nDynamically fill with AI\n. The agent tries to extract the value from available contextâfor example, from the user's message. If no appropriate value is found, it generates a question to ask the user for a value. Select\nCustomize\nto access more fine-grained customizations for input collection and filling:\nDisplay name and Description\n: How the input appears to the user.\nIdentify as\n: How the user's response is interpreted, for example as string of text or mapped to a predefined entity.\nRetry logic\n: If the agent doesn't identify an entity in the user's statement, it can ask the question again.\nInput validation\n: Configure extra validation behavior on the user's input beyond the default for the entity type.\nYou can also choose to override an input with an explicit value instead of letting the agent extract it. To set an override, set\nFill using\nto\nCustom value\n, and enter a value, select a variable, or use a Power Fx formula. If an input is overridden, the agent doesn't ask the user for a value.\nCompletion\nHere, you can select what you want to happen when the tool is done running.\nYou can have the agent automatically generate a contextual response for a user, based on their query and the result of the tool.\nAlternatively, you can choose to author a specific, formatted response for your tool to return. You can insert references to output variables from the tool using the variable picker. You can also use Power Fx formulas to format the response.\nUnder\nAfter running\n, select one of a few different options for how the tool should respond to the user after the tool runs:\nDon't respond (default)\n: The agent incorporates the tool output into its response\nWrite the response with generative AI\n: Let AI craft a contextual response using the tool outputs\nSend specific response\n: Author a templated response with variable insertion\nSend an adaptive card\n: Create rich, interactive responses with buttons and actions\nYou can also configure which output variables to make available to the agent and other tools.\nTool selection and input collection\nWhen you define a tool in Copilot Studio, you also provide information that describes its purpose. This information lets the agent identify when to use the tool. The tool description also helps the orchestrator use generative AI to generate questions, as needed, to collect inputs. Your agent can use questions to gather information to fill the inputs needed to use the tool. As a result, you don't need to manually author question nodes to gather all inputs needed, such as inputs in a flow. The agent orchestrator handles input collection for you at runtime.\nThe agent considers several factors to determine tool selection:\nThe tool's name and description\nThe current conversation context\nUser intent derived from their message\nAvailable inputs and outputs\nPrevious tool usage in the conversation\nWen using generative mode, by default, tools return their information back to the agent. With the tool response, the agent can generate a contextual response to the user's query. Alternatively, you can instruct your tool to always respond immediately, either generating a message or authoring an explicit message.\nTip\nWhen using generated questions from a tool, inform your users that AI generated some of the conversation.\nFor example, add an extra message in the\nConversation Start\nsystem topic. This topic determines the message shown to your users when a new conversation starts.\nCall an existing tool from within a topic\nYou can call a tool explicitly from within a topic. Depending on your use case, you might use your tool as part of a wider topic, which uses more nodes. Or, like in the weather example, adding a node to a topic might be all you need.\nTo call a tool from within a topic:\nIn Copilot Studio, go to the\nTopics\npage for the agent you want to edit.\nCreate a new topic, and give it a name, for example,\nGet weather\n.\nAdd appropriate\nTrigger phrases\n. To continue with the same weather example from the previous step, trigger phrases could include:\nwill it rain\ntoday's forecast\nget weather\nwhat's the weather\nSelect\nAdd node\n(\n+\n) and then select\nAdd a tool\n. Select the tool from the available tools. There are three tabs showing different types of tools:\nBasic tools\nConnector\nTool\nYour\nAction\nnode is now added to your topic.\nSelect\nSave\n.\nMCP connector information\nFor MCP connector, you can view the names and descriptions of the MCP tools and resources that are made available by the MCP connector. Information for the tools and resources is displayed in a table, one line for each tool.\nAuthentication considerations for tools\nSome tools require authentication to work correctly, such as Dynamic Prompt or others that call a Dataverse API. Proper authentication configuration ensures security while maintaining a smooth user experience.\nTools are always run in the agent's runtime in the user context and can't be run unless authentication is enabled. Two types of authentication methods are supported:\nEnd user credentals\n: The agent uses the user's credentials to authenticate with the service. This method ensures users only access data they're authorized to see.\nMaker-provided credentials\n: The agent uses the credentials of its author to authenticate with the service. Use this authentication mode for shared resources or when users shouldn't need individual access.\nTest your tool\nWith\ngenerative orchestration\n, the orchestrator selects your tool when it deems it relevant to a user query.\nAlternatively, you can\ncall an existing tool from within a topic\n.\nTurn a tool on or off in your agent\nYou can turn a tool on or off for your agent from the tool configuration page. Turning off a tool blocks the agent from using the tool, but the tool is still connected to the agent and can be turned back on later. When you add a tool to an agent, it's turned on by default.\nTo turn off a tool in an agent:\nGo to your agent and select the\nTools\npage for your agent.\nSelect the tool to go the tool configuration page.\nAt the top of the configuration page, turn off the tool using the\nEnabled\ntoggle.\nSelect\nSave\nto apply the change.\nThe tool still appears on the agent tools list, but is no longer turned on.\nDelete a tool from your agent\nTurning off a tool blocks the tool from use, but also gives you the flexibility to turn it back on later. You can also remove a tool more permanently from your agent. To delete a tool from your agent:\nGo to your agent and select the\nTools\npage for your agent.\nFind the tool on the list of tools and hover over the tool name. Select the three dots (\nâ¦\n).\nSelect\nDelete\n. A confirmation window appears.\nSelect\nDelete\nto remove the tool.\nThe tool disappears from the agent tools list.\nNote\nYou can only delete tools from the agent tools page. You canât delete tools from the main Copilot Studio\nTools\npage.\nRelated content\nUse connectors\nUse prompts\nUse agent flows with your agent\nModel context protocol (MCP)\nAdd tools from a REST API\nUse skills\nClient tools\nComputer use (preview)\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent Orchestration",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/external-security-provider": {
      "content_hash": "sha256:2773ebb3e7d2cb03e4223e94bbf76769571b44145b6220b5a06fffcae82a8dda",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEnable external threat detection and protection for Copilot Studio custom agents (preview)\nFeedback\nSummarize this article for me\n[This article is prerelease documentation and is subject to change.]\nCustom agents created in Copilot Studio are secure by default. They include built-in protection against various threats, such as user prompt-injection attacks (UPIA) and cross-domain prompt injection Attacks (XPIA). At runtime, the agent blocks attacks of these types, reducing the risk of data exfiltration.\nTo further increase the monitoring capabilities and security of custom agents, Copilot Studio lets organizations configure\nexternal threat detection systems\nfor enhanced oversight. These tools operate during the agent's runtime, continuously evaluating agent activity. If the system detects any suspicious tools or actions, it can intervene to block them from executing. This threat detection provides an extra layer of real-time protection and compliance enforcement.\nImportant\nExternal threat detection is only called on generative agents that use generative orchestration. External threat detection is skipped for classic agents.\nHow it works\nAn external threat detection system is set up as a web service, exposing a REST API with a threat detection endpoint. A secure connection is configured between the agent and the endpoint. At runtime, every time the orchestrator considers invoking a tool, it sends relevant data about the proposed tool use to the threat detection endpoint for evaluation. The threat detection system analyzes the data and returns a decision to either allow or block the tool invocation.\nIf the threat detection system detects a security issue during an agent's operation, the agent immediately stops processing, and notifies the user that their message is blocked. On the other hand, if the system approves the operation, the agent proceeds seamlessly, with no visible effect or interruption for the user.\nImportant\nThis article contains Microsoft Copilot Studio preview documentation and is subject to change.\nPreview features aren't meant for production use and may have restricted functionality. These features are available before an official release so that you can get early access and\nprovide feedback\n.\nIf you're building a production-ready agent, see\nMicrosoft Copilot Studio Overview\n.\nOptions for setting up external threat detection\nCopilot Studio supports a flexible \"bring your own protection\" approach. Organizations have the freedom to integrate security solutions that best fit their unique requirements.\nOptions include:\nDevelop your own custom monitoring tools, or have someone develop them for you. For more information on how to set up the system endpoint so that your agent can connect to it, see\nBuild a runtime threat detection system for Copilot Studio agents\nApply a robust enterprise solution by\nMicrosoft Defender\nUse products from other trusted security providers\nWhat data is shared with the threat detection provider?\nOnce you configure a connection to a threat detection system, the agent shares data with the external security provider during its run. The agent communicates with the service whenever it considers invoking a tool. This data sharing ensures efficient decision-making by the configured system, without degrading the experience of your agent's users.\nThe high-level data shared with the system includes:\nThe user's recent prompt and the latest history of chat messages exchanged between the agent and the user.\nOutputs of previous tools used by the agent.\nConversation metadata: Identity of the agent, the user who interacts with it, the user's tenant, and the trigger that triggered it (where applicable).\nThe tool the agent wants to invoke, including agent-generated reasoning of why this tool was selected and the proposed inputs and values.\nImportant\nThe provider data-handling policies might be different from the policies used by Microsoft. The differences could include processing and storing your data outside your geographic region.\nYou must ensure that the provider and terms meet the standards and comply with the regulations required to protect your organization's data.\nIf you want to block sharing data with the threat detection service, you can disconnect the integration at any time.\nPrerequisites\nBefore you begin, you need:\nAn external threat detection service set up to evaluate agent tool use requests. The service needs to expose a REST API endpoint. For the setup on the Copilot Studio side of the integration, you need the\nbase URL\nfor the security provider web service. This article refers to this URL as the\nendpoint\n. The agent sends requests for threat detection to APIs at this base URL. You should receive this URL from your security provider.\nA Microsoft Entra tenant where you can register an application for authentication between the agent and the threat detection service.\nA user with a Power Platform Administrator role to configure a connection between the agent and the external threat detection system for both the individual environment level, and the environment group level.\nConfigure an external threat detection system\nThe process to configure an external threat detection system for your agent has two steps:\nConfigure a Microsoft Entra application.\nConfigure threat detection in Power Platform admin center.\nStep 1: Configure a Microsoft Entra application\nThere are two paths you can take to configure a Microsoft Entra application:\nOption A: Configure using PowerShell script (recommended)\nOption B: Configure manually using Azure portal\nOption A: Configure using PowerShell (Recommended)\nYou can use a provided PowerShell script to automate the creation and configuration of your Microsoft Entra application.\nPrerequisites for PowerShell Configuration\nWindows PowerShell 5.1 or later\nSufficient permissions to create application registrations in your Microsoft Entra tenant\nThe base URL of the threat detection web service. The URL is referred to as the\nEndpoint\nin the script parameters that follow. You should receive this URL from your security provider.\nYour organization's Microsoft Entra tenant ID. The tenant ID is referred to as the\nTenantId\nin the script parameters that follow.\nDownload and prepare the script\nDownload the\nCreate-CopilotWebhookApp.ps1\nscript.\nScript parameters\nThe script accepts the following parameters:\nParameter\nType\nRequired\nDescription\nTenantId\nString\nYes\nYour Microsoft Entra tenant ID in GUID format (for example,\n12345678-1234-1234-1234-123456789012\n).\nEndpoint\nString\nYes\nThe base URL for the external threat detection service (provided by your security provider). If you're using Microsoft Defender as your security provider, you can get the endpoint from the\nDefender portal\n.\nDisplayName\nString\nYes\nA unique display name you provide for the application registration. Can be between 1 and 120 characters.\nFICName\nString\nYes\nA unique name you provide for the Federated Identity Credential. Can be between 1 and 120 characters.\nDryRun\nSwitch\nNo\nOptional flag. When the\n-DryRun\nflag is provided, the script performs a validation run without creating resources.\nExecute the script\nTo create the application:\nOpen Windows PowerShell as an administrator.\nGo to the directory containing the script.\nExecute the following script, replacing the placeholder values for\nTenantId\n,\nEndpoint\n,\nDisplayName\n, and\nFICName\nwith your own parameters:\n.\\Create-CopilotWebhookApp.ps1 `\n-TenantId \"11111111-2222-3333-4444-555555555555\" `\n-Endpoint \"https://provider.example.com/threat_detection/copilot\" `\n-DisplayName \"Copilot Security Integration - Production\" `\n-FICName \"ProductionFIC\"\nThe interactive script runs in the command line. The script outputs the App ID of the created Microsoft Entra application. You need the App ID later when configuring threat detection in Power Platform admin center.\nOption B: Configure manually using Azure portal\nPrerequisites for manual configuration\nYour organization's Microsoft Entra tenant ID. The tenant ID is referred to as the\ntenantId\nin the instructions that follow.\nSufficient permissions to create application registrations in your Microsoft Entra tenant.\nThe base URL of the threat detection web service you're using. This is referred to as the\nendpoint\nin the following instructions. You should receive this URL from your security provider.\nRegister a Microsoft Entra application\nFollow these steps to create a Microsoft Entra application registration. The application is used to secure authentication between the agent and the threat detection web service. See\nRegister an application in Microsoft Entra ID\nto learn how to create such an app.\nSign in to Azure portal and navigate to the\nMicrosoft Entra ID\npage.\nUnder\nApp registrations\n, select\nNew registration\n.\nProvide a name and select\nAccounts in this organizational directory only (Single tenant)\nas the supported account type.\nRegister\nthe app.\nAfter the app is created, copy the App ID. You need the App ID later when configuring threat detection in Power Platform admin center.\nAuthorize the Microsoft Entra application with your provider of choice\nThe agent uses Federated Identity Credentials (FIC) as a secure, secret-less authentication method for exchanging data with the threat detection system provider. Follow these steps to configure FIC for your Microsoft Entra application. For more information, see\nConfigure a user-assigned managed identity to trust an external identity provider\n.\nOpen the Azure portal and go to\nApp registrations\n. Select the application you created in step 1 above.\nIn the sidebar, select\nManage\n>\nCertificates & secrets\n>\nFederated credentials\n.\nSelect\nAdd credential\n.\nIn the Federated credentials scenario drop-down, select\nOther issuer\n.\nFill the fields according to these instructions:\nIssuer\n: Enter the following URL, replacing\n{tenantId}\nwith your organization's Microsoft Entra tenant ID:\nhttps://login.microsoftonline.com/{tenantId}/v2.0\nType\n: Select\nExplicit subject identifier\n.\nValue\n: Input a string structured as follows:\n/eid1/c/pub/t/{base 64 encoded tenantId}/a/m1WPnYRZpEaQKq1Cceg--g/{base 64 encoded endpoint}\nPerform base64 encoding for your organization's Microsoft Entra tenant ID and the base URL of the threat detection web service. Replace the placeholder\n{base 64 encoded tenantId}\nwith the base64-encoded value of your tenant ID, and the placeholder\n{base 64 encoded endpoint}\nwith the base64-encoded base URL.\nTo get the base64 encoding of your tenant ID and endpoint URL, use the following PowerShell script. Make sure to replace the placeholder values \"11111111-2222-3333-4444-555555555555\" and \"https://provider.example.com/threat_detection/copilot\" with your actual values for tenant ID and endpoint URL:\n# Encoding tenant ID\n$tenantId = [Guid]::Parse(\"11111111-2222-3333-4444-555555555555\")\n$base64EncodedTenantId = [Convert]::ToBase64String($tenantId.ToByteArray()).Replace('+','-').Replace('/','_').TrimEnd('=')\nWrite-Output $base64EncodedTenantId\n\n# Encoding the endpoint\n$endpointURL = \"https://provider.example.com/threat_detection/copilot\"\n$base64EncodedEndpointURL = [Convert]::ToBase64String([Text.Encoding]::UTF8.GetBytes($endpointURL)).Replace('+','-').Replace('/','_').TrimEnd('=')\nWrite-Output $base64EncodedEndpointURL\nName\n: Choose a descriptive name.\nSelect the\nAdd\nbutton.\nStep 2: Configure the threat detection system\nNext, you need to configure the threat detection system in Power Platform admin center to connect your agent to the external security provider.\nPrerequisites for configuring threat detection in Power Platform admin center\nThe App ID of the Microsoft Entra application you created in the previous step.\nThe endpoint link provided by your external monitoring system's provider. The endpoint link is the same base URL endpoint you use when configuring the Microsoft Entra application.\nA user with a Power Platform Administrator role to configure the connection.\nPerform any other steps required by your security provider to authorize your registered application. You should consult your provider's documentation (as applicable) for any specific onboarding and authorization steps.\nTo configure the threat detection system in Power Platform admin center, follow these steps:\nSign in to the\nPower Platform admin center\n.\nOn the side navigation, select\nSecurity\nand then select\nThreat detection\n. The\nThreat detection\npage opens.\nSelect\nAdditional threat detection\n. A pane opens.\nSelect the environment for which you want to enhance agent protection and select\nSet up\n. A pane opens.\nSelect\nAllow Copilot Studio to share data with a threat detection provider\n.\nUnder\nAzure Entra App ID\n, enter the App ID of the Microsoft Entra application you created previously.\nEnter the\nEndpoint link\nprovided by your external monitoring system's provider. The endpoint link is the same base URL endpoint you use when configuring the Microsoft Entra application.\nUnder\nSet error behavior\n, define the system's default behavior for when the threat detection system doesn't respond in time or responds with an error. By default, this is set to\nAllow the agent to respond\n, but you can also chose the\nBlock the query\noption to further reduce risk.\nSelect\nSave\n.\nImportant\nThe save will fail if your Microsoft Entra app is not properly configured in Microsoft Entra or not properly authorized with your provider of choice.\nNote\nOnce configured, the threat detection system triggers before any tool invocation by an agent. If the agent doesn't receive a decision from the system (either allow or block) within one second, it proceeds to\nallow\nthe tool to execute as planned.\nTroubleshooting\nHere's some information on issues that might occur and how to handle them.\nPower Platform admin center threat detection configuration issues\nThe following table describes common errors that might happen when you select\nSave\nin the previous step, and how to handle these errors:\nError\nHow to handle\nThere was a problem saving your settings. Try saving again, and if that doesn't work, contact your admin for help.\nA general issue in saving the configuration. Try again. If that doesn't work, contact Copilot Studio for support.\nThere was a problem connecting to the protection provider. Contact the provider for help.\nThis error is displayed when a call to the provided endpoint times out or fails. Contact the provider and verify there are no issues with its service.\nThere was a problem connecting to the protection provider. Try checking the endpoint link. If that doesn't work, contact the protection provider for help.\nThis error is displayed when a call to the provided endpoint fails. Check the provided endpoint link and if that doesn't work, contact the threat detection service provider, and verify there are no issues with its service.\nThere was a problem connecting to the protection provider. Try again, and if that doesn't work, contact the protection provider for help.\nThis error is displayed when a call to the provided endpoint fails. Try again, and if that doesn't work, contact the provider and verify there are no issues with its service.\nThere was a problem with the configuration. Try checking the details you entered and the Microsoft Entra configuration. If the problem persists, contact your admin for help.\nThe token acquisition failed. Check the Microsoft Entra application configuration and the Federated Identity Credentials. More details on the specific issue can be found after selecting \"Copy error info.\"\nTo change a configuration, make sure you have Power Platform admin permissions.\nHave a user with the required permissions\nFor more error details, select\nCopy error info\n.\nCommon Microsoft Entra and authentication issues\nHere are some other common issues that might occur with your Microsoft Entra app and authentication.\nMicrosoft Entra application doesn't exist\nExample\n: Failed to acquire token: AADSTS700016: Application with identifier '55ed00f8-faac-4a22-9183-9b113bc53dd4' wasn't found in the directory 'Contoso'. This can happen if the application isn't installed by the administrator of the tenant or consented to by any user in the tenant. You might have sent your authentication request to the wrong tenant.\nHow to handle\n: Make sure the application ID provided is correct and exists in Azure.\nNo FIC configured on the app\nExample:\nFailed to acquire token: A configuration issue is preventing authenticationâcheck the error message from the server for details. You can modify the configuration in the application registration portal. See\nhttps://aka.ms/msal-net-invalid-client\nfor details. Original exception: AADSTS70025: The client '57342d48-0227-47cd-863b-1f4376224c21'(Webhooks test) has no configured federated identity credentials.\nHow to handle\n: The app provided doesn't have any FIC configured on it. Follow the documentation and configure FIC accordingly.\nInvalid FIC Issuer\nExample:\nFailed to acquire token: A configuration issue is preventing authenticationâcheck the error message from the server for details. You can modify the configuration in the application registration portal. See\nhttps://aka.ms/msal-net-invalid-client\nfor details. Original exception: AADSTS7002111: No matching federated identity record found for presented assertion issuer 'https://login.microsoftonline.com/262d6d26-0e00-40b3-9c2f-31501d4dcbd1/v2.0'. Make sure the federated identity credential Issuer is 'https://login.microsoftonline.com/{tenantId}/v2.0'.\nHow to handle\n: No FIC with the expected issuer was found on the app. Open your FIC configuration and set the issuer to\nhttps://login.microsoftonline.com/{tenantId}/v2.0\n(filling in your tenant ID).\nInvalid FIC Subject\nExample:\nFailed to acquire token: A configuration issue is preventing authenticationâcheck the error message from the server for details. You can modify the configuration in the application registration portal. See\nhttps://aka.ms/msal-net-invalid-client\nfor details. Original exception: AADSTS7002137: No matching federated identity record found for presented assertion subject '/eid1/c/pub/t/Jm0tJgAOs0CcLzFQHU3L0Q/a/iDQPIrayM0GBBVzmyXgucw/aHR0cHM6Ly9jb250b3NvLnByb3ZpZGVyLmNvbeKAiw'. Make sure the federated identity credential Subject is '/eid1/c/pub/t/{tenantId}/a/iDQPIrayM0GBBVzmyXgucw/aHR0cHM6Ly9jb250b3NvLnByb3ZpZGVyLmNvbeKAiw'.\nHow to handle\n: No FIC with the expected subject is found on the app. Open your FIC configuration and set the subject to the expected value as suggested in the error (fill in your tenant ID). Make sure there are no extra whitespaces or blank lines in the subject fields.\nApp isn't allowlisted with provider (Microsoft Defender specific)\nExample:\nThe application ID in your authentication token doesn't match the registered application for webhook access. Ensure you're using the correct application credentials.\nHow to handle\n: Application isn't allowlisted with the provider. Refer to the provider documentation to grant the app webhook access.\nDisconnect the protection by the threat detection system\nIf you no longer want the threat detection system to monitor your agent, follow these steps:\nSign in to the\nPower Platform admin center\n.\nOn the side navigation, select\nSecurity\nand then select\nThreat detection\n. The\nThreat detection\npage opens.\nSelect\nAdditional threat detection\n. A pane opens.\nSelect the environment for which you want to turn off enhanced agent protection and select\nSet up\n. A pane opens.\nUnselect\nAllow Copilot Studio to share data with your selected provider\n.\nSelect\nSave\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "External Threat Detection",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/advanced-hand-off": {
      "content_hash": "sha256:7c6b45705d35e2b2f7bdf8388dc044385c913ded5db578de01ff46fb0f9d211b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nHand off to a live agent\nFeedback\nSummarize this article for me\nWith Copilot Studio, you can configure your agent to hand off conversations to live agents seamlessly and contextually.\nWhen your agent hands off a conversation, it can share the full history of the conversation, and all relevant variables. With this context, a live agent that uses a connected engagement hub can be notified that a conversation requires a live agent, see the context of the prior conversation, and resume the conversation.\nFor more information about how to configure handoff with\nOmnichannel for Customer Service\n, see\nConfigure handoff to Dynamics 365 Customer Service\n.\nNote\nYou can choose to escalate an agent conversation without linking to an engagement hub:\nAt the bottom of the desired topic, select the\nAdd node\nicon\n, point to\nTopic Management\n, and select\nGo to another topic\n.\nSelect\nEscalate\n.\nEscalate\nis a\nsystem topic\nthat, by default, provides a simple message to a user if they ask for a human agent.\nYou can edit the topic to include a simple URL to a support website or ticketing system, or to include instructions for emailing or contacting support.\nPrerequisites\nA agent built with Microsoft Copilot Studio\nAn engagement hub that is being used by live agents, such as\nOmnichannel for Customer Service\n, and you need to configure the connection, as described in\nConfigure handoff to Omnichannel for Customer Service\nConfigure the Escalate system topic\nWhen you create an agent from Dynamics 365 Customer Service, the\nEscalate\nsystem topic already includes a\nTransfer conversation\nnode. However, agents created in Copilot Studio aren't configured with this node by default. To add a\nTransfer conversation\nnode to the\nEscalate\nsystem topic, follow these steps:\nIn the side navigation pane, select\nTopics\n, switch to the\nSystem\ntab, and select the\nEscalate\ntopic.\nAt the bottom of the topic, select the\nAdd node\nicon\n, point to\nTopic Management\n, and select\nTransfer conversation\n.\nTrigger handoff to a live agent\nCustomers engaging with your agent can ask for a live agent at any point in the conversation. This escalation can happen in two ways, with an implicit trigger or an explicit trigger.\nUpon triggering the handoff topic, the agent starts the handoff to the configured engagement hub, and sends over all conversation context to find the next best live agent to ramp them up so they can resume the conversation.\nImplicit triggers\nIn some instances, your agent might be unable to determine the intent of a customer's conversation. For example, the customer might be asking a specific question for which there's no\ntopic\n, or no matching option within a topic.\nIn other instances, the customer might ask to be handed off to a live agent immediately. For example, a customer might type \"talk to agent\" mid-way into a conversation.\nWhen the agent detects an escalation in this manner, it automatically redirects the user to the\nEscalate system topic\n. This type of trigger is known as\nimplicit\ntriggering.\nExplicit triggers\nWhen creating topics for your agent, you may determine that some topics require interaction with a human. This type of trigger is known as\nexplicit\ntriggering.\nIn these instances, you must add a\nTransfer conversation\nnode to the topic. This node lets you add a\nPrivate message to agent\n, which is sent to the connected engagement hub to help the live agent understand the history and context of the conversation.\nNote\nConversations that reach this node are marked as\nEscalated\nsessions in\nreporting analytics\n.\nTo configure explicit triggering for a topic:\nAt the bottom of the topic, select the\nAdd node\nicon\n, then select\nSend a message\nto add a message node. Enter what the agent should say to indicate that transfer to a live agent is about to occur.\nBelow the message node, select the\nAdd node\nicon\n, point to\nTopic Management\n, and select\nTransfer conversation\n.\nEnter an optional private message to the live agent in the\nTransfer conversation\nnode. This optional message can be useful if you have multiple topics with\nTransfer conversation\nnodes as the information is stored in the\nva_AgentMessage\ncontext variable\n.\nThe topic starts the transfer to a live agent when this node is reached. You can test the handoff by triggering the topic in the test canvas.\nNote\nOnce you add a\nTransfer conversation\nnode into a conversation, each time you trigger handoff your users will see a \"No renderer for this activity\" message on the demo website. This message suggests the need to\ncustomize your chat canvas\nto implement custom client-side code that brings in a human agent from your engagement hub into the conversation.\nContext variables available upon handoff\nBeyond providing an automated way for a conversation to be ported into an engagement hub, it's important to ensure that the best agent for a specific problem is engaged. To help route conversations to the most appropriate live agent there are context variables that are also passed to the engagement hub.\nYou can use these variables to automatically determine where the conversation should be routed. For example, you might have added\nTransfer conversation\nnodes to several different topics, and you want to route conversations related to certain topics to specific agents.\nThe following table lists the context variables available by default.\nContext\nPurpose\nExample\nva_Scope\nRoute escalations to a live agent.\n\"agent\"\nva_LastTopic\nRoute escalations to a live agent and help them ramp-up. Includes the last topic that was triggered by an utterance from the user.\n\"Return items\"\nva_Topics\nRamp-up a live agent. Only includes topics triggered by customers using a trigger phrase. Doesn't include topics that were redirected to.\n[ \"Greetings\", \"Store Hours\", \"Return Item\" ]\nva_LastPhrases\nRoute escalation to a live agent and help them ramp-up.\n\"Can I return my item\"\nva_Phrases\nRamp-up a live agent.\n[\"Hi\", \"When does store open\", \"Can I return my item\" ]\nva_ConversationId\nUniquely identify an agent conversation.\n6dba796e-2233-4ea8-881b-4b3ac2b8bbe9\nva_AgentMessage\nRamp-up a live agent.\n\"Got a gift from: HandoffTest\"\nva_BotId\nIdentify the agent that's handing off a conversation.\n6dba796e-2233-4ea8-881b-4b3ac2b8bbe9\nva_Language\nRoute escalation to a live agent.\n\"en-us\"\nAll\nuser-defined topic variables\nRamp-up a live agent.\n@StoreLocation = \"Bellevue\"\nA customer might go through several topics prior to escalating. Your agent gathers all context variables across topics and merges them before sending to the engagement hub.\nIf there are topics with similarly named context variables, the agent promotes the most recently defined topic variable.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Human Agent Handoff",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/authoring-test-bot": {
      "content_hash": "sha256:44a6841c40398b9fedd86ac6060f2f0887b20fe87c930157fb30cbdb22c5a906",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nTest your agent\nFeedback\nSummarize this article for me\nAs you design your agent in Copilot Studio, use a test panel to see how the agent leads a customer through the conversation. It's a good way to make sure your topics work and that conversations flow as you expect.\nWhen you test an agent that uses generative orchestration, you can follow the orchestrator's plan in real time on the\nactivity map\n. Close the activity map if you want to follow through the conversation path step by step with tracking between topics turned on.\nIn addition to testing your agent in the\nTest your agent\npanel, you can create test sets of multiple queries for automated testing. For more information, see\nCreate test cases to evaluate your agent (preview)\n.\nUse the test chat\nWeb app\nClassic\nTeams\nUse the\nTest your agent\npanel to walk through your agent conversations as a user. It's a good way to make sure your topics are working and that conversations flow as you expect.\nIn addition to testing your agent in\nTest your agent\npanel, you can create test sets of multiple queries for\nautomated testing\n. To start an automated test, select the evaluate\nbutton.\nPreview a conversation\nIf the\nTest your agent\npanel is hidden, open it by selecting\nTest\nat the top of any page.\nIn the field at the bottom of the\nTest your agent\npanel, enter some text. If the text is similar to a trigger phrase for a topic, that topic begins.\nSelect the agent response in theâ¯test chat. This action takes you to the topic and the node that sent the response. Nodes that fired have a colored checkmark and a colored bottom border.\nAs you continue the conversation within the active topic, notice that each node that fires is marked with the checkbox and bottom border, and centered on the canvas.\nIf you want to follow the whole conversation automatically as it moves from topic to topic, select the three dots (\nâ¦\n) at the top of the test panel and turn on\nTrack between topics\n. For an agent that uses generative orchestration (default), consider turning off\nShow activity map when testing\nto avoid having to collapse the activity map at every conversation turn.\nContinue the conversation until you're satisfied that it flows as intended.\nTip\nYou can update a topic at any time while interacting with the test agent. Save your topic to apply changes and continue the conversation with your agent.\nYour conversation isn't automatically cleared when you save a topic. If you want your agent to forget the test conversation and start over, select the\nReset\nicon\nat the top of the test panel.\nYou can use queries you send in the test chat to\ncreate automated test sets\nfor evaluating your agent.\nIf the\nTest bot\npanel is hidden, select\nTest\non the top menu bar.\nUnless you want to continue an earlier conversation, select the\nReset\nicon\nat the top of the\nTest bot\npanel to clear the previous conversation. Clearing previous conversations makes it easier to see the flow of the topic you want to test.\nAt the\nType your message\nprompt at the bottom of the\nTest bot\npanel, enter a trigger phrase for the topic you want to test. The trigger phrase starts the topic's conversation, and the\nTest bot\npanel displays the bot responses and user response choices you specified.\nContinue the conversation and verify that it flows as expected. If you want to follow the conversation automatically as it moves from topic to topic, turn on\nTracking between topics\nat the top of the panel. You can turn it off if you prefer to focus on a specific topic.\nSelect any response in the test chat. This action takes you to the originating node in the topic editor. The test panel automatically resets itself when you save changes to a topic.\nIf the\nTest bot\npanel is hidden, select the\nTest your chatbot\nicon at the bottom of the left pane.\nUnless you want to continue an earlier conversation, select the\nReset\nicon\nat the top of the\nTest bot\npanel to clear the previous conversation. Clearing previous conversations makes it easier to see the flow of the topic you want to test.\nAt the\nType your message\nprompt at the bottom of the\nTest bot\npanel, enter a trigger phrase for the topic you want to test. The trigger phrase starts the topic's conversation, and the\nTest bot\npanel displays the bot responses and user response choices you specified.\nContinue the conversation and verify that it flows as expected. If you want to follow the conversation automatically as it moves from topic to topic, turn on\nTracking between topics\nat the top of the panel. You can turn it off if you prefer to focus on a specific topic.\nSelect any response in the test chat. This action takes you to the originating node in the topic editor. The test panel automatically resets itself when you save changes to a topic.\nTest variable values\nYou can observe the values of your variables as you test your agent.\nSelect\nVariables\non the secondary toolbar. The\nVariables\npanel appears.\nSwitch to the\nTest\ntab and expand the desired variable categories. As you proceed with your test conversation, you can monitor the value of the variables in use.\nTo inspect variable properties, select the desired variable. The\nVariable properties\npanel appears.\nSave conversation snapshots\nWhile you're testing your agent, you can capture the content of the conversation and diagnostics data, and save it. You can then analyze the data to troubleshoot issues, such as the agent not responding in the way you expect.\nWarning\nThe snapshot file contains all your agent content, which might include sensitive information.\nWeb app\nClassic / Teams\nAt the top of theâ¯\nTest your agent\nâ¯pane, select the three dots (\nâ¦\n), thenâ¯select\nSave snapshot\n. A message appears, notifying you that the snapshot file might include sensitive information.\nSelectâ¯\nSave\nto save the agent content and conversational diagnostics in a .zip archive namedâ¯\nbotContent.zip\n.\nTheâ¯\nbotContent.zip\nâ¯archive contains two files:\ndialog.json\nâ¯contains conversational diagnostics, including detailed descriptions of errors.\nbotContent.yml\nâ¯contains the agent's topics and other content, including entities and variables.\nAt the top of the\nTest bot\npanel, select the three dots (\nâ®\n), then select\nSave snapshot\n. A message appears, notifying you that the snapshot file might include sensitive information.\nSelect\nSave\nto save the bot content and conversational diagnostics in a .zip archive named\nDSAT.zip\n.\nThe\nDSAT.zip\narchive contains two files:\ndialog.json\ncontains conversational diagnostics, including detailed descriptions of errors.\nbotContent.json\ncontains the bot's topics and other content, including entities and variables.\nManage connections\nIf your agent requires\nuser connections\n, you can manage the connections used by your test chat: Select the three dots (\nâ¦\n) at the top of the test panel, thenâ¯select\nManage connections\n.\nReport issues\nHelp us improve Copilot Studio by reporting issues. All information collected remains anonymous.\nWeb app\nClassic / Teams\nAt the top of theâ¯\nTest your agent\nâ¯pane, select the three dots (\nâ¦\n), thenâ¯select\nFlag an issue\n.\nSelect\nFlag issue\n. This action sends your conversation ID to Microsoft. The ID is a unique identifier that Microsoft uses to troubleshoot issues in a conversation. When you report an issue, you don't send other information, such as what is stored in a conversation snapshotâ¯file.\nSelect the\nFlag an issue\nicon on the\nChat\nbanner at the top of the\nTest bot\npanel.\nSelect\nFlag issue\n. This action sends your conversation ID to Microsoft. The ID is a unique identifier that Microsoft uses to troubleshoot issues in a conversation. When you report an issue, you don't send other information, such as what is stored in a conversation snapshotâ¯file.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Test Your Agent",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/admin-network-isolation-vnet": {
      "content_hash": "sha256:434d058462239a220cddb4c95066550cc5e4688ae55e61216eac6d9c53165c3c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConfigure Virtual Network support for outbound connections from agents\nFeedback\nSummarize this article for me\nWhen you use\nVirtual Network support in a Power Platform environment\n, you can securely connect to and integrate Power Platform and Dataverse components with cloud services, or services hosted inside your private enterprise network, without exposing them to the public internet.\nCopilot Studio integrates with Power Platform virtual networks over a private endpoint for these scenarios:\nAgents that retrieve keys from Azure Key Vault\nover HTTP\nAgents that send telemetry to a private endpoint-enabled instance of\nApplication Insights\nAgents that use a virtual network-supported connector (like the SQL Server connector) to get data from Azure SQL Server\nIf you set up a virtual network for a Power Platform environment and enable Copilot Studio to\ncapture telemetry with Application Insights\nor\nmake HTTP requests with your agent\nover the virtual network, then the calls from Power Platform to Azure resources and Application Insights go through your private network.\nPrerequisites\nYour environment must be\na Managed Environment in Power Platform\nYou must have\nVirtual Network support enabled for your Power Platform environment\n. Also see\nSet up Virtual Network support for Power Platform\nto create virtual networks and delegate subnets that can connect between Azure resources and your Power Platform environment.\nYou must be a Power Platform\ntenant admin\nor have the\nEnvironment Admin role\nEnable virtual network support for your environment\nTo connect to services through a private endpoint, you must have\nvitual network support enabled for Power Platform\n.\nYou can enable virtual network support manually, by following the instructions at\nSet up Virtual Network support for Power Platform\nto create virtual networks and delegate subnets that can connect between Azure resources and your Power Platform environment.\nYou can also use a prebuilt Azure Resource Manager (ARM) template to configure and connect your Power Platform environment with Azure and enable virtual network support:\nDownload the\nARM template from the Microsoft Copilot Studio samples repository on GitHub\n.\nOpen PowerShell, connect to your Azure subscription and deploy the template with the\nNew-AzDeployment command\nas follows:\nConnect-AzAccount -Subscription \"<Azure subscription>\"\nNew-AzSubscriptionDeployment -Name \"<name of deployment>\" -TemplateFile \"<template.json>\" -Location \"<Azure geo>\"\nwhere:\n<Azure subscription>\nis your subscription ID.\n<name of deployment>\nis the name you want to give this deployment.\nThe name can be anything you choose, but defaults to the template's filename if you leave it blank.\n<template.json>\nis the path and filename of the template file.\n<Azure geo>\nis the geographic region where you want the deployment management files to go, such as\nWest US\n. The region doesn't control where the template creates the resources.\nSee\nDeploy resources with ARM templates and Azure PowerShell\nfor more information about ARM templates and management.\nNote\nYou only need to configure your virtual network using either the ARM template, or manually. You don't need to do both.\nReview the overview about\nVirtual Network support for Power Platform\n, before following the insutrctions at\nSet up Virtual Network support for Power Platform\nto create virtual networks and delegate subnets that can connect between Azure resources and your Power Platform environment.\nRetrieve keys from Azure Key Vault over HTTP\nWhen you\nset up a virtual network for your Power Platform environment\n, you can configure your Copilot Studio agents to retrieve information from Azure resources with HTTP calls.\nFirst, you set up a private link and endpoint for Azure Key Vault. Then, after validating that the link is working, you add a HTTP Request node from the agent's authoring canvas in Copilot Studio to connect to Key Vault.\nSet up a private link\nFollow the instructions at\nIntegrate Key Vault with Azure Private Link\nto:\nCreate a new key vault and establish a private link\nthat scopes the link to your Azure subscription and the resource group where your Key Vault is located, or\nEstablish a private link connection to an existing key vault\n.\nValidate that the private link to Key Vault is working\n.\nTip\nIf your endpoint isn't correct, review the instructions and related articles for private links and private endpoints in the\nDiagnose private links configurations issues on Azure Key Vault\narticle.\nUse HTTP Request nodes to connect over a private network\nAfter you configure the private link to Key Vault, you add an HTTP Request node to an agent in Copilot Studio to connect over the private network. You specify the connection details to the private endpoint in the node, and when that node is reached in the agent's conversation, the request is made and the information retrieved.\nIn Copilot Studio, on the top menu bar, select an environment where Virtual Network support is enabled.\nCreate or open an existing agent in that environment. If you create a new agent, you can skip the initial configuration steps in the conversational canvas.\nWith the agent open, create or modify a topic in the authoring canvas.\nFollow the instructions at\nMake HTTP requests\nto add an HTTP request node to the topic.\nUse the following settings in the HTTP Request node:\nURL\n: Enter the URL for your Azure Key Vault private endpoint, for example,\nhttps://yourkeyvault.vault.azure.net/secrets?api-version=7.3\n. Replace\nyourkeyvault\nwith the name of your Key Vault.\nMethod\n: Select\nGET\nto retrieve secrets from Key Vault.\nHeaders and body\n: Select edit.\nIn\nHTTP Request properties\n, enter\nAuthorization\nas the\nKey\n, and\nBearer <access-token>\nas the\nValue\n, where\n<access-token>\nis your Azure access token.\nSave the topic, and test that the node works by triggering the conversation in the agent's test canvas.\nSend telemetry to a private endpoint-enabled instance of Application Insights\nWhen you\nset up a virtual network for your Power Platform environment\n, you can configure your Copilot Studio agents to send telemetry to a private endpoint-enabled instance of Application Insights. Doing so allows you to monitor and analyze the performance and usage of your agents without exposing the data to the public internet.\nFirst, you set up a private link and endpoint for Application Insights. Then, after validating that the link is working, you connect Copilot Studio to Application Insights and it'll send telemetry data over the private link.\nSet up a private link\nAn\nAzure Private Link to Azure Monitor\nlets Copilot Studio use your virtual network to send agent telemetry to Azure Monitor over a private IP address instead of a public IP address.\nAzure Monitor is the backend data platform used to collect and store telemetry data, including Application Insights data.\nFollow the instructions at\nConfigure private link for Azure Monitor\nand:\nCreate an Azure Monitor Private Link Scope (AMPLS)\nto scope the link to your Azure subscription and the resource group where your Azure Monitor resources are located.\nConnect Application Insights component resources to the AMPLS\n.\nCreate a private endpoint for the Application Insights resources you added to the scope\nthat Copilot Studio can connect to in your virtual network and over your subnet. This endpoint is used to send telemetry data from the agent to the AMPLS.\nValidate that the private link to Azure Monitor is working\n.\nYou can also\nconfigure which networks can connect to resources in your AMPLS, without using a scope, in the\nNetwork Isolation\npage for your AMPLS\n. Directly configuring networks is useful if you have multiple virtual networks and want to restrict access to the AMPLS to only certain networks or subnets.\nTip\nIf your endpoint isn't correct, review the instructions and related articles for private links and private endpoints in the\nConfigure private link for Azure Monitor\narticle.\nConnect Copilot Studio to Application Insights\nWith the private link set up, you can connect Copilot Studio to Application Insights and it'll use your virtual network to send telemetry data.\nFollow the instructions at\nCapture telemetry with Application Insights\n.\nImportant\nEnsure you get the correct\nConnection string\nfor the private endpoint-enabled Application Insights .\nYou can validate it's the correct resource by checking the values under\nResource group\nand\nSubscription\non the\nOverview\nsection for Application Insights in the Azure portal.\nTelemetry from Copilot Studio agents appears in the Application Insights resource you configured. You can use the\nLive Metrics Stream\nto see telemetry data in real time, or use the\nLogs\nsection to query and analyze the data.\nUse virtual network-supported connectors to get data\nWhen you\nset up a virtual network for your Power Platform environment\n, you can configure your Copilot Studio agents to use virtual network-supported connectors to connect to data and services over your private network.\nYou can\nuse any connector that has native support for virtual networks\n.\nUsing virtual network-supported connections lets you securely connect to your cloud-hosted data sources, such as\nAzure SQL\nor\nSQL Server\n, over private endpoints without exposing them to the internet.\nFollow the instructions at\nUse Power Platform connectors in Copilot Studio\nto add and configure the connector you want to use in a topic or tool.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "VNet Support",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/whats-new": {
      "content_hash": "sha256:1762edcc36f23a32c129af4bcd3ebf7bc63df93b36061eee5c61679fb27d00e3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat's new in Copilot Studio\nFeedback\nSummarize this article for me\nThis article provides resources to learn about new features in Copilot Studio.\nRelease plans\nFor information about new features being released over the next few months that you can use for planning, see\nRelease Planner\n.\nReleased versions\nFor information about the new features, fixes, and improvements released in the past few weeks, see\nReleased versions of Microsoft Copilot Studio\n.\nNote\nReleases are rolled out over several days. New or updated functionality might not appear immediately.\nNotable changes\nThe following sections list features released in the past months, with links to related information.\nDecember 2025\nCompare multiple agent versions side by side to validate improvements and quickly spot regressions when\nevaluating agents with test sets\n.\nNovember 2025\nUpdates for models used in Copilot Studio:\nOn November 24, 2025, GPT-5 Chat rolls out to Copilot Studio in\ngeneral availability\nfor European and United States regions. You can use generally available models for orchestration in production agents. For more information on choosing orchestration models, see\nSelect a primary AI model for your agent\n.\n(Preview) Automatically create\nMicrosoft Entra agent identities\nfor agents. When turned on, automatically apply identity management to individual agents by assigning a Microsoft Entra agent identity, helping admins secure and manage agents more effectively.\nImproved knowledge retrieval for SharePoint-grounded agents using\ntenant graph grounding\n. Updated system architecture and new retrieval methods deliver more precise, context-rich responses, enhancing answer quality.\nNote\nSome queries might lead to slightly higher latency.\nImprove response accuracy with\nSharePoint metadata filters\n. Use metadata like filename, owner, and modified date to refine knowledge retrieval and ensure responses come from the most relevant, up-to-date documents.\nOrchestrate multiple agents\nto break down complex tasks across specialized agents, improving accuracy and speeding up endâtoâend automation. Enhance your agents by linking them to other agentsâeither within your environment or external sources like\nMicrosoft Fabric\ndata agentsâfor modular, task-specific functionality.\n(Preview)\nAdd tool groups to agents\nfor faster setup. Quickly equip your agents with curated sets of tools from Outlook and SharePoint connectors in one step. This streamlines setup, reduces errors, and ensures consistent, reliable orchestration.\nCopy agents from\nMicrosoft 365 Copilot to Copilot Studio\n. Easily move agents you created in Microsoft 365 Copilot into Copilot Studio to unlock advanced capabilities like multi-step workflows, custom integrations, and broader deployment options.\n(Preview) Add human input to agent workflows with the\nrequest for information\naction. Pause an agent flow to collect details from designated reviewers via Outlook, then resume execution using their responses as dynamic parameters. This action ensures workflows can handle missing data or context without relying on hard-coded values.\nUpdate Power Platform API calls to use the\nnew 'copilotstudio' namespace\n. The previous namespace will continue to work temporarily, but switching now ensures compatibility with future updates.\nUse\ncomponent collections\nwith new enhancements. Access collections directly from the sidebar, quickly export or import collections, and take advantage of support for primary agents and new connector types, including child agents and Model Context Protocol (MCP).\nOctober 2025\nUpdates for models used in Copilot Studio:\nBetween October 27 and 31, 2025, GPTâ4o will be retired in Copilot Studio for agents using generative orchestration, except for GCC customers who can continue using GPTâ4o. The new default model is\nGPTâ4.1\n, which delivers improved performance, reliability, and consistency across experiences. GPTâ4o remains available until November 26, 2025 if you turn on the â\nContinue using retired models\nâ option.\nChoose from multiple\nAI models\nto tailor your agent's performance to your needs.\n(Preview) Test and deploy\nGPTâ5\nmodels to explore advanced capabilities and enhance your agent's performance.\nLearn about\nCopilot Studio Kit\n, a suite of tools developed by the Power Customer Advisory Team (Power CAT) to help test custom agents, validate AI-generated content, analyze conversation key performance indicators, and more.\n(Preview) Group related user questions into\nthemes\nand drill down into analytics to uncover patterns and gain deeper insights.\nTrack\ntime and cost savings\nfor both autonomous and conversational agents to measure ROI and optimize performance.\nAccess a\nunified activity and transcript view\n, pin sessions, and submit feedback for faster, more effective troubleshooting.\n(Preview)\nAccelerate flow execution\nto minimize timeouts and deliver a faster, smoother user experience.\nUse the\nModel Context Protocol (MCP) server\nto access dynamic, real-time contentâsuch as files, database records, and API responsesâfor richer context and improved agent responses.\n(Preview) Evaluate your agents using customizable\ntest sets\nâwhether uploaded, manually created, or AI-generated. Test sets can include test cases using different test methods (graders) measured against defined reference answers, helping teams identify strengths and areas for improvement. This capability supports more reliable, high-quality agent experiences across diverse scenarios.\nSeptember 2025\n(Preview) Automate tasks in desktop applications on Windows using\nComputer-Using Agents (CUA)\n, which combines vision and reasoning to interact with interfacesâeven when APIs arenât available.\nEmbed Copilot agents into Android, iOS, and Windows apps using the\nClient SDK\nto provide rich, multimodal conversations within native experiences.\n(Preview) Upload Excel, CSV, and PDF files for your agent to analyze using Python code, powered by the\ncode interpreter in chat\n.\nAugust 2025\n(General availability) Use\ncode interpreter\nto generate Python code-based actions from natural language in both the prompt builder and agent workflows.\n(General availability) Enhance agentic response accuracy in Copilot Studio agents by using\nfile groups\nto organize local files to be uploaded as a single knowledge source and apply variable-based instructions.\nAllow users to\nupload files and images\nthat your Copilot Studio agent can analyze and use to generate responses, then pass those files to downstream systems using Agent Flows, Power Automate, connectors, tools, and topics for seamless integration.\n(General availability) Track and analyze unanswered queries and response generative AI quality with the\ngenerated answer rate and quality\nsection in the Analytics page to improve your agent's performance.\nConnect to an existing\nMCP server\ndirectly within Copilot Studio using a guided experience.\nJuly 2025\nUse\nadvanced NLU customization\nto define topics and entities using your own data for higher accuracy and improved containment, especially for Dynamics 365 scenarios.\nSearch across your agent\n's knowledge, topics, tools, skills, and entities instantly using a new in-app search experience accessible via keyboard shortcut or top-level search.\nEstimate time and cost savings based on successful runs or actions and customizable to your organization's metrics with\nROI analytics\nfor agents with autonomous capabilities.\nView user comments submitted with\nthumbs up/down reactions\nin analytics, offering deeper insight into customer feedback on agent responses.\n(Preview) Display\nMicrosoft Information Protection (MIP)\nlabels across connectors, test chat, Teams, and Microsoft 365 Copilot to prevent oversharing and support secure, compliant AI experiences. With new integrations between Copilot Studio, Dataverse, and Microsoft Purview, you can automatically classify sensitive data and ensure agents respect Purview sensitivity labels.\nPublish agents directly to a\nWhatsApp\nphone number, making it easier to reach customers.\n(Preview) Streamline authentication for Microsoft Entra IDâbacked actions and connectors with the SSO Consent Card by allowing users to grant consent directly within the chat with no redirects and no interruptions.\nJune 2025\nImproved experience for tools:\nGrouping and filtering for easier search and discovery of tools.\nSupport for IntelliSense automatic completion and input widgets such as calendar control, file picker, and timezone picker, when configuring tools.\nImproved tool invocation experience for customers with more affordances for complex inputs and clearer error messaging.\nAutomatic detection of SSO for connectors.\n(Preview)\nSupport for Microsoft 365 Copilot Tuning\nto train models on your own enterprise data for domain-specific tasks and integrate these models into Microsoft 365 experiences like Copilot in Teams, Word, and Chat. You can also connect your fine-tuned models to custom agents.\nActionable insights for questions that generative AI left unanswered, grouped by themes, in the\nAnswer rate and quality\nsection of the\nAnalytics\npage.\nKnowledge sources analysis for autonomous agents.\nAbility to insert Power Fx formulas directly in the embedded\nprompt builder prompt editor\n.\nSimplified text validation and extraction with regular expression support for\nPower Fx formulas\nthat use IsMatch, Match, or MatchAll functions.\n(Preview) Support for\nfile groups\nas knowledge sources.\n(Preview) Generative orchestration available for all\nsupported languages\n.\nRedesigned\nChannels\npage.\n(US-only preview) Ability to select the GPT-4.1 mini\nexperimental response model\nfor generative answers.\nMay 2025\n(Preview) Ability for makers to\nconnect an agent to other agents\nto complete tasks and respond to users.\nIntegrated\nAdaptive Card designer\nwith built-in localization support.\nAbility to deploy Copilot Studio agents to\nSharePoint\n.\nNew controls\nin Generative AI agents to better shape agent responses with knowledge and feedback.\nGeneral availability of\nMicrosoft 365 Agents SDK and Microsoft 365 Agents Toolkit\n.\nEdit agents with the\nCopilot Studio extension\nfor Visual Studio Code.\n(Preview) New autonomous agent template:\nDocument Processor\n.\nGeneral availability of agents ability to\nuse web search\n.\n(Preview) Bring Your Own Models from Azure AI Foundry to your custom engine agents.\nGeneral availability of\nModel Context Protocol support\nwith enhanced tracing and analytics.\n(Preview) Ability to build agents with\nDataverse and Dynamics 365 Model Context Protocol (MCP) servers\n.\nGeneral availability of new and improved knowledge creation experiences with knowledge recommendations, previews, and connection creation.\n(Preview) Support for\nunstructured knowledge\nfrom ServiceNow, Salesforce, Confluence, and Zendesk, enabled through Power Platform connectors.\n(Preview) Enhanced file upload experience with support for adding files from OneDrive and SharePoint.\nGeneral availability of\nAzure AI Search knowledge\nwith support for hybrid search index, virtual network support, and better citations.\nGeneral availability of\ntabular data knowledge\nfrom systems of records like Dataverse, Salesforce, ServiceNow, Azure SQL Sever.\nGeneral availability of connectors.\nSupport for\nFederated Identity Credentials\n(FIC).\nApril 2025\n(Preview) Support for\nCustomer Managed Keys\n.\nSupport for generative and autonomous agents in Analytics.\nInclusion and visibility of agent data and ROI analysis in Viva Insights.\nNine new Graph connectors\n:\nGuru\n,\nGitLab\n(Issues, Merge Requests, Knowledge),\nAsana\n,\n15Five\n,\nMiro\n,\nTrello\n,\nZendesk Ticket\n,\nSmartSheet\n, and\nSeismic\n.\nMarch 2025\nEnhancement of conversation transcripts\nto include node-level data.\nGeneral availability of\nautonomous agents\n.\nSimplified integration with AI apps and agents using\nModel Context Protocol\n.\nWorldwide general availability of\ngenerative orchestration\nin Copilot Studio.\nPreview release of\ndeep reasoning models\nfor agents.\nAbility to\nbuild agent flows\ndirectly in Copilot Studio.\nFebruary 2025\nHebrew (he-IL) language support\nfor interactions between agents and users, including support for generative answers, for text only (voice isn't supported).\nA new topic trigger,\nAI response generated\n, lets the agent override, modify, or log responses generated by the orchestrator before sending them to the conversation.\n(Preview) Ability to publish custom agents created in Copilot Studio directly to\nMicrosoft 365 Copilot Chat\n.\n(Preview) Support for more enterprise data sources using\nMicrosoft Copilot connectors\n.\nSecurity: Improved mitigation of cross-prompt injection attacks (XPIA).\nData policy enforcement\napplies by default for agents in all tenants.\nMicrosoft 365 Agents\nSoftware Development Kit for JavaScript\n.\nJanuary 2025\nMicrosoft Purview can access and manage\nuser interaction audit logs\nfrom Copilot Studio agents.\nChinese (Traditional) (zh-TW)\nlanguage support\nfor interactions between agents and users, including support for generative answers.\nDefault data policy enforcement for agents is set to\nSoft-enabled\nfor all tenants.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "What's New",
      "section": "Copilot Studio"
    },
    "https://learn.microsoft.com/en-us/microsoft-365-copilot/microsoft-365-copilot-overview": {
      "content_hash": "sha256:e5f66c9e1585501148558472a75a85ba66e108259dd1e15612e252b0c6e75bbe",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft 365 Copilot overview\nFeedback\nSummarize this article for me\nNote\nMicrosoft has onboarded Anthropic as a Microsoft subprocessor. As a subprocessor, Anthropic will operate with\nMicrosoft Enterprise data protections\n. For more information, see\nAnthropic as a subprocessor for Microsoft Online Services\n.\nMicrosoft 365 Copilot is an AI-powered tool that helps with your work tasks\n.\nUsers enter a prompt in Copilot and Copilot responds with AI-generated information. The responses are in real-time and can include internet-based content and work content that users have permission to access.\nUsers get content relevant to their work tasks, and in the context of the Microsoft 365 app they're using.\nThe following video provides an overview of Microsoft 365 Copilot. It's 1 minute and 49 seconds long.\nFor example, you're an Operations Manager and are working with human resources to update job descriptions. In a Copilot prompting session, you can ask Copilot to create a job description and also add qualifications that should be included in the description. In the same prompting session, you can expand the generated job description to also create different levels, like Level 1, Level 2, and Level 3.\nYou can also\ncreate and use agents\nto customize your Copilot experience with your organization's data sources. For example, you're a warehouse manager and you need to know the status of a shipment. You can ask your Copilot shipping agent \"What is the status of shipment 1234?\" Copilot uses your data sources to get the information and can respond with the status.\nThis article is for IT admins. It describes the different components that Microsoft 365 Copilot uses and the Copilot features in the Microsoft 365 apps. To learn more about the architecture and how Copilot works, see\nMicrosoft 365 Copilot architecture and how it works\n.\nThis article applies to:\nMicrosoft 365 Copilot\nTip\nHome users might automatically get Microsoft Copilot, which is the free consumer version. To learn more, see\nHow can Copilot help you?\nand\nWelcome to Copilot on Windows\n.\nGet sample prompts at the\nCopilot Prompt Gallery\nand training at the\nMicrosoft 365 Copilot Skilling Center\n.\nLearn more about data privacy at\nData, Privacy, and Security for Microsoft 365 Copilot\n.\nThe technical details\nMicrosoft 365 Copilot:\nPairs with the Microsoft 365 productivity apps that you use every day, like Word, Excel, PowerPoint, Outlook, Teams, and others. You can use Copilot in Word to help create a document, in Excel to get suggestions for formulas, in Outlook to summarize an email thread, and in Teams to summarize meetings.\nUses content in\nMicrosoft Graph\nto personalize the responses with a user's work emails, chats, and documents. Copilot only shows the data that users have permission to access.\nIncludes\nMicrosoft 365 Copilot Search\n, a universal search experience that allows users to search across all their Microsoft 365 and third-party data sources to find what they need quickly.\nCoordinates large language models (LLMs). LLMs are a type of artificial intelligence (AI) algorithms. These algorithms use deep learning techniques and data sets to understand, summarize, predict, and generate content.\nThe LLMs include pretrained models, like Generative Pre-Trained Transformers, like GPT-4, that are designed for these tasks. To learn more about Generative Pre-Trained Transformers (GPT), ask\nCopilot\n.\nTo learn more, see:\nMicrosoft 365 Copilot architecture and how it works\nMicrosoft 365 Copilot service description\nMicrosoft 365 Copilot Search overview\nVideo:\nCopilot system explained by Microsoft\nVideo:\nMicrosoft 365 Copilot, LLMs, and your apps\nVideo:\nHow to get ready for Microsoft 365 Copilot\nCopilot works with Microsoft 365 apps and Microsoft Graph\nCopilot has intelligent features, functionality, and prompting. These features are designed to help users in the context of their work within their Microsoft 365 apps.\nMicrosoft's LLMs and other components work together. They help users securely access and use your organizational data with AI-powered capabilities. Specifically, Microsoft 365 Copilot uses the following components:\nâ\nMicrosoft 365 apps\nApps like Word, Excel, PowerPoint, Outlook, Teams, and Loop work with Copilot to support users in the context of their work. For example, Copilot in Word helps users create, understand, and edit documents.\nFor more features, see\nCopilot features in Microsoft 365 apps\n(in this article).\nâ\nMicrosoft 365 Copilot Chat\nWith Microsoft 365 Copilot Chat, you can draft content, review what you missed, and get answers to questions using open-ended prompts. This information is securely grounded in your work data.\nYou can use Microsoft 365 Copilot Chat in Microsoft Teams, in the Microsoft 365 Copilot Chat app, at\nMicrosoft365.com\n, and at\ncopilot.microsoft.com\n.\nâ\nMicrosoft 365 Copilot Search\nCopilot Search is an AI-powered universal search experience across all your Microsoft 365 applications and non-Microsoft data sources. It's integrated with Microsoft 365 Copilot, so users can find the results they need with search, then seamlessly transition to chat for deeper exploration or follow-up task completion.\nLearn more about\nCopilot Search\n.\nâ\nMicrosoft Graph\nMicrosoft Graph includes information on users, their activities, and the organization data they can access. The Microsoft Graph API brings a personalized context into the prompt, like information from a user's emails, chats, documents, and meetings.\nTo learn more, see\nOverview of Microsoft Graph\nand\nMajor services and features in Microsoft Graph\n.\nâ\nSemantic indexing for Microsoft 365 Copilot\nMicrosoft 365 Copilot enhances search relevance and accuracy by using advanced lexical and semantic understanding of Microsoft Graph data, resulting in more contextually precise information retrieval. Copilot preserves security, compliance, and privacy, ensuring organizational boundaries are respected while offering seamless user experience.\nTo learn more, see\nSemantic indexing for Microsoft 365 Copilot\nand\nSemantic Index explained by Microsoft\n(opens YouTube's website).\nCopilot features in Microsoft 365 apps\nMicrosoft 365 productivity apps (like Word, Excel, PowerPoint, Outlook, Teams, and Loop) work with Copilot to support users in the context of their work.\nTip\nTo learn how users can use Copilot within Microsoft 365 apps, including sample prompts, see\nCopilot Prompt Gallery\n.\nSome of these features include:\nMicrosoft 365 App\nFeature\nWord\nDraft\nâGenerate text with and without formatting in new or existing documents. Word files can also be used for grounding data.\nChat\nâCreate content, summarize, ask questions about your document, and do light commanding.\nPowerPoint\nDraft\nâCreate a new presentation from a prompt or Word file using enterprise templates. PowerPoint files can also be used for grounding data.\nChat\nâSummary and Q&A\nLight commanding\nâAdd slides, pictures, or make deck-wide formatting changes.\nExcel\nDraft\nâGet suggestions for formulas, chart types, and insights about data in your spreadsheet.\nLoop\nCollaborative content creation\nâCreate content that can be collaboratively improved through direct editing.\nOutlook\nCoaching tips\nâGet coaching tips and suggestions on clarity, sentiment, & tone, and an overall message assessment and suggestions for improvement.\nSummarize\nâSummarize an email thread to quickly understand the discussion.\nDraft\nâPull from other emails or content across Microsoft 365 that the user already has access to.\nTeams\nChat\nâCopilot can summarize up to 30 days of the chat content before the last message in a chat.\nCopilot uses only the single chat thread as source content for responses. It can't reference other chats or data types, like meeting transcripts, emails, and files. Users can select prewritten prompts or write their own questions. Responses include clickable citations that direct users to the relevant source content that was used.\nConversations with Copilot take place in a side panel and allows users to copy and paste. Copilot conversations close when the side panel closes.\nMeetings\nâUsers can invoke Copilot in meetings or calls within the same tenant. Copilot uses the transcript in real-time to answer questions from the user. It only uses the transcript and knows the name of the user typing the question.\nUsers can type any question or use predetermined prompts. Copilot answers questions only related to the meeting conversation from the transcript. The user can copy/paste an answer and access Copilot after the meeting ends.\nCopilot\nâUsers access data across their Microsoft 365 Graph and use LLM functionality.\nCalls\nâAutomates important administrative tasks of a call, like capturing key points, task owners, and next steps. It supports voice over Internet Protocol (VoIP) and public switched telephone network (PSTN) calls.\nWhiteboard\nDraft\nâUse natural language to generate ideas, organize ideas into themes, create designs based on ideas, and summarize whiteboard content.\nOneNote\nDraft\nâUse prompts to draft plans, generate ideas, create lists, and organize information to help you find what you need.\nForms\nDraft\nâUse prompts to draft questions and suggestions that help you create surveys, polls, and other forms.\nMicrosoft 365 services that help support Copilot\nIn your Microsoft 365 license, there are services and features that can help you get your data and organization ready for Copilot.\nSharePoint Advanced Management (SAM)\nMicrosoft SharePoint Premium â SharePoint Advanced Management (SAM) can help you reduce oversharing and cleanup inactive sites. These tasks help declutter Copilot's data sources and improve the quality of the responses.\nTo learn more, see\nGet ready for Microsoft 365 Copilot with SharePoint Advanced Management (SAM)\n.\nRestricted SharePoint Search\nRestricted SharePoint Search (RSS) gives you time to review and configure the correct permissions on your SharePoint sites. You add the reviewed & corrected sites to an allowed list that Copilot can access.\nTo learn more, see\nRestricted SharePoint Search\n.\nMicrosoft Purview\nMicrosoft Purview can classify and label your data based on the sensitivity of the content. It can also help prevent unauthorized sharing or leakage and review Copilot prompts and responses.\nTo learn more, see\nMicrosoft Purview data security and compliance protections for generative AI apps\n.\nMicrosoft Agents\nAgents are scoped or focused versions of Microsoft 365 Copilot that act as AI assistants and can automate business processes. For example, you can create an agent that creates help desk tickets, or a human resources agent that looks up employee info from your data source.\nTo learn more, see\nMicrosoft 365 Copilot extensibility overview\n.\nMore resources:\nCompare features in the Microsoft 365 licenses that affect Copilot\nGet your data ready for Microsoft 365 Copilot using the\nE3 license admin guide\nor\nE5 license admin guide\n.\nRelated content\nGet licensing info\nand\nset up Microsoft 365 Copilot\n.\nLearn about\nData, Privacy, and Security for Microsoft 365 Copilot\n.\nGet\nsample prompts at the Copilot Prompt Gallery\nand\ntraining at the Microsoft 365 Copilot Skilling Center\n.\nStay up to date on the latest Copilot features, changes, and announcements using the\nMessage center\nin the\nMicrosoft 365 admin center\n.\nUnderstanding foundation model changes in Microsoft 365 Copilot\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "M365 Copilot Overview",
      "section": "Microsoft 365 Copilot"
    },
    "https://learn.microsoft.com/en-us/microsoft-365-copilot/microsoft-365-copilot-privacy": {
      "content_hash": "sha256:926280225520b3d2839651ce06893f79ceb793f83b74ed57843f4ff986e8225f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nData, Privacy, and Security for Microsoft 365 Copilot\nFeedback\nSummarize this article for me\nMicrosoft 365 Copilot is a sophisticated processing and orchestration engine that provides AI-powered productivity capabilities by coordinating the following components:\nLarge language models (LLMs)\nContent in Microsoft Graph, such as emails, chats, and documents that you have permission to access.\nThe Microsoft 365 productivity apps that you use every day, such as Word and PowerPoint.\nFor an overview of how these three components work together, see\nMicrosoft 365 Copilot overview\n. For links to other content related to Microsoft 365 Copilot, see\nMicrosoft 365 Copilot documentation\n.\nImportant\nMicrosoft 365 Copilot, including\nMicrosoft 365 Copilot Search\n, is compliant with our existing privacy, security, and compliance commitments to Microsoft 365 commercial customers, including the General Data Protection Regulation (GDPR) and European Union (EU) Data Boundary.\nPrompts, responses, and data accessed through Microsoft Graph aren't used to train foundation LLMs, including those used by Microsoft 365 Copilot.\nMicrosoft 365 Copilot operates with multiple protections, which include, but aren't limited to,\nblocking harmful content\n,\ndetecting protected material\n, and\nblocking prompt injections (jailbreak attacks)\n.\nAnthropic models within Microsoft 365 Copilot experiences are provided under the Microsoft Product Terms and Data Protection Addendum. Anthropic models have built-in protections, instantiated and operated by Anthropic, to help prevent harmful content from being returned in prompt responses.\nLearn more about Anthropic's safeguards.\nAnthropic models are out of scope for the EU Data Boundary and when available, in-country LLM processing commitments. For more information, see\nAnthropic as a subprocessor for Microsoft Online Services\n.\nThe information in this article is intended to help provide answers to the following questions:\nHow does Microsoft 365 Copilot use your proprietary organizational data?\nHow does Microsoft 365 Copilot protect organizational information and data?\nWhat data is stored about user interactions with Microsoft 365 Copilot?\nWhat data residency commitments does Microsoft 365 Copilot make?\nWhat extensibility options are available for Microsoft 365 Copilot\nHow does Microsoft 365 Copilot meet regulatory compliance requirements?\nDo privacy controls for connected experiences in Microsoft 365 Apps apply to Microsoft 365 Copilot?\nCan I trust the content that Microsoft 365 Copilot creates? Who owns that content?\nWhat are Microsoft's commitments to using AI responsibly?\nNote\nMicrosoft 365 Copilot will continue to evolve over time with new capabilities. To keep up to date on Microsoft 365 Copilot or ask questions, visit the\nMicrosoft 365 Copilot community\non the Microsoft Tech Community.\nHow does Microsoft 365 Copilot use your proprietary organizational data?\nMicrosoft 365 Copilot provides value by connecting LLMs to your organizational data. Microsoft 365 Copilot accesses content and context through Microsoft Graph. It can generate responses anchored in your organizational data, such as user documents, emails, calendar, chats, meetings, and contacts. Microsoft 365 Copilot combines this content with the userâs working context, such as the meeting a user is in now, the email exchanges the user had on a topic, or the chat conversations the user had last week. Microsoft 365 Copilot uses this combination of content and context to help provide accurate, relevant, and contextual responses.\nImportant\nPrompts, responses, and data accessed through Microsoft Graph aren't used to train foundation LLMs, including those used by Microsoft 365 Copilot.\nMicrosoft 365 Copilot only surfaces organizational data to which individual users have at least view permissions. It's important that you're using the permission models available in Microsoft 365 services, such as SharePoint, to help ensure the right users or groups have the right access to the right content within your organization. This includes permissions you give to users outside your organization through inter-tenant collaboration solutions, such as\nshared channels in Microsoft Teams\n.\nWhen you enter prompts using Microsoft 365 Copilot, the information contained within your prompts, the data they retrieve, and the generated responses remain within the Microsoft 365 service boundary, in keeping with our current privacy, security, and compliance commitments. Microsoft 365 Copilot uses Azure OpenAI services for processing, not OpenAIâs publicly available services. Azure OpenAI doesn't cache customer content and Copilot modified prompts for Microsoft 365 Copilot. For more information, see the\nData stored about user interactions with Microsoft 365 Copilot\nsection later in this article.\nNote\nWhen youâre using agents to help Microsoft 365 Copilot to provide more relevant information, check the privacy statement and terms of use of the agent to determine how it will handle your organizationâs data. For more information, see\nExtensibility of Microsoft 365 Copilot\n.\nWhen youâre using web search, Microsoft 365 Copilot parses the userâs prompt and identifies terms where web search would improve the quality of the response. Based on these terms, Copilot generates a search query that it sends to the Bing Search service. For more information,\nData, privacy, and security for web queries in Microsoft 365 Copilot and Microsoft 365 Copilot Chat\n.\nStarting January 7, 2026, Anthropic is a subprocessor for Microsoft 365 Copilot. For more information, see\nAnthropic as a subprocessor for Microsoft Online Services\n.\nWhile abuse monitoring, which includes human review of content, is available in Azure OpenAI, Microsoft 365 Copilot services have opted out of it. For information about content filtering, see the\nHow does Copilot block harmful content?\nsection later in this article.\nNote\nWe may use customer feedback, which is optional, to improve Microsoft 365 Copilot, just like we use customer feedback to improve other Microsoft 365 services and Microsoft 365 productivity apps. We don't use this feedback to train the foundation LLMs used by Microsoft 365 Copilot. Customers can manage feedback through admin controls. For more information, see\nManage Microsoft feedback for your organization\nand\nProviding feedback about Microsoft Copilot with Microsoft 365 apps\n.\nData stored about user interactions with Microsoft 365 Copilot\nWhen a user interacts with Microsoft 365 Copilot (using apps such as Word, PowerPoint, Excel, OneNote, Loop, or Whiteboard), we store data about these interactions. The stored data includes the user's prompt and Copilot's response, including citations to any information used to ground Copilot's response. We refer to the userâs prompt and Copilotâs response to that prompt as the \"content of interactions\" and the record of those interactions is the userâs Copilot activity history. For example, this stored data provides users with Copilot activity history in\nMicrosoft 365 Copilot Chat\n(previously named Business Chat) and\nmeetings in Microsoft Teams\n. This data is processed and stored in alignment with contractual commitments with your organizationâs other content in Microsoft 365. The data is encrypted while it's stored and isn't used to train foundation LLMs, including those used by Microsoft 365 Copilot.\nTo view and manage this stored data, admins can use Content search or Microsoft Purview. Admins can also use Microsoft Purview to set retention policies for the data related to chat interactions with Copilot. For more information, see the following articles:\nOverview of Content search\nMicrosoft Purview data security and compliance protections for generative AI apps\nLearn about retention for Copilot\nFor Microsoft Teams chats with Copilot, admins can also use\nMicrosoft Teams Export APIs\nto view the stored data.\nDeleting the history of user interactions with Microsoft 365 Copilot\nYour users can delete their Copilot activity history, which includes their prompts and the responses Copilot returns, by going to the\nMy Account portal\n. For more information, see\nDelete your Microsoft 365 Copilot activity history\n.\nMicrosoft 365 Copilot and the EU Data Boundary\nMicrosoft 365 Copilot calls to the LLM are routed to the closest data centers in the region, but also can call into other regions where capacity is available during high utilization periods.\nFor European Union (EU) users, we have additional safeguards to comply with the\nEU Data Boundary\n. EU traffic stays within the EU Data Boundary while worldwide traffic can be sent to the EU and other countries or regions for LLM processing.\nMicrosoft 365 Copilot and data residency\nMicrosoft 365 Copilot is upholding data residency commitments as outlined in the Microsoft Product Terms and Data Protection Addendum. Microsoft 365 Copilot was added as a covered workload in the data residency commitments in Microsoft Product Terms on March 1, 2024.\nMicrosoft\nAdvanced Data Residency (ADR)\nand\nMulti-Geo Capabilities\nofferings include data residency commitments for Microsoft 365 Copilot customers as of March 1, 2024. For EU customers, Microsoft 365 Copilot is an EU Data Boundary service. Customers outside the EU may have their queries processed in the US, EU, or other regions.\nExtensibility of Microsoft 365 Copilot\nWhile Microsoft 365 Copilot is already able to use the apps and data within the Microsoft 365 ecosystem, many organizations still depend on various external tools and services for work management and collaboration. Microsoft 365 Copilot experiences can reference third-party tools and services when responding to a userâs request by using\nMicrosoft Graph connectors\nor agents. Data from Graph connectors can be returned in Microsoft 365 Copilot responses if the user has permission to access that information.\nWhen agents are enabled, Microsoft 365 Copilot determines whether it needs to use a specific agent to help provide a relevant response to the user. If an agent is needed, Microsoft 365 Copilot generates a search query to send to the agent on the userâs behalf. The query is based on the userâs prompt, Copilot activity history, and data the user has access to in Microsoft 365.\nIn the\nIntegrated apps\nsection of the\nMicrosoft 365 admin center\n, admins can view the permissions and data access required by an agent as well as the agentâs terms of use and privacy statement. Admins have full control to select which agents are allowed in their organization. A user can only access the agents that their admin allows and that the user installed or is assigned. Microsoft 365 Copilot only uses agents that are turned on by the user.\nFor more information, see the following articles:\nManage agents for Microsoft 365 Copilot in the Microsoft 365 admin center\nMicrosoft 365 Copilot extensibility overview\nHow Microsoft 365 Copilot can work with your external data\nHow does Microsoft 365 Copilot protect organizational data?\nThe permissions model within your Microsoft 365 tenant can help ensure that data won't unintentionally leak between users, groups, and tenants. Microsoft 365 Copilot presents only data that each individual can access using the same underlying controls for data access used in other Microsoft 365 services. Semantic Index honors the user identity-based access boundary so that the grounding process only accesses content that the current user is authorized to access. For more information, see Microsoftâs\nprivacy policy and service documentation\n.\nWhen you have data that's encrypted by Microsoft Purview Information Protection, Microsoft 365 Copilot honors the usage rights granted to the user. This encryption can be applied by\nsensitivity labels\nor by restricted permissions in apps in Microsoft 365 by using Information Rights Management (IRM). For more information about using Microsoft Purview with Microsoft 365 Copilot, see\nMicrosoft Purview data security and compliance protections for generative AI apps\n.\nWe already implement multiple forms of protection to help prevent customers from compromising Microsoft 365 services and applications or gaining unauthorized access to other tenants or the Microsoft 365 system itself. Here are some examples of those forms of protection:\nLogical isolation of customer content within each tenant for Microsoft 365 services is achieved through Microsoft Entra authorization and role-based access control. For more information, see\nMicrosoft 365 isolation controls\n.\nMicrosoft uses rigorous physical security, background screening, and a multi-layered encryption strategy to protect the confidentiality and integrity of customer content.\nMicrosoft 365 uses service-side technologies that encrypt customer content at rest and in transit, including BitLocker, per-file encryption, Transport Layer Security (TLS), and Internet Protocol Security (IPsec). For specific details about encryption in Microsoft 365, see\nEncryption in the Microsoft Cloud\n.\nYour control over your data is reinforced by Microsoft's commitment to comply with broadly applicable privacy laws, such as the GDPR, and privacy standards, such as ISO/IEC 27018, the worldâs first international code of practice for cloud privacy.\nFor content accessed through Microsoft 365 Copilot agents, encryption can exclude programmatic access, thus limiting the agent from accessing the content. For more information, see\nConfigure usage rights for Azure Information Protection\n.\nMeeting regulatory compliance requirements\nMicrosoft continues to adapt and respond to fulfill AI regulatory requirements as they evolve, so we earn and keep the trust of customers, partners, and regulators.\nMicrosoft 365 Copilot provides broad compliance offerings and certifications, including\nGDPR\n,\nISO 27001\n,\nHIPAA\n, and the\nISO 42001 standard for AI management systems\n. These help support our customers on their compliance journeys, complemented by features such as contractual readiness, built-in information and communication technology risk management, and operational resilience tooling.\nMicrosoft is committed to complying with all laws and regulations applicable to Microsoft, including the EU AI Act, to enable our AI solutions to meet evolving standards for trustworthy and responsible AI. Microsoft 365 Copilot is built on top of\nMicrosoftâs existing commitments to data security and privacy\n. There's no change to these commitments. Copilot is integrated into Microsoft 365 and adheres to existing privacy, security, and compliance commitments to Microsoft 365 customers.\nAdditionally, we prioritize open dialogue with our partners and regulatory authorities. We provide customers with direct access to Microsoft compliance professionals, proactive guidance, and curated solutions to help navigate regulatory compliance, such as the\nMicrosoft 365 Copilot & Copilot Chat Risk Assessment Quickstart\n. Our approach in the AI-driven landscape aims to empower organizations to innovate confidently with solutions built with transparency, privacy, and security in mind.\nAdditional information\nMicrosoft 365 Copilot and privacy controls for connected experiences\nSome privacy controls for connected experiences in Microsoft 365 Apps can affect the availability of Microsoft 365 Copilot features. This includes the privacy controls for connected experiences that analyze your content and the privacy control for optional connected experiences. For more information about these privacy controls, see\nOverview of privacy controls for Microsoft 365 Apps for enterprise\n.\nPrivacy control for connected experiences that analyze your content\nIf you turn off connected experiences that analyze your content on devices in your organization, Microsoft 365 Copilot features wonât be available to your users in the following apps:\nExcel\nOneNote\nOutlook\nPowerPoint\nWord\nThis applies to when youâre running the most current version of these apps on Windows, Mac, iOS, or Android devices.\nThere's also a privacy control that turns off all connected experiences, including connected experiences that analyze your content. If you use that privacy control, Microsoft 365 Copilot features wonât be available in the apps and on the devices described above.\nPrivacy control for optional connected experiences\nIf you turn off optional connected experiences in your organization, Microsoft 365 Copilot features that are optional connected experiences wonât be available to your users. For example, turning off optional connected experiences could affect the availability of\nweb search\n.\nThere's also a privacy control that turns off all connected experiences, including optional connected experiences. If you use that privacy control, Microsoft 365 Copilot features that are optional connected experiences wonât be available.\nAbout the content that Microsoft 365 Copilot creates\nThe responses that generative AI produces aren't guaranteed to be 100% factual. While we continue to improve responses, users should still use their judgment when reviewing the output before sending them to others. Our Microsoft 365 Copilot capabilities provide useful drafts and summaries to help you achieve more while giving you a chance to review the generated AI rather than fully automating these tasks.\nWe continue to improve algorithms to proactively address issues, such as misinformation and disinformation, content blocking, data safety, and preventing the promotion of harmful or discriminatory content in line with our\nresponsible AI principles\n.\nMicrosoft doesn't claim ownership of the output of the service. That said, we don't make a determination on whether a customerâs output is copyright protected or enforceable against other users. This is because generative AI systems may produce similar responses to similar prompts or queries from multiple customers. Consequently, multiple customers may have or claim rights in content that is the same or substantially similar.\nIf a third party sues a commercial customer for copyright infringement for using Microsoftâs Copilots or the output they generate, we'll defend the customer and pay the amount of any adverse judgments or settlements that result from the lawsuit, as long as the customer used the guardrails and content filters we have built into our products. For more information, see\nMicrosoft announces new Copilot Copyright Commitment for customers\n.\nHow does Copilot block harmful content?\nTo help block harmful content, Microsoft 365 Copilot uses safeguards that work alongside AI models used to generate responses. Depending on the scenario, these safeguards may include Microsoft firstâparty protections or, in some cases, safety mitigations built into the underlying model. These safeguards use a defense-in-depth approach and can include a mix of Microsoft first-party protections that help detect and reduce jailbreak attempts and prompt injection patterns (including cross-prompt injection attacks), content harm filters to identify harmful content in prompts or generated responses (such as Hate & Fairness, Sexual, Violence, and Self-harm), or in some scenarios, safety mitigations built into the underlying model.\nHate and fairness-related harms refer to any content that uses pejorative or discriminatory language based on attributes like race, ethnicity, nationality, gender identity and expression, sexual orientation, religion, immigration status, ability status, personal appearance, and body size. Fairness is concerned with making sure that AI systems treat all groups of people equitably without contributing to existing societal inequities. Sexual content involves discussions about human reproductive organs, romantic relationships, acts portrayed in erotic or affectionate terms, pregnancy, physical sexual acts, including those portrayed as an assault or a forced act of sexual violence, prostitution, pornography, and abuse. Violence describes language related to physical actions that are intended to harm or kill, including actions, weapons, and related entities. Self-harm language refers to deliberate actions that are intended to injure or kill oneself.\nIn addition to content filtering provided by the Azure OpenAI Service, certain Microsoft 365 Copilot scenarios provide other mitigations, such as filters to help prevent workplace harms from happening. Workplace harms refers to a category of harms that can result from generative AI or models making inferences, judgments, or evaluations about an employee based on their workplace communication. Currently, that means inferences, judgments, or evaluations about an employee's performance, attitude, internal or emotional state, or personal characteristics. We restrict the use of generative AI or models from being used for these purposes.\nDoes Copilot provide protected material detection?\nYes, Microsoft 365 Copilot provides detection for protected materials, which includes text subject to copyright and code subject to licensing restrictions. This detection may not be available in all Microsoft 365 Copilot scenarios, and not all of these mitigations are relevant for all Microsoft 365 Copilot scenarios.\nDoes Copilot block prompt injections (jailbreak attacks)?\nJailbreak attacks are prompts designed to bypass Copilot's safeguards or induce non-compliant behavior. Microsoft 365 Copilot helps mitigate these attacks by using proprietary techniques, such as jailbreak and cross-prompt injection attack (XPIA) classifiers. These classifiers analyze inputs to the Copilot service and help block high-risk prompts prior to model execution. These classifiers may not be available in all Microsoft 365 Copilot scenarios.\nWhat happens when foundation model changes occur?\nThe AI models that power Microsoft 365 Copilot are regularly updated and enhanced. Model updates bring performance improvements, more advanced reasoning, and expanded capabilities, but they don't change your security, privacy, or compliance settings. For more information, see\nMicrosoft 365 Blog: Understanding foundation model changes in Microsoft 365 Copilot\n.\nCommitted to responsible AI\nAs AI is poised to transform our lives, we must collectively define new rules, norms, and practices for the use and impact of this technology. Microsoft has been on a Responsible AI journey since 2017, when we defined our principles and approach to ensuring this technology is used in a way that is driven by ethical principles that put people first.\nAt Microsoft, we're guided by our\nAI principles\n, our\nResponsible AI Standard\n, and decades of research on AI, grounding, and privacy-preserving machine learning. A multidisciplinary team of researchers, engineers, and policy experts reviews our AI systems for potential harms and mitigations â refining training data, filtering to limit harmful content, query- and result-blocking sensitive topics, and applying Microsoft technologies like\nInterpretML\nand\nFairlearn\nto help detect and correct data bias. We make it clear how the system makes decisions by noting limitations, linking to sources, and prompting users to review, fact-check, and adjust content based on subject-matter expertise. For more information, see\nGoverning AI: A Blueprint for the Future\n.\nWe aim to help our customers use our AI products responsibly, sharing our learnings, and building trust-based partnerships. For these new services, we want to provide our customers with information about the intended uses, capabilities, and limitations of our AI platform service, so they have the knowledge necessary to make responsible deployment choices. We also share resources and templates with developers inside organizations and with independent software vendors (ISVs), to help them build effective, safe, and transparent AI solutions.\nRelated articles\nMicrosoft 365 Copilot requirements\nGet started with Microsoft 365 Copilot\nMicrosoft 365 Copilot adoption site\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data, Privacy, and Security",
      "section": "Microsoft 365 Copilot"
    },
    "https://learn.microsoft.com/en-us/microsoft-365-copilot/microsoft-365-copilot-enable-users": {
      "content_hash": "sha256:7a8dbbc75f0ae1c5204e52615fb8a4fcc731000306efc07704255f293cf1e14c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWelcome users, create organizational messages, and enable feedback for Microsoft 365 Copilot\nFeedback\nSummarize this article for me\nMicrosoft 365 Copilot\nis an AI-powered productivity tool that helps users with everyday tasks.\nAs part of your\nMicrosoft 365 Copilot adoption\n, a welcome email to your Microsoft 365 Copilot users is sent on license assignment that announces Microsoft 365 Copilot and its features. You can also enable feedback for Microsoft 365 Copilot users.\nAdditionally, admins can use Organizational Messaging in the Microsoft Admin Center to deliver tailored in-product messages to your users directly through Teams.\nThis article provides information about how to send users a welcome email, enable feedback, send organizational messages, and review the Microsoft 365 Copilot usage activity report.\nThis article applies to:\nMicrosoft 365 Copilot\nSend welcome email\nAfter you assign a Microsoft 365 Copilot license to a user, they will automatically be sent a notification email that can look like the following email.\nThe welcome email also includes a link to\nMicrosoft Copilot help and learning\n.\nWe also recommend sending an in-product notification to your users through Organizational Messaging.\nOrganizational Messages\nAdmins can also send a customizable in-product message through Teams with Organizational Messaging in the Microsoft Admin Center. After you\nset up Microsoft 365 Copilot and assign licenses\nto your users, they can be notified with your message in-product telling them that they can now use Microsoft 365 Copilot.\nAdmins can configure their message through the Microsoft 365 admin center.\nIn your Microsoft 365 admin center, in the navigation pane, select\nSetup\n.\nOn the Setup page, in the\nFeatured collections\nsection, select\nAdvanced deployment guides & assistance\n.\nSelect\nSet up Microsoft 365 Copilot\n.\nOn the\nSet up Microsoft 365 Copilot\npage, in the\nPromote using Microsoft 365 Copilot\ntile, select\nSchedule message\n.\nNote\nThe\nPromote using Microsoft 365 Copilot\noption is also available in Advanced Deployment Guides for\nQuickstart\n,\nFoundations+\n, and\nAdvanced Configuration\n.\nThe Organization messages pane displays and shows the default message and how it will dsiplay to your users. If you choose to use it, select the recipients, schedule when and how regularly you want the message to be delivered to your users, and then select\nSchedule message\n.\nCreate a custom message\nIf you want to create a custom message instead of using the default one provided to you, at the bottom of the Organizational messages pane, select\nMore customization\n. You can then create and deliver messages to targeted groups of users in your organization.\nSelect\nCreate a message\n.\nSelect an objective (for example, Adoption, Onboarding, Sustainability, or Training). Select\nNext\n.\nSelect where you would like your message to display (for example, Notifications area, Taskbar, Teaching popover, or Windows spotlight). Select\nNext\n.\nChoose to create your own message or start with a premade template. Select\nNext\n.\nWrite your message, then select\nNext\n.\nSelect your target audience, then select\nNext\n.\nSchedule how long and how often you want your message to appear to your recipients. Select\nNext\n.\nReview your selections, and then select\nSchedule\n.\nEnable feedback\nWe recommend that you enable all feedback settings for the Microsoft 365 Apps.\nThis option allows Microsoft 365 Copilot users to provide details with a thumbs up or thumbs down reaction to a Copilot prompt response.\nTo enable the feedback for your users, you can use the\ncloud policy service\nor group policies.\nWhen all the policies are enabled, users can provide logs, screenshots, and a contact email address for their feedback submission.\nReview the Copilot usage activity report\nAfter your users start using Copilot, we recommend running and reviewing the\nMicrosoft 365 Copilot usage report\n. This report summarizes user adoption, retention, and engagement with Microsoft 365 Copilot.\nThe report is in the\nMicrosoft 365 admin center\n>\nReports\n>\nUsage\n.\nTo learn more about the Microsoft 365 Copilot reports, see\nMicrosoft 365 Copilot reporting options for admins\n.\nRelated articles\nMicrosoft 365 Copilot adoption guide and overview for IT admins\nAdvanced deployment guides for Microsoft 365 and Office 365 products\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Manage Copilot",
      "section": "Microsoft 365 Copilot"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/admin/manage/manage-copilot-agents-integrated-apps": {
      "content_hash": "sha256:0023d2e688005426af07782f79b56cdc5833718d59711e4d497b3130e27c11d3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage Copilot agents in the Microsoft 365 admin center\nFeedback\nSummarize this article for me\nImportant\nThis article is intended for IT administrators.\nThe capability is enabled by default in all Microsoft 365 Copilot licensed tenants.\nMicrosoft 365 Copilot combines the power of large language models with your data and apps in Microsoft 365. It captures natural language commands to produce content and analyze data. It enables access to and use of other apps, such as Jira,\nDynamics 365\n, or Bing Web Search.\nYou can manage agents for Copilot by using the\nMicrosoft 365 admin center\n. You can enable, disable, assign, block, or remove agents for your organization, and manage Copilot capabilities.\nNote\nResearcher and Analyst are first-party Microsoft experiences built on the same foundation as Microsoft 365 Copilot, operating entirely within the Microsoft 365 commercial data processing boundary. These tools inherit all existing security, privacy, and compliance commitments that apply across the suite of Microsoft 365 products. These tools are available in Microsoft 365 Copilot Chat under\nTools\nand can be invoked by the user anytime. While Researcher and Analyst coexist with agents and abide by all the agent-related governance capabilities, Researcher and Analyst are part of the core Copilot chat experience and will not fall under any agent-related settings. For related information, see\nAgent settings in Microsoft 365 admin center\n.\nMicrosoft Agent 365 is the control plane for AI agents, empowering your organization to confidently deploy, govern, and manage all your agents at scale, regardless of where these agents are built or acquired. For more information, see\nOverview of Microsoft Agent 365\nand\nMicrosoft Agent 365 documentation\n.\nOverview\nAgents enhance the functionality of Copilot by adding search capabilities, custom actions, connectors, and APIs. Agents are custom versions of Microsoft 365 Copilot that combine instructions, knowledge, and skills to perform specific tasks or scenarios. For more information, see\nGet started with agents for Microsoft 365 Copilot\n.\nHowever, before users can access these agents, the agents must undergo a streamlined process of submission and approval. To learn more, see\nPublish agents\n.\nThe hub Copilot experience shows the list of agents that are available and deployed for the user. Users can toggle it on or off to restrict access of Copilot to any specific agents during the interaction. Users can also add or remove agents in their Copilot experience by right-clicking on the agents and selecting the appropriate option. Users can only access the agents that the admin allows and that they install or are assigned to.\nAgent types you can manage\nYou can manage several types of agents in Microsoft 365 Copilot, each serving different purposes:\nPublished by your organization\n:â¯Built with predefined instructions and actions. These agents follow structured logic and are best for predictable, rule-based tasks. Before agents become available to users, these agents go through an admin approval and publishing process to ensure compliance and readiness.\nNote\nPublishing agents to the organization is supported in Microsoft 365 Government Community Cloud High (GCCH) and Government Community Cloud Moderate (GCCM) environments.\nShared by creator\n:â¯Shared agents are custom versions of Microsoft 365 Copilot that combine instructions, knowledge, and skills to perform specific tasks or scenarios. Creators can create and share these agents through multiple channels, such as Microsoft 365 Copilot Studio, Microsoft 365 Copilot Agent Builder, and more. Shared agents enhance the functionality of Copilot by adding search capabilities, custom actions, connectors, and APIs. For more information, see\nShare agents with other users\n.\nAs an admin, you can view shared agents on the\nAgents\npage in the Microsoft 365 admin center. You can see a list of all shared agents, including details such as the agent's name, creator, creation date, host products, and availability status. You can search for specific agents and manage their lifecycle, including blocking agents that are deemed unsafe or noncompliant.\nFor your users, shared agents are available through Copilot on different surfaces. Users can interact with these agents to perform specific tasks or get assistance based on the agent's capabilities.\nMicrosoft agents\n:â¯Developed by Microsoft and integrated with Microsoft 365 services.\nExternal partner agents\n:â¯Created by external developers or vendors. You can control their availability and permissions.\nFrontier agents\n:â¯Experimental or advanced agents that use new capabilities or integrations. These agents might be in early stages of development or testing and could require more oversight or limited rollout.\nApp Builder agent\n: A type of Frontier agent developed by Microsoft that can be managed as part of Microsoft 365 Copilot. You can also manage App Builder using\nPower Platform admin center\n.\nWorkflows agent\n: A type of Frontier agent developed by Microsoft that can be managed as part of Microsoft 365 Copilot. Flows created in Copilot are saved to the default environment unless\nenvironment routing\nis enabled for Copilot Studio. You can also manage flows using the\nPower Platform admin center\n.\nGet started\nThe following administrator roles can manage agents in the Microsoft 365 admin center:\nAI Admin\nGlobal Reader (view-only, no edit)\nImportant\nUse roles with the fewest permissions. Accounts with lower permissions help improve security for your organization. Global Administrator is a highly privileged role. Limit its use to emergency scenarios when you can't use an existing role. For more information, see\nAbout admin roles in the Microsoft 365 admin center\n.\nYou can manage agents in the\nMicrosoft 365 admin center\nby using the\nAgents\npage. On this page, you can:\nView available, deployed, or blocked agents.\nConfigure agent availability and access.\nPerform actions such as publishing, deploying, blocking, or removing agents.\nRelated articles\nAgent 365 Overview in the Microsoft 365 admin center\n.\nAgent Registry in the Microsoft 365 admin center\n.\nAgent Settings in Microsoft 365 admin center\n.\nManage agent instances in Microsoft 365 admin center\n.\nManage Connected Agents for Researcher in the Microsoft 365 admin center\n.\nManage Tools for Agent 365 in the Microsoft 365 admin center\nOverview of Microsoft Agent 365\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Manage Copilot Agents",
      "section": "Microsoft 365 Copilot"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/admin/activity-reports/microsoft-365-copilot-usage": {
      "content_hash": "sha256:29dbf02e0d759e30fb60cda2992c6657714646ed5f83c8e85b9762a6b750e2bc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft 365 reports in the admin center â Microsoft 365 Copilot usage\nFeedback\nSummarize this article for me\nThe Microsoft 365 Usage page shows you the activity overview across the Microsoft 365 productivity apps in your organization. It enables you to drill into individual product-level reports to give you granular insight about the activities within each app. To view all reports, check out the\nReports overview article\n.\nIn the Microsoft 365 Copilot usage report, which is in continuous enhancement, you can view a summary of how users' adoption, retention, and engagement are with Microsoft 365 Copilot and its associated enabled apps, including agent usage. For Copilot activity on a given day, the report becomes available typically within 72 hours of the end of that day (in UTC).\nHow do I get to the Microsoft 365 Copilot usage report?\nIn the admin center, go to\nReports\n>\nUsage\n.\nSelect the\nMicrosoft 365 Copilot\npage.\nSelect the Usage tab to view adoption and usage metrics.\nInterpret the Microsoft 365 Copilot usage report\nYou can use this report to see the usage of Microsoft 365 Copilot in your organization.\nAt the top, you can filter by different timeframes. The Microsoft 365 Copilot report can be viewed over the last 7 days, 30 days, 90 days, or 180 days.\nYou can view several numbers for Microsoft 365 Copilot usage, which highlight the enablement number and the adoption of the enablement:\nEnabled Users\nshows the total number of unique users in your organization with Microsoft 365 Copilot licenses over the selected timeframe.\nActive Users\nshows the total number of enabled users in your organization who tried a user-initiated Microsoft 365 Copilot feature, in one or more apps in Microsoft 365 over the selected timeframe.\nActive users rate\nshows you the number of active users in your organization divided by the number of enabled users.\nIn\nRecommendations\n, the recommended action card highlights\nMicrosoft Copilot Dashboard\n, where you can deliver insights to your IT leaders to explore Copilot readiness, adoption, and impact in Viva Insights.\nActive agent users\nshows you the total number of unique Microsoft 365 Copilot users in your org who used agents built by your org (including admin-approved agents and agents created via agent builderâ¯and shared with users in your org).\nNote\nAgent usage is available starting November 1, 2024, and is currently limited to agents built by your org. Usage of agents built by Microsoft and Microsoft Partners will be introduced in the coming months.\nTotal prompts submitted\nshows you the total number of prompts users sent to Microsoft 365 Copilot Chat during the selected time frame.\nAverage prompts submitted per user\nrepresents the mean number of prompts each active user sent to Microsoft 365 Copilot Chat during the selected timeframe.\nIn the\nAdoption\nsection,\nAdoption by app\nshows enabled users and active users of Copilot in Microsoft 365 apps.\nYou can see the following summary charts in this report as default view:\nThe definitions for Enabled Users and Active Users metrics are the same as provided earlier.\nSummary view\nshows you the total usage of Microsoft 365 Copilot apps of the time frame.\nTrend view\nshows you the daily time trend of Microsoft 365 Copilot apps of the time frame.\nWhen switching to\nTrend\nview, you can select one product in the dropdown list to see daily usage.\nIn the\nPrompts submitted\nsection,\nSummary view\nshows the total number of prompts users submitted to Microsoft Copilot Chat over the selected time frame.\nTrend view\nshows the daily trend of prompts submitted in Microsoft 365 Copilot over the selected time frame.\nCopilot Chat adoption\nshows enabled users and total usage of Copilot Chat and split usage between Copilot Chat (work) and Copilot Chat (web).\nAgent adoption\nshows active users of agents in Microsoft 365 Copilot for the selected period. Only usage of agents created by your org, including both admin-approved agents and agents shared by users in your org, are included in this chart.\nSummary view\nshows the total number of agent users in Microsoft 365 Copilot over the selected time frame.\nTrend view\nshows the daily trend of active agent users in Microsoft 365 Copilot over the selected time frame.\nThe following table lists the features included for active users of Copilot apps:\nCopilot app\nFeatures\nHow to use\nLearn more about the feature\nMicrosoft Edge\nCopilot Chat (web)\nTyping a message into the chat window or selecting a suggested prompt and submitting. Or selecting âAsk Copilotâ in the right-click of contextual web info.\nCopilot - Microsoft Edge\nCopilot Chat (work)\nTyping a message into the chat window or selecting a suggested prompt and submitting.\nCopilot - Microsoft Edge\nMicrosoft 365 Copilot (app)\nCopilot Chat (web)\nTyping a message into the chat window or selecting a suggested prompt and submitting.\nGet started with Microsoft 365 Copilot Chat\nCopilot Chat (work)\nTyping a message into the chat window or selecting a suggested prompt and submitting.\nGet started with Microsoft 365 Copilot Chat\nOutlook\nSummarize an Outlook email thread\nIn an email thread, selecting\nSummarize by Copilot or Summarize\nat the top of the email thread. (User experience is slightly different among web, Windows, Mac, or mobile.)\nSummarize an email thread with Copilot in Outlook - Microsoft Support\nGenerate an Outlook email draft\nSelecting Copilot icon from the toolbar, selecting\nDraft with Copilot\n, typing prompt in Copilot box and submitting. (User experience is slightly different among web, Windows, Mac, or mobile.)\nDraft an email message with Copilot in Outlook - Microsoft Support\nCoach\nSelecting Copilot icon in the email message, choosing\nCoaching by Copilot\nand Copilot reviews email and offers suggestions on improving the tone, clarity, and reader sentiment. (User experience is slightly different among web, Windows, Mac, or mobile.)\nEmail coaching with Copilot in Outlook - Microsoft Support\nCopilot Chat (work)\nGoing to the left side of Outlook web app, selecting Copilot from the apps list, typing a prompt and sending. This feature is included in the Outlook app level and all up Microsoft 365 active usage count effective August 28, 2024.\nGet started with Microsoft 365 Copilot Chat\nCopilot Chat (web)\nGoing to the left navigation of Outlook app, selecting Copilot from the apps list and select âWebâ option at the top of the chat pane, typing a prompt into the chat window or selecting a suggested prompt and submitting. This feature is included in the Outlook app level and all up Microsoft 365 active usage count effective July 01, 2025.\nGet started with Microsoft 365 Copilot Chat\nApp Chat\nGoing to top right corner of Outlook web app, selecting Copilot placed next to settings option, typing a prompt and sending. This feature is included in the Outlook app level and all up Microsoft 365 active usage count effective August 17, 2024.\nFrequently asked questions about Copilot in Outlook\nTeams\nSummarizing key points during meetings\nSummarizing key discussion points during meeting using Copilot in Microsoft Teams.\nGet started with Copilot in Microsoft Teams meetings - Microsoft Support\nSummarize chats and channel conversations\nTyping a prompt or selecting a prompt from 'More prompts' in Copilot compose box in a chat or channel and submitting.\nUse Copilot in Microsoft Teams chat and channels - Microsoft Support\nRewrite and adjust messages\nWriting a message in message box, selecting\nRewrite/Adjust\nin Copilot beneath the message box to rewrite/adjust the whole/specific selection of the message.\nRewrite and adjust your messages with Copilot in Microsoft Teams - Microsoft Support\nIntelligent Recap\nSelecting\nRecap\ntab in the meeting chat for Teams calendar event and viewing the AI Notes section after the meeting ends (meeting is recorded and transcribed).\nGet started with Microsoft 365 Copilot in Teams - Microsoft Support\nCopilot Chat (work)\nGoing to Chat on the left side of Teams, selecting Copilot from the top of your Teams chat list, typing a prompt and sending.\nGet started with Microsoft 365 Copilot in Teams - Microsoft Support\nCopilot Chat (web)\nGoing to the left navigation of Teams application, selecting Copilot from the apps list and select âWebâ option at the top of the chat pane, typing a prompt into the chat window or selecting a suggested prompt and submitting. This feature is included in the Teams app level and all up Microsoft 365 active usage count effective July 01, 2025.\nGet started with Microsoft 365 Copilot in Teams - Microsoft Support\nWord\nAll Copilot in Word features are automatically included in the Microsoft 365 Copilot usage report. Usage of any Copilot in Word feature counts towards the Active users metric and is indicated in the per-user Last activity date (UTC).\nTo learn more about Copilot in Word features, refer to\nWelcome to Copilot in Word - Microsoft Support\n.\nExcel\nAll Copilot in Excel features are automatically included in the Microsoft 365 Copilot usage report. Usage of any Copilot in Excel feature counts towards the Active users metric and is indicated in the per-user Last activity date (UTC).\nTo learn more about Copilot in Excel features, refer to\nGet started with Copilot in Excel - Microsoft Support\n.\nPowerPoint\nAll Copilot in PowerPoint features are automatically included in the Microsoft 365 Copilot usage report. Usage of any Copilot in PowerPoint feature counts towards the Active users metric and is indicated in the per-user Last activity date (UTC).\nTo learn more about Copilot in PowerPoint features, refer to\nWelcome to Copilot in PowerPoint - Microsoft Support\n.\nOneNote\nAll Copilot in OneNote features are automatically included in the Microsoft 365 Copilot usage report. Usage of any Copilot in OneNote feature counts towards the Active users metric and is indicated in the per-user Last activity date (UTC).\nTo learn more about Copilot in OneNote features, refer to\nWelcome to Copilot in OneNote - Microsoft Support\n.\nLoop\nAll Copilot in Loop features are automatically included in the Microsoft 365 Copilot usage report. Usage of any Copilot in Loop feature counts towards the Active users metric and is indicated in the per-user Last activity date (UTC).\nTo learn more about Copilot in Loop features, refer to\nGet started with Microsoft 365 Copilot in Loop - Microsoft Support\n.\nTo note, Active users of Word, Excel, and PowerPoint is incomplete prior to January 25, 2024.\nThe following table lists the features included for active users of agents:\nFeature\nHow to use\nLearn more about the feature\nUX interactions that count towards agent usage\nEnd-users can interact with agents in two ways:\n1. by at-mentioning the agent in a chat experience or\n2. by selecting the agent from the right-side panel in Copilot Chat or from the menu icon in the top left corner in Copilot in Word or PowerPoint.\nAn active user of an agent is a user who sends a prompt request to an agent and receives a response\nLearn about\nGetting started with agents for Microsoft 365 Copilot\nImportant\nThe metrics displayed in the Microsoft 365 Copilot usage report are powered by data that is classified as required service data. Optional diagnostic data isn't required for comprehensive information, although this might change in the future.\nLearn more about required service data\n.\nIn the\nAdoption\nsection, you might see a recommendation card:\nTo learn more about using organizational messages for Microsoft 365 Copilot, see\nMicrosoft 365 features adoption using organizational messages\n.\nYou can also export the report data into an Excel .csv file by selecting the ellipses and then\nExport\nin the top-right corner.\nYou can view a table list to show each Microsoft 365 Copilot enabled user's last activity date among Microsoft 365 Copilot apps.\nSelect\nChoose columns\nto add or remove columns from the table.\nYou can also export the report data into an Excel .csv file by selecting the\nExport\nlink. This link exports the Microsoft 365 Copilot usage data of all users and enables you to do simple sorting, filtering, and searching for further analysis.\nTo ensure data quality, we perform daily data validation checks for the past three days and fill any gaps detected. You might notice differences in historical data during the process.\nUser last activity table\nItem\nDescription\nUser name\nThe user's principal name.\nDisplay name\nThe full name of the user.\nPrompts submitted (any app)\nThe total number of prompts submitted by this user to Microsoft 365 Copilot Chat during the selected timeframe.\nCopilot Chat (work) prompts submitted\nThe total number of prompts submitted by this user to Copilot Chat (work) during the selected timeframe.\nCopilot Chat (web) prompts submitted\nThe total number of prompts submitted by this user to Copilot Chat (web) during the selected timeframe.\nActive Days\nThe total number of days the user submitted prompts to Microsoft 365 Copilot Chat within the selected timeframe.\nLast activity date (UTC (Universal Time Code))\nThe most recent date on which the user sent a message to Microsoft 365 Copilot Chat in Teams, Outlook, m365.cloud.microsoft/chat, Microsoft Edge, the Microsoft 365 Copilot (app), Word, Excel, PowerPoint, or OneNote. This date remains fixed even if the timeframe of the report is changed.â¯\nLast activity date of Teams Copilot (UTC)\nThe latest date the user had activity in Microsoft Teams Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Word Copilot (UTC)\nThe latest date the user had activity in Word Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Excel Copilot (UTC)\nThe latest date the user had activity in Excel Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of PowerPoint Copilot (UTC)\nThe latest date the user had activity in PowerPoint Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Outlook Copilot (UTC)\nThe latest date the user had activity in Outlook Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of OneNote Copilot (UTC)\nThe latest date the user had activity in OneNote Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Loop Copilot (UTC)\nThe latest date the user had activity in Loop Copilot, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Copilot Chat (work) (UTC)\nThe latest date the user had activity in Copilot Chat (work), including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Copilot Chat (web) (UTC)\nThe latest date the user had activity in Copilot Chat (web), including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Microsoft 365 App (UTC)\nThe latest date the user had activity in Copilot Chat in entry point Microsoft 365 App, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of Microsoft Edge (UTC)\nThe latest date the user had activity in Copilot Chat in entry point Microsoft Edge, including any of the intentional activities, regardless of the selected timeframe of past 7/30/90/180 days.\nLast activity date of any agent (UTC)\nThe latest date the user had activity with an agent built by your org, regardless of the selected timeframe of past 7/30/90/180 days.\nDisplay user-specific data\nBy default, usernames and display names in Copilot Search usage reports are anonymous. Global administrators can update the settings to reveal usernames and display names.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. This helps improve security for your organization. Global Administrator is a highly privileged role that should be limited to emergency scenarios when you can't use an existing role.\nIn the admin center, go to the\nSettings\n>\nOrg Settings\npage.\nSelect the\nServices\ntab, then select\nReports\n.\nIn the\nReports\npanel, select the checkbox next to\nDisplay Concealed user, group, and site names in all reports\n.\nSelect\nSave\n.\nFAQ\nHow is a user considered active in Microsoft 365 Copilot usage?\nA user is considered active in a given app if they performed an intentional action for an AI-powered capability. For example, if a user selects the Copilot icon in the Word ribbon to open the Copilot chat pane, this action doesn't count towards active usage. However, if the user interacts with the chat pane by submitting a prompt, this action would count towards active usage.\nWhat's the difference between the user activity table and audit log?\nThe audit log data that powers Microsoft Purview solutions, such as Data Security Posture Management for AI (previously called AI Hub), are built for data security and compliance purposes, and provide comprehensive visibility into Copilot interactions for these use cases. (For example, to discover data oversharing risks or to collect interactions for regulatory compliance or legal purposes). They aren't, however, intended to be used as the basis for Copilot usage reporting. Any aggregated metrics that customers build on top of this data, such as \"prompt count\" or \"active user count,\" might not be consistent with the corresponding data points in the official Copilot usage reports provided by Microsoft. Microsoft can't provide guidance on how to use audit log data as the basis for usage reporting, nor can Microsoft guarantee that aggregated usage metrics built on top of audit log data will match similar usage metrics reported in other tools.\nTo access accurate information on Microsoft 365 Copilot usage, use one of the following reports: the\nMicrosoft 365 Copilot usage report\nin the Microsoft 365 Admin Center or the\nCopilot Dashboard\nin Viva Insights.\nWhat's the scope of the user-level table?\nThe user-level table in the report is configured to show all users who were licensed for Microsoft 365 Copilot at any point over the past 180 days, even if the user has since had the license removed or never had any Copilot active usage.\nI assigned the Microsoft 365 Copilot license to users, but why is 'last activity date' for users empty in rare cases?\nBased on system constraints, some users might not have a 'last activity date' in the user-level table of the report under the following conditions:\nThe user used Microsoft 365 Copilot within a short time window (less than 24 hours) after the Microsoft 365 Copilot license was assigned.\nThe user later had no other Microsoft 365 Copilot usage up to the date on which the report is viewed.\nWhy is the 'Last activity date of Word, Excel, PowerPoint, OneNote, or Outlook Copilot (UTC)' sometimes blank or newer than the actual date, even when users have recently used Copilot features?\nThis might be caused by a known limitation: the uploading of client events data for Copilot features in Word, Excel, PowerPoint, OneNote, and Outlook can be delayed for various reasons, such as when end users disconnect from the internet immediately after taking a Copilot action.\nHow do the numbers in this report compare to what is shown in the Microsoft Copilot Dashboard in Viva Insights?\nThe data in these reports is based on the same underlying definitions of active usage, but the population of users included in the analysis and the timeframe displayed might differ. To learn more, see\nUse Microsoft Copilot Dashboard advanced features with a Viva Insights subscription\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Copilot Usage Reports",
      "section": "Microsoft 365 Copilot"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/dlp-learn-about-dlp": {
      "content_hash": "sha256:93150c7f0e65e7e435c487b70d2c57c3dfa7eb3cc950b9e57e7fb24c5a824c4f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about data loss prevention\nFeedback\nSummarize this article for me\nOrganizations control sensitive information like:\nfinancial data\nproprietary data\ncredit card numbers\nhealth records\nSocial Security numbers\nTo help protect this sensitive data, and to reduce the risk from oversharing, they need a way to help prevent their users from inappropriately sharing sensitive data with people who shouldn't have it. This practice is called data loss prevention (DLP).\nIn Microsoft Purview, you implement data loss prevention by defining and applying DLP policies. A DLP policy can help you identify, monitor, and automatically protect sensitive in\nEnterprise applications & devices\nand\nInline web traffic\ndata. DLP policies act on a variety of locations, methods of data transmission, and types of user activities.\nDLP uses deep content analysisânot a simple text scan. It analyzes content:\nFor primary data matches to keywords\nBy the evaluation of regular expressions\nBy internal function validation\nBy secondary data matches that are in proximity to the primary data match\nDLP also uses machine learning algorithms and other methods to detect content that matches your DLP policies\nInline by\nMicrosoft Edge for business\nfor Windows devices that haven't been onboarded into Microsoft Purview (preview) and\nUse Network Data Security to help prevent sharing sensitive information with unmanaged AI (preview)\nEnterprise applications and devices\nDLP monitors and protects against oversharing in enterprise apps and on devices. It targets Microsoft 365 locations, like Exchange and SharePoint, and locations you add, like on-premises file shares, endpoint devices, and non-Microsoft cloud apps. These locations and sources include:\nMicrosoft 365 services, like Exchange, SharePoint, OneDrive accounts, and Teams chat and channel messages\nOffice applications, such as Word, Excel, and PowerPoint\nDevices running Windows 10, Windows 11, and the three most recent versions of macOS\nNon-Microsoft cloud apps\nOn-premises file shares and on-premises SharePoint\nMicrosoft Fabric and Power BI workspaces\nMicrosoft 365 Copilot and Copilot chat (preview)\nManaged cloud apps\nCreate DLP policies for\nEnterprise applications & devices\nto cover these locations.\nInline web traffic\nDLP, with\ncollection policies\n, monitors and protects against oversharing to\nUnmanaged cloud apps\nby targeting data transmitted on your network and in Microsoft Edge for Business.\nCreate policies that target Inline web traffic (preview)\nand\nNetwork activity (preview)\nto cover locations like:\nOpenAI ChatGPTâfor\nEdge for Business\nand\nNetwork\noptions\nGoogle Geminiâfor\nEdge for Business\nand\nNetwork\noptions\nDeepSeekâfor\nEdge for Business\nand\nNetwork\noptions\nMicrosoft Copilotâfor\nEdge for Business\nand\nNetwork\noptions\nOver 34,000 cloud apps in the\nMicrosoft Defender for Cloud Apps cloud app catalog\nâ\nNetwork\noption only\nBefore you start\nAdministrative units\nLearn about Microsoft Purview Data Loss Prevention\nPlan for data loss prevention (DLP)\n- by working through this article you will:\nIdentify stakeholders\nDescribe the categories of sensitive information to protect\nSet goals and strategy\nCollection Policies solution overview\nCollection policy reference\nData Loss Prevention policy reference\n- this article introduces all the components of a DLP policy and how each one influences the behavior of a policy\nDesign a DLP policy\n- this article walks you through creating a policy intent statement and mapping it to a specific policy configuration.\nCreate and Deploy data loss prevention policies\n- This article presents some common policy intent scenarios that you map to configuration options, then it walks you through configuring those options.\nLearn about investigating data loss prevention alerts\n- This article introduces you to the lifecycle of alerts from creation, through final remediation and policy tuning. It also introduces you to the tools you use to investigate alerts.\nMicrosoft Purview licensing\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nDLP in Microsoft Purview\nDLP is just one of the Microsoft Purview tools that you use to help protect your sensitive items wherever they live or travel. You should understand the other tools in the Microsoft Purview tool set, how they interrelate, and work better together. See,\nMicrosoft Purview tools\nto learn more about the information protection process.\nProtective actions of DLP policies\nDLP policies monitor the activities that users take on sensitive items and, if the policy conditions are met, take protective actions. For example, when a user attempts a prohibited action, like copying a sensitive item to an unapproved location or sharing medical information in an email, DLP can:\nshow a pop-up policy tip to the user that warns them that they might be trying to share a sensitive item inappropriately\nblock the sharing and, via a policy tip, allow the user to override the block and capture the users' justification\nblock the sharing without the override option\nfor data at rest, sensitive items can be locked and moved to a secure quarantine location\nfor Teams chat, the sensitive information won't be displayed\nAll DLP monitored activities are recorded to the\nMicrosoft 365 Audit log\nby default and routed to\nActivity explorer\n.\nDLP lifecycle\nA DLP implementation typically follows these major phases.\nPlan for DLP\nPrepare for DLP\nDeploy your policies in production\nPlan for DLP\nDLP monitoring and protection are native to the applications that users use every day. This helps to protect your organization's sensitive items from risky activities, even if your users are unaccustomed to data loss prevention thinking and practices. If your organization and your users are new to data loss prevention practices, the adoption of DLP might require a change to your business processes, and there will be a culture shift for your users. But, with proper planning, testing and tuning, your DLP policies protect your sensitive items while minimizing any potential business process disruptions.\nTechnology planning for DLP\nKeep in mind that DLP as a technology can monitor and protect your data at rest, data in use and data in motion across Microsoft 365 services, Windows 10, Windows 11, and macOS (three latest released versions) devices, on-premises file shares, and on-premises SharePoint. There are planning implications for the different locations, the type of data you want to monitor and protect, and the actions to be taken when a policy match occurs.\nBusiness processes planning for DLP\nDLP policies can block users from performing prohibited activities, like inappropriate sharing of sensitive information via email. As you plan your DLP policies, you must identify the business processes that touch your sensitive items. The business process owners can help you identify appropriate user behaviors that should be allowed and inappropriate user behaviors that should be protected against. You should plan your policies and deploy them in\nsimulation mode\n, and evaluate their impact, before running them in more restrictive modes.\nOrganizational culture planning for DLP\nA successful DLP implementation is as much dependent on getting your users trained and acclimated to data loss prevention practices as it is on well planned and tuned policies. Since your users are heavily involved, be sure to plan for training for them too. You can strategically use policy tips to raise awareness with your users before changing the policy status from simulation mode to more restrictive modes.\nPrepare for DLP\nYou can apply DLP policies to data at rest, data in use, and data in motion in locations such as:\nExchange Online email\nSharePoint sites\nOneDrive accounts\nTeams chat and channel messages\nInstances: Microsoft Defender for Cloud Apps\nDevices: Windows 10, Windows 11, and macOS (three latest released versions)\nOn-premises repositories\nFabric and Power BI workspaces\nMicrosoft 365 Copilot (preview)\nEach one has different prerequisites. Sensitive items in some locations, like Exchange online, can be brought under the DLP umbrella by just configuring a policy that applies to them. Others, such as on-premises file repositories, require a deployment of\nMicrosoft Purview Information Protection scanner\n. You'll need to prepare your environment, code draft policies, and test them thoroughly before activating any blocking actions.\nDeploy your policies in production\nDesign your policies\nStart by defining your control objectives, and how they apply across each respective workload. Draft a policy that embodies your objectives. Feel free to start with one workload at a time, or across all workloads - there's no impact yet. For more information, see\nCreate and deploy data loss prevention policies\n.\nImplement policy in simulation mode\nEvaluate the impact of the controls by implementing them with a DLP policy in\nsimulation mode\n. Actions defined in a policy aren't applied while the policy is in simulation mode. It's ok to apply the policy to all workloads in simulation mode, so that you can get the full breadth of results, but you can start with one workload if you need to. For more information, see\nPolicy Deployment\n.\nMonitor outcomes and fine-tune the policy\nWhile in simulation mode, monitor the outcomes of the policy and fine-tune it so that it meets your control objectives while ensuring you aren't adversely or inadvertently impacting valid user workflows and productivity. Here are some examples of things to fine-tune:\nadjusting the locations and people/places that are in or out of scope\ntune the conditions that are used to determine if an item and what is being done with it matches the policy\nthe sensitive information definition/s\nadd new controls\nadd new people\nadd new restricted apps\nadd new restricted sites\nNote\nStop processing more rules\ndoesn't work in simulation mode, even when it's turned on.\nEnable the control and tune your policies\nOnce the policy meets all your objectives, turn it on. Continue to monitor the outcomes of the policy application and tune as needed.\nNote\nIn general, policies take effect about an hour after being turned on.\nDLP policy configuration overview\nYou have flexibility in how you create and configure your DLP policies. You can start from a predefined template and create a policy in just a few clicks or you can design your own from the ground up. No matter which you choose, all DLP policies require the same information from you.\nChoose what you want to monitor\n- DLP comes with many predefined policy templates to help you get started or you can create a custom policy.\nA predefined policy template, such as Financial data, Medical and health data, Privacy data all for various countries and regions.\nA custom policy that uses the available\nsensitive information types (SIT)\n,\nretention labels\n, and\nsensitivity labels\n.\nChoose administrative scoping\n- DLP supports assigning\nAdministrative Units\nto some\nEnterprise applications & devices\npolicies. Administrators who are assigned to an administrative unit can only create and manage policies for the users, groups, distribution groups, accounts, and sites that they're assigned to. So, policies can be applied to all users, groups, and sites by an unrestricted administrator, or they can be scoped to administrative units. See,\nPolicy Scoping\nfor more DLP specific details. See,\nAdministrative units\nfor the details on administrative units across Microsoft Purview Information Protection.\nChoose where you want to monitor\n- You pick one or more locations that you want DLP to monitor for sensitive information. You can monitor:\nlocation\ninclude/exclude by\nExchange email\ndistribution groups\nSharePoint sites\nsites\nOneDrive accounts\naccounts or distribution groups\nTeams chat and channel messages\naccount or distribution group\nWindows 10, Windows 11, and macOS (three latest released versions) devices\nusers and groups + devices and device groups\nMicrosoft Cloud App Security\ninstance\nOn-premises repositories\nrepository file path\nFabric and Power BI\nworkspaces\nMicrosoft 365 Copilot (preview)\naccount or distribution group\nNote\nThe users and groups mentioned above should be Online users and M365, Exchange online, and Microsoft Entra groups\nChoose the conditions that must be matched for a policy to be applied to an item\n- You can accept preconfigured conditions or you can define custom conditions. Some examples are:\nitem contains a specified type of sensitive information that is being used in a certain context. For example, 95 social security numbers being emailed to recipient outside your org.\nitem has a specified sensitivity label\nitem with sensitive information is shared either internally or externally\nChoose the action to take when the policy conditions are met\n- The actions depend on the location where the activity is happening. Some examples are:\nSharePoint/Exchange/OneDrive: Block people who are outside your organization from accessing the content. Show the user a tip and send them an email notification that they're taking an action that is prohibited by the DLP policy.\nTeams Chat and Channel: Block sensitive information from being shared in the chat or channel.\nWindows 10, Windows 11, and macOS (three latest released versions) Devices: Audit or restrict copying a sensitive item to a removable USB device.\nOffice Apps: Show a popup notifying the user that they're engaging in a risky behavior and block or block but allow override.\nOn-premises file shares: move the file from where it's stored to a quarantine folder.\nNote\nThe conditions and the actions to take are defined in an object called a\nrule\n.\nCreate and deploy a DLP policy\nAll DLP policies are created and maintained in the Microsoft Purview portal. See,\nCreate and Deploy data loss prevention policies\nfor more information.\nAfter you create a DLP policy, it's stored in a central policy store, and then synced to the various content sources, including:\nExchange, and from there to Outlook on the web and Outlook\nOneDrive\nSharePoint sites\nOffice desktop programs (Excel, PowerPoint, and Word)\nMicrosoft Teams channels and chat messages\nAfter the policy is synced to the right locations, it starts to evaluate content and enforce actions.\nViewing policy application results\nDLP reports a vast amount of information to Microsoft Purview from monitoring policy matches and actions, to user activities. You need to consume and act on that information to tune your policies and triage actions taken on sensitive items. The telemetry goes into the\nMicrosoft 365 audit Logs\nfirst, is processed, and makes its way to different reporting tools. Each reporting tool has a different purpose.\nOverview page\nThe DLP\nOverview\npage gives you quick access to important information about your DLP policies, including:\nPolicy sync status\nDevice status\nTop activites detected\nDevice overall health\nYou can investigate incidents for Microsoft Purview Data Loss Prevention (DLP) from the Microsoft Defender portal\nIncidents & alerts\n>\nIncidents\n. See\nInvestigate data loss incidents with Microsoft Defender XDR\nand\nInvestigate alerts in Microsoft Defender XDR\n.\nDLP Alerts\nDLP can\ngenerate alerts\nwhen a user(s) performs an activity that meets the criteria of a rule in a DLP policy, and you have\nincident reports\nconfigured to generate alerts. Depending on your subscription level, alerts can be aggregated on a time window/rule basis or on\na time windows/user basis(preview)\n.\nDLP posts the alert for investigation in the\nDLP Alerts dashboard\n. Use the DLP Alerts dashboard to view alerts, triage them, set investigation status, and track resolution. Alerts are also routed to\nMicrosoft Defender portal\nwhere you can do all the alert dashboard tasks plus more.\nDLP alerts are available in the Microsoft Defender portal for six months. They're only available in the Microsoft Purview DLP alerts dashboard for 30 days.\nIf you're an administrative unit restricted admin, you'll only see the DLP alerts for your administrative unit.\nHere's an example of alerts generated by policy matches and activities from Windows 10 devices.\nYou can also view details of the associated event with rich metadata in the same dashboard.\nNote\nAlerts are generated differently for emails than they are for SharePoint or OneDrive items. In SharePoint and OneDrive, DLP scans existing items as well as new ones and generates an alert whenever a match is found. In Exchange, new email messages are scanned and an alert is generated if there's a policy match. DLP\ndoes not\nscan or match previously existing email items that are stored in a mailbox or archive.\nFor more information on Alerts, see:\nAlerts in DLP policies\n: Describes alerts in the context of a DLP policy.\nGet started with data loss prevention alerts\n: Covers the necessary liscensing, permissions, and prerequisites for DLP alerts and alert reference details.\nCreate and deploy data loss prevention policies\n: Includes guidance on alert configuration in the context of creating a DLP policy.\nLearn about investigating data loss prevention alerts\n: Covers the various methods for investigating of DLP alerts.\nInvestigate data loss incidents with Microsoft Defender XDR\n: How to investigate DLP alerts in Microsoft Defender portal.\nDLP Activity Explorer and reports\nThe Activity explorer tab on the DLP page has multiple filters you can use to view DLP events. Use this tool to review activity related to content that contains sensitive info or has labels applied, such as what labels were changed, files were modified, and matched a rule.\nYou can view the last 30 days of DLP information in\nActivity Explorer\nusing these preconfigured filters:\nEndpoint DLP activities\nFiles containing sensitive info types\nEgress activities\nDLP policies that detected activities\nDLP policy rules that detected activities\nTo see this information\nSelect this activity\nUser overrides\nDLP rule undo\nItems that match a DLP rule\nDLP rule matched\nYou can also access DLP report using via these cmdlets in the Security & Compliance PowerShell.\nConnect to Security & Compliance PowerShell\nUse these cmdlets:\nGet-DlpDetailReport\nGet-DlpDetectionsReport\nGet-DlpSiDetectionsReport\nHowever, DLP reports need to pull data from across Microsoft 365, including Exchange. For this reason, the following cmdlets for DLP reports are available in Exchange PowerShell. To use the cmdlets for these DLP reports, take the following steps:\nConnect to Exchange PowerShell\nUse these cmdlets:\nGet-DlpDetailReport\nGet-MailDetailDlpPolicyReport\nContextual summary\nYou can see the text that surrounds the matched content, like a credit card number in a\nDLPRuleMatch\nevent in Activity explorer.\nDLPRuleMatch\nevents are paired with user egress activities such as \"CopyToClipboard\" or \"CloudEgress\". They should be right next to (or at least very close to) each other in Activity explorer. You want to look at both because the\nuser activity\ncontains details about the matched policy and the\nDLPRuleMatch\nevent contains the details about the text that surrounds the matched content.\nFor endpoint, be sure that you have applied KB5016688 for Windows 10 devices and KB5016691 for Windows 11 devices or above.\nFor more information, see\nGet started with activity explorer\n.\nTo learn more about Microsoft Purview DLP, see:\nLearn about Endpoint data loss prevention\nLearn about the default data loss prevention policy in Microsoft Teams (preview)\nLearn about data loss prevention on-premises scanner\nLearn about the Microsoft Compliance Extension\nGet started with the data loss prevention Alerts dashboard\nTo learn how to use data loss prevention to comply with data privacy regulations, see\nDeploy information protection for data privacy regulations with Microsoft Purview\n(aka.ms/m365dataprivacy).\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data Loss Prevention",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/dlp-create-deploy-policy": {
      "content_hash": "sha256:919f16e8cb5508d9c2711f50764409e9da511488499646fc28eb2b053aa89c8a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and deploy data loss prevention policies\nFeedback\nSummarize this article for me\nMicrosoft Purview Data Loss Prevention (DLP) policies include many configuration options. Each option changes the policy's behavior. The articles in this series cover some of the most common DLP policy scenarios. They walk you through configuring those options to give you hands-on experience with the DLP policy creation process. When you familiarize yourself with these scenarios, you gain the foundational skills that you need to use the DLP policy creation UX to create your own policies.\nHow you deploy a policy is as important policy design. You have\nmultiple options to control policy deployment\n. This article shows you how to use these options so that the policy achieves your intent while avoiding costly business disruptions.\nIn preview\nYou can change the display name of DLP policies and rules. Once you rename a policy or a rule, any existing records retain their previous name in activity explorer evetns, in alerts and in audit records. New records will reflect the new name in activity explorer events, in alerts and in audit records. These names will remain until the items age out of the system.\nOrient yourself to DLP\nAdministrative units\nLearn about Microsoft Purview Data Loss Prevention\nPlan for data loss prevention (DLP)\n- by working through this article you will:\nIdentify stakeholders\nDescribe the categories of sensitive information to protect\nSet goals and strategy\nCollection Policies solution overview\nCollection policy reference\nData Loss Prevention policy reference\n- this article introduces all the components of a DLP policy and how each one influences the behavior of a policy\nDesign a DLP policy\n- this article walks you through creating a policy intent statement and mapping it to a specific policy configuration.\nCreate and Deploy data loss prevention policies\n- This article presents some common policy intent scenarios that you map to configuration options, then it walks you through configuring those options.\nLearn about investigating data loss prevention alerts\n- This article introduces you to the lifecycle of alerts from creation, through final remediation and policy tuning. It also introduces you to the tools you use to investigate alerts.\nSKU/subscriptions licensing\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nPermissions\nThe account you use to create and deploy policies must be a member of one of these role groups:\nCompliance administrator\nCompliance data administrator\nInformation Protection\nInformation Protection Admin\nSecurity administrator\nImportant\nBefore you start, make sure you understand the difference between an\nunrestricted administrator\nand an\nadministrative unit restricted administrator\nby reading\nAdministrative units\n.\nGranular Roles and Role Groups\nYou can use these roles and role groups to fine tune your access controls.\nHere's a list of applicable roles. To learn more, see\nPermissions in the Microsoft Purview portal\n.\nDLP Compliance Management\nInformation Protection Admin\nInformation Protection Analyst\nInformation Protection Investigator\nInformation Protection Reader\nHere's a list of applicable role groups. To learn more, see\nPermissions in the Microsoft Purview portal\n.\nInformation Protection\nInformation Protection Admins\nInformation Protection Analysts\nInformation Protection Investigators\nInformation Protection Readers\nPolicy creation scenarios for Enterprise applications & devices\nThe previous article,\nDesign a DLP policy\n, introduces you to the methodology of creating a policy intent statement and then mapping that intent statement to policy configuration options.\nHelp prevent sharing credit card numbers through email\nHelp prevent sharing sensitive items via SharePoint and OneDrive with external users\nHelp protect files that Endpoint Data Loss Prevention fails to scan\nHelp protect files that Endpoint Data Loss Prevention doesn't scan\nHelp protect against sharing of a defined set of unsupported files\nDisable Microsoft Purview data loss prevention scanning for some supported files and apply controls\nHelp prevent sharing Power BI reports with credit card numbers\nPolicy creation scenarios for Inline web traffic\nHelp prevent sharing via Microsoft Edge for Business to unmanaged AI apps from managed devices\nHelp Prevent Users from Sharing Sensitive Info with Cloud Apps in Edge for Business\nHelp prevent sharing sensitive information with unmanaged AI apps via network data security\nDeployment\nA successful policy deployment isn't just about getting the policy into your environment to enforce controls on user actions. A haphazard, rushed deployment can negatively impact business processes and annoy your users. Those consequences slow acceptance of DLP technology in your organization and the safer behaviors it promotes. Ultimately, those consequences make your sensitive items less safe in the long run.\nBefore you start your deployment, make sure you read through\nPolicy deployment\n. It gives you a broad overview of the policy deployment process and general guidance.\nThis section dives more deeply into the three types of controls you use in concert to manage your policies in production. You can change any of these controls at any time, not just during policy creation.\nThree axes of deployment management\nUse three axes to control the policy deployment process: scope, state, and actions. Always take an incremental approach to deploying a policy, starting from the least impactful\nsimulation mode\nthrough full enforcement.\nRecommended deployment control configurations\nWhen your policy state is\nYour policy scope can be\nImpact of policy actions\nRun the policy in simulation mode\nPolicy scope of locations can be narrow or broad\n- You can configure any action\n- No user impact from configured actions\n- Admin sees alerts and can track activities\nRun the policy in simulation mode with policy tips\nPolicy should be scoped to target a pilot group and then expand the scope as you tune the policy\n- You can configure any action\n- No user impact from configured actions\n- Users can receive policy tips and alerts\n- Admin sees alerts and can track activities\nTurn it on\nAll targeted location instances\n- All configured actions are enforced on user activities\n- Admin sees alerts and can track activities\nKeep it off\nn/a\nn/a\nState\nState is the primary control you use to roll out a policy. When you finish creating your policy, set the state of the policy to\nKeep it off\n. Leave it in this state while you work on the policy configuration and until you get a final review and sign off. Set the state to:\nRun the policy in simulation mode\n: No policy actions are enforced, events are audited. While in this state, you can monitor the impact of the policy in the DLP simulation mode overview and the DLP\nActivity explorer\nconsole.\nRun the policy in simulation mode and show policy tips while in simulation mode\n: No actions are enforced, but users receive policy tips and notification emails to raise their awareness and educate them.\nTurn it on right away\n: This is full enforcement mode.\nKeep it off\n: The policy is inactive. Use this state while developing and reviewing your policy before deployment.\nYou can change the state of a policy at any time.\nActions\nActions are what a policy does in response to user activities on sensitive items. Because you can change these actions at any time, you can start with the least impactful,\nAllow\n(for devices) and\nAudit only\n(for all other locations), gather and review the audit data, and use it to tune the policy before moving to more restrictive actions.\nAllow\n: The user activity is allowed to occur, so no business processes are impacted. You get audit data and there aren't any user notifications or alerts.\nNote\nThe\nAllow\naction is only available for policies that are scoped to the\nDevices\nlocation.\nAudit only\n: The user activity is allowed to occur, so no business processes are impacted. You get audit data and you can add notifications and alerts to raise awareness and train your users to know that what they're doing is a risky behavior. If your organization intends to enforce more restrictive actions later on, you can tell your users that too.\nBlock with override\n: The user activity is blocked by default. You can audit the event, raise alerts and notifications. This action impacts the business process, but your users are given the option to override the block and provide a reason for the override. Because you get direct feedback from your users, this action can help you identify false positive matches, which you can use to further tune the policy.\nNote\nFor Exchange online and SharePoint in Microsoft 365, you configure overrides in the user notification section.\nBlock\n: The user activity is blocked no matter what. You can audit the event, raise alerts and notifications.\nPolicy scope\nEvery policy is scoped to one or more locations, such as Exchange, SharePoint in Microsoft 365, Teams, and Devices. By default, when you select a location, all instances of that location fall under the scope and none are excluded. You can further refine which instances of the location (such as sites, groups, accounts, distribution groups, mailboxes, and devices) that the policy is applied to by configuring the include/exclude options for the location. To learn more about your include/exclude scoping options, see,\nLocations\n.\nIn general, you have more flexibility with scoping while the policy is in\nRun the policy in simulation mode\nstate because no actions are taken. You can start with just the scope you designed the policy for or go broad to see how the policy would impact sensitive items in other locations.\nWhen you change the state to\nRun the policy in simulation mode and show policy tips\n, narrow your scope to a pilot group that can give you feedback and be early adopters who can be a resource for others when they come onboard.\nWhen you move the policy to\nTurn it on right away\n, you broaden the scope to include all the instances of locations that you intended when the policy was designed.\nPolicy deployment steps\nAfter you've created the policy and set its state to\nKeep it off\n, do a final review with your stakeholders.\nChange the state to\nRun the policy in simulation mode\n. The location scope can be broad at this point so you can gather data on the behavior of the policy across multiple locations or just start with a single location.\nTune the policy based on the behavior data so that it better meets the business intent.\nChange the state to\nRun the policy in simulation mode and show policy tips\n. Refine the scope of locations to support a pilot group if needed and make use of includes/excludes so that the policy is first rolled out to that pilot group.\nGather user feedback and alert and event data. If needed, tune the policy and your plans. Make sure you address all the issues that your users bring up. Your users will most likely encounter issues and raise questions about things that you didn't think of during the design phase. Develop a group of super users at this point. They can be a resource to help train other users as the scope of the policy is increased and more users come onboard. Before you go to the next stage of deployment, make sure that the policy is achieved your control objectives.\nChange the state to\nTurn it on right away\n. The policy is fully deployed. Monitor DLP alerts and DLP activity explorer. Address alerts.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create DLP Policies",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/dlp-policy-reference": {
      "content_hash": "sha256:8242639cb1dfdbf03b794425f4031ea25c7757f7581656eb836788ea56541587",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nData Loss Prevention policy reference\nFeedback\nSummarize this article for me\nMicrosoft Purview Data Loss Prevention (DLP) policies have many components to configure. To create an effective policy, you need to understand what the purpose of each component is and how its configuration alters the behavior of the policy. This article provides a detailed anatomy of a DLP policy.\nTip\nGet started with Microsoft Security Copilot to explore new ways to work smarter and faster using the power of AI. Learn more about\nMicrosoft Security Copilot in Microsoft Purview\n.\nRecommended reading\nAdministrative units\nLearn about Microsoft Purview Data Loss Prevention\nPlan for data loss prevention (DLP)\n- by working through this article you will:\nIdentify stakeholders\nDescribe the categories of sensitive information to protect\nSet goals and strategy\nCollection Policies solution overview\nCollection policy reference\nData Loss Prevention policy reference\n- this article introduces all the components of a DLP policy and how each one influences the behavior of a policy\nDesign a DLP policy\n- this article walks you through creating a policy intent statement and mapping it to a specific policy configuration.\nCreate and Deploy data loss prevention policies\n- This article presents some common policy intent scenarios that you map to configuration options, then it walks you through configuring those options.\nLearn about investigating data loss prevention alerts\n- This article introduces you to the lifecycle of alerts from creation, through final remediation and policy tuning. It also introduces you to the tools you use to investigate alerts.\nDLP platform considersations\nAlso, you need to be aware of these constraints of the platform:\nMaximum number of MIP + MIG policies in a tenant: 10,000\nMaximum size of a DLP policy (100 KB)\nMaximum number of DLP rules:\nIn a policy: Limited by the size of the policy\nIn a tenant: 600\nMaximum size of an individual DLP rule: 100 KB (102,400 characters)\nGenerate Incident Report evidence limit: 100, with each SIT evidence, in proportion of occurrence\nMaximum size of text scanned from a file: The first 2 million characters (~2 MB) of extractable text. If a file exceeds this limit, first two million characters are scanned, and a âDocument didnât complete scanningâ signal is emitted.\nMaximum number of nested levels of data scanned from a file: The first three levels. If a file exceeds this limit, data in the first three levels are scanned, and a\nDocument didnât complete scanning\nevent is emitted.\nRegex size limit for all matches predicted: 20 KB\nPolicy name length limit: 64 characters\nPolicy rule length limit: 64 characters\nComment length limit: 1,024 characters\nDescription length limit: 1,024 characters\nMaximum size of Endpoint DLP Settings: 16,384 characters\nPolicy templates\nThere are five types of DLP policy templates across two categories.\nEnterprise applications & devices\nenhanced policies\npolicies that can detect and protect types of\nFinancial\ninformation.\npolicies that can detect and protect types of\nMedical and health\ninformation.\npolicies that can detect and protect types of\nPrivacy\ninformation.\nA\nCustom\npolicy template that you can use to build your own policy if none of the others meet your organization's needs.\nThe following table lists all policy templates and the sensitive information types (SIT) that they cover.\nCategory\nTemplate\nSIT\nFinancial\nAustralia Financial Data\n-\nSWIFT code\n-\nAustralia tax file number\n-\nAustralia bank account number\n-\nCredit card number\nFinancial\nCanada Financial data\n-\nCredit card number\n-\nCanada bank account number\nFinancial\nFrance Financial data\n-\nCredit card number\n-\nEU debit card number\nFinancial\nGermany Financial Data\n-\nCredit card number\n-\nEU debit card number\nFinancial\nIsrael Financial Data\n-\nIsrael bank account number\n-\nSWIFT code\n-\nCredit card number\nFinancial\nJapan Financial Data\n-\nJapan bank account number\n-\nCredit card number\nFinancial\nPCI Data Security Standard (PCI DSS)\n-\nCredit card number\nFinancial\nSaudi Arabia Anti-Cyber Crime Law\n-\nSWIFT code\n-\nInternational banking account number (IBAN)\nFinancial\nSaudi Arabia Financial Data\n-\nCredit card number\n-\nSWIFT code\n-\nInternational banking account number (IBAN)\nFinancial\nUK Financial Data\n-\nCredit card number\n-\nEU debit card number\n-\nSWIFT code\nFinancial\nUS Financial Data\n-\nCredit card number\n-\nU.S. bank account number\n-\nABA Routing Number\nFinancial\nU.S. Federal Trade Commission (FTC) Consumer Rules\n-\nCredit card number\n-\nU.S. bank account number\n-\nABA Routing Number\nFinancial\nU.S. Gramm-Leach-Bliley Act (GLBA) Enhanced\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\n-\nU.S./U.K. passport number\n-\nU.S. driver's license number\n-\nAll Full Names\n-\nU.S. Physical Addresses\nFinancial\nU.S. Gramm-Leach-Bliley Act (GLBA)\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\nMedical and health\nAustralia Health Records Act (HRIP Act) Enhanced\n-\nAustralia tax file number\n-\nAustralia medical account number\n-\nAll Full Names\n-\nAll Medical Terms And Conditions\n-\nAustralia Physical Addresses\nMedical and health\nAustralia Health Records Act (HRIP Act)\n-\nAustralia tax file number\n-\nAustralia medical account number\nMedical and health\nCanada Health Information Act (HIA)\n-\nCanada passport number\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nMedical and health\nCanada Personal Health Information Act (PHIA) Manitoba\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nMedical and health\nCanada Personal Health Act (PHIPA) Ontario\n-\nCanada passport number\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nMedical and health\nU.K. Access to Medical Reports Act\n-\nU.K. national health service number\n-\nU.K. national insurance number (NINO)\nMedical and health\nU.S. Health Insurance Act (HIPAA) Enhanced\n-\nInternational classification of diseases (ICD-9-CM)\n-\nInternational classification of diseases (ICD-10-CM)\n-\nAll Full Names\n-\nAll Medical Terms And Conditions\n-\nU.S. Physical Addresses\nMedical and health\nU.S. Health Insurance Act (HIPAA)\n-\nInternational classification of diseases (ICD-9-CM)\n-\nInternational classification of diseases (ICD-10-CM)\nPrivacy\nAustralia Privacy Act Enhanced\n-\nAustralia driver's license number\n-\nAustralia passport number\n-\nAll Full Names\n-\nAll Medical Terms And Conditions\n-\nAustralia Physical Addresses\nPrivacy\nAustralia Privacy Act\n-\nAustralia drivers license number\n-\nAustralia passport number\nPrivacy\nAustralia Personally Identifiable Information (PII) Data\n-\nAustralia tax file number\n-\nAustralia driver's license number\nPrivacy\nCanada Personally Identifiable Information (PII) Data\n-\nCanada driver's license number\n-\nCanada bank account number\n-\nCanada passport number\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nPrivacy\nCanada Personal Information Protection Act (PIPA)\n-\nCanada passport number\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nPrivacy\nCanada Personal Information Protection Act (PIPEDA)\n-\nCanada driver's license number\n-\nCanada bank account number\n-\nCanada passport number\n-\nCanada social insurance number\n-\nCanada health service number\n-\nCanada Personal Health Identification Number\nPrivacy\nFrance Data Protection Act\n-\nFrance national ID card (CNI)\n-\nFrance social security number (INSEE)\nPrivacy\nFrance Personally Identifiable Information (PII) Data\n-\nFrance social security number (INSEE)\n-\nFrance driver's license number\n-\nFrance passport number\n-\nFrance national ID card (CNI)\nPrivacy\nGeneral Data Protection Regulation (GDPR) Enhanced\n-\nAustria Physical Addresses\n-\nBelgium Physical Addresses\n-\nBulgaria Physical Addresses\n-\nCroatia Physical Addresses\n-\nCyprus Physical Addresses\n-\nCzech Republic Physical Addresses\n-\nDenmark Physical Addresses\n-\nEstonia Physical Addresses\n-\nFinland Physical Addresses\n-\nFrance Physical Addresses\n-\nGermany Physical Addresses\n-\nGreece Physical Addresses\n-\nHungary Physical Addresses\n-\nIreland Physical Addresses\n-\nItaly Physical Addresses\n-\nLatvia Physical Addresses\n-\nLithuania Physical Addresses\n-\nLuxembourg Physical Addresses\n-\nMalta Physical Addresses\n-\nNetherlands Physical Addresses\n-\nPoland Physical Addresses\n-\nPortuguese Physical Addresses\n-\nRomania Physical Addresses\n-\nSlovakia Physical Addresses\n-\nSlovenia Physical Addresses\n-\nSpain Physical Addresses\n-\nSweden Physical Addresses\n-\nAustria Social Security Number\n-\nFrance Social Security Number (INSEE)\n-\nGreece Social Security Number (AMKA)\n-\nHungarian Social Security Number (TAJ)\n-\nSpain Social Security Number (SSN)\n-\nAustria Identity Card\n-\nCyprus Identity Card\n-\nGermany Identity Card Number\n-\nMalta Identity Card Number\n-\nFrance National ID Card (CNI)\n-\nGreece National ID Card\n-\nFinland National ID\n-\nPoland National ID (PESEL)\n-\nSweden National ID\n-\nCroatia Personal Identification (OIB) Number\n-\nCzech Personal Identity Number\n-\nDenmark Personal Identification Number\n-\nEstonia Personal Identification Code\n-\nHungary Personal Identification Number\n-\nLuxemburg National Identification Number natural persons\n-\nLuxemburg National Identification Number (Non-natural persons)\n-\nItaly Fiscal Code\n-\nLatvia Personal Code\n-\nLithuania Personal Code\n-\nRomania Personal Numerical Code (CNP)\n-\nNetherlands Citizen's Service (BSN) Number\n-\nIreland Personal Public Service (PPS) Number\n-\nBulgaria Uniform Civil Number\n-\nBelgium National Number\n-\nSpain DNI\n-\nSlovenia Unique Master Citizen Number\n-\nSlovakia Personal Number\n-\nPortugal Citizen Card Number\n-\nMalta Tax ID Number\n-\nAustria Tax Identification Number\n-\nCyprus Tax Identification Number\n-\nFrance Tax Identification Number (numÃ©ro SPI.)\n-\nGermany Tax Identification Number\n-\nGreek Tax identification Number\n-\nHungary Tax identification Number\n-\nNetherlands Tax Identification Number\n-\nPoland Tax Identification Number\n-\nPortugal Tax Identification Number\n-\nSlovenia Tax Identification Number\n-\nSpain Tax Identification Number\n-\nSweden Tax Identification Number\n-\nAustria Driver's License\n-\nBelgium Driver's License Number\n-\nBulgaria Driver's License Number\n-\nCroatia Driver's License Number\n-\nCyprus Driver's License Number\n-\nCzech Driver's License Number\n-\nDenmark Driver's License Number\n-\nEstonia Driver's License Number\n-\nFinland Driver's License Number\n-\nFrance Driver's License Number\n-\nGerman Driver's License Number\n-\nGreece Driver's License Number\n-\nHungary Driver's License Number\n-\nIreland Driver's License Number\n-\nItaly Driver's License Number\n-\nLatvia Driver's License Number\n-\nLithuania Driver's License Number\n-\nLuxemburg Driver's License Number\n-\nMalta Driver's License Number\n-\nNetherlands Driver's License Number\n-\nPoland Driver's License Number\n-\nPortugal Driver's License Number\n-\nRomania Driver's License Number\n-\nSlovakia Driver's License Number\n-\nSlovenia Driver's License Number\n-\nSpain Driver's License Number\n-\nSweden Driver's License Number\n-\nAustria Passport Number\n-\nBelgium Passport Number\n-\nBulgaria Passport Number\n-\nCroatia Passport Number\n-\nCyprus Passport Number\n-\nCzech Republic Passport Number\n-\nDenmark Passport Number\n-\nEstonia Passport Number\n-\nFinland Passport Number\n-\nFrance Passport Number\n-\nGerman Passport Number\n-\nGreece Passport Number\n-\nHungary Passport Number\n-\nIreland Passport Number\n-\nItaly Passport Number\n-\nLatvia Passport Number\n-\nLithuania Passport Number\n-\nLuxemburg Passport Number\n-\nMalta Passport Number\n-\nNetherlands Passport Number\n-\nPoland Passport\n-\nPortugal Passport Number\n-\nRomania Passport Number\n-\nSlovakia Passport Number\n-\nSlovenia Passport Number\n-\nSpain Passport Number\n-\nSweden Passport Number\n-\nEU Debit Card Number\n-\nAll Full Names\nPrivacy\nGeneral Data Protection Regulation (GDPR)\n-\nEU debit card number\n-\nEU driver's license number\n-\nEU national identification number\n-\nEU passport number\n-\nEU social security number or equivalent identification\n-\nEU Tax identification number\nPrivacy\nGermany Personally Identifiable Information (PII) Data\n-\nGermany driver's license number\n-\nGermany passport number\nPrivacy\nIsrael Personally Identifiable Information (PII) Data\n-\nIsrael national identification number\nPrivacy\nIsrael Protection of Privacy\n-\nIsrael national identification number\n-\nIsrael bank account number\nPrivacy\nJapan Personally Identifiable Information (PII) Data enhanced\n-\nJapan Social Insurance Number (SIN)\n-\nJapan My Number - Personal\n-\nJapan passport number\n-\nJapan driver's license number\n-\nAll Full Names\n-\nJapan Physical Addresses\nPrivacy\nJapan Personally Identifiable Information (PII) Data\n-\nJapan resident registration number\n-\nJapan Social Insurance Number (SIN)\nPrivacy\nJapan Protection of Personal Information Enhanced\n-\nJapan Social Insurance Number (SIN)\n-\nJapan My Number - Personal\n-\nJapan passport number\n-\nJapan driver's license number\n-\nAll Full Names\n-\nJapan Physical Addresses\nPrivacy\nJapan Protection of Personal Information\n-\nJapan resident registration number\n-\nJapan Social Insurance Number (SIN)\nPrivacy\nSaudi Arabia Personally Identifiable (PII) Data\n-\nSaudi Arabia National ID\nPrivacy\nU.K. Data Protection Act\n-\nU.K. national insurance number (NINO)\n-\nU.S./U.K. passport number\n-\nSWIFT code\nPrivacy\nU.K. Privacy and Electronic Communications Regulations\n-\nSWIFT code\nPrivacy\nU.K. Personally Identifiable Information (PII) Data\n-\nU.K. national insurance number (NINO)\n-\nU.S./U.K. passport number\nPrivacy\nU.K. Personal Information Online Code of Practice (PIOCP)\n-\nU.K. national insurance number (NINO)\n-\nU.K. national health service number\n-\nSWIFT code\nPrivacy\nU.S Patriot Act Enhanced\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\n-\nAll Full Names\n-\nU.S. Physical Addresses\nPrivacy\nU.S. Patriot Act\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\nPrivacy\nU.S. Personally Identifiable Information (PII) Data Enhanced\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\n-\nU.S./U.K. passport number\n-\nAll Full Names\n-\nU.S. Physical Addresses\nPrivacy\nU.S. Personally Identifiable Information (PII) Data\n-\nU.S. Individual Taxpayer Identification Number (ITIN)\n-\nU.S. social security number (SSN)\n-\nU.S./U.K. passport number\nPrivacy\nU.S. State Breach Notification Laws Enhanced\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. driver's license number\n-\nU.S. social security number (SSN)\n-\nAll Full Names\n-\nU.S./U.K. passport number\n-\nAll Medical Terms And Conditions\nPrivacy\nU.S. State Breach Notification Laws\n-\nCredit card number\n-\nU.S. bank account number\n-\nU.S. driver's license number\n-\nU.S. social security number (SSN)\nPrivacy\nU.S. State Social Security Number Confidentiality Laws\n-\nU.S. social security number (SSN)\nInline web traffic policies\nA\nCustom\npolicy template that you can use to build your own policy.\nPolicy scoping\nSee,\nAdministrative units\nto make sure you understand the difference between an unrestricted admin and an administrative unit restricted admin.\nDLP policies are scoped at two different levels. The first level applies unrestricted admin scope policies to all of the following in your organization (depending on the locations that are selected) or to subgroups of your organization, called\nAdministrative Unit restricted policies\n:\nusers\ngroups\ndistribution groups\naccounts\nsites\ncloud app instances\non-premises repositories\nFabric and Power BI workspaces\nAt this level, an administrative unit restricted admin will only be able to pick from the administrative units that they're assigned to. DLP support admin unit scoping for some of the locations protected under Enterprise applications & devices.\nThe second level of DLP policy scoping is by the\nlocations\nthat DLP supports. At this level, both unrestricted and administrative unit restricted administrators see only the users, distribution groups, groups, and accounts that were included in the first level of policy scoping and that are available for that location.\nSupport for adding SharePoint sites to Administrative Units\nMicrosoft Purview supports\nadding SharePoint sites to existing administrative units\n. When you assign a DLP policy for the SharePoint location to an administrative unit, the policy will only apply to the sites that are part of that administrative unit. The option to further edit the scope to include or exclude specific sites isn't available. The policy applies to all sites that are part of the administrative unit.\nHere's an example use case:\nContoso has created an Entra ID administrative unit for the engineering department and has assigned certain administrators to manage the users and groups for that department. The engineering department has a SharePoint site that is used to store sensitive information. Contoso wants to ensure that the DLP policy for the engineering department SharePoint sites only applies to the SharePoint site that is part of the administrative unit. By assigning the DLP policy to the administrative unit, the policy will only apply to the SharePoint site that is part of that administrative unit. Also, the administrative unit restricted administrator will only be able to manage the DLP policy for that site and only see policy match result data for the administrative unit in activity explorer and the alert dashboard.\nUnrestricted policies\nUnrestricted policies are created and managed by users in these role groups:\nCompliance administrator\nCompliance data administrator\nInformation Protection\nInformation Protection Admin\nSecurity administrator\nSee, the\nPermissions\narticle for more details.\nUnrestricted administrators can manage all policies and see all the alerts and events that flow from policy matches into the\nAlerts dashboard\nand\nDLP Activity Explorer\n.\nAdministrative unit restricted policies\nAdministrative units are subsets of your Microsoft Entra ID directory and are created for the purposes of managing collections of users, groups, distribution groups, and accounts. These collections are typically created along business group lines or geopolitical areas. Administrative units have a delegated administrator who is associated with an administrative unit in the role group. These are called administrative unit restricted admins.\nDLP supports associating policies with administrative units. See\nAdministrative units\nfor implementation details in the Microsoft Purview portal. Administrative unit admins need to be assigned to one of the same roles or role groups as administrators of unrestricted DLP policies in order to create and manage DLP policies for their administrative unit.\nDLP Administrative Role Group\nCan\nUnrestricted administrator\n- create and scope DLP policies to entire organization\n- edit all DLP policies\n- create and scope DLP policies to administrative units\n- view all alerts and events from all DLP policies\nAdministrative Unit Restricted administrator\n- must be a member of/\nassigned to a role group/role\nthat can administer DLP\n- create and scope DLP policies only to the administrative unit that they're assigned to\n- edit DLP policies that are associated to their administrative unit\n- view alerts and events only from the DLP policies that are scoped to their administrative unit\nLocations\nA DLP policy can find and protect items that contain sensitive information across multiple locations.\nLocation\nSupports Administrative Units\nInclude/Exclude scope\nData state\nOther prerequisites\nExchange Online\nYes\n- distribution groups assigned or dynamic\n- security groups\n- non-email enabled security groups assigned or dynamic)\n- Microsoft 365 groups assigned or dynamic\ndata-in-motion\nNo\nSharePoint\nYes\nsite location at the policy level. If the policy is scoped to an administrative unit that includes SharePoint sites, the policy will only apply to all sites in the administrative unit, no further scoping is possible\ndata-at-rest\ndata-in-use\nNo\nOneDrive\nYes\n- Distribution groups\n- Security groups\n- Non-email enabled security groups\n- Microsoft 365 groups (Group members only, not the group as an entity)\ndata-at-rest\ndata-in-use\nNo\nTeams chat and channel messages\nYes\n- Distribution groups\n- Security groups\n- Mail-enabled security groups\n- Microsoft 365 groups (Group members only, not the group as an entity)\ndata-in-motion\ndata-in-use\nSee\nScope of DLP protection\nInstances\nNo\nCloud app instance\ndata-at-rest\n-\nUse data loss prevention policies for non-Microsoft cloud apps\nDevices\nYes\n- Distribution groups\n- Security groups\n- Non-email enabled security groups\n- Microsoft 365 groups (Group members only, not the group as an entity)\ndata-in-use\ndata-in-motion\n-\nLearn about Endpoint data loss prevention\n-\nGet started with Endpoint data loss prevention\n-\nConfigure device proxy and internet connection settings for Information Protection\nOn-premises repositories (file shares and SharePoint)\nNo\nRepository\ndata-at-rest\n-\nLearn about the data loss prevention on-premises repositories\n-\nGet started with the data loss prevention on-premises repositories\nFabric and Power BI\nNo\nWorkspaces\ndata-in-use\nNo\nThird-party apps\nNone\nNo\nNo\nNo\nMicrosoft 365 Copilot (preview)\nNo\nAccount or Distribution group\ndata-at-rest\ndata-in-use\n- Only available in the\nCustom\npolicy template\nManaged cloud apps\nNo\nAccount or Distribution group\ndata-in-motion\n- Only available in the\nCustom\npolicy template\nUnmanaged cloud apps\nNo\nAccount or Distribution group\ndata-in-motion\n- Only available in the\nCustom\npolicy template\nExchange location scoping\nIf you choose to include specific distribution groups in Exchange, the DLP policy is scoped to the emails sent by members of that group or sent to members of that group. Similarly, excluding a distribution group excludes all the emails sent by the members of that distribution group or from policy evaluation.\nGroup Type\nMembership Type\nSupported during Policy Creation\nSupported during Rule Evaluation\nNotes\nNon-Mail Enabled Security Groups\nAssigned\nYes\nNo\nEnabled for specific customers only\nNon-Mail Enabled Security Groups\nDynamic\nYes\nNo\nMail-Enabled Security Groups\nAssigned\nYes\nYes\nDistribution Groups\nAssigned\nYes\nYes\nDistribution Groups\nDynamic\nYes\nYes\nMicrosoft 365 Groups\nAssigned\nYes\nYes\nMicrosoft 365 Groups\nDynamic\nYes\nYes\nAdaptive Scopes\nDynamic\nNo\nNo\nSender is\nRecipient is\nResultant behavior\nIn scope\nN/A\nPolicy is applied\nOut of scope\nIn scope\nPolicy isn't applied\nExchange location scope calculation\nHere's an example of how Exchange location scope is calculated:\nSay you have four users in your org and two distribution groups that you use for defining Exchange location inclusion and exclusion scopes. Group membership is set up like this:\nDistribution Group\nMembership\nGroup1\nUser1, User2\nGroup2\nUser2, User3\nNo group\nUser4\nInclude setting\nExclude setting\nPolicy applies to\nPolicy doesn't apply to\nExplanation of behavior\nAll\nNone\nAll senders in the Exchange org (User1, User2, User3, User4)\nN/A\nWhen neither are defined, all senders are included\nGroup1\nNone\nMember senders of Group1 (User1, User2)\nAll senders who aren't members of Group1 (User3, User4)\nWhen one setting is defined and the other isn't, the defined setting is used\nAll\nGroup2\nAll senders in the Exchange org who aren't members of Group2 (User1, User4)\nAll senders who are members of Group2 (User2, User3)\nWhen one setting is defined and the other isn't, the defined setting is used\nGroup1\nGroup2\nUser1\nUser2, User3, User4\nExclude overrides include\nYou can choose to scope a policy to the members of distribution lists, dynamic distribution groups, and security groups. A DLP policy can contain no more than 50 such inclusions and exclusions.\nOneDrive location scoping\nWhen scoping a policy for OneDrive locations, in addition to applying your DLP policies to all users and groups in your organization, you can limit the scope of a policy to specific users and groups. DLP supports scoping policies to up to 100 individual users.\nFor instance, if you want to include more than 100 users, you must first put those users in distribution groups or security groups, as appropriate. You can then scope your policy to up to 50 groups.\nIn some cases, you might want to apply a policy to one or two groups, plus two or three individual users who don't belong to either of those groups. Here, the best practice is to\nput those two or three individuals into a group of their own\n. This is the only way to make sure that the policy is scoped to all intended users.\nThe reason for this is that, when you list only users, DLP adds all of the users specified to the policy scope. Similarly, when you add only groups, DLP adds all the members of all the groups to the policy scope.\nSay you have the following groups and users:\nDistribution Group\nMembership\nGroup1\nUser1, User2\nGroup2\nUser2, User3\nIf you limit the scope of a policy to\nonly\nusers or\nonly\ngroups, the DLP applies the policy to users as illustrated in the following table:\nSpecified scope\nDLP Scope evaluation behavior\nUsers in scope\n(Users only)\nUser1\nUser2\nDLP takes the union of the specified users\nUser1, User2\n(Groups only)\nGroup1\nGroup2\nDLP takes the union of the specified groups\nUser1, User2, User3\nHowever, when users and groups are mixed in the scoping configuration, things get complicated. Here's why: DLP only scopes policies to users to\nthe intersection\nof the listed groups and users.\nDLP uses the following order of operations when determining which users and groups to include in the scope:\nEvaluate the union of group membership\nEvaluate the union of users\nEvaluate the intersection of group members and users, that is, where the results overlap\nIt then applies the scope of the policy to the intersection of group members and users.\nLet's extend our example, working with the same set of groups, and let's add User4, who isn't in a group:\nDistribution Group\nMembership\nGroup1\nUser1, User2\nGroup2\nUser2, User3\nNo group\nUser 4\nThe following table explains how policy scoping works in cases where users and groups are both included in the scoping instructions.\nSpecified scope\nDLP Scope evaluation behavior\nUsers in scope\nGroup1\nGroup2\nUser3\nUser4\nFirst evaluation: Union of groups:\n(Group1 + Group2) = User1, User2, User3\nSecond evaluation: Union of users:\n(User3 + User4) = User3, User4\nThird evaluation: Intersection of groups and Users (the overlap):\n(Group1 + Group2) = User1, User2, User3\n(User3 + User4) = User3, User4\nUser3\n(User3 is the only user that appears in the results of both the first and second evaluations.)\nGroup1\nGroup2\nUser1\nUser3\nUser4\nFirst evaluation: Union of groups:\n(Group1 + Group2) = User1, User2, User3\nSecond evaluation: Union of users:\n(User1 + User3 + User4) = User1, User3, User4\nThird evaluation: Intersection of groups and Users (the overlap):\n(Group1 + Group2) = User1, User3\n(User1 + User3, User4) = User1, User3, User4\nUser1\n,\nUser3\n(These are the only users that appear in the results of both the first and second evaluations.)\nSharePoint location scoping\nWhen scoping a policy for SharePoint locations, you can limit the scope of a policy to specific SharePoint sites. DLP supports scoping policies to up to 100 sites.\nDevice scoping\nIn preview, DLP policies for endpoints are scoped by users, and devices. For an endpoint policy to be applied, both the user and the device must be in the policy scope. This means that if a user is in the policy scope, but the device isn't, the policy won't be applied. Similarly, if a device is in the policy scope, but the user isn't, the policy won't be applied.\nNote\nPlease use 101.25072 or higher build for this feature support on macOS.\nHere's how to configure the scope of a DLP policy for different outcomes.\nIf you want to target the policy to...\nSet user scope to...\nSet device scope to...\nExample use case\nAll users on all onboarded devices\nAll users and groups\nAll devices and device groups\nUse this for general enforcement of DLP policies on all devices in your organization. This is the default setting for DLP policies.\nAll users on specific devices\nAll users and groups\neither\nAll devices and device groups\nwith\nExclude devices and device groups\nand add the devices to be excluded or\nSpecific devices and device groups\nand add the devices to be included\nUse this to apply a restrictive policy to kiosk devices that will be used by multiple users.\nSpecific users on all onboarded devices\neither\nAll users and groups\nwith\nExclude users and groups\nand add the users to be excluded or\nSpecific users and groups\nand add the users to be included\nAll devices and device groups\nUse this to help control data leakage by specific users on all devices in your organization.\nSpecific users on specific devices\nSpecific users and groups\nSpecific devices and device groups\nSay you have special use devices in payroll that are used for printing checks and there are only a few accounts that are allowed to use those devices for the purpose of printing checks. You can scope a very restrictive endpoint DLP policy to those user accounts on those specific devices\nLocation support for how content can be defined\nDLP policies detect sensitive items by matching them to a sensitive information type (SIT), or to a sensitivity label or a retention label. Each location supports different methods of defining sensitive content. How content can be defined when you combine locations in a policy, can change from how it can be defined when limited to a single location.\nImportant\nWhen you select multiple locations for a policy, a \"no\" value for a content definition category takes precedence over \"yes\" value. For example, when you select SharePoint sites only, the policy supports detecting sensitive items by one or more of SIT, by sensitivity label or by retention label. But, when you select SharePoint sites\nand\nTeams chat and channel messages locations, the policy will only support detecting sensitive items by SIT.\nLocation\nContent can be defined by SIT\nContent can be defined sensitivity label\nContent can be defined by retention label\nExchange email online\nYes\nYes\nNo\nSharePoint in Microsoft 365 sites\nYes\nYes\nYes\nOneDrive for work or school accounts\nYes\nYes\nYes\nTeams Chat and Channel messages\nYes\nNo\nNo\nDevices\nYes\nYes\nNo\nInstances\nYes\nYes\nYes\nOn-premises repositories\nYes\nYes\nNo\nFabric and Power BI\nYes\nYes\nNo\nMicrosoft 365 Copilot (preview)\nNo\nYes\nNo\nManaged cloud apps\nYes\nNo\nNo\nUnmanaged cloud apps\nYes\nNo\nNo\nDLP supports using trainable classifiers as a condition to detect sensitive information. Content can be defined by trainable classifiers in Exchange, SharePoint sites, OneDrive accounts, Teams Chat and Channels, Devices, and unmanaged cloud apps. For more information, see\nTrainable Classifiers\n.\nNote\nDLP supports detecting sensitivity labels on emails and attachments. For more information, see\nUse sensitivity labels as conditions in DLP policies\n.\nRules\nRules are the business logic of DLP policies. They consist of:\nConditions\nthat when matched, trigger the policy\nActions\nthat determine the activities included and outcomes of a match.\nUser notifications\nto inform your users when they're doing something that triggers a policy and help educate them on how your organization wants sensitive information treated\nUser Overrides\nwhen configured by an admin, allow users to selectively override a blocking action\nIncident reports\nthat notify admins and other key stakeholders when a rule match occurs\nAdditional options\nwhich define the priority for rule evaluation and can stop further rule and policy processing.\nA policy contains one or more rules. Rules are executed sequentially, starting with the highest-priority rule in each policy.\nHow DLP classification works\nDLP evaluates an item for sensitive information when the item is created, read, or modified. Evaluation is also initiated by\non demand classification\n. However, events such as\nDLP Rule Matched\nonly appear in Audit log or activity explorer when a user attempts an activity that matches a DLP policy.\nHere's a list of some of the user activities that DLP can monitor and take actions on:\nText upload via Edge browser using integrated capabilities\nFile upload via Edge browser using integrated capabilities\nFile download via Edge browser using integrated capabilities\nCut/copy data via Edge browser using integrated capabilities\nPaste data via Edge browser using integrated capabilities\nPrint data via Edge browser using integrated capabilities\nPrint data from other locations\nCopy to removable media\nCopy to network share\nCopy to clipboard\nTransfer using Bluetooth\nFile accessed by unallowed app\nPaste to browsers other than Edge\nPrint data\nTransfer using remote desktop\nAn item that is created, read, or modified will match a DLP rule and policy on the client if the conditions and user activity are met. This is audited as file activity, such as FileRead, or FileRenamed.\nIf an activity is met, then a DLP rule match event appears in activity explorer as a 'DLP Rule Matched' event. An event describing the mode of egress will also be generated.\nPolicies take actions and actions are different from conditions. A rule can match on a file even if no actions are performed.\nThe priority by which rules are evaluated and applied\nHosted service locations\nFor the hosted service locations, like Exchange, SharePoint, and OneDrive, each rule is assigned a priority in the order in which it's created. This means that the rule created first has first priority, the rule created second has second priority, and so on.\nWhen content is evaluated against rules, the rules are processed in priority order. If content matches multiple rules, the first rule evaluated that has the\nmost\nrestrictive action is enforced. For example, if content matches all of the following rules,\nRule 3\nis enforced because it's the highest priority, most restrictive rule:\nRule 1: only notifies users\nRule 2: notifies users, restricts access, and allows user overrides\nRule 3: notifies users, restricts access, and doesn't allow user overrides\nRule 4: restricts access\nRules 1, 2, and 4 would be evaluated, but not applied. In this example, matches for all of the rules are recorded in the audit logs and shown in the DLP reports, even though only the most restrictive rule is applied.\nYou can use a rule to meet a specific protection requirement, and then use a DLP policy to group together common protection requirements, such as all of the rules needed to comply with a specific regulation.\nFor example, you might have a DLP policy that helps you detect the presence of information subject to the Health Insurance Portability and Accountability Act (HIPAA). This DLP policy could help protect HIPAA data (the \"what\") across all SharePoint sites and all OneDrive sites (the \"where\") by finding any document containing this sensitive information that's shared with people outside your organization (the conditions) and then blocking access to the document and sending a notification (the actions). These requirements are stored as individual rules and grouped together as a DLP policy to simplify management and reporting.\nFor endpoints\nWhen an item matches multiple DLP rules, DLP goes uses through a complex algorithm to decide which actions to apply. Endpoint DLP applies the aggregate or sum of most restrictive actions. DLP uses these factors when making the calculation.\nPolicy priority order\nWhen an item matches multiple policies and those policies have identical actions, the actions from the highest priority policy is applied.\nRule priority order\nWhen an item matches multiple rules in a policy and those rules have identical actions, the actions from the highest priority rule is applied.\nMode of the policy\nWhen an item matches multiple policies and those policies have identical actions, the actions from all policies that are in\nTurn it on\nstate (enforce mode) are applied preferentially over the policies in\nRun the policy in simulation mode with policy tips\nand\nRun the policy in simulation mode\nstate.\naction\nWhen an item matches multiple policies and those policies differ in actions, the aggregate or sum of the most restrictive actions are applied.\nAuthorization groups\nconfiguration\nWhen an item matches multiple policies and those policies differ in action, the aggregate, or sum, of the most restrictive actions are applied.\noverride options\nWhen an item matches multiple policies and those policies differ in the override option, actions are applied in this order:\nNo override\n>\nAllow override\nHere are scenarios that illustrate the runtime behavior. For the first three scenarios, you have three DLP policies configured like this:\nPolicy name\nCondition to match\nAction\nPolicy priority\nABC\nContent contains credit card number\nBlock print, audit all other user egress activities\n0\nMNO\nContent contains credit card number\nBlock copy to USB, audit all other user egress activities\n1\nXYZ\nContent contains U.S. social security number\nBlock copy to clipboard, audit all other user egress activities\n2\nItem contains credit card numbers\nAn item on a monitored device contains credit card numbers, so it matches policy ABC and policy MNO. Both ABC and MNO are in\nTurn it on\nmode.\nPolicy\nCloud egress action\nCopy to clipboard action\nCopy to USB action\nCopy to network share action\nUnallowed apps action\nPrint action\nCopy via Bluetooth action\nCopy to remote desktop action\nABC\nAudit\nAudit\nAudit\nAudit\nAudit\nBlock\nAudit\nAudit\nMNO\nAudit\nAudit\nBlock\nAudit\nAudit\nAudit\nAudit\nAudit\nActions applied at runtime\nAudit\nAudit\nBlock\nAudit\nAudit\nBlock\nAudit\nAudit\nItem contains credit card numbers and U.S. social security numbers\nAn item on a monitored device contains credit card numbers and U.S. social security numbers, so this item matches policy ABC, policy MNO, and policy XYZ. All three policies are in\nTurn it on\nmode.\nPolicy\nCloud egress action\nCopy to clipboard action\nCopy to USB action\nCopy to network share action\nUnallowed apps action\nPrint action\nCopy via Bluetooth action\nCopy to remote desktop action\nABC\nAudit\nAudit\nAudit\nAudit\nAudit\nBlock\nAudit\nAudit\nMNO\nAudit\nAudit\nBlock\nAudit\nAudit\nAudit\nAudit\nAudit\nXYZ\nAudit\nBlock\nAudit\nAudit\nAudit\nBlock\nAudit\nAudit\nActions applied at runtime\nAudit\nBlock\nBlock\nAudit\nAudit\nBlock\nAudit\nAudit\nItem contains credit card numbers, different policy state\nAn item on a monitored device contains credit card number, so it matches policy ABC and policy MNO. Policy ABC is in\nTurn it on\nmode and policy\nMNO\nis in\nRun the policy in simulation mode\nstate.\nPolicy\nCloud egress action\nCopy to clipboard action\nCopy to USB action\nCopy to network share action\nUnallowed apps action\nPrint action\nCopy via Bluetooth action\nCopy to remote desktop action\nABC\nAudit\nAudit\nAudit\nAudit\nAudit\nBlock\nAudit\nAudit\nMNO\nAudit\nAudit\nBlock\nAudit\nAudit\nAudit\nAudit\nAudit\nActions applied at runtime\nAudit\nAudit\nAudit\nAudit\nAudit\nBlock\nAudit\nAudit\nItem contains credit card numbers, different override configuration\nAn item on a monitored device contains credit card number, so it matches policy ABC and policy MNO. Policy ABC is in\nTurn it on\nstate and policy\nMNO\nis in\nTurn it on\nstate. They have different\nOverride\nactions configured.\nPolicy\nCloud egress action\nCopy to clipboard action\nCopy to USB action\nCopy to network share action\nUnallowed apps action\nPrint action\nCopy via Bluetooth action\nCopy to remote desktop action\nABC\nAudit\nAudit\nBlock with override\nAudit\nAudit\nBlock\nAudit\nAudit\nMNO\nAudit\nAudit\nBlock without override\nAudit\nAudit\nAudit\nAudit\nAudit\nActions applied at runtime\nAudit\nAudit\nBlock without override\nAudit\nAudit\nBlock\nAudit\nAudit\nItem contains credit card numbers, different authorization groups configuration\nAn item on a monitored device contains credit card number, so it matches policy ABC and policy MNO. Policy ABC is in\nTurn it on\nstate and policy\nMNO\nis in\nTurn it on\nstate. They have different\nauthorization group\nactions configured.\nPolicy\nCloud egress action\nCopy to clipboard action\nCopy to USB action\nCopy to network share action\nUnallowed apps action\nPrint action\nCopy via Bluetooth action\nCopy to remote desktop action\nABC\nAudit\nAudit\nAuth group A - Block\nAudit\nAudit\nAuth group A - Block\nAudit\nAudit\nMNO\nAudit\nAudit\nAuth group A - Block with override\nAudit\nAudit\nAuth group B - block\nAudit\nAudit\nActions applied at runtime\nAudit\nAudit\nAuth group A - Block\nAudit\nAudit\nAuth group A - Block, Auth group B - Block\nAudit\nAudit\nConditions\nConditions are where you define what you want the rule to look for and the context in which those items are being used. They tell the rule: when you find an item that looks like\nthis\nand is being used like\nthat\nâit's a match and the rest of the actions in the policy should be taken on it. You can use conditions to assign different actions to different risk levels. For example, sensitive content shared internally might be lower risk and require fewer actions than sensitive content shared with people outside the organization.\nNote\nUsers who have non-guest accounts in a host organization's Active Directory or Microsoft Entra tenant are considered as people inside the organization.\nContent contains\nAll locations support the\nContent contains\ncondition. You can select multiple instances of each content type and further refine the conditions by using the\nAny of these\n(logical OR) or\nAll of these\n(logical AND) operators:\nsensitive information types\nsensitivity labels\nretention labels\nTrainable Classifiers\nThe rule will only look for the presence of any\nsensitivity labels\nand\nretention labels\nyou pick.\nSITs have a predefined\nconfidence level\nwhich you can alter if needed. For more information, see\nMore on confidence levels\n.\nImportant\nSITs have two different ways of defining the maximum unique instance count parameters. To learn more, see\nInstance count supported values for SIT\n.\nAdaptive Protection in Microsoft Purview\nAdaptive protection integrates Microsoft Purview Insider Risk Management risk profiles into DLP policies so that DLP can help protect against dynamically identified risky behaviors. When configured in insider risk management, the\nInsider risk level for Adaptive Protection is\nwill show up as condition for Exchange Online, Devices, Teams, and unmanaged cloud apps locations. Refer to\nLearn about Adaptive Protection in Data Loss Prevention\nfor more details.\nConditions that Adaptive Protection supports\nInsider risk level for Adaptive Protection is...\nwith these values:\nElevated risk level\nModerate risk level\nMinor risk level\nCondition context\nThe available context options change depending on which location you choose. If you select multiple locations, only the conditions that the locations have in common are available.\nConditions Exchange supports\nNote\nDLP policies for Exchange scan non-system generated emails and journaling emails.\nContent contains\nInsider risk level for Adaptive Protection is\nContent isn't labeled\nContent is shared from Microsoft 365\nContent is received from\nSender IP address is\nHeader contains words or phrases\nSender AD Attribute contains words or phrases\nContent character set contains words\nHeader matches patterns\nSender AD Attribute matches patterns\nRecipient AD Attribute contains words or phrases\nRecipient AD Attribute matches patterns\nRecipient is member of\nDocument property is\nAny email attachment's content could not be scanned\nDocument or attachment is password protected\nHas sender overridden the policy tip\nSender is a member of\nAny email attachment's content didn't complete scanning\nRecipient address contains words\nFile extension is\nRecipient domain is\nRecipient is\nSender is\nSender domain is\nRecipient address matches patterns\nDocument name contains words or phrases\nDocument name matches patterns\nSubject contains words or phrases\nSubject matches patterns\nSubject or body contains words or phrases\nSubject or body matches patterns\nSender address contains words\nSender address matches patterns\nDocument size equals or is greater than\nDocument content contains words or phrases\nDocument content matches patterns\nMessage size equals or is greater than\nMessage type is\nMessage importance is\nTip\nFor more information on the conditions that Exchange supports, including PowerShell values, see:\nData loss prevention Exchange conditions and actions reference\n.\nConditions SharePoint supports\nContent contains\nContent is shared from Microsoft 365\nDocument property is\nDocument could not be scanned\nDocument or attachment is password protected\nDocument didn't complete scanning\nFile extension is\nDocument name contains words or phrases\nDocument size equals or is greater than\nDocument created by\nConditions OneDrive accounts support\nContent contains\nContent is shared from Microsoft 365\nDocument property is\nDocument could not be scanned\nDocument or attachment is password protected\nDocument didn't complete scanning\nFile extension is\nDocument name contains words or phrases\nDocument size equals or is greater than\nDocument created by\nDocument is shared\nConditions Teams chat and channel messages support\nContent contains\nInsider risk level for Adaptive Protection is\nContent is shared from Microsoft 365\nRecipient domain is\nRecipient is\nSender is\nSender domain is\nConditions managed cloud apps support\nContent contains\nFile extension is\nDocument size equals or is greater than\nManaged or unmanaged devices (the cut/copy data, paste data, and print data activities only support the managed or unmanaged devices condition).\nConditions unmanaged cloud apps support\nContent contains\nInsider risk level for Adaptive Protection is\nConditions supported for Endpoints\nContent contains:\nSpecifies content to be detected. For details on supported file types, see\nFiles scanned for content\n.\nContent is not labeled:\nDetects content that doesn't have a sensitivity label applied. To help ensure only supported file types are detected, you should use this condition with the\nFile extension is\nor\nFile type is\nconditions. PDF and Office files are supported:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord, PDF\n.doc, .docx, .docm, .dot, dotx, .dotm, .docb, .pdf\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, xltx, xltm, xlsb, .xlw, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx\nDocument could not be scanned:\nApplies to files that can't be scanned for one of the following reasons:\nFile contains one or more transient text-extraction errors\nFile is password-protected\nFile size exceeds the supported limit (Maximum file sizes: 64 MB for uncompressed files; 256 MB for compressed files)\nMicrosoft classification engine (MCE) timeout or failure\nDocument name contains words or phrases:\nDetects documents with file names that contain any of the words or phrases you specify, for example:\nfile\n,\ncredit card\n,\npatent\n, etc.\nDocument name matches patterns:\nDetects documents where the file name matches specific patterns. The evaluation considers the entire path of the document, not just the documentâs name. The pattern is checked as a string match, meaning it can match any part of the document path. To define the patterns, use wild cards. For information on regex patterns, see the Regular Expression documentation\nhere\n.\nNote\nDue to potential performance issues, this condition will gradually be phased out from Purview Endpoint DLP. We recommend using the 'Document name contains words or phrases' condition instead.\nDocument or attachment is password protected:\nDetects only protected files that are open. The following files are supported:\nArchive files (ZIP, .7z, RAR)\nOffice files\nPDFs\nSymantec PGP encrypted files\nDocument size equals or is greater than:\nDetects documents with file sizes that are equal to or greater than the specified value. DLP only supports content inspection for files less than 64 MB.\nImportant\nWe recommend setting this condition to detect items that are larger than 10KB\nFile type is:\nDetects the following file types:\nFile type\nApps\nMonitored file extensions\nWord processing\nWord, PDF\ndoc, .docx, .docm, .dot, dotx, .dotm, .docb, .pdf\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, xltx, xltm, xlsb, .xlw, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx\nEmail\nOutlook\n.msg\nImportant\nThe\nfile extensions\nand\nfile types\noptions\ncan't\nbe used as conditions in the same rule. If you want to use them as conditions in the same policy, they must be in separate rules.\nTo use the\nFile type is\ncondition, you must have one of the following versions of Windows:\nWindows Endpoints (X64):\nWindows 10 (21H2, 22H2)\nWindows 10 21H2 update details\nWindows 10 22H2 update details\nWindows Endpoints (ARM64):\nWindows 11 (21H2, 22H2)\nWindows 11 21H2 update details\nWindows 11 22H2 update details\nFile extension is:\nIn addition to detecting sensitive information in files with the same extensions as those covered by the\nFile type is\ncondition, you can use the\nFile extension is\ncondition to detect sensitive information in files with any file extension you need to monitor. To do so, add the necessary file extensions, separated by commas to a rule in your policy. The\nFile extension is\ncondition is supported only for those versions of Windows that support the\nFile type is\ncondition.\nFile extension is\ndoesn't support archive file types.\nWarning\nIncluding any of the following file extensions in your policy rules might significantly increase the CPU load:\n.dll, .exe, .mui, .ost, .pf, .pst.\nScanning did not complete:\nApplies when the scanning of a file started, but stopped before the entire file was scanned. The primary reason for an incomplete scan is that extracted text within the file exceeds the maximum size allowed. (Maximum sizes for extracted text: Uncompressed files: The first 4 MB of extractable text; Compressed files: N=1000 / Extraction Time = 5 minutes.)\nDocument property is:\nDetects documents with custom properties matching specified values. For example:\nDepartment = 'Marketing'\n,\nProject = 'Secret'\n. To specify multiple values for a custom property, use double quotes. For example, \"Department: Marketing, Sales\". Supported file types are Office and PDF:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord, PDF\n.doc, .docx, .docm, .dot, dotx, .dotm, .docb, .pdf\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, xltx, xltm, xlsb, .xlw, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx\nThe user accessed a sensitive website from Microsoft Edge:\nFor more information, see\nScenario 6 Monitor or restrict user activities on sensitive service domains (preview)\n.\nInsider risk level for Adaptive Protection is:\nDetects the insider risk level.\nSee also:\nEndpoint activities you can monitor and take action on\n.\nOperating system requirements for five conditions\nDocument could not be scanned\nDocument name contains words or phrases\nDocument name matches patterns\nDocument size equals or is greater than\nScanning did not complete\nTo use any of these conditions, your endpoint devices must be running one of the following operating systems:\nWindows 11 23H2:\nDecember 4, 2023âKB5032288 (OS Builds 22621.2792 and 22631.2792) Preview\nWindows 11 22H2:\nDecember 4, 2023âKB5032288 (OS Builds 22621.2792 and 22631.2792) Preview - Microsoft Support\nWindows 11 21H2:\nDecember 12, 2023âKB5033369 (OS Build 22000.2652) - Microsoft Support\nWindows 10 22H2:\nNovember 30, 2023âKB5032278 (OS Build 19045.3758) Preview - Microsoft Support\nWindows 10 21H2:\nNovember 30, 2023âKB5032278 (OS Build 19045.3758) Preview - Microsoft Support\nWindows Server 2022/2019:\nNovember 14, 2023âKB5032198 (OS Build 20348.2113) - Microsoft Support\n(or later)\nOperating system requirements for Condition 'Document Property is'\nWindows 11:\nFebruary 29, 2024âKB5034848 (OS Builds 22621.3235 and 22631.3235) Preview - Microsoft Support\n(or later)\nWindows 10:\nFebruary 29, 2024âKB5034843 (OS Build 19045.4123) Preview - Microsoft Support\n(or later)\nImportant\nFor information about the Adobe requirements for using Microsoft Purview Data Loss Prevention (DLP) features with PDF files, see this article from Adobe:\nMicrosoft Purview Information Protection Support in Acrobat\n.\nConditions Instances supports\nContent contains\nContent is shared from Microsoft 365\nConditions On-premises repositories support\nContent contains\nFile extension is\nDocument property is\nConditions Fabric and Power BI support\nContent contains\nConditions Microsoft 365 Copilot supports\nThis feature is in preview.\nContent contains (sensitivity labels)\nCondition groups\nSometimes you need a rule to identify only one thing, such as all content that contains a U.S. Social Security Number, which is defined by a single SIT. However, in many scenarios where the types of items you're trying to identify are more complex and therefore harder to define, more flexibility in defining conditions is required.\nFor example, to identify content subject to the U.S. Health Insurance Act (HIPAA), you need to look for:\nContent that contains specific types of sensitive information, such as a U.S. Social Security Number or Drug Enforcement Agency (DEA) Number.\nAND\nContent that's more difficult to identify, such as communications about a patient's care or descriptions of medical services provided. Identifying this content requires matching keywords from large keyword lists, such as the International Classification of Diseases (ICD-9-CM or ICD-10-CM).\nYou can identify this type of data by grouping conditions and using logical operators (AND, OR) between the groups.\nFor the\nU.S. Health Insurance Act (HIPAA)\n, conditions are grouped like this:\nThe first group contains the SITs that identify an individual and the second group contains the SITs that identify medical diagnosis.\nConditions can be grouped and joined by boolean operators (AND, OR, NOT) so that you define a rule by stating what should be included and then defining exclusions in a different group joined to the first by a NOT. To learn more about how Purview DLP implements booleans and nested groups see,\nComplex rule design\n.\nDLP platform limitations for conditions\nCondition\nWorkload\nLimit\nCost of Evaluation\nContent Contains\nEXO/SPO/ODB\n125 SITs per rule\nHigh\nContent is shared from Microsoft 365\nEXO/SPO/ODB\n-\nHigh\nSender IP address is\nEXO\nIndividual range length <= 128; Count <= 600\nLow\nHas sender overridden the policy tip\nEXO\n-\nLow\nSender is\nEXO\nIndividual email length <= 256; Count <= 600\nMedium\nSender is a member of\nEXO\nCount <= 600\nHigh\nSender domain is\nEXO\nDomain name length <= 67; Count <= 600\nLow\nSender address contains words\nEXO\nIndividual word length <= 128; Count <= 600\nLow\nSender address matches patterns\nEXO\nRegex length <= 128 char; Count <= 600\nLow\nSender AD attribute contains words\nEXO\nIndividual word length <= 128; Count <= 600\nMedium\nSender AD attribute matches patterns\nEXO\nRegex length <= 128 char; Count <= 600\nMedium\nContent of email attachment(s) can't be scanned\nEXO\nSupported file types\nLow\nIncomplete scan of email attachment content\nEXO\nExtracted content size > 2 MB (2 million characters)\nLow\nAttachment is password-protected\nEXO\nFile types: Office files, .PDF, .ZIP, and 7z\nLow\nAttachment's file extension is\nEXO/SPO/ODB\nCount <= 600 per rule\nHigh\nRecipient is a member of\nEXO\nCount <= 600\nHigh\nRecipient domain is\nEXO\nDomain name length <= 67; Count <= 5000\nLow\nRecipient is\nEXO\nIndividual email length <= 256; Count <= 600\nLow\nRecipient address contains words\nEXO\nIndividual word length <= 128; Count <= 600\nLow\nRecipient address matches patterns\nEXO\nCount <= 300\nLow\nDocument name contains words or phrases\nEXO\nIndividual word length <= 128; Count <=600\nLow\nDocument Name matches patterns\nEXO\nRegex length <= 128 char; Count <= 300\nLow\nDocument property is\nEXO/SPO/ODB\n-\nLow\nDocument size equals or is greater than\nEXO\n-\nLow\nSubject contains words or phrases\nEXO\nIndividual word length <= 128; Count <= 600\nLow\nHeader contains words or phrases\nEXO\nIndividual word length <= 128; Count <= 600\nLow\nSubject or body contains words or phrases\nEXO\nIndividual word length <= 128; Count <= 600\nLow\nContent character set contains words\nEXO\nCount <= 600\nLow\nHeader matches patterns\nEXO\nRegex length <= 128 char; Count <= 300\nLow\nSubject matches patterns\nEXO\nRegex length <= 128 char; Count <= 300\nLow\nSubject or body matches patterns\nEXO\nRegex length <= 128 char; Count <= 300\nLow\nMessage type is\nEXO\n-\nLow\nMessage size over\nEXO\n-\nLow\nWith importance\nEXO\n-\nLow\nSender AD attribute contains words\nEXO\nEach attribute key value pair: has Regex length <= 128 char; Count <= 600\nMedium\nSender AD attribute matches patterns\nEXO\nEach attribute key value pair: has Regex length <= 128 char; Count <= 300\nMedium\nDocument contains words\nEXO\nIndividual word length <= 128; Count <= 600\nMedium\nDocument matches patterns\nEXO\nRegex length <= 128 char; Count <= 300\nMedium\nActions\nAny item that makes it through the\nconditions\nfilter has any\nactions\nthat are defined in the rule applied to it. You have to configure the required options to support the action. For example, if you select Exchange with the\nRestrict access or encrypt the content in Microsoft 365 locations\naction, you need to choose from these options:\nBlock users from accessing shared SharePoint, OneDrive, and Teams content\nBlock everyone. Only the content owner, last modifier, and site admin will continue to have access\nBlock only people from outside your organization. Users inside your organization continue to have access.\nEncrypt email messages (applies only to content in Exchange)\nThe actions that are available in a rule depend on the locations that have been selected. The available actions for each individual location are listed below.\nImportant\nFor SharePoint and OneDrive locations, documents will be proactively blocked right after detection of sensitive information (regardless of whether the document is shared or not) for all guests; internal users continue to have access to the document.\nSupported actions: Exchange\nWhen DLP policy rules are applied in Exchange, they may be\nhalting\n,\nnon-halting\n, or\nneither\n. Most of the rules that Exchange supports are non-halting. Non-halting actions are applied after processing the subsequent rules and policies.\nDLP actions are taken on inbound encrypted emails that are in scope of a policy, such as block,\nbut\nto maintain the confidentiality of the encryption, the event won't appear in Activity Explorer or in the Alert and the content of the message won't be accessible to anyone other than the recipient.\nHowever, when a\nhalting\naction is triggered by a DLP policy rule, Purview stops processing any subsequent rules. For instance, when the\nRestrict access or encrypt the content in Microsoft 365 locations\naction is triggered, no further rules or policies are processed.\nIf an action is\nneither\nhalting nor non-halting, Purview waits for the result of the action to occur before continuing. So, when an outgoing email triggers the\nForward the message for approval to sender's manager\naction,\nPurview waits to get the manager's decision on whether or not the email may be sent. If the manager approves, the action behaves as a non-halting action and the subsequent rules are processed. In contrast, if the manager rejects sending the email,\nForward the message for approval to sender's manager\nbehaves as a halting action and blocks sending the email; no subsequent rules or policies are processed.\nThe following table lists the actions that Exchange supports, and indicates whether they're halting or non-halting.\nAction\nHalting / Non-halting\nRestrict access or encrypt the content in Microsoft 365 locations (Block Everyone, Block only people outside your organization)\nHalting\nRestrict access or encrypt the content in Microsoft 365 locations (Encrypt Email Messages)\nNon - Halting\nSet headers\nNon-halting\nRemove header\nNon-halting\nRedirect the message to specific users\nNon-halting\nForward the message for approval to sender's manager\nNeither\nForward the message for approval to specific approvers\nNeither\nAdd recipient to the To box\nNon-halting\nAdd recipient to the Cc box\nNon-halting\nAdd recipient to the Bcc box\nNon-halting\nAdd the sender's manager as recipient\nNon-halting\nRemove message encryption and rights protection\nNon-halting\nPrepend Email Subject\nNon-halting\nAdd HTML Disclaimer\nNon-halting\nModify Email Subject\nNon-halting\nDeliver the message to the hosted quarantine\nHalting\nApply branding to encrypted messages\nNon-halting\nTip\nFor the\nApply branding to encrypted messages\naction, if you already have Microsoft Purview Message Encryption implemented, the templates automatically show up in the drop-down list. If you want to implement Microsoft Purview Message Encryption, see\nAdd your organization's brand to your Microsoft Purview Message Encryption encrypted messages\nfor background on message encryption and how to create and configure your branding templates.\nFor more information on the actions that Exchange supports, including PowerShell values, see:\nData loss prevention Exchange conditions and actions reference\n.\nSupported actions: SharePoint\nRestrict access or encrypt the content in Microsoft 365 locations\nSupported actions: OneDrive\nRestrict access or encrypt the content in Microsoft 365 locations\nSupported actions: Teams Chat and Channel Messages\nRestrict access or encrypt the content in Microsoft 365 locations\nSupported actions: Devices\nThe\nDevices\nlocation supports these actions:\nRestrict access or encrypt the content in Microsoft 365 locations\nBlock users from receiving email, or accessing shared SharePoint, OneDrive, Teams files, and Power BI items\nAudit or restrict activities when users access sensitive sites in Microsoft Edge browsers on Windows devices\nSensitive site restrictions\nAudit or restrict activities on devices\nUpload to a restricted cloud service domain or accerss from an unallowed browser\nPaste to supported browsers\nFile activities for all apps\nCopy to clipboard\nCopy to removable USB device\nCopy to a network share\nPrint\nCopy or move using unallowed Bluetooth app\nCopy or move using RDP\nFile activities for apps in restricted app groups\nApp access restrictions\nAccess by restricted apps\nAccess by apps not included in restricted apps list or any restricted app groups added to rule\nin preview\nRestrictions in Windows Recall in Copilot+ PCs\nApply restrictions to only unsupported file extensions\nStart a Power Automate flow\nImportant\nWhen you select the\nAudit or restrict activities on devices\naction, the\nApply restrictions to only unsupported file extensions\nshows up.\nApply restrictions to only unsupported file extensions\nconfiguration option\nDOES NOT\nsupport scoping by\nDevice and device groups\nin the policy location setting.\nYou can tell DLP to\nAllow\n,\nAudit only\n,\nBlock with override\n, or\nBlock\n(the actions) these user activities for onboarded Windows devices.\nYou can tell DLP to\nAudit only\n,\nBlock with override\n, or\nBlock\n(the actions) these user activities for onboarded macOS devices.\nBlock\n: User related activity is blocked, and auditing is enabled. Admins may optionally see alerts.\nBlock with override\n: This option acts as a standard block but permits users to bypass it. By clicking the 'Allow' button on the toast notification or the 'Ok' button on the Microsoft Edge notification, users can proceed. Once allowed, Endpoint DLP will automatically resume for actions including 'Copy to a network share', 'Copy to a removable USB device', and 'Print'. For other actions, users will need to repeat the process after clicking 'Allow' to bypass the policy.\nAudit\n: No blocking of activities, but auditing is enabled, and admins may optionally see alerts.\nAllow\n: Activities are allowed without triggering alerts, but auditing is still enabled.\nOff\n: No blocking or auditing of activities.\nEnforcement mode\nBlock user\nAlert generation\nAuditing record generation\nBlock\nYes\nYes if alert is turned on for the DLP rule\nYes\nBlock with override\nYes\nYes if alert is turned on for the DLP rule\nYes\nAudit\nNo\nYes if alert is turned on for the DLP rule\nYes\nAllow\nNo\nNever triggered\nYes\nOff\nNo\nNo\nNo\nSupported actions: Managed cloud apps\nYou can tell DLP to\nAudit only\nor\nBlock\n(the actions) for user activities in managed cloud apps on Windows and macOS devices.\nSupported actions: Unmanaged cloud apps\nYou can tell DLP to\nAudit only\nor\nBlock\n(the actions) for user activities in unmanaged cloud apps on Windows.\nMore information on supported actions\nYou can find more details here about actions:\nRestrict access or encrypt content in Microsoft 365 locations\nAudit or restrict activities when users access sensitive sites in Microsoft Edge browsers on Windows devices\nAudit or restrict activities on devices\nService domain and browser activities\nFile activities for all apps\nRestricted app activities\nFile activities for apps in restricted app groups\nRestrict access or encrypt content in Microsoft 365 locations\nUse this to block users from receiving email, or accessing shared SharePoint, OneDrive, Teams files, and Power BI items. This action can block everyone or block only people who are outside your organization.\nAudit or restrict activities when users access sensitive sites in Microsoft Edge browsers on Windows devices\nUse this action to control when users attempt to:\nActivity\nDescription/options\nPrint the site\nDetects when users try to print a protected site from an onboarded device.\nCopy data from the site\nDetects when users try to copy data from a protected site from an onboarded device.\nSave the site as local files (Save-As)\nDetects when users try to save a protected site as local files from an onboarded device.\nAudit or restrict activities on devices\nUse this to restrict user activities by Service domain and browser activities, File activities for all apps, Restricted app activities. To use\nAudit or restrict activities on devices\n, you have to configure options in\nDLP settings\nand in the policy in which you want to use them. See,\nRestricted apps and app groups\nfor more information.\nDLP rules with the action\nAudit or restrict activities on devices\ncan have\nBlock with override\nconfigured. When this rule is applied to a file, any attempt to perform a restricted action on the file is blocked. A notification is displayed with the option to override the restriction. If the user chooses to override, the action is permitted for a period of 1 minute, during which the user can retry the action without restriction. The exception to this behavior is when a sensitive file is dragged and dropped into Microsoft Edge, which will immediately attach the file if the rule is overridden.\nService domain and browser activities\nWhen you configure the\nAllow/Block cloud service domains\nand the\nUnallowed browsers\nlist (see\nBrowser and domain restrictions to sensitive data\n) and a user attempts to upload a protected file to a cloud service domain or access it from an unallowed browser, you can configure the policy action to\nAudit only\n,\nBlock with override\n, or\nBlock\nthe activity.\nActivity\nDescription/options\nUpload to a restricted cloud services domain or access from an unallowed app\nDetects when protected files are blocked or allowed to be uploaded to cloud service domains. See,\nBrowser and domain restrictions to sensitive data\nand\nScenario 6 Monitor or restrict user activities on sensitive service domains)\n.\nPaste to supported browsers\nDetects when users paste sensitive information into a text field or web form using Microsoft Edge, Google Chrome (with Microsoft Purview extension), or Mozilla Firefox (with Microsoft Purview extension). Evaluation is independent of the classification of the source file. For more information, see:\nEndpoint activities you can monitor and take action on\n.\nPaste to Browser limitations\nOnly certain rule conditions will work with Paste to Browser events due to the fact that the rules are being evaluated only on the clipboard data. Paste to Browser will not evaluate based on where the text is being copied from.\nRule conditions that work with Paste to Browser:\nContent contains\nContent is not labeled\nAdditional notes:\nPaste to Browser supports SITs, not Sensitivity Labels.\nPaste to Browser doesn't not evaluate on text smaller than 30 characters.\nAdvanced Classification isn't supported.\nContextual Summary doesn't show for Paste to Browser events.\nPaste to Browser takes 2 seconds to evaluate before allowing the paste action.\nIF JIT is configured to block on fallback, it will block pasting.\nPaste to Browser only classifies the first 4 MB of text from the clipboard\nFile activities for all apps\nWith the\nFile activities for all apps\noption, you select either\nDon't restrict file activities\nor\nApply restrictions to specific activities\n. When you select\nApply restrictions to specific activities\n, the actions that you select here are applied when a user has accessed a DLP protected item.\nActivity\nDescription/options\nCopy to clipboard\nDetects when protected files are copied to the clipboard on an onboarded device. For more information, see\nEndpoint activities you can monitor and take action on\nand\nCopy to clipboard behavior\nCopy to a removable device\nDetects when protected files are copied or moved from an onboarded device to a removable USB device. For more information, see\nRemovable USB device groups\n.\nCopy to a network share\nDetects when protected files are copied or moved from an onboarded device to any network share. For more information, see\nEndpoint activities you can monitor and take action on\nand\nNetwork share coverage and exclusions\n.\nPrint\nDetects when a protected file is printed from an onboarded device. For more information, see\nPrinter groups\n.\nCopy or move using unallowed Bluetooth app\nDetects when a protected file is copied or moved from an onboarded Windows device using an unallowed Bluetooth app. For more information, see\nUnallowed Bluetooth apps\n. This isn't supported for macOS.\nCopy or move using RDP\nDetects when users copy or move protected files from an onboarded Windows device to another location using RDP. This isn't supported for macOS.\nRestricted app activities\nPreviously called Unallowed apps,\nrestricted app activities\nare apps that you want to place restrictions on. You define these apps in a list in Endpoint DLP settings. When a user attempts to access a DLP protected file using an app that is on the list, you can either\nAudit only\n,\nBlock with override\n, or\nBlock\nthe activity. DLP actions defined in\nRestricted app activities\nare overridden if the app is a member of restricted app group. Then the actions defined in the restricted app group are applied.\nActivity\nDescription/options\nAccess by restricted apps\nDetects when unallowed apps try to access protected files on an onboarded Windows device. For more information, see\nRestricted apps and app groups\n.\nFile activities for apps in restricted app groups\nYou define your restricted app groups in Endpoint DLP settings and add restricted app groups to your policies. When you add a restricted app group to a policy, you must select one of these options:\nDon't restrict file activity\nApply restrictions to all activity\nApply restrictions to specific activity\nWhen you select either of the\nApply restrictions\noptions, and a user attempts to access a DLP protected file using an app that is in the restricted app group, you can either\nAudit only\n,\nBlock with override\n, or\nBlock\nby activity. DLP actions that you define here override actions defined in\nRestricted app activities\nand\nFile activities for all apps\nfor the app.\nFor more information, see\nRestricted apps and app groups\n.\nNote\nThe devices location provides many subactivities (conditions) and actions. To learn more, see\nEndpoint activities you can monitor and take action on\n.\nImportant\nThe\nCopy to clipboard\ncondition detects when a user copies information from a\nprotected file\nto the clipboard. Use\nCopy to clipboard\nto block, block with override, or audit when users copy information from a protected file.\nThe\nPaste to supported browsers\ncondition detects when a user attempts to paste sensitive text into a text field or web form using Microsoft Edge, Google Chrome with Microsoft Purview extension, or Mozilla Firefox with Microsoft Purview\nextension\nregardless of where that information came from\n. Use\nPaste to supported browsers\nto block, block with override, or audit when users paste sensitive information into a text field or web form.\nInstances actions\nRestrict access or encrypt the content in Microsoft 365 locations\nRestrict Third Party Apps\nOn-premises repositories actions\nRestrict access or remove on-premises files.\nBlock people from accessing files stored in on-premises repositories\nSet permissions on the file (permissions inherited from the parent folder)\nMove file from where it's stored to a quarantine folder\nSee,\nDLP On-premises repository actions\nfor full details.\nFabric and Power BI actions\nNotify users with email and policy tips\nSend alerts to Administrator\nRestrict access\nNote\nApplicable to\nsupported item types\nonly.\nMicrosoft 365 Copilot actions\nThis feature is in preview.\nExclude content in the location\nManaged cloud apps actions\nRestrict browser and network activities\nUnmanaged cloud apps actions\nRestrict browser and network activities\nActions available when you combine locations\nIf you select Exchange and any other single location for the policy to be applied to, the\nRestrict access or encrypt the content in Microsoft 365 locations and all actions for the non-Exchange location actions are available.\nIf you select two or more non-Exchange locations for the policy to be applied to, the\nRestrict access or encrypt the content in Microsoft 365 locations and all actions for non-Exchange locations actions are available.\nFor example, if you select the Exchange and Devices locations, these actions are available:\nRestrict access or encrypt the content in Microsoft 365 locations\nAudit or restrict activities on Windows devices\nIf you select Devices and Instances, these actions are available:\nRestrict access or encrypt the content in Microsoft 365 locations\nAudit or restrict activities on Windows devices\nRestrict Third Party Apps\nWhether an action takes effect or not depends on how you configure the mode of the policy. You can choose to run the policy in simulation mode with or without showing policy tip by selecting the\nRun the policy in simulation mode\noption. You choose to run the policy as soon as an hour after it's created by selecting the\nTurn it on right away\noption, or you can choose to just save it and come back to it later by selecting the\nKeep it off\noption.\nDLP platform limitations for actions\nAction Name\nWorkload\nLimits\nRestrict access or encrypt content in Microsoft 365\nEXO/SPO/ODB\nSet headers\nEXO\nRemove header\nEXO\nRedirect the message to specific users\nEXO\nTotal of 100 across all DLP rules. Can't be DL/SG\nForward the message for approval to sender's manager\nEXO\nManager should be defined in AD\nForward the message for approval to specific approvers\nEXO\nGroups aren't supported\nAdd recipient to the\nTo\nbox\nEXO\nRecipient count <= 10; Can't be DL/SG\nAdd recipient to the\nCc\nbox\nEXO\nRecipient count <= 10; Can't be DL/SG\nAdd recipient to the\nBcc\nbox\nEXO\nRecipient count <= 10; Can't be DL/SG\nAdd the sender's manager as recipient\nEXO\nManager attribute should be defined in AD\nApply HTML disclaimer\nEXO\nPrepend subject\nEXO\nApply message encryption\nEXO\nRemove message encryption\nEXO\n(preview) Exclude content in Copilot location\nMicrosoft 365 Copilot (preview)\nOnly content in SharePoint and OneDrive for Business can be excluded from being processed by Microsoft 365 Copilot\nUser notifications and policy tips\nWhen a user attempts an activity on a sensitive item in a context that meets the conditions of a rule (for example, content such as an Excel workbook on a OneDrive site that contains personal data (PII) and is shared with a guest), you can let them know about it through user notification emails and in-context policy tip popups. These notifications are useful because they increase awareness and help educate people about your organization's DLP policies.\nAn Alert email, Incident Report email, and User Notification will only be sent once per document. If a document with a 'Content is Shared' condition is shared twice, there will still be only one notification.\nImportant\nNotification emails are sent unprotected.\nEmail notifications are only supported for the Microsoft 365 services.\nEmail notifications support by selected location\nSelected location\nEmail notifications supported\nDevices\n- Not supported\nExchange + Devices\n- Supported for Exchange\n- Not supported for Devices\nExchange\n- Supported\nSharePoint + Devices\n- Supported for SharePoint\n- Not supported for Devices\nSharePoint\n- Supported\nExchange + SharePoint\n- Supported for Exchange\n- Supported for SharePoint\nDevices + SharePoint + Exchange\n- Not supported for Devices\n- Supported for SharePoint\nSupported for Exchange\nTeams\n- Not supported\nOneDrive\n- Supported for OneDrive for work or school\n- Not supported for Devices\nFabric and Power-BI\n- Not supported\nInstances\n- Not supported\nOn-premises repositories\n- Not supported\nExchange + SharePoint + OneDrive\n- Supported for Exchange\n- Supported for SharePoint\n- Supported for OneDrive\nM365 Copilot (preview)\n- Not supported\nManaged cloud apps\n- Not supported\nUnmanaged cloud apps\n- Not supported\nYou can also give people the option to\noverride the policy\n, so that they're not blocked if they have a valid business need or if the policy is detecting a false positive.\nPolicy tips and user notifications configuration options\nThe user notifications and policy tips configuration options vary depending on the monitoring locations you've selected. If you selected:\nExchange\nSharePoint\nOneDrive\nTeams Chat and Channel\nInstances\nYou can enable/disable user notifications for various Microsoft apps, see\nData Loss Prevention policy tips reference\n.\nYou can also enable/disable notifications with a policy tip.\nemail notifications to the user who sent, shared, or last modified the content\nOR\nnotify specific people\nFurthermore, you can customize the email text, subject, and the policy tip text.\nFor detailed information on customizing end user notification emails, see\nCustom email notifications\n.\nIf you selected Devices only, you get all the same options that are available for Exchange, SharePoint, OneDrive, Teams Chat and Channel, and Instances, plus the option to customize the notification title, content, and add a hyperlink in the form of a\nGet Support\nbutton that appears on the Windows 10/11 device.\nCustom policy tip notifications character limits\nPolicy tip notifications are subject to the following character limits:\nVariable\nCharacter Limit\nTITLE\n120\nCONTENT\n250\nJUSTIFICATION\n250\nHyperlink has no character limit but is limited to the remaining space available in the entire DLP package. The hyperlink must be a resolvable URL, and it's abstracted behind a selectable control. The more information hyperlink is available in Microsoft 365 Office apps.\nYou can customize the title and body of text using the following parameters.\nCommon name\nParameter\nExample\nfile name\n%%FileName%%\nContoso doc 1\nprocess name\n%%ProcessName%%\nWord\npolicy name\n%%PolicyName%%\nContoso highly confidential\naction\n%%AppliedActions%%\npasting document content from the clipboard to another app\n%%AppliedActions%%\nsubstitutes these values into the message body:\naction common name\nvalue substituted in for %%AppliedActions%% parameter\ncopy to removeable storage\nwriting to removable storage\ncopy to network share\nwriting to a network share\nprint\nprinting\npaste from clipboard\npasting from the clipboard\ncopy via bluetooth\ntransferring via Bluetooth\nopen with an unallowed app\nopening with this app\ncopy to a remote desktop (RDP)\ntransferring to remote desktop\nuploading to an unallowed website\nuploading to this site\naccessing the item via an unallowed browser\nopening with this browser\nUsing this customized text\n%%AppliedActions%% File name %%FileName%% via %%ProcessName%% isn't allowed by your organization. Select 'Allow' if you want to bypass the policy %%PolicyName%%\nproduces this text in the customized notification:\npasting from the clipboard File Name: Contoso doc 1 via WINWORD.EXE isn't allowed by your organization. Select the 'Allow' button if you want to bypass the policy Contoso highly confidential\nYou can localize your custom policy tips by using the\nSet-DlpComplianceRule -NotifyPolicyTipCustomTextTranslations cmdlet\n.\nCustom Policy Tips show for the most restrictive rule, not necessarily the rule that is performing the restriction.\nNote\nUser notifications and policy tips aren't available for the On-premises location\nOnly the policy tip from the highest priority, most restrictive rule is shown. For example, a policy tip from a rule that blocks access to content will be shown over a policy tip from a rule that simply sends a notification. This prevents people from seeing a cascade of policy tips.\nTo learn more about user notification and policy tip configuration and use, including how to customize the notification and tip text, see\nSend email notifications and show policy tips for DLP policies\n.\nPolicy tip considerations\nPolicy tips aren't generated if the sensitivity labels is in a compressed file.\nDLP has difficulty generating policy tips for encrypted files.\nPolicy tip references\nDetails on support for policy tips and notifications for different apps can be found here:\nData loss prevention policy tip reference for Outlook for Microsoft 365\nData loss prevention policy tip reference for Outlook on the Web\nData loss prevention policy tip reference SharePoint in Microsoft 365 and OneDrive. web client\nBlock users in Exchange\nNote\nIf you have policy tips enabled when the policy is configured to\nBlock only users outside your organization\nis met, the policy tips notification will block you from sending a message at all if there are external recipients. Therefore, you have to remove any external recipients before you can send the message to internal recipients.\nBlocking and notifications in SharePoint in Microsoft 365 and OneDrive\nThe following table shows the DLP blocking and notification behavior for policies that are scoped to SharePoint in Microsoft 365 and OneDrive. This isn't intended to be an exhaustive list, and there are more settings that aren't in scope for this article.\nNote\nThe notification behavior described in this table may require the following settings to be enabled:\nUser notifications:\nOn\nNotify users in Office 365 service with a policy tip\nNotify the user who sent, shared, or last modified the content\nIncident reports:\nSend an alert to admins when a rule match occurs\nSend alert every time an activity matches the rule is selected\nUse email incident reports to notify you when a policy match occurs\nConditions\nRestrict access setting\nBlocking and notification behavior\n-\nContent is shared from Microsoft 365\n- with people outside my organization\nNot configured\nUser notifications, alerts, and incident reports are sent only when a file is shared with a guest and a guest access the file\n-\nContent is shared from Microsoft 365\n- only with people inside my organization\nNot configured\nUser notifications, alerts, and incident reports are sent when a file is uploaded\n-\nContent is shared from Microsoft 365\n- only with people inside my organization\n-\nRestrict access or encrypt the content in Microsoft 365 locations\n-\nBlock users from receiving email or accessing shared SharePoint, OneDrive, and Teams files\n-\nBlock everyone\n- Access to sensitive files is blocked as soon as they're uploaded.\n- User notifications, alerts, and incident reports are sent when a file is uploaded\n- **Content is shared from Microsoft 365 - with people outside my organization\n-\nRestrict access or encrypt the content in Microsoft 365 locations\n-\nBlock users from receiving email or accessing shared SharePoint, OneDrive, and Teams files\n-\nBlock only people outside your organization\n- Access to a sensitive file is blocked as soon as its uploaded, regardless of whether the document is shared or not for all guests.\n- If the sensitive information is added to a file after it's shared and accessed by a user outside the organization, user notifications, alerts, and incident reports are sent.\n- If the document contains sensitive information before it's uploaded, external sharing will be blocked proactively. Because external sharing in this scenario is blocked when the file is uploaded, no alerts or incident reports are sent. Suppression of the alerts and incident reports is designed to prevent a flood of alerts to the user for each blocked file.\n- Proactive blocking will show up as event in the Audit Log and Activity Explorer.\n-\nContent is shared from Microsoft 365\n-\nwith people outside my organization\n-\nRestrict access or encrypt the content in Microsoft 365 locations\n-\nBlock users from receiving email or accessing shared SharePoint, OneDrive, and Teams files\n-\nBlock everyone\n- When the first user outside the organization access the document, the event causes the document to be blocked.\n- It's expected that for a short time, the document is accessible by guests who have the link to the file.\n- User notifications, alerts, and incident reports are sent when a file is shared with a guest and a guest access that file\n-\nContent contains\n,\nSensitivity label\nAND\n-\nContent is shared from Microsoft 365\nBlock\nThe actions defined in the policy (block, user notifications, alerts, and incident reports) will happen either before or when the user opens, modifies, or shares the item.\nLearn more URL\nUsers may want to learn why their activity is being blocked. You can configure a site or a page that explains more about your policies. When you select\nProvide a compliance URL for the end user to learn more about your organization's policies (only available for Exchange)\n, and the user receives a policy tip notification in Outlook Win32, the\nLearn more\nlink points to the site URL that you provide. This URL has priority over the global compliance URL configured with\nSet-PolicyConfig -ComplainceURL\n.\nImportant\nYou must configure the site or page that\nLearn more\npoints to from scratch. Microsoft Purview doesn't provide this functionality out of the box.\nUser overrides\nThe intent of\nUser overrides\nis to give users a way to bypass, with justification, DLP policy blocking actions on sensitive items in Exchange, SharePoint, OneDrive, or Teams, so that they can continue their work. User overrides are enabled only when\nNotify users in Office 365 services with a policy tip\nis enabled, so user overrides go hand-in-hand with Notifications and Policy tips.\nNote\nUser overrides aren't available for the On-premises repositories location.\nTypically, user overrides are useful when your organization is first rolling out a policy. The feedback that you get from any override justifications and identifying false positives helps in tuning the policy.\nIf the policy tips in the most restrictive rule allow people to override the rule, then overriding this rule also overrides any other rules that the content matched.\nUser override behavior\nWhen a user selects the\nAllow\noption to override a block action for these activities:\nPrint\nCopy to a removable USB device\nCopy to a network share\nwithin 30 seconds of the popup notification showing, the activity is allowed to continue. If the user doesn't select the\nAllow\noption within 30 seconds, the activity is blocked.\nFor all other activities, the user must repeat the activity after selecting the\nAllow\noption in order for it to complete\nBusiness justification X-Header\nWhen a user overrides a block with override action on an email, the override option and the text that they provide are stored in the\nAudit log\nand in the email X-header. To view the business justification overrides,\nsearch the audit log\nfor\nExceptionInfo\nvalue for the details. Here's an example of the audit log values:\n{\n \"FalsePositive\"; false,\n \"Justification\"; My manager approved sharing of this content\",\n \"Reason\"; \"Override\",\n \"Rules\": [\n \"<message guid>\"\n ]\n}\nIf you have an automated process that makes use of the business justification values, the process can access that information programmatically in the email X-header data.\nNote\nThe\nmsip_justification\nvalues are stored in the following order:\nFalse Positive; Recipient Entitled; Manager Approved; I Acknowledge; JustificationText_[free text]\n.\nNotice that the values are separated by semicolons. The maximum free text allowed is 500 characters.\nIncident reports\nWhen a rule is matched, you can send an\nAlert\nemail to your compliance officer (or any people you choose) with details of the event and you can view them in the Microsoft Purview Data Loss Prevention\nAlerts\ndashboard and in the\nMicrosoft 365 Defender portal\n. An alert includes information about the item that was matched, the actual content that matched the rule, and the name of the person who last modified the content.\nIn preview admin alert emails include details such as:\nThe alert severity\nThe time the alert occurred\nThe activity.\nThe sensitive data that were detected.\nThe alias of the user whose activity triggered the alert.\nThe policy that was matched.\nThe alert ID\nThe endpoint operation that was attempted if the\nDevices\nlocation is in the scope of the policy.\nThe app that was being used.\nThe device name, if the match occurred on an endpoint device.\nDLP feeds incident information to other Microsoft Purview Information Protection services, like\ninsider risk management\n. In order to get incident information to insider risk management, you must set the\nIncident reports\nseverity level to\nHigh\n.\nAlert types\nAlerts can be sent every time an activity matches a rule, which can be noisy. To help cut down on the noise, they can be aggregated based on number of matches or volume of items over a set period of time. There are two types of alerts that can be configured in DLP policies.\nSingle-event alerts\nare typically used in policies that monitor for highly sensitive events that occur in a low volume, like a single email with 10 or more customer credit card numbers being sent outside your organization. In preview\nuser based alert aggregation (preview)\nmodifies the behavior of single event alerts.\nAggregate-event alerts\nare typically used in policies that monitor for events that occur in a higher volume over a period of time. For example, an aggregate alert can be triggered when 10 individual emails each with one customer credit card number is sent outside your org over 48 hours.\nNote\nFor rules with Alerts configured on Sharepoint, or OneDrive workloads we only send one alert per file per rule. This is true, even if the same violation has been committed by multiple users.\nOther alert options\nWhen you select\nUse email incident reports to notify you when a policy match occurs\nyou can choose to include:\nThe name of the person who last modified the content.\nThe types of sensitive content that matched the rule.\nThe rule's severity level.\nThe content that matched the rule, including the surrounding text.\nThe item containing the content that matched the rule.\nFor more information on alerts, see:\nAlerts in DLP policies\n: Describes alerts in the context of a DLP policy.\nGet started with data loss prevention alerts\n: Covers the necessary liscensing, permissions, and prerequisites for DLP alerts and alert reference details.\nCreate and deploy data loss prevention policies\n: Includes guidance on alert configuration in the context of creating a DLP policy.\nLearn about investigating data loss prevention alerts\n: Covers the various methods for investigating of DLP alerts.\nInvestigate data loss incidents with Microsoft Defender XDR\n: How to investigate DLP alerts in Microsoft Defender portal.\nEvidence collection for file activities on devices\nIf you've enabled\nSetup evidence collection for file activities on devices\nand added Azure storage accounts, you can select\nCollect original file as evidence for all selected file activities on Endpoint\nand the Azure storage account you want to copy the items to. You must also choose the activities you want to copy items for. For example, if you select\nPrint\nbut not\nCopy to a network share\n, then only items that are printed from monitored devices will be copied to the Azure storage account.\nAdditional options\nIf you have multiple rules in a policy, you can use the\nAdditional options\nto control further rule processing if there's a match to the rule you're editing as well as setting the priority for evaluation of the rule. This is only supported for Exchange and Teams locations\nSee also\nLearn about data loss prevention\nPlan for data loss prevention (DLP)\nCreate and Deploy data loss prevention policies\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DLP Policy Reference",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/dlp-create-deploy-policy": {
      "content_hash": "sha256:919f16e8cb5508d9c2711f50764409e9da511488499646fc28eb2b053aa89c8a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and deploy data loss prevention policies\nFeedback\nSummarize this article for me\nMicrosoft Purview Data Loss Prevention (DLP) policies include many configuration options. Each option changes the policy's behavior. The articles in this series cover some of the most common DLP policy scenarios. They walk you through configuring those options to give you hands-on experience with the DLP policy creation process. When you familiarize yourself with these scenarios, you gain the foundational skills that you need to use the DLP policy creation UX to create your own policies.\nHow you deploy a policy is as important policy design. You have\nmultiple options to control policy deployment\n. This article shows you how to use these options so that the policy achieves your intent while avoiding costly business disruptions.\nIn preview\nYou can change the display name of DLP policies and rules. Once you rename a policy or a rule, any existing records retain their previous name in activity explorer evetns, in alerts and in audit records. New records will reflect the new name in activity explorer events, in alerts and in audit records. These names will remain until the items age out of the system.\nOrient yourself to DLP\nAdministrative units\nLearn about Microsoft Purview Data Loss Prevention\nPlan for data loss prevention (DLP)\n- by working through this article you will:\nIdentify stakeholders\nDescribe the categories of sensitive information to protect\nSet goals and strategy\nCollection Policies solution overview\nCollection policy reference\nData Loss Prevention policy reference\n- this article introduces all the components of a DLP policy and how each one influences the behavior of a policy\nDesign a DLP policy\n- this article walks you through creating a policy intent statement and mapping it to a specific policy configuration.\nCreate and Deploy data loss prevention policies\n- This article presents some common policy intent scenarios that you map to configuration options, then it walks you through configuring those options.\nLearn about investigating data loss prevention alerts\n- This article introduces you to the lifecycle of alerts from creation, through final remediation and policy tuning. It also introduces you to the tools you use to investigate alerts.\nSKU/subscriptions licensing\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nPermissions\nThe account you use to create and deploy policies must be a member of one of these role groups:\nCompliance administrator\nCompliance data administrator\nInformation Protection\nInformation Protection Admin\nSecurity administrator\nImportant\nBefore you start, make sure you understand the difference between an\nunrestricted administrator\nand an\nadministrative unit restricted administrator\nby reading\nAdministrative units\n.\nGranular Roles and Role Groups\nYou can use these roles and role groups to fine tune your access controls.\nHere's a list of applicable roles. To learn more, see\nPermissions in the Microsoft Purview portal\n.\nDLP Compliance Management\nInformation Protection Admin\nInformation Protection Analyst\nInformation Protection Investigator\nInformation Protection Reader\nHere's a list of applicable role groups. To learn more, see\nPermissions in the Microsoft Purview portal\n.\nInformation Protection\nInformation Protection Admins\nInformation Protection Analysts\nInformation Protection Investigators\nInformation Protection Readers\nPolicy creation scenarios for Enterprise applications & devices\nThe previous article,\nDesign a DLP policy\n, introduces you to the methodology of creating a policy intent statement and then mapping that intent statement to policy configuration options.\nHelp prevent sharing credit card numbers through email\nHelp prevent sharing sensitive items via SharePoint and OneDrive with external users\nHelp protect files that Endpoint Data Loss Prevention fails to scan\nHelp protect files that Endpoint Data Loss Prevention doesn't scan\nHelp protect against sharing of a defined set of unsupported files\nDisable Microsoft Purview data loss prevention scanning for some supported files and apply controls\nHelp prevent sharing Power BI reports with credit card numbers\nPolicy creation scenarios for Inline web traffic\nHelp prevent sharing via Microsoft Edge for Business to unmanaged AI apps from managed devices\nHelp Prevent Users from Sharing Sensitive Info with Cloud Apps in Edge for Business\nHelp prevent sharing sensitive information with unmanaged AI apps via network data security\nDeployment\nA successful policy deployment isn't just about getting the policy into your environment to enforce controls on user actions. A haphazard, rushed deployment can negatively impact business processes and annoy your users. Those consequences slow acceptance of DLP technology in your organization and the safer behaviors it promotes. Ultimately, those consequences make your sensitive items less safe in the long run.\nBefore you start your deployment, make sure you read through\nPolicy deployment\n. It gives you a broad overview of the policy deployment process and general guidance.\nThis section dives more deeply into the three types of controls you use in concert to manage your policies in production. You can change any of these controls at any time, not just during policy creation.\nThree axes of deployment management\nUse three axes to control the policy deployment process: scope, state, and actions. Always take an incremental approach to deploying a policy, starting from the least impactful\nsimulation mode\nthrough full enforcement.\nRecommended deployment control configurations\nWhen your policy state is\nYour policy scope can be\nImpact of policy actions\nRun the policy in simulation mode\nPolicy scope of locations can be narrow or broad\n- You can configure any action\n- No user impact from configured actions\n- Admin sees alerts and can track activities\nRun the policy in simulation mode with policy tips\nPolicy should be scoped to target a pilot group and then expand the scope as you tune the policy\n- You can configure any action\n- No user impact from configured actions\n- Users can receive policy tips and alerts\n- Admin sees alerts and can track activities\nTurn it on\nAll targeted location instances\n- All configured actions are enforced on user activities\n- Admin sees alerts and can track activities\nKeep it off\nn/a\nn/a\nState\nState is the primary control you use to roll out a policy. When you finish creating your policy, set the state of the policy to\nKeep it off\n. Leave it in this state while you work on the policy configuration and until you get a final review and sign off. Set the state to:\nRun the policy in simulation mode\n: No policy actions are enforced, events are audited. While in this state, you can monitor the impact of the policy in the DLP simulation mode overview and the DLP\nActivity explorer\nconsole.\nRun the policy in simulation mode and show policy tips while in simulation mode\n: No actions are enforced, but users receive policy tips and notification emails to raise their awareness and educate them.\nTurn it on right away\n: This is full enforcement mode.\nKeep it off\n: The policy is inactive. Use this state while developing and reviewing your policy before deployment.\nYou can change the state of a policy at any time.\nActions\nActions are what a policy does in response to user activities on sensitive items. Because you can change these actions at any time, you can start with the least impactful,\nAllow\n(for devices) and\nAudit only\n(for all other locations), gather and review the audit data, and use it to tune the policy before moving to more restrictive actions.\nAllow\n: The user activity is allowed to occur, so no business processes are impacted. You get audit data and there aren't any user notifications or alerts.\nNote\nThe\nAllow\naction is only available for policies that are scoped to the\nDevices\nlocation.\nAudit only\n: The user activity is allowed to occur, so no business processes are impacted. You get audit data and you can add notifications and alerts to raise awareness and train your users to know that what they're doing is a risky behavior. If your organization intends to enforce more restrictive actions later on, you can tell your users that too.\nBlock with override\n: The user activity is blocked by default. You can audit the event, raise alerts and notifications. This action impacts the business process, but your users are given the option to override the block and provide a reason for the override. Because you get direct feedback from your users, this action can help you identify false positive matches, which you can use to further tune the policy.\nNote\nFor Exchange online and SharePoint in Microsoft 365, you configure overrides in the user notification section.\nBlock\n: The user activity is blocked no matter what. You can audit the event, raise alerts and notifications.\nPolicy scope\nEvery policy is scoped to one or more locations, such as Exchange, SharePoint in Microsoft 365, Teams, and Devices. By default, when you select a location, all instances of that location fall under the scope and none are excluded. You can further refine which instances of the location (such as sites, groups, accounts, distribution groups, mailboxes, and devices) that the policy is applied to by configuring the include/exclude options for the location. To learn more about your include/exclude scoping options, see,\nLocations\n.\nIn general, you have more flexibility with scoping while the policy is in\nRun the policy in simulation mode\nstate because no actions are taken. You can start with just the scope you designed the policy for or go broad to see how the policy would impact sensitive items in other locations.\nWhen you change the state to\nRun the policy in simulation mode and show policy tips\n, narrow your scope to a pilot group that can give you feedback and be early adopters who can be a resource for others when they come onboard.\nWhen you move the policy to\nTurn it on right away\n, you broaden the scope to include all the instances of locations that you intended when the policy was designed.\nPolicy deployment steps\nAfter you've created the policy and set its state to\nKeep it off\n, do a final review with your stakeholders.\nChange the state to\nRun the policy in simulation mode\n. The location scope can be broad at this point so you can gather data on the behavior of the policy across multiple locations or just start with a single location.\nTune the policy based on the behavior data so that it better meets the business intent.\nChange the state to\nRun the policy in simulation mode and show policy tips\n. Refine the scope of locations to support a pilot group if needed and make use of includes/excludes so that the policy is first rolled out to that pilot group.\nGather user feedback and alert and event data. If needed, tune the policy and your plans. Make sure you address all the issues that your users bring up. Your users will most likely encounter issues and raise questions about things that you didn't think of during the design phase. Develop a group of super users at this point. They can be a resource to help train other users as the scope of the policy is increased and more users come onboard. Before you go to the next stage of deployment, make sure that the policy is achieved your control objectives.\nChange the state to\nTurn it on right away\n. The policy is fully deployed. Monitor DLP alerts and DLP activity explorer. Address alerts.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DLP for M365 Copilot",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/sensitivity-labels": {
      "content_hash": "sha256:eb0cca0eb037d4540caae13b96882a8a331aaa0127e483528f43c827f30f4fcb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about sensitivity labels\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nNote\nIf you're looking for information about sensitivity labels that you see and can select in your Office apps, see\nApply sensitivity labels to your files and email in Office\n.\nThe information on this page is for IT administrators who can create and configure those labels.\nTo get their work done, people in your organization collaborate with others both inside and outside the organization. This means that content no longer stays behind a firewallâit can roam everywhere, across devices, apps, and services. And when it roams, you want it to do so in a secure, protected way that meets your organization's business and compliance policies.\nSensitivity labels from Microsoft Purview Information Protection let you classify and protect your organization's data, while making sure that user productivity and their ability to collaborate isn't hindered.\nThe following example from Excel shows how users might see an applied sensitivity label from the window bar, and how they can easily change the label by using the\nsensitivity bar\nthat's available with the latest versions of Office. The labels are also available from the\nSensitivity\nbutton on the\nHome\ntab from the ribbon.\nTo apply sensitivity labels, users must be signed in with their Microsoft 365 work or school account.\nNote\nFor US Government tenants, sensitivity labels are supported for all platforms.\nIf you use the Microsoft Purview Information Protection client and scanner, see the\nAzure Information Protection Premium Government Service Description\n.\nYou can use sensitivity labels to:\nProvide protection settings that include encryption and content markings.\nFor example, apply a \"Confidential\" label to a document or email, and that label encrypts the content and applies a \"Confidential\" watermark. Content markings include headers and footers as well as watermarks, and encryption can also restrict what actions specified people can take on the content.\nExtend SharePoint protection when files are downloaded\nwhen you configure a default sensitivity label for SharePoint document libraries and select the option to extend protection for unencrypted files. Then, when these files are downloaded, the current SharePoint permissions travel with the labeled file.\nProtect content in Office apps across different platforms and devices.\nSupported by Word, Excel, PowerPoint, and Outlook on the Office desktop apps and Office for the web. Supported on Windows, macOS, iOS, and Android.\nProtect content in third-party apps and services\nby using Microsoft Defender for Cloud Apps. With Defender for Cloud Apps, you can detect, classify, label, and protect content in third-party apps and services, such as SalesForce, Box, or DropBox, even if the third-party app or service doesn't read or support sensitivity labels.\nIdentify content for eDiscovery cases\n. The condition builder to create search queries in eDiscovery supports sensitivity labels that are applied to content. For example, as part of your eDiscovery case, restrict content to files and emails that have a Highly Confidential sensitivity label. Or conversely, exclude content to files and emails that have a Public sensitivity label.\nProtect containers\nthat include Teams, Microsoft 365 Groups, SharePoint sites, and Loop workspaces. For example, set privacy settings, external user access and external sharing, access from unmanaged devices, and control how channels can be shared with other teams.\nProtect meetings and chat\nby labeling (and optionally, encrypting) meeting invites and any responses, and enforce Teams-specific options for the meeting and chat.\nExtend sensitivity labels to Power BI\n: When you turn on this capability, you can apply and view labels in Power BI, and protect data when it's saved outside the service.\nExtend sensitivity labels to assets in Microsoft Purview Data Map\n: When you turn on this capability, currently in preview, you can apply your sensitivity labels to files and schematized data assets in Microsoft Purview Data Map. The schematized data assets include SQL, Azure SQL, Azure Synapse, Azure Cosmos DB, and AWS RDS.\nExtend sensitivity labels to third-party apps and services.\nUsing the Microsoft Information Protection SDK, third-party apps can read sensitivity labels and apply protection settings.\nLabel content without using any protection settings.\nYou can also just apply a label as a result of identifying the sensitivity of the data. This action provides users with a visual mapping of your organization's data sensitivity, and the labels can generate usage reports and activity data for data that has different levels of sensitivity. Based on this information, you can always choose to apply protection settings later.\nProtect data when Microsoft 365 Copilot and Microsoft 365 Copilot Chat is used.\nCopilot and agents recognize and integrate sensitivity labels into the user interactions to help keep labeled data protected. For more information, see the following section\nSensitivity labels for Microsoft 365 Copilot and Microsoft 365 Copilot Chat\n.\nIn all these cases, sensitivity labels from Microsoft Purview can help you take the right actions on the right content. With sensitivity labels, you can identify the sensitivity of data across your organization, and the label can enforce protection settings that are appropriate for the sensitivity of that data. That protection then stays with the content.\nFor more information about these and other scenarios that are supported by sensitivity labels, see\nCommon scenarios for sensitivity labels\n. To see how your sensitivity labels are being used, view the reports from the\nMicrosoft Purview portal\n.\nNew features are being developed all the time that support sensitivity labels, so you might also find it useful to check the\nMicrosoft 365 roadmap\n.\nWhat a sensitivity label is\nWhen you assign a sensitivity label to content, it's like a stamp that's applied and is:\nCustomizable.\nSpecific to your organization and business needs, you can create categories for different levels of sensitive content in your organization. For example, Personal, Public, General, Confidential, and Highly Confidential.\nClear text.\nBecause a label is stored in clear text in the metadata for files and emails, third-party apps and services can read it and then apply their own protective actions, if required.\nPersistent.\nBecause the label is stored in metadata for files and emails, the label stays with the content, no matter where it's saved or stored. The label identification that's unique to your organization becomes the basis for applying and enforcing policies that you configure.\nWhen viewed by users in your organization, an applied sensitivity label appears like a tag on apps and can be easily integrated into their existing workflows. Your sensitivity labels\naren't visible in apps to users from other organizations, or to guests\n.\nThe following example shows an opened email where another user has applied the sensitivity label named\nGeneral\n, which doesn't apply encryption. The label description supplied by the admin displays more detail to users about the category of data identified by this sensitivity label.\nNote\nDon't confuse sensitivity labels with Outlook's built-in\nsensitivity levels\nthat indicate the sender's intention but can't provide data security.\nEach item that supports sensitivity labels can have a single sensitivity label applied to it from your organization. Documents and emails can have both a sensitivity label and a\nretention label\napplied to them.\nWhat sensitivity labels can do\nAfter a sensitivity label is applied to content, for example in an email, meeting invite, document, or Loop page, any configured protection settings for that label are enforced on the content. You can configure a sensitivity label to:\nControl access to content, using encryption\nfor emails, meeting invites, and documents to prevent unauthorized people from accessing this data. You can additionally choose which users or group have permissions to perform which actions and for how long. For example, you can choose to allow all users in your organization to modify a document while a specific group in another organization can only view it. Alternatively, instead of administrator-defined permissions, you can allow your users to assign permissions to the content when they apply the label.\nFor more information about the encryption-based access control settings when you create or edit a sensitivity label, see\nRestrict access to content by using encryption in sensitivity labels\n.\nMark the content\nwhen you use Office apps, by adding watermarks, headers, or footers to email, meeting invites, or documents that have the label applied. Watermarks can be applied to documents and Loop component and pages, but not email or meeting invites. Example header and watermark:\nContent markings also support variables. For example, insert the label name or document name into the header, footer, or watermark. For more information, see\nContent markings with variables\n.\nNeed to check when content markings are applied? See\nWhen Office apps apply content marking and encryption\n.\nIf you have templates or workflows that are based on specific documents, test those documents with your chosen content markings before you make the label available for users. Some string length restrictions to be aware of:\nWatermarks are limited to 255 characters. Headers and footers are limited to 1024 characters, except in Excel. Excel has a total limit of 255 characters for headers and footers but this limit includes characters that aren't visible, such as formatting codes. If that limit is reached, the string you enter isn't displayed in Excel.\nProtect content in containers such as sites and groups\nwhen you enable the capability to\nuse sensitivity labels with Microsoft Teams, Microsoft 365 groups, and SharePoint sites\n.\nYou can't configure protection settings for groups and sites until you enable this capability. This label configuration doesn't result in documents or emails being automatically labeled but instead, the label settings protect content by controlling access to the container where content can be stored. These settings include privacy settings, external user access and external sharing, access from unmanaged devices, private teams discoverability, and sharing controls for channels.\nApply the label automatically to files and emails, or recommend a label.\nChoose how to identify sensitive information that you want labeled, and the label can be applied automatically, or you can prompt users to apply the label that you recommend with a policy tip. If you recommend a label, you can customize the prompt but the following example shows the automatically generated text:\nFor more information about the\nAuto-labeling for files and emails\nsettings when you create or edit a sensitivity label, see\nAutomatically apply a sensitivity label to Microsoft 365 data\nfor Office apps, and\nLabeling in Microsoft Purview Data Map\n.\nSet the default sharing link type\nfor SharePoint sites and individual documents. To help prevent users oversharing, set the\ndefault scope and permissions\nfor when users share documents from SharePoint and OneDrive.\nFor more label configurations, see\nManage sensitivity labels for Office apps\n.\nLabel scopes\nWhen you create a sensitivity label, you're asked to configure the label's scope, which determines two things:\nWhich label settings you can configure for that label\nThe availability of the label to apps and services, which includes whether users can see and select the label\nThis scope configuration lets you have sensitivity labels that are just for items such as files, emails, and meetings, and can't be selected for groups and sites. Similarly, sensitivity labels that are just for groups and sites and can't be selected for items.\nBy default, the\nFiles & other data assets\nscope is always selected for a new label. As well as files for Office, Loop, and Power BI, it includes items from Microsoft Fabric, and data assets for Microsoft Purview Data Map when you\nextend your sensitivity labels beyond Microsoft 365\n. For more information about which items support sensitivity labels:\nFor Office files:\nOffice file types supported\nFor Microsoft Loop:\nSensitivity labels to protect Loop components and pages\nFor Power BI:\nSupported export paths\nFor Microsoft Fabric:\nInformation protection in Microsoft Fabric\nFor Data Map:\nData sources that connect to Data Map\nYou typically select the\nEmails\nscope together with\nFiles & other data assets\n, because emails often include files as attachments and share the same sensitivity. Many labeling features require both options to be selected, but there might be times when you want a new label to be available for emails only. For more information, see\nScope labels to just files or emails\n.\nThe scope for\nMeetings\nincludes calendar events, Teams meetings options, and Team chat. You must also select the\nFiles & other data assets\nscope and\nEmails\nscope for this option. For more information about this labeling scenario, see\nUse sensitivity labels to protect calendar items, Teams meetings, and chat\n.\nThe\nGroups & sites\nscope becomes available and selected by default when you\nenable sensitivity labels for containers and synchronize labels\n. This option lets you protect content in SharePoint sites, Teams sites, and Loop workspaces by labeling those containers but doesn't label the items in them.\nNote\nItems that were previously in the\nSchematized data assets\nscope are now included in\nFiles & other data assets\n.\nIf one or more scopes aren't selected, you see the first page of the configuration settings for these scopes, but you can't configure the settings. For these pages that have unavailable options, select\nNext\nto continue to configure settings for the next scope. Or, select\nBack\nto change the label's scope.\nLabel priority (order matters)\nWhen you create your sensitivity labels in the Microsoft Purview portal, they appear in a list on the\nLabels\npage from\nInformation Protection\n. In this list, the order of the labels is important because it sets their priority. You want your most restrictive sensitivity label, such as Highly Confidential, to appear at the\nbottom\nof the list, and your least restrictive sensitivity label, such as Personal or Public, to appear at the\ntop\n.\nYou can apply just one sensitivity label to an item such as a document, email, or container. If you use the option that requires your users to provide a justification for changing a label to a lower sensitivity for files, emails, and meetings, the order of this list identifies the lower sensitivity. However, this option doesn't apply to sublabels that share the priority of their parent label, and doesn't apply to data assets or labels that protect containers.\nNote\nIf you're using the\nmodern label scheme\nthat replaces parent labels with label groups, sublabels in the same label group also don't support the justification setting.\nThe priority of sublabels is used with\nautomatic labeling\n, though. When you configure auto-labeling policies, multiple matches can result for more than one label. Then, the last sensitive label is selected, and then if applicable, the last sublabel. When you configure the auto-labeling label setting (rather than auto-labeling policies) for sublabels themselves, the behavior is a little different when these labels share the same parent label or label group. For example, a sublabel configured for automatic labeling is preferred over a sublabel configured for recommended labeling. For more information, see\nHow multiple conditions are evaluated when they apply to more than one label\n.\nThe priority of sublabels is also used with\nlabel inheritance from email attachments\n.\nWhen you select a sensitivity label, you can change its priority by using the options to move it to the top or bottom of the list if it's not a sublabel, move it up or down by one label, or directly assign a priority number. For example:\nSublabels that use parent labels or label groups\nYou might often want to logically group sensitivity labels in a two-tier hierarchy, to denote the overall sensitivity level but provide labels with different settings. As an example from the\ndefault sensitivity labels\n:\nConfidential\nAnyone (unrestricted)\nAll Employees\nTrusted People\nIn apps, users first see\nConfidential\nand then must select one of the other sensitivity labels, such as\nAll Employees\n. The applied sensitivity label is then\nConfidential \\ All Employees\n.\nThe second tier of sensitivity labels don't inherit any settings from the first tier label, except the label color. In our example, the\nConfidential\nlabel is simply a text label with no protection settings, and can't be applied by itself to content.\nThe initial implementation to group labels in this two-tier hierarchy used parent labels and sublabels. The configuration of parent labels looked the same as the configuration of sublabels, but behaved differently when sublabels were published to users.\nTo reduce this complexity, label groups are now replacing parent labels. Label groups look and behave the same to users, but have configuration options only for the settings that they support: the label name, descriptions, color, and priority. You can't publish label groups themselves, only the labels within the groupings.\nIf you're still using parent labels with sublabels: Don't choose a parent label as the default label, or configure a parent label to be automatically applied (or recommended). If you do, the parent label can't be applied.\nExample of how sublabels display for users:\nIf required, you can manually convert parent labels to label groups. For more information, see\nMigrate parent sensitivity labels to label groups\n.\nEditing or deleting a sensitivity label\nIf you delete a sensitivity label from the Microsoft Purview portal, the label isn't automatically removed from content, and any protection settings continue to be enforced on content that had that label applied.\nIf you edit a sensitivity label, the version of the label that was applied to content is what's enforced on that content.\nFor detailed information about what happens when you delete a sensitivity label and how this is different from removing it from a sensitivity label policy, see\nRemoving and deleting labels\n.\nWhat label policies can do\nAfter you create your sensitivity labels, you need to publish them to make them available to people and services in your organization. The sensitivity labels can then be applied to Office documents and emails, and other items that support sensitivity labels.\nUnlike retention labels, which are published to locations such as all Exchange mailboxes, sensitivity labels are published to users or groups. Apps that support sensitivity labels can then display them to those users and groups as labels that they can apply.\nAlthough the default is to publish labels to all users in your organization, multiple label policies let you publish different sensitivity labels to different users if this is needed. For example, all users see labels that they can apply for Public, General, and Confidential, but only users in your legal department also see a Highly Confidential label that they can apply.\nAll users in the same organization can see the name of a sensitivity label applied to content, even if that label isn't published to them. They won't see sensitivity labels from other organizations.\nWhen you configure a publishing label policy, you can:\nChoose which users and groups see the labels.\nLabels can be published to any specific user or email-enabled security group, distribution group, or Microsoft 365 group (which can have\ndynamic membership\n) in Microsoft Entra ID.\nSpecify a default label\nfor unlabeled documents and Loop components and pages, emails and meeting invites, new containers (when you've\nenabled sensitivity labels for Microsoft Teams, Microsoft 365 groups, and SharePoint sites\n), and also a default label for\nPower BI content\n. You can specify the same label for all five types of items, or different labels. Users can change the applied default sensitivity label to better match the sensitivity of their content or container.\nConsider using a default label to set a base level of protection settings that you want applied to all your content. However, without user training and other controls, this setting can also result in inaccurate labeling. It's usually not a good idea to select a label that applies encryption as a default label to documents. For example, many organizations need to send and share documents with external users who might not have apps that support the encryption or they might not use an account that can be authorized. For more information about this scenario, see\nSharing encrypted documents with external users\n.\nImportant\nWhen you have\nsublabels\n, be careful not to configure the parent label as a default label.\nRequire a justification for changing a label.\nFor files, emails, and meetings, but not for groups and sites (used by Teams and SharePoint), if a user tries to remove a label or replace it with a label that has a lower priority, by default the user must provide a justification to perform this action. For example, a user opens a document labeled Confidential (order number 3) and replaces that label with one named Public (order number 1). For Office apps, this justification prompt is triggered once per app session. When you use the Microsoft Purview Information Protection client, the prompt is triggered for each file. Administrators can read the justification reason along with the label change in\nactivity explorer\n.\nRequire users to apply a label\nfor the different types of items and the containers that support sensitivity labels. Also known as mandatory labeling, these options ensure a label must be applied before users can save files and send emails or meeting invites, create new groups or sites, and when they use unlabeled content for Power BI.\nFor documents and emails, a label can be assigned manually by the user, automatically as a result of a condition that you configure, or be assigned by default (the default label option previously described). An example prompt when a user is required to assign a label:\nFor more information about mandatory labeling for documents and emails, see\nRequire users to apply a label to their email and documents\n.\nFor containers, a label must be assigned at the time the group or site is created.\nFor more information about mandatory labeling for Power BI, see\nMandatory label policy for Power BI\n.\nConsider using this option to help increase your labeling coverage. However, without user training, these settings can result in inaccurate labeling. In addition, unless you also set a corresponding default label, mandatory labeling can frustrate your users with the frequent prompts.\nProvide help link to a custom help page.\nIf your users aren't sure what your sensitivity labels mean or how they should be used, you can provide a Learn More URL that appears after the list of available sensitivity labels in the Office apps. For example:\nFor more label policy configurations, see\nManage sensitivity labels for Office apps\n.\nAfter you create a publishing label policy that assigns new sensitivity labels to users and groups, users start to see those labels in their Office apps. Allow up to 24 hours for the latest changes to replicate throughout your organization.\nThere's no limit to the number of sensitivity labels that you can create and publish, with one exception: If the label applies encryption that specifies the users and permissions, there's a maximum of 500 labels per tenant supported with this configuration. However, as a best practice to lower admin overheads and reduce complexity for your users, try to keep the number of labels to a minimum.\nTip\nReal-world deployments have proved effectiveness to be noticeably reduced when users have more than five main labels or more than five sublabels per main label. You might also find that some applications can't display all your labels when too many are published to the same user.\nLabel policy priority (order matters)\nYou make your sensitivity labels available to users by publishing them in a sensitivity label policy that appears in a list on the\nLabel policies\npage. Just like sensitivity labels (see\nLabel priority (order matters)\n), the order of the sensitivity label policies is important because it reflects their priority: The label policy with lowest priority is shown at the top of the list with the\nlowest\norder number, and the label policy with the highest priority is shown at the bottom of the list with the\nhighest\norder number.\nA label policy consists of:\nA set of labels.\nThe users and groups that will be assigned the policy with labels.\nThe scope of the policy and policy settings for that scope (such as default label for files and emails).\nYou can include a user in multiple label policies, and the user will get all the sensitivity labels and settings from those policies. If there's a conflict in settings from multiple policies, the settings from the policy with the highest priority (highest order number) is applied. In other words, the highest priority wins for each setting.\nIf you're not seeing the label policy setting behavior that you expect for a user or group, check the order of the sensitivity label policies. You might need to move the policy down. To reorder the label policies, select a sensitivity label policy > choose the Actions ellipsis for that entry >\nMove down\nor\nMove up\n. For example:\nFrom our screenshot example that shows three label policies, all users are assigned the standard label policy, so it's appropriate it has the lowest priority (lowest order number of 0). Only users in the IT department are assigned the second policy that has the order number 1. For these users, if there are any conflicts in settings between their policy and the standard policy, the settings from their policy wins because it has a higher order number.\nSimilarly for users in the legal department, who are assigned the third policy with distinct settings. It's likely these users will have more stringent settings, so it's appropriate that their policy has the highest order number. It's unlikely a user from the legal department will be in a group that's also assigned to the policy for the IT department. But if they are, the order number 2 (highest order number) ensures the settings from the legal department always take priority if there's a conflict.\nNote\nRemember: If there is a conflict of settings for a user who has multiple policies assigned to them, the setting from the assigned policy with the highest order number is applied.\nSensitivity labels for Microsoft 365 Copilot and Microsoft 365 Copilot Chat\nThe sensitivity labels that you use to protect your organization's data are recognized and used by Microsoft 365 Copilot, Microsoft 365 Copilot Chat, and Copilot agents to provide an extra layer of protection. For example, in Microsoft 365 Copilot Chat conversations that can reference data from different types of items, the sensitivity label with the highest priority (typically, the most restrictive label) is visible to users. Similarly, when sensitivity label inheritance is supported by Copilot and agents, the sensitivity label with the highest priority is selected.\nIf the labels applied encryption from Microsoft Purview Information Protection, Copilot and agents check the usage rights for the user. Only if the user is granted permissions to copy (the EXTRACT usage right) from an item, is data from that item returned by Copilot or agents.\nFor more detailed information about how sensitivity labels help protect your data when you use Copilot and other AI apps, see the following articles:\nMicrosoft Purview data security and compliance protections for generative AI apps\nUse Microsoft Purview to manage data security & compliance for Microsoft 365 Copilot & Microsoft 365 Copilot Chat\nConsiderations to manage Microsoft 365 Copilot for security and compliance\nSensitivity labels and Azure Information Protection\nThe older labeling client, the Azure Information Protection unified labeling client, is now replaced with the\nMicrosoft Purview Information Protection client\nto extend labeling on Windows to File Explorer, PowerShell, the on-premises scanner, and provide a viewer for encrypted files.\nOffice apps support sensitivity labels with a subscription versions of Office, such as Microsoft 365 Apps for enterprise.\nSensitivity labels and the Microsoft Information Protection SDK\nBecause a sensitivity label is stored in the metadata of a document, third-party apps and services can read from and write to this labeling metadata to supplement your labeling deployment. Additionally, software developers can use the\nMicrosoft Information Protection SDK\nto fully support labeling and encryption capabilities across multiple platforms. To learn more, see the\nGeneral Availability announcement on the Tech Community blog\n.\nYou can also learn about\npartner solutions that are integrated with Microsoft Purview Information Protection\n.\nDeployment guidance\nFor deployment planning and guidance that includes licensing information, permissions, deployment strategy, a list of supported scenarios, and end-user documentation, see\nGet started with sensitivity labels\n.\nTo learn how to use sensitivity labels to comply with data privacy regulations, see\nDeploy information protection for data privacy regulations with Microsoft 365\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Sensitivity Labels",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/sensitivity-labels": {
      "content_hash": "sha256:eb0cca0eb037d4540caae13b96882a8a331aaa0127e483528f43c827f30f4fcb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about sensitivity labels\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nNote\nIf you're looking for information about sensitivity labels that you see and can select in your Office apps, see\nApply sensitivity labels to your files and email in Office\n.\nThe information on this page is for IT administrators who can create and configure those labels.\nTo get their work done, people in your organization collaborate with others both inside and outside the organization. This means that content no longer stays behind a firewallâit can roam everywhere, across devices, apps, and services. And when it roams, you want it to do so in a secure, protected way that meets your organization's business and compliance policies.\nSensitivity labels from Microsoft Purview Information Protection let you classify and protect your organization's data, while making sure that user productivity and their ability to collaborate isn't hindered.\nThe following example from Excel shows how users might see an applied sensitivity label from the window bar, and how they can easily change the label by using the\nsensitivity bar\nthat's available with the latest versions of Office. The labels are also available from the\nSensitivity\nbutton on the\nHome\ntab from the ribbon.\nTo apply sensitivity labels, users must be signed in with their Microsoft 365 work or school account.\nNote\nFor US Government tenants, sensitivity labels are supported for all platforms.\nIf you use the Microsoft Purview Information Protection client and scanner, see the\nAzure Information Protection Premium Government Service Description\n.\nYou can use sensitivity labels to:\nProvide protection settings that include encryption and content markings.\nFor example, apply a \"Confidential\" label to a document or email, and that label encrypts the content and applies a \"Confidential\" watermark. Content markings include headers and footers as well as watermarks, and encryption can also restrict what actions specified people can take on the content.\nExtend SharePoint protection when files are downloaded\nwhen you configure a default sensitivity label for SharePoint document libraries and select the option to extend protection for unencrypted files. Then, when these files are downloaded, the current SharePoint permissions travel with the labeled file.\nProtect content in Office apps across different platforms and devices.\nSupported by Word, Excel, PowerPoint, and Outlook on the Office desktop apps and Office for the web. Supported on Windows, macOS, iOS, and Android.\nProtect content in third-party apps and services\nby using Microsoft Defender for Cloud Apps. With Defender for Cloud Apps, you can detect, classify, label, and protect content in third-party apps and services, such as SalesForce, Box, or DropBox, even if the third-party app or service doesn't read or support sensitivity labels.\nIdentify content for eDiscovery cases\n. The condition builder to create search queries in eDiscovery supports sensitivity labels that are applied to content. For example, as part of your eDiscovery case, restrict content to files and emails that have a Highly Confidential sensitivity label. Or conversely, exclude content to files and emails that have a Public sensitivity label.\nProtect containers\nthat include Teams, Microsoft 365 Groups, SharePoint sites, and Loop workspaces. For example, set privacy settings, external user access and external sharing, access from unmanaged devices, and control how channels can be shared with other teams.\nProtect meetings and chat\nby labeling (and optionally, encrypting) meeting invites and any responses, and enforce Teams-specific options for the meeting and chat.\nExtend sensitivity labels to Power BI\n: When you turn on this capability, you can apply and view labels in Power BI, and protect data when it's saved outside the service.\nExtend sensitivity labels to assets in Microsoft Purview Data Map\n: When you turn on this capability, currently in preview, you can apply your sensitivity labels to files and schematized data assets in Microsoft Purview Data Map. The schematized data assets include SQL, Azure SQL, Azure Synapse, Azure Cosmos DB, and AWS RDS.\nExtend sensitivity labels to third-party apps and services.\nUsing the Microsoft Information Protection SDK, third-party apps can read sensitivity labels and apply protection settings.\nLabel content without using any protection settings.\nYou can also just apply a label as a result of identifying the sensitivity of the data. This action provides users with a visual mapping of your organization's data sensitivity, and the labels can generate usage reports and activity data for data that has different levels of sensitivity. Based on this information, you can always choose to apply protection settings later.\nProtect data when Microsoft 365 Copilot and Microsoft 365 Copilot Chat is used.\nCopilot and agents recognize and integrate sensitivity labels into the user interactions to help keep labeled data protected. For more information, see the following section\nSensitivity labels for Microsoft 365 Copilot and Microsoft 365 Copilot Chat\n.\nIn all these cases, sensitivity labels from Microsoft Purview can help you take the right actions on the right content. With sensitivity labels, you can identify the sensitivity of data across your organization, and the label can enforce protection settings that are appropriate for the sensitivity of that data. That protection then stays with the content.\nFor more information about these and other scenarios that are supported by sensitivity labels, see\nCommon scenarios for sensitivity labels\n. To see how your sensitivity labels are being used, view the reports from the\nMicrosoft Purview portal\n.\nNew features are being developed all the time that support sensitivity labels, so you might also find it useful to check the\nMicrosoft 365 roadmap\n.\nWhat a sensitivity label is\nWhen you assign a sensitivity label to content, it's like a stamp that's applied and is:\nCustomizable.\nSpecific to your organization and business needs, you can create categories for different levels of sensitive content in your organization. For example, Personal, Public, General, Confidential, and Highly Confidential.\nClear text.\nBecause a label is stored in clear text in the metadata for files and emails, third-party apps and services can read it and then apply their own protective actions, if required.\nPersistent.\nBecause the label is stored in metadata for files and emails, the label stays with the content, no matter where it's saved or stored. The label identification that's unique to your organization becomes the basis for applying and enforcing policies that you configure.\nWhen viewed by users in your organization, an applied sensitivity label appears like a tag on apps and can be easily integrated into their existing workflows. Your sensitivity labels\naren't visible in apps to users from other organizations, or to guests\n.\nThe following example shows an opened email where another user has applied the sensitivity label named\nGeneral\n, which doesn't apply encryption. The label description supplied by the admin displays more detail to users about the category of data identified by this sensitivity label.\nNote\nDon't confuse sensitivity labels with Outlook's built-in\nsensitivity levels\nthat indicate the sender's intention but can't provide data security.\nEach item that supports sensitivity labels can have a single sensitivity label applied to it from your organization. Documents and emails can have both a sensitivity label and a\nretention label\napplied to them.\nWhat sensitivity labels can do\nAfter a sensitivity label is applied to content, for example in an email, meeting invite, document, or Loop page, any configured protection settings for that label are enforced on the content. You can configure a sensitivity label to:\nControl access to content, using encryption\nfor emails, meeting invites, and documents to prevent unauthorized people from accessing this data. You can additionally choose which users or group have permissions to perform which actions and for how long. For example, you can choose to allow all users in your organization to modify a document while a specific group in another organization can only view it. Alternatively, instead of administrator-defined permissions, you can allow your users to assign permissions to the content when they apply the label.\nFor more information about the encryption-based access control settings when you create or edit a sensitivity label, see\nRestrict access to content by using encryption in sensitivity labels\n.\nMark the content\nwhen you use Office apps, by adding watermarks, headers, or footers to email, meeting invites, or documents that have the label applied. Watermarks can be applied to documents and Loop component and pages, but not email or meeting invites. Example header and watermark:\nContent markings also support variables. For example, insert the label name or document name into the header, footer, or watermark. For more information, see\nContent markings with variables\n.\nNeed to check when content markings are applied? See\nWhen Office apps apply content marking and encryption\n.\nIf you have templates or workflows that are based on specific documents, test those documents with your chosen content markings before you make the label available for users. Some string length restrictions to be aware of:\nWatermarks are limited to 255 characters. Headers and footers are limited to 1024 characters, except in Excel. Excel has a total limit of 255 characters for headers and footers but this limit includes characters that aren't visible, such as formatting codes. If that limit is reached, the string you enter isn't displayed in Excel.\nProtect content in containers such as sites and groups\nwhen you enable the capability to\nuse sensitivity labels with Microsoft Teams, Microsoft 365 groups, and SharePoint sites\n.\nYou can't configure protection settings for groups and sites until you enable this capability. This label configuration doesn't result in documents or emails being automatically labeled but instead, the label settings protect content by controlling access to the container where content can be stored. These settings include privacy settings, external user access and external sharing, access from unmanaged devices, private teams discoverability, and sharing controls for channels.\nApply the label automatically to files and emails, or recommend a label.\nChoose how to identify sensitive information that you want labeled, and the label can be applied automatically, or you can prompt users to apply the label that you recommend with a policy tip. If you recommend a label, you can customize the prompt but the following example shows the automatically generated text:\nFor more information about the\nAuto-labeling for files and emails\nsettings when you create or edit a sensitivity label, see\nAutomatically apply a sensitivity label to Microsoft 365 data\nfor Office apps, and\nLabeling in Microsoft Purview Data Map\n.\nSet the default sharing link type\nfor SharePoint sites and individual documents. To help prevent users oversharing, set the\ndefault scope and permissions\nfor when users share documents from SharePoint and OneDrive.\nFor more label configurations, see\nManage sensitivity labels for Office apps\n.\nLabel scopes\nWhen you create a sensitivity label, you're asked to configure the label's scope, which determines two things:\nWhich label settings you can configure for that label\nThe availability of the label to apps and services, which includes whether users can see and select the label\nThis scope configuration lets you have sensitivity labels that are just for items such as files, emails, and meetings, and can't be selected for groups and sites. Similarly, sensitivity labels that are just for groups and sites and can't be selected for items.\nBy default, the\nFiles & other data assets\nscope is always selected for a new label. As well as files for Office, Loop, and Power BI, it includes items from Microsoft Fabric, and data assets for Microsoft Purview Data Map when you\nextend your sensitivity labels beyond Microsoft 365\n. For more information about which items support sensitivity labels:\nFor Office files:\nOffice file types supported\nFor Microsoft Loop:\nSensitivity labels to protect Loop components and pages\nFor Power BI:\nSupported export paths\nFor Microsoft Fabric:\nInformation protection in Microsoft Fabric\nFor Data Map:\nData sources that connect to Data Map\nYou typically select the\nEmails\nscope together with\nFiles & other data assets\n, because emails often include files as attachments and share the same sensitivity. Many labeling features require both options to be selected, but there might be times when you want a new label to be available for emails only. For more information, see\nScope labels to just files or emails\n.\nThe scope for\nMeetings\nincludes calendar events, Teams meetings options, and Team chat. You must also select the\nFiles & other data assets\nscope and\nEmails\nscope for this option. For more information about this labeling scenario, see\nUse sensitivity labels to protect calendar items, Teams meetings, and chat\n.\nThe\nGroups & sites\nscope becomes available and selected by default when you\nenable sensitivity labels for containers and synchronize labels\n. This option lets you protect content in SharePoint sites, Teams sites, and Loop workspaces by labeling those containers but doesn't label the items in them.\nNote\nItems that were previously in the\nSchematized data assets\nscope are now included in\nFiles & other data assets\n.\nIf one or more scopes aren't selected, you see the first page of the configuration settings for these scopes, but you can't configure the settings. For these pages that have unavailable options, select\nNext\nto continue to configure settings for the next scope. Or, select\nBack\nto change the label's scope.\nLabel priority (order matters)\nWhen you create your sensitivity labels in the Microsoft Purview portal, they appear in a list on the\nLabels\npage from\nInformation Protection\n. In this list, the order of the labels is important because it sets their priority. You want your most restrictive sensitivity label, such as Highly Confidential, to appear at the\nbottom\nof the list, and your least restrictive sensitivity label, such as Personal or Public, to appear at the\ntop\n.\nYou can apply just one sensitivity label to an item such as a document, email, or container. If you use the option that requires your users to provide a justification for changing a label to a lower sensitivity for files, emails, and meetings, the order of this list identifies the lower sensitivity. However, this option doesn't apply to sublabels that share the priority of their parent label, and doesn't apply to data assets or labels that protect containers.\nNote\nIf you're using the\nmodern label scheme\nthat replaces parent labels with label groups, sublabels in the same label group also don't support the justification setting.\nThe priority of sublabels is used with\nautomatic labeling\n, though. When you configure auto-labeling policies, multiple matches can result for more than one label. Then, the last sensitive label is selected, and then if applicable, the last sublabel. When you configure the auto-labeling label setting (rather than auto-labeling policies) for sublabels themselves, the behavior is a little different when these labels share the same parent label or label group. For example, a sublabel configured for automatic labeling is preferred over a sublabel configured for recommended labeling. For more information, see\nHow multiple conditions are evaluated when they apply to more than one label\n.\nThe priority of sublabels is also used with\nlabel inheritance from email attachments\n.\nWhen you select a sensitivity label, you can change its priority by using the options to move it to the top or bottom of the list if it's not a sublabel, move it up or down by one label, or directly assign a priority number. For example:\nSublabels that use parent labels or label groups\nYou might often want to logically group sensitivity labels in a two-tier hierarchy, to denote the overall sensitivity level but provide labels with different settings. As an example from the\ndefault sensitivity labels\n:\nConfidential\nAnyone (unrestricted)\nAll Employees\nTrusted People\nIn apps, users first see\nConfidential\nand then must select one of the other sensitivity labels, such as\nAll Employees\n. The applied sensitivity label is then\nConfidential \\ All Employees\n.\nThe second tier of sensitivity labels don't inherit any settings from the first tier label, except the label color. In our example, the\nConfidential\nlabel is simply a text label with no protection settings, and can't be applied by itself to content.\nThe initial implementation to group labels in this two-tier hierarchy used parent labels and sublabels. The configuration of parent labels looked the same as the configuration of sublabels, but behaved differently when sublabels were published to users.\nTo reduce this complexity, label groups are now replacing parent labels. Label groups look and behave the same to users, but have configuration options only for the settings that they support: the label name, descriptions, color, and priority. You can't publish label groups themselves, only the labels within the groupings.\nIf you're still using parent labels with sublabels: Don't choose a parent label as the default label, or configure a parent label to be automatically applied (or recommended). If you do, the parent label can't be applied.\nExample of how sublabels display for users:\nIf required, you can manually convert parent labels to label groups. For more information, see\nMigrate parent sensitivity labels to label groups\n.\nEditing or deleting a sensitivity label\nIf you delete a sensitivity label from the Microsoft Purview portal, the label isn't automatically removed from content, and any protection settings continue to be enforced on content that had that label applied.\nIf you edit a sensitivity label, the version of the label that was applied to content is what's enforced on that content.\nFor detailed information about what happens when you delete a sensitivity label and how this is different from removing it from a sensitivity label policy, see\nRemoving and deleting labels\n.\nWhat label policies can do\nAfter you create your sensitivity labels, you need to publish them to make them available to people and services in your organization. The sensitivity labels can then be applied to Office documents and emails, and other items that support sensitivity labels.\nUnlike retention labels, which are published to locations such as all Exchange mailboxes, sensitivity labels are published to users or groups. Apps that support sensitivity labels can then display them to those users and groups as labels that they can apply.\nAlthough the default is to publish labels to all users in your organization, multiple label policies let you publish different sensitivity labels to different users if this is needed. For example, all users see labels that they can apply for Public, General, and Confidential, but only users in your legal department also see a Highly Confidential label that they can apply.\nAll users in the same organization can see the name of a sensitivity label applied to content, even if that label isn't published to them. They won't see sensitivity labels from other organizations.\nWhen you configure a publishing label policy, you can:\nChoose which users and groups see the labels.\nLabels can be published to any specific user or email-enabled security group, distribution group, or Microsoft 365 group (which can have\ndynamic membership\n) in Microsoft Entra ID.\nSpecify a default label\nfor unlabeled documents and Loop components and pages, emails and meeting invites, new containers (when you've\nenabled sensitivity labels for Microsoft Teams, Microsoft 365 groups, and SharePoint sites\n), and also a default label for\nPower BI content\n. You can specify the same label for all five types of items, or different labels. Users can change the applied default sensitivity label to better match the sensitivity of their content or container.\nConsider using a default label to set a base level of protection settings that you want applied to all your content. However, without user training and other controls, this setting can also result in inaccurate labeling. It's usually not a good idea to select a label that applies encryption as a default label to documents. For example, many organizations need to send and share documents with external users who might not have apps that support the encryption or they might not use an account that can be authorized. For more information about this scenario, see\nSharing encrypted documents with external users\n.\nImportant\nWhen you have\nsublabels\n, be careful not to configure the parent label as a default label.\nRequire a justification for changing a label.\nFor files, emails, and meetings, but not for groups and sites (used by Teams and SharePoint), if a user tries to remove a label or replace it with a label that has a lower priority, by default the user must provide a justification to perform this action. For example, a user opens a document labeled Confidential (order number 3) and replaces that label with one named Public (order number 1). For Office apps, this justification prompt is triggered once per app session. When you use the Microsoft Purview Information Protection client, the prompt is triggered for each file. Administrators can read the justification reason along with the label change in\nactivity explorer\n.\nRequire users to apply a label\nfor the different types of items and the containers that support sensitivity labels. Also known as mandatory labeling, these options ensure a label must be applied before users can save files and send emails or meeting invites, create new groups or sites, and when they use unlabeled content for Power BI.\nFor documents and emails, a label can be assigned manually by the user, automatically as a result of a condition that you configure, or be assigned by default (the default label option previously described). An example prompt when a user is required to assign a label:\nFor more information about mandatory labeling for documents and emails, see\nRequire users to apply a label to their email and documents\n.\nFor containers, a label must be assigned at the time the group or site is created.\nFor more information about mandatory labeling for Power BI, see\nMandatory label policy for Power BI\n.\nConsider using this option to help increase your labeling coverage. However, without user training, these settings can result in inaccurate labeling. In addition, unless you also set a corresponding default label, mandatory labeling can frustrate your users with the frequent prompts.\nProvide help link to a custom help page.\nIf your users aren't sure what your sensitivity labels mean or how they should be used, you can provide a Learn More URL that appears after the list of available sensitivity labels in the Office apps. For example:\nFor more label policy configurations, see\nManage sensitivity labels for Office apps\n.\nAfter you create a publishing label policy that assigns new sensitivity labels to users and groups, users start to see those labels in their Office apps. Allow up to 24 hours for the latest changes to replicate throughout your organization.\nThere's no limit to the number of sensitivity labels that you can create and publish, with one exception: If the label applies encryption that specifies the users and permissions, there's a maximum of 500 labels per tenant supported with this configuration. However, as a best practice to lower admin overheads and reduce complexity for your users, try to keep the number of labels to a minimum.\nTip\nReal-world deployments have proved effectiveness to be noticeably reduced when users have more than five main labels or more than five sublabels per main label. You might also find that some applications can't display all your labels when too many are published to the same user.\nLabel policy priority (order matters)\nYou make your sensitivity labels available to users by publishing them in a sensitivity label policy that appears in a list on the\nLabel policies\npage. Just like sensitivity labels (see\nLabel priority (order matters)\n), the order of the sensitivity label policies is important because it reflects their priority: The label policy with lowest priority is shown at the top of the list with the\nlowest\norder number, and the label policy with the highest priority is shown at the bottom of the list with the\nhighest\norder number.\nA label policy consists of:\nA set of labels.\nThe users and groups that will be assigned the policy with labels.\nThe scope of the policy and policy settings for that scope (such as default label for files and emails).\nYou can include a user in multiple label policies, and the user will get all the sensitivity labels and settings from those policies. If there's a conflict in settings from multiple policies, the settings from the policy with the highest priority (highest order number) is applied. In other words, the highest priority wins for each setting.\nIf you're not seeing the label policy setting behavior that you expect for a user or group, check the order of the sensitivity label policies. You might need to move the policy down. To reorder the label policies, select a sensitivity label policy > choose the Actions ellipsis for that entry >\nMove down\nor\nMove up\n. For example:\nFrom our screenshot example that shows three label policies, all users are assigned the standard label policy, so it's appropriate it has the lowest priority (lowest order number of 0). Only users in the IT department are assigned the second policy that has the order number 1. For these users, if there are any conflicts in settings between their policy and the standard policy, the settings from their policy wins because it has a higher order number.\nSimilarly for users in the legal department, who are assigned the third policy with distinct settings. It's likely these users will have more stringent settings, so it's appropriate that their policy has the highest order number. It's unlikely a user from the legal department will be in a group that's also assigned to the policy for the IT department. But if they are, the order number 2 (highest order number) ensures the settings from the legal department always take priority if there's a conflict.\nNote\nRemember: If there is a conflict of settings for a user who has multiple policies assigned to them, the setting from the assigned policy with the highest order number is applied.\nSensitivity labels for Microsoft 365 Copilot and Microsoft 365 Copilot Chat\nThe sensitivity labels that you use to protect your organization's data are recognized and used by Microsoft 365 Copilot, Microsoft 365 Copilot Chat, and Copilot agents to provide an extra layer of protection. For example, in Microsoft 365 Copilot Chat conversations that can reference data from different types of items, the sensitivity label with the highest priority (typically, the most restrictive label) is visible to users. Similarly, when sensitivity label inheritance is supported by Copilot and agents, the sensitivity label with the highest priority is selected.\nIf the labels applied encryption from Microsoft Purview Information Protection, Copilot and agents check the usage rights for the user. Only if the user is granted permissions to copy (the EXTRACT usage right) from an item, is data from that item returned by Copilot or agents.\nFor more detailed information about how sensitivity labels help protect your data when you use Copilot and other AI apps, see the following articles:\nMicrosoft Purview data security and compliance protections for generative AI apps\nUse Microsoft Purview to manage data security & compliance for Microsoft 365 Copilot & Microsoft 365 Copilot Chat\nConsiderations to manage Microsoft 365 Copilot for security and compliance\nSensitivity labels and Azure Information Protection\nThe older labeling client, the Azure Information Protection unified labeling client, is now replaced with the\nMicrosoft Purview Information Protection client\nto extend labeling on Windows to File Explorer, PowerShell, the on-premises scanner, and provide a viewer for encrypted files.\nOffice apps support sensitivity labels with a subscription versions of Office, such as Microsoft 365 Apps for enterprise.\nSensitivity labels and the Microsoft Information Protection SDK\nBecause a sensitivity label is stored in the metadata of a document, third-party apps and services can read from and write to this labeling metadata to supplement your labeling deployment. Additionally, software developers can use the\nMicrosoft Information Protection SDK\nto fully support labeling and encryption capabilities across multiple platforms. To learn more, see the\nGeneral Availability announcement on the Tech Community blog\n.\nYou can also learn about\npartner solutions that are integrated with Microsoft Purview Information Protection\n.\nDeployment guidance\nFor deployment planning and guidance that includes licensing information, permissions, deployment strategy, a list of supported scenarios, and end-user documentation, see\nGet started with sensitivity labels\n.\nTo learn how to use sensitivity labels to comply with data privacy regulations, see\nDeploy information protection for data privacy regulations with Microsoft 365\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Sensitivity Labels Overview",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/sensitivity-labels-teams-groups-sites": {
      "content_hash": "sha256:3f7e864af769a5b666ae8a210b808a4caba850e681d182d13ba9b53df6bb9b58",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nUse sensitivity labels to protect content in Microsoft Teams, Microsoft 365 groups, and SharePoint sites\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nIn addition to using\nsensitivity labels\nto protect documents and emails, you can also use sensitivity labels to protect content in the following containers: Microsoft Teams sites, Microsoft 365 groups (\nformerly Office 365 groups\n), and SharePoint sites. For this container-level protection, use the following label settings:\nPrivacy (public or private) of teams sites and Microsoft 365 groups\nExternal user access\nExternal sharing from SharePoint sites\nAccess from unmanaged devices\nAuthentication contexts\nPrevent discovery of private teams for users who have this capability\nShared channels control for team invitations\nDefault sharing link for a SharePoint site (PowerShell-only configuration)\nSite sharing settings (PowerShell-only configuration)\nDefault label for channel meetings\nImportant\nThe settings for unmanaged devices and authentication contexts work in conjunction with Microsoft Entra Conditional Access. You must configure this dependent feature if you want to use a sensitivity label for these settings. Additional information is included in the instructions that follow.\nWhen you apply this sensitivity label to a supported container, the label automatically applies the sensitivity category and configured protection settings to the site or group.\nBe aware that some label options can extend configuration settings to site owners that are otherwise restricted to administrators. When you configure and publish the label settings for external sharing options and the authentication context, a site owner can now set and change these options for a site by applying or changing the sensitivity label for a team or site. Don't configure these specific label settings if you don't want site owners to be able to make these changes.\nContent in these containers however, do not inherit the labels for the sensitivity category or settings for files and emails, such as content markings and encryption. So that users can label their documents in SharePoint sites or team sites, make sure you've\nenabled sensitivity labels for Office files in SharePoint and OneDrive\n.\nContainer labels don't support displaying\nother languages\nand display the original language only for the label name and description.\nUsing sensitivity labels for Microsoft Teams, Microsoft 365 groups, and SharePoint sites\nBefore you enable sensitivity labels for containers and configure sensitivity labels for the new settings, users can see and apply sensitivity labels in their apps. For example, from Word:\nAfter you enable and configure sensitivity labels for containers, users can additionally see and apply sensitivity labels to Microsoft team sites, Microsoft 365 groups, and SharePoint sites. For example, when you create a new team site from SharePoint:\nAfter a sensitivity label has been applied to a site, you must have the following role to change that label in SharePoint or Teams:\nFor a group-connect site: Microsoft 365 group\nOwners\nFor a site that isn't group-connected: SharePoint\nsite admin\nNote\nSensitivity labels for containers support\nTeams shared channels\n. If a team has any shared channels, they automatically inherit sensitivity label settings from their parent team, and that label can't be removed or replaced with a different label.\nHow to enable sensitivity labels for containers and synchronize labels\nIf you haven't yet enabled sensitivity labels for containers, do the following set of steps as a one-time procedure:\nBecause this feature uses Microsoft Entra functionality, follow the instructions from the Microsoft Entra documentation to enable sensitivity label support:\nAssign sensitivity labels to Microsoft 365 groups in Microsoft Entra ID\n.\nYou now need to synchronize your sensitivity labels to Microsoft Entra ID. First,\nconnect to Security & Compliance PowerShell\n.\nFor example, in a PowerShell session that you run as administrator, sign in with a global administrator account.\nThen run the following command to ensure your sensitivity labels can be used with Microsoft 365 groups:\nExecute-AzureAdLabelSync\nHow to configure groups and site settings\nAfter sensitivity labels are enabled for containers as described in the previous section, you can then configure protection settings for groups and sites in the sensitivity labeling configuration. Until sensitivity labels are enabled for containers, the settings are visible but you can't configure them.\nFollow the general instructions to\ncreate or edit a sensitivity label\nand make sure you select\nGroups & sites\nfor the label's scope:\nWhen only this scope is selected for the label, the label won't be displayed in Office apps that support sensitivity labels and can't be applied to files and emails. Having this separation of labels can be helpful for both users and administrators, but can also add to the complexity of your label deployment.\nFor example, you need to carefully review your\nlabel ordering\nbecause SharePoint detects when a labeled document is uploaded to a labeled site. In this scenario, an audit event and email are automatically generated when the document has a higher priority sensitivity label than the site's label. For more information, see the\nAuditing sensitivity label activities\nsection on this page.\nThen, on the\nDefine protection settings for groups and sites\npage, select the options you want to configure:\nPrivacy and external user access settings\nto configure the\nPrivacy\nand\nExternal users access\nsettings.\nExternal sharing and Conditional Access settings\nto configure the\nControl external sharing from labeled SharePoint sites\nand\nUse Microsoft Entra Conditional Access to protect labeled SharePoint sites\nsetting.\nPrivate teams discoverability and shared channel controls\nto configure the settings to prevent users who can discover private teams from finding a private team with this sensitivity label applied, and channel sharing controls for invitations to other teams.\nApply a label to channel meetings\n: This additional option is applicable only if you are editing an existing label where the scope includes meetings, and you've configured\nlabels to protect meetings\n. Select a sensitivity label to automatically apply to channel meetings and all channel chats. For non-channel meetings, you can select a default label as a policy setting.\nIf you selected\nPrivacy and external user access settings\n, now configure the following settings:\nPrivacy\n: Keep the default of\nPublic\nif you want anyone in your organization to access the team site or group where this label is applied.\nSelect\nPrivate\nif you want access to be restricted to only approved members in your organization.\nSelect\nNone\nwhen you want to protect content in the container by using the sensitivity label, but still let users configure the privacy setting themselves.\nThe settings of\nPublic\nor\nPrivate\nset and lock the privacy setting when you apply this label to the container. Your chosen setting replaces any previous privacy setting that might be configured for the team or group, and locks the privacy value so it can be changed only by first removing the sensitivity label from the container. After you remove the sensitivity label, the privacy setting from the label remains and users can now change it again.\nExternal user access\n: Control whether the group owner can\nadd guests to the group\n.\nIf you selected\nExternal sharing and Conditional Access settings\n, now configure the following settings:\nControl external sharing from labeled SharePoint sites\n: Select this option to then select either external sharing for anyone, new and existing guests, existing guests, or only people in your organization. For more information about this configuration and settings, see the SharePoint documentation,\nTurn external sharing on or off for a site\n.\nUse Microsoft Entra Conditional Access to protect labeled SharePoint sites\n: Select this option only if your organization has configured and is using\nMicrosoft Entra Conditional Access\n. Then, select one of the following settings:\nDetermine whether users can access SharePoint sites from unmanaged devices\n: This option uses the SharePoint feature that uses Microsoft Entra Conditional Access to block or limit access to SharePoint and OneDrive content from unmanaged devices. For more information, see\nControl access from unmanaged devices\nfrom the SharePoint documentation. The option you specify for this label setting is the equivalent of running a PowerShell command for a site, as described in steps 3-5 from the\nBlock or limit access to a specific SharePoint site or OneDrive\nsection from the SharePoint instructions.\nFor additional configuration information, see\nMore information about the dependencies for the unmanaged devices option\nat the end of this section.\nChoose an existing authentication context\n: This option lets you enforce more stringent access conditions when users access SharePoint sites that have this label applied. These conditions are enforced when you select an existing authentication context that has been created and published for your organization's Conditional Access deployment. If users don't meet the configured conditions or if they use apps that don't support authentication contexts, they are denied access.\nFor additional configuration information, see\nMore information about the dependencies for the authentication context option\nat the end of this section.\nExamples for this label configuration:\nYou choose an authentication context that is configured to require\nmultifactor authentication (MFA)\n. This label is then applied to a SharePoint site that contains highly confidential items. As a result, when users from an untrusted network attempt to access a document in this site, they see the MFA prompt that they must complete before they can access the document.\nYou choose an authentication context that is configured for\nterms-of-use (ToU) policies\n. This label is then applied to a SharePoint site that contains items that require a terms-of-use acceptance for legal or compliance reasons. As a result, when users attempt to access a document in this site, they see a terms-of-use document that they must accept before they can access the original document.\nIf you selected\nPrivate teams discoverability and shared channel controls\n:\nFor\nPrivate teams discoverability\n, use the\nAllow users to discover private teams that have this label applied\ncheckbox when you've configured a\nTeams policy that allows private teams discovery\n:\nWhen the checkbox is selected (the default setting), a private team with the sensitivity label applied will be discoverable for a user who is allowed to discover private teams.\nWhen the checkbox is cleared, a private team with the sensitivity label applied will remain hidden and won't be discoverable for all users.\nFor\nTeams shared channels\n, when a team has a sensitivity label applied, you can allow or prevent other teams from being invited to the original team's shared channels. For more information about shared channels, see\nShared channels in Microsoft Teams\n.\nImportant\nThese options for Teams shared channels have a dependency on the settings on the previous\nPrivacy and external user access\npage. If you select an option that's not compatible with these previous settings, you see a validation message to change your selection. Alternatively, you can go back in the configuration to change the dependent setting.\nOptions include\nInternal only\n,\nSame label only\n, and\nPrivate team only\n. Only the last option can potentially remove previously invited teams, and none of the options affect invitations to individual users.\nThe site and group settings take effect when you apply the label to a team, group, or site. If the\nlabel's scope\nincludes files and emails, other label settings such as encryption and content marking aren't applied to the content within the team, group, or site.\nIf your sensitivity label isn't already published, now publish it by\nadding it to a sensitivity label policy\n. The users who are assigned a sensitivity label policy that includes this label will be able to select it for sites and groups.\nMore information about the dependencies for the unmanaged devices option\nIf you don't configure the dependent conditional access policy for SharePoint as documented in\nUse app-enforced restrictions\n, the option you specify here will have no effect. Additionally, it will have no effect if it's less restrictive than a configured setting at the tenant level. If you have configured an organization-wide setting for unmanaged devices, choose a label setting that's either the same or more restrictive\nFor example, if your tenant is configured for\nAllow limited, web-only access\n, the label setting that allows full access will have no effect because it's less restrictive. For this tenant-level setting, choose the label setting to block access (more restrictive) or the label setting for limited access (the same as the tenant setting).\nBecause you can configure the SharePoint settings separately from the label configuration, there's no check in the sensitivity label configuration that the dependencies are in place. These dependencies can be configured after the label is created and published, and even after the label is applied. However, if the label is already applied, the label setting won't take effect until after the user next authenticates.\nMore information about the dependencies for the authentication context option\nTo display in the drop-down list for selection, authentication contexts must be created, configured, and published as part of your Microsoft Entra Conditional Access configuration. For more information and instructions, see the\nConfigure authentication contexts\nsection from the Microsoft Entra Conditional Access documentation.\nNot all apps support authentication contexts. If a user with an unsupported app connects to the site that's configured for an authentication context, they see either an access denied message or they are prompted to authenticate but rejected. The apps that currently support authentication contexts:\nOffice for the web, which includes Outlook for the web\nMicrosoft Teams for Windows and macOS (excludes Teams web app)\nMicrosoft Planner\nMicrosoft 365 Apps for Word, Excel, and PowerPoint; minimum versions:\nWindows: 2103\nmacOS: 16.45.1202\niOS: 2.48.303\nAndroid: 16.0.13924.10000\nMicrosoft 365 Apps for Outlook; minimum versions:\nWindows: 2103\nmacOS: 16.45.1202\niOS: 4.2109.0\nAndroid: 4.2025.1\nOneDrive sync app, minimum versions:\nWindows: 21.002\nmacOS: 21.002\niOS: 12.30\nAndroid: Not yet supported\nKnown limitations:\nFor the OneDrive sync app, supported for OneDrive only and not for other sites.\nThe following features and apps might be incompatible with authentication contexts, so we encourage you to check that these continue to work after a user successfully accesses a site by using an authentication context:\nWorkflows that use Power Apps or Power Automate\nThird-party apps\nConfigure settings for the default sharing link type for a site by using PowerShell advanced settings\nIn addition to the label settings for sites and groups that you can configure from the Microsoft Purview portal, you can also configure the default sharing link type for a site. Sensitivity labels for documents can also be configured for a default sharing link type. These settings that help to prevent over-sharing are automatically selected when users select the\nShare\nbutton in their Office apps.\nFor more information and instructions, see\nUse sensitivity labels to configure the default sharing link type for sites and documents in SharePoint and OneDrive\n.\nConfigure site sharing permissions by using PowerShell advanced settings\nAnother PowerShell advanced setting that you can configure for the sensitivity label to be applied to a SharePoint site is\nMembersCanShare\n. This setting is the equivalent configuration that you can set from the SharePoint admin center >\nSite permissions\n>\nSite Sharing\n>\nChange how members can share\n>\nSharing permissions\n.\nThe three options are listed with the equivalent values for the PowerShell advanced setting\nMembersCanShare\n:\nOption from the SharePoint admin center\nEquivalent PowerShell value for MembersCanShare\nSite owners and members can share files, folders, and the site. People with Edit permissions can share files and folders.\nMemberShareAll\nSite owners and members, and people with Edit permissions can share files and folders, but only site owners can share the site.\nMemberShareFileAndFolder\nOnly site owners can share files, folders, and the site.\nMemberShareNone\nFor more information about these configuration options, see\nChange how members can share\nfrom the SharePoint community documentation.\nExample, where the sensitivity label GUID is\n8faca7b8-8d20-48a3-8ea2-0f96310a848e\n:\nSet-Label -Identity 8faca7b8-8d20-48a3-8ea2-0f96310a848e -AdvancedSettings @{MembersCanShare=\"MemberShareNone\"}\nFor more help in specifying PowerShell advanced settings, see\nPowerShell tips for specifying the advanced settings\n.\nSensitivity label management\nUse the following guidance for when you create, modify, or delete sensitivity labels that are configured for sites and groups.\nCreating and publishing labels that are configured for sites and groups\nUse the following guidance to publish a label for your users when that label is configured for site and group settings:\nAfter you create and configure the sensitivity label, add this label to a label policy that applies to just a few test users.\nWait for the change to replicate:\nNew label: Wait at least one hour, unless your configured settings include\nTeams shared channel controls\n. If that's the case, wait at least 24 hours.\nExisting label: Wait at least 24 hours.\nFor more information about the timing of labels, see\nWhen to expect new labels and changes to take effect\n.\nAfter this wait period, use one of the test user accounts to create a team, Microsoft 365 group, or SharePoint site with the label that you created in step 1.\nIf there are no errors during this creation operation, you know it's safe to publish the label to all users in your tenant.\nModifying published labels that are configured for sites and groups\nAs a best practice, don't change the site and group settings for a sensitivity label after the label has been applied to teams, groups, or sites. If you do, remember to wait at least 24 hours for the changes to replicate to all containers that have the label applied.\nIn addition, if your changes include the\nExternal users access\nsetting:\nThe new setting applies to new users but not to existing users. For example, if this setting was previously selected and as a result, guest users accessed the site, these guest users can still access the site after this setting is cleared in the label configuration.\nThe privacy settings for the group properties hiddenMembership and roleEnabled aren't updated.\nDeleting published labels that are configured for sites and groups\nIf you delete a sensitivity label that has the site and group settings enabled, and that label is included in one or more label policies, this action can result in creation failures for new teams, groups, and sites. To avoid this situation, use the following guidance:\nRemove the sensitivity label from all label policies that include the label.\nWait at least one hour.\nAfter this wait period, try creating a team, group, or site and confirm that the label is no longer visible.\nIf the sensitivity label isn't visible, you can now safely delete the label.\nHow to apply sensitivity labels to containers\nYou're now ready to apply the sensitivity label or labels to the following containers:\nMicrosoft 365 group in Microsoft Entra ID\nMicrosoft Teams team site\nMicrosoft 365 group in Outlook on the web\nSharePoint site\nYou can use PowerShell if you need to\napply a sensitivity label to multiple sites\n.\nApply sensitivity labels to Microsoft 365 groups\nYou're now ready to apply the sensitivity label or labels to Microsoft 365 groups. Return to the Microsoft Entra documentation for instructions:\nAssign a label to a new group in Azure portal\nAssign a label to an existing group in Azure portal\nRemove a label from an existing group in Azure portal\n.\nApply a sensitivity label to a new team\nUsers can select sensitivity labels when they create new teams in Microsoft Teams. When they select the label from the\nSensitivity\ndropdown, the privacy setting might change to reflect the label configuration. Depending on the external users access setting you selected for the label, users can or can't add people outside the organization to the team.\nLearn more about sensitivity labels for Teams\nAfter you create the team, the sensitivity label appears in the upper-right corner of all channels.\nThe service automatically applies the same sensitivity label to the Microsoft 365 group and the connected SharePoint team site.\nApply a sensitivity label to a new group in Outlook on the web\nIn Outlook on the web, when you create a new group, you can select or change the\nSensitivity\noption for published labels:\nApply a sensitivity label to a new site\nAdmins and end users can select sensitivity labels when they\ncreate modern team sites and communication sites\n, and expand\nAdvanced settings\n:\nThe dropdown box displays the label names for the selection, and the help icon displays all the label names with their tooltip, which can help users determine the correct label to apply.\nWhen the label is applied, and users browse to the site, they see the name of the label and applied policies. For example, this site has been labeled as\nConfidential\n, and the privacy setting is set to\nPrivate\n:\nUse PowerShell to apply a sensitivity label to multiple sites\nYou can use the\nSet-SPOSite\nand\nSet-SPOTenant\ncmdlet with the\nSensitivityLabel\nparameter from the current\nSharePoint Online Management Shell\nto apply a sensitivity label to many sites. You can use the same procedure to replace an existing label. The sites can be any SharePoint site collection, or a OneDrive site.\nMake sure you have version 16.0.19418.12000 or later of the SharePoint Online Management Shell.\nOpen a PowerShell session with the\nRun as Administrator\noption.\nIf you don't know your label GUID:\nConnect to Security & Compliance PowerShell\nand get the list of sensitivity labels and their GUIDs.\nGet-Label |ft Name, Guid\nNow\nconnect to SharePoint Online PowerShell\nand store your label GUID as a variable. For example:\n$Id = [GUID](\"e48058ea-98e8-4940-8db0-ba1310fd955e\")\nCreate a new variable that identifies multiple sites that have an identifying string in common in their URL. For example:\n$sites = Get-SPOSite -IncludePersonalSite $true -Limit all -Filter \"Url -like 'documents\"\nRun the following command to apply the label to these sites. Using our examples:\n$sites | ForEach-Object {Set-SPOTenant $_.url -SensitivityLabel $Id}\nThis series of commands lets you label multiple sites across your tenant with the same sensitivity label, which is why you use the Set-SPOTenant cmdlet, rather than the Set-SPOSite cmdlet that's for per-site configuration. However, use the Set-SPOSite cmdlet when you need to apply a different label to specific sites by repeating the following command for each of these sites:\nSet-SPOSite -Identity <URL> -SensitivityLabel \"<labelguid>\"\nView and manage sensitivity labels in the SharePoint admin center\nTo view, sort, and search the applied sensitivity labels, use\nActive sites\nin the SharePoint admin center. You might need to first add the\nSensitivity\ncolumn:\nFor more information about managing sites from the Active sites page, including how to add a column, see\nManage sites in the SharePoint admin center\n.\nYou can also change and apply a label from this page:\nSelect the site name to open the details pane.\nSelect the\nPolicies\ntab, and then select\nEdit\nfor the\nSensitivity\nsetting.\nFrom the\nEdit sensitivity setting\npane, select the sensitivity label you want to apply to the site. Unlike user apps, where sensitivity labels can be assigned to specific users, the admin center displays all container labels for your tenant. After you've chosen a sensitivity label, select\nSave\n.\nFor information about managing sensitivity labels for containers in SharePoint Embedded, which are the equivalent of sites, see\nManage SharePoint Embedded containers in SharePoint Admin Center\n.\nSupport for sensitivity labels\nWhen you use admin centers that support sensitivity labels, with the exception of the Microsoft Entra admin center, you see all sensitivity labels for your tenant. In comparison, user apps and services that filter sensitivity labels according to publishing policies can result in you seeing a subset of those labels. The Microsoft Entra admin center also filters the labels according to publishing policies.\nThe following apps and services support sensitivity labels configured for sites and group settings:\nAdmin centers:\nSharePoint admin center\nTeams admin center\nMicrosoft 365 admin center\nMicrosoft Purview portal\nUser apps and services:\nSharePoint\nTeams\nOutlook on the web and for Windows, macOS, iOS, and Android\nForms\nStream\nPlanner\nThe following apps and services don't currently support sensitivity labels configured for sites and group settings:\nAdmin centers:\nExchange admin center\nUser apps and services:\nDynamics 365\nViva Engage\nProject\nPower BI\nMy Apps portal\nClassic Microsoft Entra group classification\nAfter you enable sensitivity labels for containers, the group classifications from Microsoft Entra ID are no longer supported by Microsoft 365 and won't display on sites that support sensitivity labels. However, you can convert your old classifications to sensitivity labels.\nAs an example of how you might have used the old group classification for SharePoint, see\nSharePoint \"modern\" sites classification\n.\nThese classifications were configured by using Microsoft Graph PowerShell or the PnP Core library and defining values for the\nClassificationList\nsetting.\n($setting[\"ClassificationList\"])\nTo convert your old classifications to sensitivity labels, do one of the following:\nUse existing labels: Specify the label settings you want for sites and groups by editing existing sensitivity labels that are already published.\nCreate new labels: Specify the label settings you want for sites and groups by creating and publishing new sensitivity labels that have the same names as your existing classifications.\nThen:\nUse PowerShell to apply the sensitivity labels to existing Microsoft 365 groups and SharePoint sites by using name mapping. See the next section for instructions.\nRemove the old classifications from the existing groups and sites.\nAlthough you can't prevent users from creating new groups in apps and services that don't yet support sensitivity labels, you can run a recurring PowerShell script to look for new groups that users have created with the old classifications, and convert these to use sensitivity labels.\nTo help you manage the coexistence of sensitivity labels and Microsoft Entra classifications for sites and groups, see\nMicrosoft Entra classification and sensitivity labels for Microsoft 365 groups\n.\nUse PowerShell to convert classifications for Microsoft 365 groups to sensitivity labels\nFirst,\nconnect to Security & Compliance PowerShell\nwith a compliance administrator account.\nGet the list of sensitivity labels and their GUIDs by using the\nGet-Label\ncmdlet:\nGet-Label |ft Name, Guid\nMake a note of the GUIDs for the sensitivity labels you want to apply to your Microsoft 365 groups.\nNow\nconnect to Exchange Online PowerShell\nin a separate Windows PowerShell window.\nUse the following command as an example to get the list of groups that currently have the classification of \"General\":\n$Groups= Get-UnifiedGroup | Where {$_.classification -eq \"General\"}\nFor each group, add the new sensitivity label GUID. For example:\nforeach ($g in $groups)\n{Set-UnifiedGroup -Identity $g.Identity -SensitivityLabelId \"457fa763-7c59-461c-b402-ad1ac6b703cc\"}\nRepeat steps 5 and 6 for your remaining group classifications.\nAuditing sensitivity label activities\nImportant\nIf you use label separation by selecting just the\nGroups & sites\nscope for labels that protect containers: Because of the\nDetected document sensitivity mismatch\naudit event and email described in this section, consider\nordering labels\nbefore labels that have a scope for\nFiles & other data assets\n.\nIf somebody uploads a document to a site that's protected with a sensitivity label and their document has a\nhigher priority\nsensitivity label than the sensitivity label applied to the site, this action isn't blocked. For example, you've applied the\nGeneral\nlabel to a SharePoint site, and somebody uploads to this site a document labeled\nConfidential\n. Because a sensitivity label with a higher priority identifies content that is more sensitivity than content that has a lower priority order, this situation could be a security concern.\nAlthough the action isn't blocked, it is audited and by default, automatically generates an email to the person who uploaded the document and the site administrator. As a result, both the user and administrators can identify documents that have this misalignment of label priority and take action if needed. For example, delete or move the uploaded document from the site.\nImportant\nIf the file is in the Preservation Hold library, it's not supported to interact with files in this location. Files can automatically move into the Preservation Hold library as a result of compliance requirements to automatically retain files that users delete or are cloud attachments. For more information, see\nLearn about retention for SharePoint and OneDrive\n.\nIt wouldn't be a security concern if the document has a lower priority sensitivity label than the sensitivity label applied to the site. For example, a document labeled\nGeneral\nis uploaded to a site labeled\nConfidential\n. In this scenario, an auditing event and email aren't generated.\nNote\nJust as for the policy option that requires users to provide a justification for changing a label to a lower classification, sublabels for the same parent label are all considered to have the same priority.\nTo search the audit log for this event, look for\nDetected document sensitivity mismatch\nfrom the\nFile and page activities\ncategory.\nThe automatically generated email has the subject\nIncompatible sensitivity label detected\nand the email message explains the labeling mismatch with a link to the uploaded document and site. It also contains a line for your own internal documentation:\nHelpLink : Troubleshooting Guide\n. You must configure the hyperlink for the troubleshooting guide by using the\nSet-SPOTenant\ncmdlet with the\nLabelMismatchEmailHelpLink\nparameter. For example:\nSet-SPOTenant âLabelMismatchEmailHelpLink \"https://support.contoso.com\"\nThe email message also has a Microsoft documentation link that provides basic information for users to change the sensitivity label:\nApply sensitivity labels to your files and email in Office\nExcept for the internal URL that you must specify, these automated emails cannot be customized. However, you can prevent them from being sent when you use the following PowerShell command from\nSet-SPOTenant\n:\nSet-SPOTenant -BlockSendLabelMismatchEmail $True\nWhen somebody adds or removes a sensitivity label to or from a site or group, these activities are also audited but without automatically generating an email.\nAll these auditing events can be found in the\nSensitivity label activities\nsection from the audit log activities documentation.\nHow to disable sensitivity labels for containers\nYou can turn off sensitivity labels for Microsoft Teams, Microsoft 365 groups, and SharePoint sites by using the same instructions from\nEnable sensitivity label support in PowerShell\n. However, to disable the feature, in step 5, specify\n$setting[\"EnableMIPLabels\"] = \"False\"\n.\nIn addition to making all the settings unavailable for groups and sites when you create or edit sensitivity labels, this action reverts which property the containers use for their configuration. Enabling sensitivity labels for Microsoft Teams, Microsoft 365 groups, and SharePoint sites switches the property used from\nClassification\n(used for\nMicrosoft Entra group classification\n) to\nSensitivity\n. When you disable sensitivity labels for containers, the containers ignore the Sensitivity property and use the Classification property again.\nThis means that any label settings from sites and groups previously applied to containers won't be enforced, and containers no longer display the labels.\nIf these containers have Microsoft Entra classification values applied to them, the containers revert to using the classifications again. Be aware that any new sites or groups that were created after enabling the feature won't display a label or have a classification. For these containers, and any new containers, you can now apply classification values. For more information, see\nSharePoint \"modern\" sites classification\nand\nCreate classifications for Office groups in your organization\n.\nAdditional resources\nFor more information about managing Teams connected sites and channel sites, see\nManage Teams connected sites and channel sites\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Sensitivity Labels for Sites",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/audit-solutions-overview": {
      "content_hash": "sha256:e3cc26a7c69391e276736d1968a02e9cd68933fa5e0e39ddff07a6e76fea0c0c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about auditing solutions in Microsoft Purview\nFeedback\nSummarize this article for me\nMicrosoft Purview auditing solutions provide an integrated solution to help organizations effectively respond to security events, forensic investigations, internal investigations, and compliance obligations. Your organization's unified audit log captures, records, and retains thousands of user and admin operations performed in dozens of Microsoft services and solutions. Security ops, IT admins, insider risk teams, and compliance and legal investigators in your organization can search audit records for these events. This capability provides visibility into the activities performed across your organization.\nComparison of key capabilities\nThe following table compares the key capabilities available in Audit (Standard) and Audit (Premium). Audit (Premium) includes all Audit (Standard) functionality.\nCapability\nAudit (Standard)\nAudit (Premium)\nEnabled by default\nThousands of searchable audit events\nAudit search tool in the Microsoft Purview portal\nAudit Search Graph API\nSearch-UnifiedAuditLog cmdlet\nExport audit records to CSV file\nAccess to audit logs via Office 365 Management Activity API\n1\n180-day audit log retention\nUp to 1-year audit log retention\n10-year audit log retention\n2\nAudit log retention policies\nIntelligent insights\nNote\n1\nAudit (Premium) includes higher bandwidth access to the Office 365 Management Activity API, which provides faster access to audit data.\n2\nIn addition to the required licensing for Audit (Premium) (described in the next section), a user must be assigned a 10-Year Audit Log Retention add-on license to retain their audit records for 10 years.\nAudit (Standard)\nMicrosoft Purview Audit (Standard) enables you to log and search for audited activities to support your forensic, IT, compliance, and legal investigations.\nEnabled by default\n. Audit (Standard) is enabled by default for all organizations with the appropriate subscription. That configuration captures and makes searchable records for audited activities. You only need to assign the necessary permissions to access the audit log search tool (and the corresponding cmdlet) and ensure that users have the right license for Microsoft Purview Audit (Premium) features.\nThousands of searchable audit events\n. You can search for a wide range of audited activities that occur in most of the Microsoft services in your organization. For a list of the activities you can search for, see\nAudit log activities\n. For a list of the services and features that support audited activities, see\nAudit log record type\n.\nAudit search tool in the Microsoft Purview portal\n. Use the Audit log search tool in the portal to search for audit records. You can search for specific activities, for activities performed by specific users, and activities that occurred within a date range.\nAudit Search Graph API\n. Microsoft Graph offers a unified API endpoint for accessing data from multiple Microsoft cloud services in a single response. The\nAudit Search Graph API\nallows you to programmatically access the audit search experience through Microsoft Graph.\nSearch-UnifiedAuditLog cmdlet\n. You can also use the\nSearch-UnifiedAuditLog\ncmdlet in Exchange Online PowerShell (the underlying cmdlet for the search tool) to search for audit events or to use in a script. For more information, see:\nSearch-UnifiedAuditLog cmdlet reference\nUse a PowerShell script to search the audit log\nExport audit records to a CSV file\n. After running the Audit log search tool in the Microsoft Purview portal, you can export the audit records returned by the search to a CSV file. This process lets you use Microsoft Excel to sort and filter on different audit record properties. You can also use Excel Power Query transform functionality to split each property in the AuditData JSON object into its own column. This process lets you effectively view and compare similar data for different events. For more information, see\nExport, configure, and view audit log records\n.\nAccess to audit logs via Office 365 Management Activity API\n. A third method for accessing and retrieving audit records is to use the Office 365 Management Activity API. This method lets organizations retain auditing data for longer periods than the default 180 days and lets them import their auditing data to a SIEM solution. For more information, see\nOffice 365 Management Activity API reference\n.\n180-day audit log retention\n. When a user or admin performs an audited activity, the system generates an audit record and stores it in the audit log for your organization. In Audit (Standard), the system retains records for 180 days, which means you can search for activities that occurred within the past six months.\nImportant\nThe default retention period for Audit (Standard) changed from 90 days to 180 days. Audit (Standard) logs generated before October 17, 2023, are retained for 90 days. Audit (Standard) logs generated on or after October 17, 2023, follow the new default retention of 180 days.\nAudit (Premium)\nImportant\nClassic Search retired on November 30, 2023.\nNew Search\nincludes enhancements such as faster search times, additional search options, ability to save searches, and more.\nAudit (Premium) builds on the capabilities of Audit (Standard) by providing audit log retention policies, longer retention of audit records, high-value intelligent insights, and higher bandwidth access to the Office 365 Management Activity API.\nAudit log retention policies\n. Create customized audit log retention policies to retain audit records for longer periods, up to one year (and up to 10 years for users with the required add-on license). Create a policy to retain audit records based on the service where the audited activities occur, specific audited activities, or the user who performs an audited activity.\nLonger retention of audit records\n. Microsoft Entra ID, Exchange, OneDrive, and SharePoint audit records are retained for one year by default. Audit records for all other activities are retained for 180 days by default, or you can use audit log retention policies to configure longer retention periods.\nAudit (Premium) intelligent insights\n. Audit records for intelligent insights can help your organization conduct forensic and compliance investigations by providing visibility to events such as when mail items were accessed, or when mail items were replied to and forwarded, or when and what a user searched for in Exchange Online and SharePoint Online. These intelligent insights can help you investigate possible breaches and determine the scope of compromise.\nHigher bandwidth to the Office 365 Management Activity API\n. Audit (Premium) provides organizations with more bandwidth to access auditing logs through the Office 365 Management Activity API. Although all organizations (that have Audit (Standard) or Audit (Premium)) initially receive a baseline of 2,000 requests per minute, this limit dynamically increases depending on an organization's seat count and their licensing subscription. This change results in organizations with Audit (Premium) getting about twice the bandwidth as organizations with Audit (Standard).\nLong-term retention of audit logs\nAudit (Premium) retains all Exchange, SharePoint, and Microsoft Entra audit records for one year. This retention happens through a default audit log retention policy that retains any audit record that contains the value of\nAzureActiveDirectory\n,\nExchange\n,\nOneDrive\n, or\nSharePoint\n, for the\nWorkload\nproperty (which indicates the service in which the activity occurred) for one year. Retaining audit records for longer periods can help with ongoing forensic or compliance investigations. For more information, see the \"Default audit log retention policy\" section in\nManage audit log retention policies\n.\nIn addition to the one-year retention capabilities of Audit (Premium), we also released the capability to retain audit logs for 10 years. The 10-year retention of audit logs helps support long running investigations and respond to regulatory, legal, and internal obligations.\nNote\nRetaining audit logs for 10 years requires an additional per-user add-on license. After you assign this license to a user and set an appropriate 10-year audit log retention policy for that user, audit logs covered by that policy start to be retained for the 10-year period. This policy isn't retroactive and can't retain audit logs that were generated before the 10-year audit log retention policy was created.\nAudit log retention policies\nAll audit records that other services generate and that the default audit log retention policy doesn't cover are retained for 180 days. You can create customized audit log retention policies to retain other audit records for longer periods, up to 10 years. You can create a policy to retain audit records based on one or more of the following criteria:\nThe Microsoft service where the audited activities occur.\nSpecific audited activities.\nThe user who performs an audited activity.\nImportant\nThe default retention period for Audit (Standard) changed from 90 days to 180 days. Audit (Standard) logs generated before October 17, 2023, are retained for 90 days. Audit (Standard) logs generated on or after October 17, 2023, follow the new default retention of 180 days.\nYou can also specify how long to retain audit records that match the policy and a priority level so that specific policies take priority over other policies. Any custom audit log retention policy takes precedence over the default audit retention policy if you need to retain Exchange, SharePoint, or Microsoft Entra ID audit records for less than a year or for 10 years for some or all users in your organization. For more information, see\nManage audit log retention policies\n.\nImportant\nThe audit item lifetime for data is determined when the auditing pipeline adds the data and is based on the licensing defaults or applicable retention policies. Any changes to licensing or applicable retention policies change the expiration time of the audit data after updating. These changes don't affect any previously committed items.\nAudit (Premium) activity properties\nAudit (Premium) helps organizations conduct forensic and compliance investigations by providing access to important events, such as when users access mail items, reply to and forward mail items, and search in Exchange Online and SharePoint Online. These events can help you investigate possible breaches and determine the scope of compromise. In addition to these events in Exchange and SharePoint, other Microsoft services include important events that require assigning users the\nappropriate Audit (Premium) license\n. Assign an Audit (Premium) license to users so the system generates audit logs when they perform these events.\nThese activities require that you assign users the\nappropriate Audit (Premium) license\n. Assign an Audit (Premium) license to users so the system generates audit logs when they perform these activities and properties.\nAudit (Premium) provides access to the following activity properties:\nExchange Online\nActivity\nProperty\nMailItemsAccessed\nSensitivityLabel\nMicrosoft Teams\nActivity\nProperty\nChatCreated\nAppAccessContext\nChatRetrieved\nAppAccessContext\nChatUpdated\nAppAccessContext\nMeetingParticipantDetail\nIsJoinedFromLobby\nArtifactShared\nMessageCreatedNotification\nAppAccessContext\nMessageDeletedNotification\nAppAccessContext\nMessageHostedContentsListed\nAppAccessContext\nMessageHostedContentRead\nAppAccessContext\nMessagesListed\nAppAccessContext\nMessageRead\nAppAccessContext\nMessageSent\nAppAccessContext\nParticipatingDomainInformation\nParticipantInfo\nMessageUpdated\nParticipantInfo\nAppAccessContext\nMessageUpdatedNotification\nAppAccessContext\nSubscribedToMessages\nAppAccessContext\nHigh-bandwidth access to the Office 365 Management Activity API\nOrganizations that access auditing logs through the Office 365 Management Activity API faced throttling limits at the publisher level. This throttling limit meant that if a publisher pulled data for multiple customers, all those customers shared the same limit.\nWith Audit (Premium), this limit changed from a publisher-level limit to a tenant-level limit. Each organization now gets its own fully allocated bandwidth quota to access its auditing data. The bandwidth isn't a static, predefined limit. Instead, it's modeled on a combination of factors, including the number of seats in the organization. E5, A5, and G5 organizations get more bandwidth than non-E5, non-A5, and non-G5 organizations.\nAll organizations initially get a baseline of 2,000 requests per minute. This limit dynamically increases based on an organization's seat count and licensing subscription. E5, A5, and G5 organizations get about twice as much bandwidth as non-E5, non-A5, and non-G5 organizations. A cap on the maximum bandwidth protects the health of the service.\nFor more information, see the\nAPI throttling\nsection in\nOffice 365 Management Activity API reference\n.\nLicensing requirements\nBefore you get started, review the\nsubscription requirements\nfor Audit (Standard) and Audit (Premium).\nTraining\nTraining your security operations team, IT administrators, and compliance investigators in the fundamentals for Audit (Standard) and Audit (Premium) can help your organization get started more quickly using auditing to help with your investigations. Microsoft Purview provides the following resource to help these users in your organization get started with auditing:\nDescribe the eDiscovery and audit capabilities of Microsoft Purview\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Audit Logging",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/audit-copilot": {
      "content_hash": "sha256:7a8373393ee6ebfb92513191e7ee92d2370e29cc226b95193b5ce5051d8367f4",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAudit logs for Copilot and AI applications\nFeedback\nSummarize this article for me\nThis article provides an overview of audit logs generated for user interactions and admin activities related to\nMicrosoft Copilot\nand AI applications. The system automatically logs these activities as part of\nAudit (Standard)\n. If your organization enables auditing, you don't need to take extra steps to configure auditing support for Copilot and AI applications.\nBilling for auditing non-Microsoft AI applications\nAudit logs for non-Microsoft AI applications use pay-as-you-go billing. This billing model provides user and admin interaction audit logs that the system retains for 180 days. These audit logs cover interactions with non-Microsoft AI applications.\nYour enterprise subscription doesn't include audit logs for this type of user interaction. Instead, it falls under\npay-as-you-go billing\n. The system logs these interactions under the\nAIAppInteraction\nrecordType or\nAIApp\nworkload. Some scenarios logged under the\nConnectedAiAppInteraction\nrecordType are also part of this pay-as-you-go billing model. You need to enable pay-as-you-go features to turn on these logs. When you enable them, the system retains these audit logs for 180 days. Consumption is charged based on the number of audit records ingested for user interactions with these non-Microsoft AI applications.\nPay-as-you-go billing doesn't apply to Microsoft applications. All Microsoft applications, including Microsoft Copilots like\nMicrosoft Security Copilot\n,\nCopilot in Microsoft Fabric\n, and custom applications built using\nMicrosoft Copilot Studio\nand Azure AI Studio are included in Audit Standard.\nAdmin activities with Copilot and AI applications\nThe system generates audit logs when an administrator performs activities related to Copilot settings, plugins, promptbooks, or workspaces. For more information, see\nMicrosoft 365 Copilot activities\n.\nUser activities with Copilot and AI applications\nThe system automatically generates audit logs when a user interacts with Copilot or an AI Application. These audit records contain details about which user interacted with Copilot, when the interaction took place, and where it occurred. Audit records also include references to files, sites, or other resources Copilot and AI applications accessed to generate responses to user prompts.\nCommon properties in Copilot audit logs\nThe following table outlines some of the common properties included in audit logs.\nAttribute\nDefinition\nExamples\nAccessedResources\nReferences to all resources (files, documents, emails, etc.) which Copilot accessed in response to the userâs request.\n-\nID\nis the unique identifier for the resource. This could be a fileId on OneDrive, or a messageId in Teams, or email ID in Outlook, etc.\n-\nSiteUrl\nis the URL of the resource that was accessed. This could be the URL of a SharePoint site, full file path of a file, etc.\n-\nListItemUniqueId\nis a unique identifier for an item in SharePoint.\n-\nType\nrefers to the type of resource that was accessed. It can contain values like the filetype extension (pptx, docx, etc.) or describe the type of resource (for non-SharePoint resources).\n-\nName\nis the user-friendly readable name of the resource (for example, fileName).\n-\nSensitivityLabelId\nis the ID of the sensitivity label assigned to the resource. This is helpful in identifying whether Copilot accessed any sensitive information while generating its response.\n-\nAction\nrefers to the nature of access which Copilot performed on the resource. Common values include\nread\n,\ncreate\n,\nmodify\n.\n-\nPolicyDetails\nis used in scenarios where Copilot's access to a particular resource was blocked or restricted based on some policy. This property can include details like\nPolicyId\n,\nPolicyName\n, list of rules, etc.\n-\nStatus\nis used to specify whether Copilot's action on a specific resource was a\nsuccess\nor\nfailure\n.\n-\nXPIADetected\nis a boolean that denotes whether there was an XPIA (Cross Prompt Injection Attack) detected from a particular resource which Copilot accessed.\nFor example: \"AccessedResources\":[{\"Action\":\"Read\",\"ID\":\"AAAAAEYE2GAACp1FlnN_CHXStUkHAGWJYgtgcv1eOxe2v4H4jOsAAAQsLLeAAGWJYgtgcv1EoXe2v4H4josAABwvq8gAAA2\",\"Name\":\"Document1.docx\",\"SensitivityLabelId\":\"f41ab342-8706-4188-bd11-ebb85995028c\",\"SiteUrl\":\"\nhttps://microsoft.sharepoint.com/teams/OfficeSerbia/Shared%20Documents/SPOPPE/Document%20transformation%20services/Crawled%20Word%20documents/IW/Document1.docx?web=1\n\",\"Type\":\"docx\",\"listItemUniqueId\":\"AAAAAEYE2GAACp1FlnN_CHXStUkHAGWJYgtgcv1eOxe2v4H4jOsAAAQsLLeAAGWJYgtgcv1EoXe2v4H4josAABwvq8gAAA2\"}],\nAgentId\nUnique identifier for an agent. The string can also include details about the category of agent involved in the interaction.\nFor example, when a user interacts with a Declarative Agent or a Custom-engine Agent created through Microsoft Copilot Studio, then Agent ID contains values like\nCopilotStudio.Declarative.8ad83f3e-b424-4d54-8ddb-15dc19247088\nor\nCopilotStudio.CustomEngine.11fd28b5-4452-4615-be3d-7046a6f31131\n.\nAgentName\nA friendly readable name of the agent.\nJiraStatusAgent\n,\nSalesAgent\n,\nReminderBot\n, and others.\nAgentVersion\nThe version number or version ID of the agent involved.\nValues like\n25.001\n,\n8076fbed-be52-4004-ac89-81181ecd7b33\n, and others.\nAISystemPlugin\nDetails of plugins or extensions enabled for the Copilot interaction.\n-\nName\nis the name of the plugin that Copilot uses in generating the response.\n-\nID\nis the unique identifier for the plugin.\n-\nVersion\nrefers to the version of plugin used.\nAppHost\nThe same Copilot application can be deployed within multiple host applications. This property helps identify the application that hosted the interaction between a user and Copilot.\nSome of the common AppHost scenarios are:\n-\nBizChat\n: The Copilot interaction was performed in the Microsoft 365 Copilot Chat client (either via Teams, or the app), or via the website microsoft365.com/copilot or microsoft365.com/chat\n-\nBing\n: The Copilot interaction was performed through the Microsoft Edge browser, Office mobile apps, or copilot.cloud.microsoft.com\n-\nOffice\n: The Copilot interaction was performed through office.com or microsoft365.com\n- Other application-specific values: Values like\nWord\n,\nExcel\n,\nPowerPoint\n,\nOneNote\n,\nStream\n, and others indicate that the interaction was performed within these applications\nAppIdentity\nA detailed string that you use to uniquely identify the specific Copilot or AI Application that the user interacted with. It typically follows the structure\nworkloadName.appGroup.appName\n.\nFor example, interactions with first-party Copilot apps developed by Microsoft use values like\nCopilot.MicrosoftCopilot.Microsoft365Copilot\n,\nCopilot.Fabric.CopilotforPowerBI\n,\nCopilot.Security.SecurityCopilot\n, and others.\nInteractions with custom-built Copilots created through Copilot Studio use values like\nCopilot.Studio.AppId\n.\nInteractions with third-party AI apps deployed within your organization (which use\nConnectedAIApp\nas the workload) use values like\nConnectedAIApp.Entra.AppId\nor\nConnectedAIApp.AzureAI.AzureResourceName\n. Interactions with third-party AI apps that are audited through network/browser Data Loss Prevention (DLP) (which use\nAIApp\nas the workload) use values like\nAIApp.SaaS.AppName\n.\nCapacityId\nUnique identifier for the Microsoft Fabric Capacity in a tenant.\nYou can find the\nCapacityID\nin the URL of the capacity management page. In Microsoft Fabric, go to\nSettings\n>\nGovernance and insights\n>\nAdmin portal\n>\nCapacity settings\nand select a capacity. The\nCapacityID\nis shown in the URL after\n/capacities/\n. For example,\n00001111-aaaa-2222-bbbb-3333cccc4444\nis the\nCapacityID\nin the following URL:\nhttps://app.powerbi.com/admin-portal/capacities/00001111-aaaa-2222-bbbb-3333cccc4444\n.\nClientRegion\nThe userâs region when they performed the operation.\nContexts\nContains a collection of attributes to help describe where the user was during the Copilot interaction.\n-\nID\nis the identifier of the resource that was being used during the Copilot interaction.\n-\nType\nis the filetype/name of the app or service where the interaction occurred.\n-\nID\ncontains values like\nFileId\nor\nFilePath\n(for SharePoint scenarios), or Teams Chat ID or Meeting ID (for Teams scenarios), and others.\n-\nType\ncontains values like docx, pptx, xlsx, TeamsMeeting, TeamsChannel, TeamsChat, and others.\nMessages\nContains details about the prompt and response messages within the Copilot interaction. A single audit record typically contains a prompt-response pair but can also include a prompt with multiple response messages (that is, all Copilot responses associated with that prompt).\n-\nID\nis the messageId of the prompt/response message in the Copilot interaction.\n-\nIsPrompt\nis a boolean flag to denote whether this message is a user prompt or Copilot response.\n-\nJailbreakDetected\nis a boolean flag to denote whether a jailbreak attempt was made using this prompt message.\n-\nSize\nis currently not used.\n\"Messages\": [ {\"ID\":\"1715186983849\", \"isPrompt\":true}, {\"ID\":\"1715186984291\", \"isPrompt\":false} ]\nModelTransparencyDetails\nDetails of the AI/GAI model provider.\n-\nModelName\nis the name of the model used.\n-\nModelVersion\nis the version of the model used.\n-\nModelProviderName\nis the publisher of the model.\nOperation\nSpecifies the name of the activity that was audited.\nFor user interactions with Copilot, this property uses values like\nCopilotInteraction\n,\nConnectedAIAppInteraction\n, and\nAIAppInteraction\n, as described for RecordType.\nAlso includes Copilot admin operations like\nUpdateTenantSettings\n,\nCreatePlugin\n,\nDeletePlugin\n,\nEnablePromptBook\n, and others.\nRecordType\nIdentifies the category of Copilot or AI application that the user interacted with.\nCopilotInteraction\nrefers to scenarios where a user interacted with a Microsoft-developed Copilot application.\nConnectedAIAppInteraction\nrefers to scenarios where a user interacted with a custom-built Copilot or third-party AI application deployed and registered within your organization.\nAIAppInteraction\nrefers to interactions with third-party AI applications that aren't deployed within your organization.\nWorkload\nIdentifies the app category, similar to RecordType.\nCopilot\n,\nConnectedAIApp\n,\nAIApp\nCommon AppHost scenarios in Copilot\nThe following table lists some of the commonly used values for AppHost and describes the scenarios in which they're used.\nAppHost\nCopilot Scenario\nCopilot product\nBing\nBusiness Chat via Bing/Windows interface.\nRefers to Microsoft 365 Copilot's cross-app\nBusiness Chat\naccess through the Bing Chat experience (for instance, in the Microsoft Edge browser sidebar, Windows Copilot, or the copilot.cloud.microsoft.com web portal). This scenario occurs when a user engages the Copilot in a general-purpose chat outside any specific Office app.\nMicrosoft 365 Copilot Chat\nBookings\nCopilot in Microsoft Bookings.\nMicrosoft 365 Copilot\nCopilot in Azure\nCopilot in Microsoft Azure (Cloud Management).\nThis refers to Copilot usage in the context of\nMicrosoft Azure\n. Though labeled under Microsoft 365 Copilot, the scenario is a cloud admin or developer using Copilot to manage Azure resources. For example, in the Azure portal, ad admin might ask, \"How do I set up an alert for CPU usage on my VMs?\" and Copilot would generate an ARM template or Azure CLI steps. Or \"list untagged resources and suggest a tagging scheme\". Essentially, Copilot in Azure is an AI cloud assistant to query and control Azure services via natural language.\nMicrosoft 365 Copilot\nCopilot in Defender\nSecurity Copilot in Microsoft Defender.\nThe user is using Copilot within the\nMicrosoft Defender\nsecurity portal. This assists security operations (SecOps) tasks. For example, an analyst could ask, \"Investigate alert ID 23455 and summarize what happened,\" and Copilot analyzes Defender alerts and incidents to produce an explanation or even recommend next steps. It can also cross-reference threat intelligence. This scenario specifically focuses on\nDefender for Endpoint/Office/Cloud, etc.\ndata via the Security Copilot interface.\nSecurity Copilot\nCopilot in Intune\nSecurity Copilot in Microsoft Intune (Endpoint Management).\nCopilot is used in the\nMicrosoft Intune\nadmin center. It helps IT admins with device management and security posture. For instance, an admin might ask, \"How many devices are noncompliant this week and why?\". Copilot retrieves Intune data on device compliance and summarize reasons. It can also assist with troubleshooting by comparing device configuration or retrieving app deployment status. This is essentially Security Copilot tapping into Intune's information to answer questions and provide insights for IT and security teams.\nSecurity Copilot\nDesigner\nCopilot in Microsoft Designer.\nMicrosoft 365 Copilot\nEdge\nBusiness Chat in Edge sidebar.\nRepresents Microsoft 365 Copilot chat accessed through the\nEdge browser's Copilot (Bing Chat Enterprise) sidebar\n. In this scenario, the user is likely using the Microsoft Edge sidebar Copilot to query organizational data (a BizChat experience within Microsoft Edge).\nMicrosoft 365 Copilot Chat\nExcel\nCopilot in Microsoft Excel.\nThe user is using Copilot inside an Excel spreadsheet. For example, Copilot might be asked to analyze data, create formulas, or generate a summary of a table. It's the Excel-integrated Copilot helping with computations or insights in workbooks.\nMicrosoft 365 Copilot\nForms\nCopilot in Microsoft Forms.\nRepresents Copilot being used in the context of Forms. For example, Copilot could help create survey questions, quizzes, or analyze form responses. This would be the AI assistant helping content creation or summarization in Forms.\nMicrosoft 365 Copilot\nLogic App\nCopilot in Azure Logic Apps.\nMicrosoft 365 Copilot\nLoop\nCopilot in Microsoft Loop.\nThis refers to Copilot assisting within the Microsoft Loop application or Loop components. The user might have Copilot generate or summarize content in a Loop workspace. For example, Copilot could help brainstorm in a Loop page, given Loop's collaborative canvas. This integration brings Copilot to the Loop app context.\nMicrosoft 365 Copilot\nM365AdminCenter\nCopilot in Microsoft 365 Admin Center.\nThis refers to an AI assistant for IT administrators. In this scenario, Copilot could help an admin with tasks in the Microsoft 365 admin center. For example, answering questions about settings, generating PowerShell scripts, or summarizing user reports.\nMicrosoft 365 Copilot\nM365App\nBusiness Chat via Microsoft 365 app (desktop or mobile).\nSimilar to the Office apphost, this denotes Business Chat launched from the\nMicrosoft 365 unified app\non Windows or mobile. It covers the scenario where a user uses the Office/Microsoft 365 app itself (outside a specific product like Word) to chat with Copilot across their data.\nMicrosoft 365 Copilot Chat\nMicrosoft Purview\nSecurity Copilot in Purview (Compliance).\nThe user is interacting with Copilot in the\nMicrosoft Purview\ncompliance portal. Copilot helps compliance officers and security teams triage and summarize issues related to data protection and governance. For example, Copilot can summarize a batch of Data Loss Prevention (DLP) alerts, highlight inside risk activities, or answer questions like \"Have we had any policy violations in email this week?\". It can work in both an embedded way (inside Microsoft Purview UI, summarizing whatever section you're on) and in a standalone Q&A way for Microsoft Purview data. This scenario brings AI to compliance workflows, making it faster to grasp risks and decide on actions.\nSecurity Copilot\nOffice\nBusiness Chat via Office.com or Microsoft 365 app.\nIndicates the Copilot Business Chat accessed through the Office.com or Microsoft 365 home app (web, desktop, or mobile). For example, when a user opens the \"Copilot\" chat on Office.com (microsoft365.com) or the Microsoft 365 mobile app to ask cross-domain questions.\nMicrosoft 365 Copilot Chat\nOfficeCopilotNotebook\nCopilot Notebook (Microsoft 365).\nRefers to the\nCopilot Notebooks\nfeature in Microsoft 365 Copilot (a central AI-powered notebook). This scenario is when Copilot compiles or interacts with a\ncross-application notebook\nof content. Copilot Notebooks allow users to gather and generate information across multiple sources in a notebook interface. This AppHost appears when that notebook is used on the Office.com/Microsoft 365 side (outside of OneNote).\nMicrosoft 365 Copilot Chat\nOfficeCopilotSearchAnswer\nCopilot answer in Microsoft 365 Search.\nThis value refers to Copilot generating an\nAI-powered answer in the Office/Microsoft 365 search experience\n. For instance, when a user searches on Office.com or SharePoint and Copilot provides a natural language answer (drawing from workplace data) instead of just search results. This is a Business Chat-like Q&A feature within the search context.\nMicrosoft 365 Copilot Chat\nOneDrive\nAlso refers to the\nCopilot in SharePoint\nscenario, as described previously.\nMicrosoft 365 Copilot\nOneNote\nCopilot in Microsoft OneNote.\nThe user is using Copilot inside OneNote notebooks. This in-app OneNote Copilot can summarize notes, generate plans or lists, or answer questions based on NoteNote content. Copilot \"\nsupercharges your note-taking\n\" in OneNote, helping to create, recall, and organize information.\nMicrosoft 365 Copilot\nOneNoteCopilotNotebook\nCopilot Notebook in OneNote.\nSimilar to the OfficeCopilotNotebook scenario, but specifically when the Copilot Notebook is accessed within OneNote. Microsoft introduced Copilot Notebooks integrated into OneNote, so this AppHost logs when a user uses the\nAI-powered notebook inside OneNote\n(bringing cross-data Copilot functionality into OneNote).\nMicrosoft 365 Copilot Chat\nOutlook\nCopilot in Microsoft Outlook.\nThe user in engaging Copilot while using Outlook (desktop, web, or mobile). This typically means the Copilot is helping with email tasks. For example, drafting an email reply, summarizing a long email thread, or organizing an inbox.\nMicrosoft 365 Copilot Chat\nOutlookOnCanvas\nCopilot inline in Outlook compose.\nThis refers to Copilot's assistance directly in the email canvas. For example, when composing an email, Copilot might autogenerate text right in the draft. It's the on-canvas helper in Outlook's compose window (as opposed to using a separate Copilot pane).\nMicrosoft 365 Copilot\nOutlookSidepane\nCopilot in Outlook side pane.\nDenotes the classic Outlook Copilot experience via the Copilot pane in Outlook. For example, a user opens the Copilot sidebar in Outlook to draft or summarize messages. This value explicitly captures that side pane interaction.\nMicrosoft 365 Copilot\nPlanner\nCopilot in Microsoft Planner.\nIndicates a Copilot scenario in Planner, likely assisting with project plans or tasks. A user might ask Copilot to draft a plan, generate task checklists, or update task descriptions.\nMicrosoft 365 Copilot\nPower BI\nCopilot in Microsoft Power BI.\nMicrosoft 365 Copilot\nPowerPoint\nCopilot in Microsoft PowerPoint.\nCopilot is being used within a PowerPoint presentation. In this scenario, a user could ask Copilot to create slides, generate speaker notes, or redesign content in PowerPoint.\nMicrosoft 365 Copilot\nPowerPointOnCanvas\nCopilot on PowerPoint slides.\nIndicates an on-canvas Copilot experience in PowerPoint, where Copilot inserts or modifies content directly on slides. This could be the scenario of Copilot generating layouts or bulleted points straight into the presentation (without solely relying on the chat pane). It's a more embedded form of the PowerPoint Copilot.\nMicrosoft 365 Copilot\nSecurity Copilot Standalone\nSecurity Copilot standalone experience.\nThe user is interacting with Security Copilot through the standalone experience, as opposed to interacting with Copilot through an embedded experience within Defender, Purview, etc.\nSecurity Copilot\nSharePoint\nCopilot in SharePoint.\nCopilot is used within SharePoint (likely on a SharePoint site or page). For instance, a user might ask Copilot to summarize a SharePoint news post or draft content for a SharePoint page. This scenario corresponds to a SharePoint-integrated Copilot helping with intranet content.\nMicrosoft 365 Copilot\nStream\nCopilot in Microsoft Stream.\nMicrosoft 365 Copilot\nTeams\nCopilot in Microsoft Teams.\nRepresents Copilot usage inside the Microsoft Teams app (Web/Desktop/Mobile). This covers interactions with Copilot in Teams chats or channels. For example, asking Copilot to summarize a Teams chat, answer a question in a channel, or assist in a meeting context. This is essentially the Copilot experience within Teams' interface. For example, the \"Chat Copilot\" in a Teams chat thread.\nMicrosoft 365 Copilot\nTeamsAdminPortal\nCopilot in Microsoft Teams Admin Center.\nSimilar to the M365AdminCenter scenario, this indicated a Copilot scenario in the Teams Admin Portal. An admin might use Copilot to configure Teams settings or generate reports.\nMicrosoft 365 Copilot\nVivaEngage\nCopilot in Viva Engage (Yammer).\nThe user is interaction with Copilot within Viva Engage. For example, drafting a post or summarizing conversation threads in a Yammer community. This scenario covers any AI assistance inside Viva Engage, such as helping craft announcements or answers.\nMicrosoft 365 Copilot\nVivaGoals\nCopilot in Viva Goals.\nViva Goals manages OKRs (objectives and key results). A Copilot here could draft OKRs, update progress, or analyze goal attainment.\nMicrosoft 365 Copilot\nVivaPulse\nCopilot in Viva Pulse.\nViva Pulse is a feedback survey tool; Copilot here might draft survey questions or summarize sentiment from responses.\nMicrosoft 365 Copilot\nWhiteboard\nCopilot in Microsoft Whiteboard.\nThe user is using Copilot on a digital whiteboard. Copilot in Whiteboard helps brainstorm and organize ideas on the whiteboard canvas. For example, suggesting ideas, clustering sticky notes, or summarizing the board's content. This scenario covers using Copilot during a Whiteboard session (in Teams or the Whiteboard app) to enhance creativity and structure.\nMicrosoft 365 Copilot\nWord\nCopilot in Microsoft Word.\nThe user is interacting with Copilot within Word. For example, asking it to draft or edit portions of a Word document. This is the in-app\nWord Copilot\n(side-pane chat and commands in Word). Copilot can generate content, summarize text, or adjust formatting the document context.\nMicrosoft 365 Copilot\nWordOnCanvas\nCopilot inline in Word's document.\nThis refers to Copilot assistance directly\non the canvas\nin Word. Instead of the side pane, Copilot acts within the document editing area. For example, the feature where Copilot writes directly into the document or provides inline suggestions. It's essentially Word Copilot's capabilities applies within the document body, rather than via the chat pane.\nMicrosoft 365 Copilot\nExample Copilot scenarios for user activities\nThe following tables list some example scenarios and how they appear in the audit log. These example audit logs come from Copilot activities.\nMicrosoft Copilot\nA user interacts with Microsoft Copilot through the Microsoft 365 Copilot Chat client.\nOperation\nRecordType\nAppIdentity\nAppHost\nCopilotInteraction\nCopilotInteraction\nCopilot.MicrosoftCopilot.BizChat\nBizChat\nSecurity Copilot\nA user interacts with Security Copilot within Microsoft Defender.\nOperation\nRecordType\nAppIdentity\nAppHost\nCopilotInteraction\nCopilotInteraction\nCopilot.Security.SecurityCopilot\nDefender\nCopilot Studio applications\nA user interacts with a custom-built Copilot Studio application (whose appId is the GUID contained in appIdentity). The interaction takes place within Microsoft Teams, where this custom-built application is deployed.\nOperation\nRecordType\nAppIdentity\nAppHost\nCopilotInteraction\nCopilotInteraction\nCopilot.Studio.f4d97b45-1deb-40ce-9004-b473b79eab85\nTeams\nMicrosoft Facilitator\nMicrosoft Facilitator updates AI Notes, Live Notes, or Meeting Moderation in Microsoft Teams.\nOperation\nRecordType\nAppIdentity\nAppHost\nAINotesUpdate\nTeamCopilotInteraction\nCopilot.TeamCopilot.AINotes\nTeams\nLiveNotesUpdate\nTeamCopilotInteraction\nCopilot.TeamCopilot.LiveNotes\nTeams\nLiveNotesUpdate\nTeamCopilotInteraction\nCopilot.TeamCopilot.MeetingModerator\nTeams\nTeamCopilotMsgInteraction\nTeamCopilotInteraction\nCopilot.TeamCopilot.Message\nTeams\nIdentifying if Copilot accessed the web\nWhen you enable web search, Microsoft 365 Copilot and Microsoft 365 Copilot Chat parse user prompts and determine whether web search would improve the quality of the response. To identify if Copilot referenced the public web in a user interaction, review the\nAISystemPlugin.Id\nproperty in the\nCopilotInteraction\naudit record.\nAISystemPlugin.Id\ncontains the value\nBingWebSearch\nwhen user Copilot requests use the public web via Microsoft Bing for additional data.\nAccessing Copilot audit logs\nAccess Copilot audit logs by using the Microsoft Purview portal and selecting\nAudit\n.\nTo search for specific Copilot or AI application scenarios, use the\nActivities â operation names\nfield in the Microsoft Purview portal to filter audit logs by properties like\nOperation\n,\nRecordType\n, and\nWorkload\n.\nIf you need to search for audit logs containing a specific\nAppIdentity\nvalue or set of values, first search and export all relevant Copilot audit logs by filtering by operation name. From the exported search results, apply a filter on the\nAppIdentity\nproperty offline.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Audit Copilot Activities",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/audit-log-retention-policies": {
      "content_hash": "sha256:f04b2dc9dc86bbe0141f839f4f057381864e665830a903bcebb2b7cdc900891e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage audit log retention policies\nFeedback\nSummarize this article for me\nYou can create and manage audit log retention policies in the\nMicrosoft Purview portal\n. Audit log retention policies are part of the new Microsoft Purview Audit (Premium) capabilities. An audit log retention policy lets you specify how long to retain audit logs in your organization. You can retain audit logs for up to 10 years. You can create policies based on the following criteria:\nAll activities in one or more Microsoft services\nSpecific activities in a Microsoft service performed by all users or by specific users\nA priority level that specifies which policy takes precedence if you have multiple policies in your organization\nDefault audit log retention policy in Audit (Premium)\nAudit (Premium) in Microsoft Purview provides a default audit log retention policy for all organizations. You can't modify this policy. It retains all Exchange Online, SharePoint, OneDrive, and Microsoft Entra audit records for one year. This default policy retains audit records that contain the value of\nAzureActiveDirectory\n,\nExchange\n,\nOneDrive\n, and\nSharePoint\nfor the\nWorkload\nproperty (which is the service in which the activity occurred). Audit records for all other activities are retained for 180 days by default or you can change the retention to a different duration using a custom retention policy.\nNote\nThe default audit log retention policy only applies to audit records for activity performed by users who are assigned an Office 365 or Microsoft 365 E5 license or have a Microsoft Purview Suite (formerly known as Microsoft 365 E5 Compliance) or E5 eDiscovery and Audit add-on license. If you have non-E5 users or guest users in your organization, their corresponding audit records are retained for 180 days.\nImportant\nThe default retention period for Audit (Standard) changed from 90 days to 180 days. Audit (Standard) logs generated before October 17, 2023 are retained for 90 days. Audit (Standard) logs generated on or after October 17, 2023 follow the new default retention of 180 days.\nBefore you create an audit log retention policy\nYou need the\nOrganization Configuration\nrole in the Microsoft Purview portal to create or modify an audit retention policy.\nYour organization can have up to 50 audit log retention policies.\nTo retain an audit log for longer than 180 days (and up to 1 year), the user who generates the audit log (by performing an audited activity) must have an Office 365 E5 or Microsoft 365 E5 license or a Microsoft Purview Suite (formerly known as Microsoft 365 E5 Compliance) or E5 eDiscovery and Audit add-on license. To retain audit logs for 10 years, the user who generates the audit log must also have a 10-year audit log retention add-on license in addition to an E5 license.\nNote\nIf the user generating the audit log doesn't meet these licensing requirements, data is retained according to the highest priority retention policy. This retention might be either the default retention policy for the user's license or the highest priority policy that matches the user and its record type.\nAll custom audit log retention policies (created by your organization) take priority over the default retention policy. For example, if you create an audit log retention policy for Exchange mailbox activity that has a retention period that's shorter than one year, audit records for Exchange mailbox activities are retained for the shorter duration specified by the custom policy.\nThe audit item lifetime for data is determined when you add it to the auditing pipeline and is based on the licensing defaults or applicable retention policies. Any changes to licensing or applicable retention policies change the expiration time of the audit data after updating. These changes don't update any previously committed items.\nCreate an audit log retention policy\nComplete the following steps to create an audit retention policy:\nSign in to the\nMicrosoft Purview portal\nwith a user account assigned the\nOrganization Configuration\nrole on the\nRoles & scopes\npage in the Microsoft Purview portal.\nSelect the\nAudit\nsolution card. If the\nAudit\nsolution card isn't displayed, select\nView all solutions\nand then select\nAudit\nfrom the\nCore\nsection.\nSelect\nCreate audit retention policy\n, and then complete the following fields on the flyout page:\nPolicy name\n: The name of the audit log retention policy. This name must be unique in your organization, and you can't change it after creating the policy.\nDescription\n: Optional, but helpful to provide information about the policy, such as the record type or workload, users specified in the policy, and the duration.\nUsers:\nSelect one or more users to apply the policy to. If you leave this box blank, the policy applies to all users.\nRecord type\n: The audit record type the policy applies to. If you leave this property blank, the policy applies to all record types. You can select a single record type or multiple record types:\nIf you select a single record type, the\nActivities\nfield is dynamically displayed. Use the drop-down list to select activities from the selected record type to apply the policy to. If you don't choose specific activities, the policy applies to all activities of the selected record type.\nIf you select multiple record types, you don't have the ability to select activities. The policy applies to all activities of the selected record types.\nDuration:\nThe amount of time to retain the audit logs that meet the criteria of the policy. The available options are\n7 Days\n,\n30 Days\n,\n6 Months\n,\n9 Months\n,\n1 Year\n,\n3 Years\n,\n5 Years\n, and\n7 Years\n. Users with the 10-year Audit Log Retention add-on license can select a\n10 Years\noption.\nImportant\nTo retain audit logs for the 7 and 30 days duration options, you must have a Microsoft 365 Enterprise E5 subscription. To retain audit logs for the 3, 5, and 7 years duration options, you must be assigned to a 10-Year Audit Log Retention add-on license in addition to your Microsoft 365 Enterprise E5 subscription. For more information about Audit subscriptions and add-ons, see\nAuditing solutions in Microsoft Purview\nPriority\n: This value determines the order in which audit log retention policies in your organization are processed. A lower value indicates a higher priority. Valid priorities are numerical values between\n1\nand\n10000\n. A value of\n1\nis the highest priority, and a value of\n10000\nis the lowest priority. For example, a policy with a value of\n5\ntakes priority over a policy with a value of\n10\n. Any custom audit log retention policy takes priority over the default policy for your organization.\nSelect\nSave\nto create the new audit log retention policy.\nThe new policy appears in the list on the\nPolicies\npage.\nManage audit log retention policies in the Microsoft Purview portal\nThe\nAudit retention policies\ntab (also called the\ndashboard\n) lists audit log retention policies. You can use the dashboard to view, edit, and delete audit retention policies.\nView policies in the dashboard\nThe dashboard lists audit log retention policies. One advantage of viewing policies in the dashboard is that you can select the\nPriority\ncolumn to list the policies in the priority order in which they're applied. As previously explained, a lower value indicates a higher priority.\nYou can also select a policy to display its settings on the flyout page.\nNote\nThe dashboard doesn't display the default audit log retention policy for your organization.\nEdit policies in the dashboard\nTo edit a policy, select it to display the flyout page. You can modify one or more settings and then save your changes.\nImportant\nIf you use the\nNew-UnifiedAuditLogRetentionPolicy\ncmdlet, you might create an audit log retention policy for record types or activities that aren't available in the\nCreate audit retention policy\ntool in the dashboard. In this case, you can't edit the policy (for example, change the retention duration or add and remove activities) from the\nAudit retention policies\ndashboard. You can only view and delete the policy in the Microsoft Purview portal. To edit the policy, you need to use the\nSet-UnifiedAuditLogRetentionPolicy\ncmdlet in Security & Compliance PowerShell.\nTip\nA message is displayed at the top of the flyout page for policies that you need to edit by using PowerShell.\nDelete policies in the dashboard\nTo delete a policy, select the\nDelete\nicon and then confirm that you want to delete the policy. The policy is removed from the dashboard, but it might take up to 30 minutes for the policy to be removed from your organization.\nCreate and manage audit log retention policies in PowerShell\nYou can also use Security & Compliance PowerShell to create and manage audit log retention policies. One reason to use PowerShell is to create a policy for a record type or activity that isn't available in the UI.\nCreate an audit log retention policy in PowerShell\nFollow these steps to create an audit log retention policy in PowerShell:\nConnect to Security & Compliance PowerShell\n.\nRun the following command to create an audit log retention policy:\nNew-UnifiedAuditLogRetentionPolicy -Name \"Microsoft Teams Audit Policy\" -Description \"One year retention policy for all Microsoft Teams activities\" -RecordTypes MicrosoftTeams -RetentionDuration TenYears -Priority 100\nThis example creates an audit log retention policy named \"Microsoft Teams Audit Policy\" with these settings:\nA description of the policy.\nRetains all Microsoft Teams activities (as defined by the\nRecordType\nparameter).\nRetains Microsoft Teams audit logs for 10 years.\nA priority of 100.\nHere's another example of creating an audit log retention policy. This policy retains audit logs for the \"User logged in\" activity for six months for the user admin@contoso.onmicrosoft.com.\nNew-UnifiedAuditLogRetentionPolicy -Name \"SixMonth retention for admin logons\" -RecordTypes AzureActiveDirectoryStsLogon -Operations UserLoggedIn -UserIds admin@contoso.onmicrosoft.com -RetentionDuration SixMonths -Priority 25\nFor more information, see\nNew-UnifiedAuditLogRetentionPolicy\n.\nView policies in PowerShell\nUse the\nGet-UnifiedAuditLogRetentionPolicy\ncmdlet in Security & Compliance PowerShell to view audit log retention policies.\nThe following command displays the settings for all audit log retention policies in your organization. This command sorts the policies from the highest to lowest priority.\nGet-UnifiedAuditLogRetentionPolicy | Sort-Object -Property Priority -Descending | FL Priority,Name,Description,RecordTypes,Operations,UserIds,RetentionDuration\nNote\nThe\nGet-UnifiedAuditLogRetentionPolicy\ncmdlet doesn't return the default audit log retention policy for your organization.\nEdit policies in PowerShell\nUse the\nSet-UnifiedAuditLogRetentionPolicy\ncmdlet in Security & Compliance PowerShell to edit an existing audit log retention policy.\nDelete policies in PowerShell\nUse the\nRemove-UnifiedAuditLogRetentionPolicy\ncmdlet in Security & Compliance PowerShell to delete an audit log retention policy. It might take up to 30 minutes for the policy to be removed from your organization.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Audit Log Retention",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/audit-log-search": {
      "content_hash": "sha256:5fcc4864d58fba7fbc80bd641c7c48512a40872116fb50bf1be67cf0aacb2d6b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSearch the audit log\nFeedback\nSummarize this article for me\nSearch in Microsoft Purview Audit (Standard) and Audit (Premium) gives your organization access to critical audit log event data so you can gain insight and further investigate user activities.\nSearch jobs that you start through the Microsoft Purview portal don't need the web browser window to stay open to finish. These jobs keep running even after you close the browser window.\nThe system now keeps completed search jobs for 30 days, so you can look back at past audit searches.\nEach admin Audit account user can have up to 10 search jobs running at the same time, with a limit of one unfiltered search job.\nBefore you search the audit log\nReview the following items before you start searching the audit log.\nAudit log search is turned on by default for Microsoft 365 and Office 365 enterprise organizations. To verify that audit log search is turned on, run the following command in\nExchange Online PowerShell\n:\nGet-AdminAuditLogConfig | Format-List UnifiedAuditLogIngestionEnabled\nThe value of\nTrue\nfor the\nUnifiedAuditLogIngestionEnabled\nproperty indicates that audit log search is turned on. For more information, see\nTurn audit log search on or off\n.\nImportant\nBe sure to run the previous command in Exchange Online PowerShell. Although the\nGet-AdminAuditLogConfig\ncmdlet is also available in Security & Compliance PowerShell, the\nUnifiedAuditLogIngestionEnabled\nproperty is always\nFalse\n, even when audit log search is turned on.\nYou must be assigned the\nAudit Logs\nor\nView-Only Audit Logs\nroles in the Microsoft Purview portal to search the audit log. For more information, see\nGet started with auditing solutions\n. To access audit cmdlets, you must be assigned the\nAudit Logs\nor\nView-Only Audit Logs\nroles in the Exchange admin center. You can also create custom role groups with the ability to search the audit log by adding the\nView-Only Audit Logs\nor\nAudit Logs\nroles to a custom role group. For more information, see\nPermissions in the Microsoft Purview portal\n.\nWhen a user or admin performs an audited activity, the system generates an audit record and stores it in the audit log for your organization. The length of time that an audit record is retained (and searchable in the audit log) depends on your Office 365 or Microsoft 365 Enterprise subscription, and specifically the type of the license that is assigned to specific users.\nFor users assigned an Office 365 E5 or Microsoft 365 E5 license (or users with a Microsoft Purview Suite (formerly known as Microsoft 365 E5 Compliance) or Microsoft 365 E5 eDiscovery and Audit add-on license), the system retains audit records for Microsoft Entra ID, Exchange, and SharePoint activity for one year by default. Organizations can also create audit log retention policies to retain audit records for activities in other services for up to one year. For more information, see\nManage audit log retention policies\n.\nNote\nIf your organization participated in the private preview program for the one-year retention of audit records, the retention duration for audit records that were generated before the general availability rollout date won't be reset.\nFor users assigned any other (non-E5) Office 365 or Microsoft 365 license, the system retains audit records for 180 days. For a list of Office 365 and Microsoft 365 subscriptions that support unified audit logging, see the\nsubscription requirements\nfor Audit (Standard) and Audit (Premium).\nImportant\nThe default retention period for Audit (Standard) changed from 90 days to 180 days. Audit (Standard) logs generated before October 17, 2023 are retained for 90 days. Audit (Standard) logs generated on or after October 17, 2023 follow the new default retention of 180 days.\nNote\nEven when mailbox auditing on by default is turned on, you might notice that mailbox audit events for some users aren't found in audit log searches in the Microsoft Purview portal or via the Office 365 Management Activity API. For more information, see\nMore information about mailbox audit logging\n.\nTo turn off audit log search for your organization, run the following command in Exchange Online PowerShell:\nSet-AdminAuditLogConfig -UnifiedAuditLogIngestionEnabled $false\nTo turn on audit search again, run the following command in Exchange Online PowerShell:\nSet-AdminAuditLogConfig -UnifiedAuditLogIngestionEnabled $true\nFor more information, see\nTurn off audit log search\n.\nThe underlying cmdlet used to search the audit log is an Exchange Online cmdlet, which is\nSearch-UnifiedAuditLog\n. That means you can use this cmdlet to search the audit log instead of using the search tool on the\nAudit\npage in the Microsoft Purview portal. You have to run this cmdlet in Exchange Online PowerShell. For more information, see\nSearch-UnifiedAuditLog\n.\nFor information about exporting the search results returned by the\nSearch-UnifiedAuditLog\ncmdlet to a CSV file, see the \"Tips for exporting and viewing the audit log\" section in\nExport, configure, and view audit log records\n.\nTo programmatically download data from the audit log, we recommend that you use the Office 365 Management Activity API instead of using a PowerShell script. The Office 365 Management Activity API is a REST web service that you can use to develop operations, security, and compliance monitoring solutions for your organization. For more information, see\nOffice 365 Management Activity API reference\n.\nMicrosoft Entra ID is the directory service for Microsoft 365. The unified audit log contains user, group, application, domain, and directory activities performed in the\nMicrosoft 365 admin center\nor in the Azure management portal. For a complete list of Microsoft Entra events, see\nMicrosoft Entra audit Report Events\n.\nMicrosoft doesn't guarantee a specific time after an event occurs for the corresponding audit record to be returned in the results of an audit log search. For core services (such as Exchange, SharePoint, OneDrive, and Teams), audit record availability is typically 60 to 90 minutes after an event occurs. For other services, audit record availability might be longer. However, some issues that are unavoidable (such as a server outage) might occur outside of the audit service that delays the availability of audit records. For this reason, Microsoft doesn't commit to a specific time.\nTo search for Power BI activities in the audit log, you have to enable auditing in the Power BI admin portal. For instructions, see the \"Audit logs\" section in\nPower BI admin portal\n.\nGet started with search\nComplete the following steps to get started with search:\nSign in to the\nMicrosoft Purview portal\n.\nSelect the\nAudit\nsolution card. If the\nAudit\nsolution card isn't displayed, select\nView all solutions\nand then select\nAudit\nfrom the\nCore\nsection.\nOn the\nSearch\npage, configure the following search criteria as applicable:\nDate and time range (UTC)\n: The last seven days are selected by default. Select a date and time range to display the events that occurred within that period. The date and time are presented in Coordinated Universal Time (UTC). The maximum date range that you can specify is 180 days. An error is displayed if the selected date range is greater than 180 days.\nTip\nIf you use the maximum date range of 180 days, select the current time for the\nStart date\n. Otherwise, you receive an error saying that the start date is earlier than the end date. If you turn on auditing within the last 180 days, the maximum date range can't start before the date that auditing was turned on.\nKeyword Search\n: Enter a keyword or phrase to search for in the audit log. The keyword or phrase is searched for in the audit log or in the file, folder, or sites (if specified) for the search. To search for text that contains special characters, replace the special characters with an asterisk(*) in your keyword search. For example, to search for\ntest_search_document\n, use\ntest*search*document\n.\nImportant\nTerms entered in the\nKeyword Search\nfield are only searched within indexed content (content within the Audit\ncommon schema\n). Audit\ndata content\nin the audit log isn't searched for these keywords.\nAdmin Units\n: Select the drop-down list to display the\nadministrative units\nyou want the audited activities scoped to for your search. You can select one or more administrative units to scope your search to. Leave this box blank to return entries for all administrative units in your organization.\nActivities - friendly names\n: Select the drop-down list to display the friendly names for audited activities that you can search for. Friendly names for user and admin activities are organized into groups of related activities. Using friendly names, you can select specific audited activities or you can select the activity group name to select all activities in the group. You can also select a selected activity to clear the selection. To search for a friendly name for the activities in the list, use the search box over the list.\nActivities - operations names\n: Enter the exact operation names to search for audited activities to include in your search results. You can enter one or more operation names, separated by commas. This search criterion is similar to previous searches only available in PowerShell and provides greater flexibility helping you find the data that you need.\nImportant\nOperation names must be entered exactly as they are named. If operation names are entered incorrectly, no results are returned.\nFor example, to search for all activities related to enabling and disabling information barriers for a SharePoint site in your organization, you would:\nReview the\naudit activities\narticle to find the exact operation name for the information barriers activities you want to search for. In this\nexample\n, the operation names are\nSPOIBIsEnabled\nand\nSPOIBIsDisabled\n.\nEnter\nSPOIBIsEnabled,SPOIBIsDisabled\nin operation search field. We recommend copying and pasting the operation names directly from the article to the operation search field to ensure that they're entered correctly and without typos.\nRecord types\n: Select the drop-down list to display the record types for audited activities that you can search for. You can select one or more record types to search for. To search for a record type in the list, use the search box over the list.\nSpecific\nrecord types\nare associated with specific Microsoft services and applications. For example, if you want to scope your search for specific record types associated with sensitivity labels in Microsoft Purview Information Protection (MIP), you could select the\nMIPLabel\n,\nMipAutoLabelExchangeItem\n,\nMipAutoLabelSharePointItem\n, and\nMipAutoLabelSharePointPolicyLocation\nrecord types from the list.\nSearch name\n: Enter in a custom name for your search job. This name is used to identify your search job in the search job history. If you don't enter a name, the search job is automatically named using a combination of the date and time defined for the search and other defined search criteria values.\nUsers\n: Select this field and choose the names one or more users to display search results for. The audit log entries for the selected activity performed by the users you select in this box are displayed in the list of results. Leave this box blank to return entries for all users (and service accounts) in your organization.\nFile, folder, or site\n: Enter part or all of a file or folder name to find related activity. This returns results for matching files, folders, and sites. You can also enter a full URL or part of one, just avoid special characters or spaces. You can use * as a wildcard at the end of the URL. For example,\nhttps://<tenantname>.sharepoint.com/sites/site123*\n. Leave the field blank to see activity for all files and folders in your organization.\nWorkloads\n: Enter or search for workload services to search for activity related to the selected workloads. Enter the name of a workload to jump to the workload in the list or scroll to the workloads you'd like to select.\nSelect\nSearch\nto start your search job. A maximum of 10 search jobs can be run in parallel for one user account. If a user requires more than 10 search jobs, they must wait for an\nIn progress\njob to finish or delete a search job.\nSearch job dashboard\nThe search job dashboard displays active and completed search jobs. For each search job, the dashboard shows the following information:\nSearch name\n: The name of the search job. You can see the full search name for a job by hovering the cursor over the search job name.\nJob status\n: The status of the search job. The status can be\nQueued\n,\nIn Progress\n, or\nCompleted\n.\nProgress (%)\n: The percentage of the search job that the job completes.\nSearch time\n: The total running time that elapses to complete the search job.\nTotal results\n: The total number of results the search job returns.\nCreation time\n: The date and time the search job created in UTC.\nSearch performed by\n: The user account that creates the search job.\nDelete search jobs by selecting the job and then selecting\nDelete\non the command bar. Deleting a search job doesn't delete the backend data associated with search. It only deletes the search job definition and the associated search result.\nTo copy the search criteria for an existing search job, select the job and then select\nCopy this search\non the command bar. The search criteria are copied to the search page and you can modify the search criteria as needed for a new search.\nSearch job details dashboard\nTo view details about a search job, select the search job. The dashboard shows the total number of items in the job at the top. The total result number removes duplicates, so it might be less than the number of items in the search job dashboard.\nThe search job details dashboard displays the following information about the individual items gathered in the search job results:\nDate (UTC)\n: The date and time the activity occurred.\nIP Address\n: The IP address of the device that was used to perform the activity.\nUser\n: The user account that performed the activity.\nRecord type\n: The record type associated with the activity.\nActivity\n: The friendly name of the activity that was performed.\nItem\n: The name of the file, folder, or site that the activity was acted on.\nAdmin Units\n: The admin unit that the user account that performed the activity belongs to.\nDetails\n: Additional details about the activity.\nYou can sort the search job items by using the column headers or create a custom filter by using the filter pane. Use the filter to filter the search job items for specific values for any of the dashboard column criteria. To export all search job items to a .csv file, select\nExport\non the command bar. Export supports results up to 50 KB for Audit (Standard) and up to 500 KB (500,000 rows) for Audit (Premium).\nSelect a specific activity to see more details about the activity in a fly-out window. The fly-out window displays the additional information about the activity.\nScoping access to audit logs using administrative units\nAccess to search the audit log is based on the\nadministrative units\nassigned to the user in the Microsoft Purview portal. A restricted admin can only search and export user-generated audit logs within the scope of their assigned administrative units. An unrestricted admin has access to all audit logs, including logs generated by non-user and system accounts. To access scoped activity logs from any Microsoft service, including Exchange mailbox activity logs, use the\nSearch-UnifiedAuditLog\ncmdlet.\nAdmin units assigned to admins\nAdmin units available to perform scoped search on\nAccess to search and export audit logs\nNone (Default): Unrestricted admin\nAll administrative units are available\nAccess to all activity logs from any user, nonuser, or system account.\nOne or more administrative units: Restricted admin\nOnly those administrative units assigned to the admin are available\nAccess to activity logs from users with a matching administrative unit assignment.\nOnly\nunrestricted admins\ncan access the following audit activities through search queries. We're working to ensure these logs are accessible when queried by a restricted admin. To view a complete list of audit logs for these activities, submit a search request by using an unrestricted admin account.\nService\nOperation\nAzure Information Protection\nDiscover\nDynamics 365\nCrmDefaultActivity\nEndpoint data loss prevention\nFileCreated\nFileCreatedOnNetworkShare\nFileCreatedOnRemovableMedia\nFileDeleted\nExchange\nSet-Mailbox\nSet-MailboxPlan\nSupervisionBulkEmailExclusion\nMicrosoft Forms\nViewRuntimeForm\nFor more information about administrative units, see\nPermissions in the Microsoft Purview portal\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Search the Audit Log",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ai-microsoft-purview": {
      "content_hash": "sha256:d7bef9f6af88f80073a99972d2919535a56fabd82da0778c7ab171132e2369a4",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Purview data security and compliance protections for generative AI apps\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\nUse Microsoft Purview to mitigate and manage the risks associated with AI usage, and implement corresponding protection and governance controls.\nThe following sections on this page provide an overview of Data Security Posture Management for AI and the Microsoft Purview capabilities that provide additional data security and compliance controls to accelerate your organization's adoption of Copilots and agents, and other generative AI apps.\nIn some Microsoft Purview solutions, you might see the supported AI apps grouped by the following category names:\nCopilot experiences and agents\nor\nMicrosoft Copilot experiences\nfor supported Copilots and agents that include:\nMicrosoft 365 Copilot\nSecurity Copilot\nCopilot in Fabric\nCopilot Studio\nEnterprise AI apps\nfor non-Copilot AI apps and agents connected to your organization through Entra registration, data connectors, Microsoft Foundry, and other methods, and include:\nEntra-registered AI apps\nChatGPT Enterprise\nMicrosoft Foundry\nOther AI apps\nthat are detected through browser activity and categorized as \"Generative AI\" in the Defender for Cloud Apps catalog. This category can include AI apps and agents from the other two categories but also uniquely includes AI apps and agents from third-party LLMs, such as:\nChatGPT\nGoogle Gemini\nMicrosoft Copilot (consumer version)\nDeepSeek\nNote\nNow rolling out with the\nFrontier preview program\ndata security and compliance protections from Microsoft Purview also support\nMicrosoft Agent 365\n. Currently, agent instances are identified and managed like other users.\nFor a breakdown of Microsoft Purview security and compliance supported capabilities for AI interactions by app, see the additional pages identified in the following table. Where these AI apps support agents, they inherit the same security and compliance capabilities as their parent AI app. However, for a quick summary, see\nUse Microsoft Purview to manage data security & compliance for AI agents\n.\nCopilot experiences and agents\nEnterprise AI apps\nOther AI apps\nMicrosoft 365 Copilot & Microsoft 365 Copilot Chat\nEntra-registered AI apps\nOther AI apps\nMicrosoft Security Copilot\nMicrosoft Foundry\nCopilot in Fabric\nChatGPT Enterprise\nMicrosoft Copilot Studio\nMicrosoft Facilitator\nChannel Agent in Teams\nFor a list of supported Microsoft Purview security and compliance supported capabilities for Microsoft Agent 365, see\nUse Microsoft Purview to manage data security & compliance for Microsoft Agent 365\n.\nIf you're new to Microsoft Purview, you might also find an overview of the product helpful:\nLearn about Microsoft Purview\n.\nDSPM for AI (classic) and DSPM (preview)\nUse\nData Security Posture Management for AI (classic)\nor\nData Security Posture Management (preview)\nas your front door to discover, secure, and apply compliance controls for AI usage across your enterprise. Both DSPM versions use existing controls from Microsoft Purview information protection and compliance management with easy-to-use graphical tools and reports to quickly gain insights into AI use within your organization. With personalized recommendations, and one-click policies help you protect your data and comply with regulatory requirements.\nMicrosoft Purview strengthens information protection for AI apps\nBecause of the power and speed AI can proactively surface content, generative AI amplifies the problem and risk of oversharing or leaking data. Learn how information protection capabilities from Microsoft Purview can help to strengthen your existing data security solutions.\nSensitivity labels and AI interactions\nAI apps that Microsoft Purview support use\nexisting controls to ensure that data stored in your tenant is never returned\nto the user or used by a large language model (LLM) if the user doesn't have access to that data. When the data has\nsensitivity labels\nfrom your organization applied to the content, there's an extra layer of protection:\nWhen a file is open in Word, Excel, PowerPoint, or similarly an email or calendar event is open in Outlook, the sensitivity of the data is displayed to users in the app with the label name and content markings (such as header or footer text) that have been configured for the label.\nLoop components and pages also support the same sensitivity labels\n.\nWhen the sensitivity label applies encryption, users must have the\nEXTRACT usage right\n, as well as VIEW, for the AI apps to return the data.\nThis protection extends to data stored outside your Microsoft 365 tenant when it's open in an Office app (data in use). For example, local storage, network shares, and cloud storage.\nTip\nIf you haven't already, we recommend you enable sensitivity labels for SharePoint and OneDrive and also familiarize yourself with the file types and label configurations that these services can process. When sensitivity labels aren't enabled for these services, the encrypted files that Copilot and agents can access are limited to data in use from Office apps on Windows.\nFor instructions, see\nEnable sensitivity labels for Office files in SharePoint and OneDrive\n.\nIf you're not already using sensitivity labels, see\nGet started with sensitivity labels\n.\nEncryption without sensitivity labels and AI interactions\nEven if a sensitivity label isn't applied to content, services and products might use the encryption capabilities from the Azure Rights Management service. As a result, AI apps can still check for the VIEW and EXTRACT usage rights before returning data and links to a user, but there's no automatic inheritance of protection for new items.\nTip\nYou'll get the best user experience when you always use sensitivity labels to protect your data, and encryption is applied by a label.\nExamples of products and services that can use the encryption capabilities from the Azure Rights Management service without sensitivity labels:\nMicrosoft Purview Message Encryption\nMicrosoft Information Rights Management (IRM)\nMicrosoft Rights Management connector\nMicrosoft Rights Management SDK\nFor other encryption methods that don't use the Azure Rights Management service:\nS/MIME protected emails won't be returned by Copilot, and Copilot isn't available in Outlook when an S/MIME protected email is open.\nPassword-protected documents can't be accessed by AI apps unless they're already opened by the user in the same app (data in use). Passwords aren't inherited by a destination item.\nAs with other Microsoft 365 services, such as eDiscovery and search, items encrypted with\nMicrosoft Purview Customer Key\nor\nyour own root key (BYOK)\nare supported and eligible to be returned by Copilot.\nData loss prevention and AI interactions\nMicrosoft Purview Data Loss Prevention\n(DLP) helps you identify sensitive items across Microsoft 365 services and endpoints, monitor them, and helps protect against leakage of those items. It uses deep content inspection and contextual analysis to identify sensitive items and it enforces policies to protect sensitive data such as financial records, health information, or intellectual property.\nWindows computers that are\nonboarded to Microsoft Purview\ncan be configured for Endpoint data loss prevention (DLP) policies that warn or block users from sharing sensitive information with third-party generative AI sites that are accessed via a browser. For example, a user is prevented from pasting credit card numbers into ChatGPT, or they see a warning that they can override. For more information about the supported DLP actions and which platforms support them, see the first two rows in the table from\nEndpoint activities you can monitor and take action on\n.\nInsider Risk Management and AI interactions\nMicrosoft Purview Insider Risk Management\nhelps you detect, investigate, and mitigate internal risks such as IP theft, data leakage, and security violations. It leverages machine learning models and various signals from Microsoft 365 and third-party indicators to identify potential malicious or inadvertent insider activities. The solution includes privacy controls like pseudonymization and role-based access, ensuring user-level privacy while enabling risk analysts to take appropriate actions.\nUse the\nRisky AI usage policy template\nto detect risky usage that includes prompt injection attacks and accessing protected materials. Insights from these signals are integrated into Microsoft Defender XDR to provide a comprehensive view of AI-related risks.\nData classification and AI interactions\nMicrosoft Purview data classification provides a comprehensive framework for identifying and tagging sensitive data across various Microsoft services, including Office 365, Dynamics 365, and Azure. Classifying data is often the first step to ensure compliance with data protection regulations and safeguard against unauthorized access, alteration, or destruction. You can use built-in system classifications or create your own.\nSensitive information types and trainable classifiers can be used to find sensitive data in user prompts and responses when they use AI apps. The resulting information then surfaces in\nMicrosoft Purview Reports overview\nand\nactivity explorer\nin DSPM for AI and the\nAI activities\ntab in activity explorer from the preview version of DSPM.\nMicrosoft Purview supports compliance management for AI apps\nInteractions using supported AI apps can be monitored for each user in your tenant. As such, together with data classification, you can use Microsoft Purview's auditing, communication compliance, eDiscovery with content search, and automatic retention and deletion capabilities from Data Lifecycle Management to manage this AI usage.\nAuditing and AI interactions\nMicrosoft Purview Audit solutions\nprovide comprehensive tools for searching and managing audit records of activities performed across various Microsoft services by users and admins, and help organizations to effectively respond to security events, forensic investigations, internal investigations, and compliance obligations.\nLike other activities, prompts and responses are\ncaptured in the unified audit log\n. Events include how and when users interact with the AI app, and can include in which Microsoft 365 service the activity took place, and references to the files stored in Microsoft 365 that were accessed during the interaction. If these files have a sensitivity label applied, that's also captured.\nThese events flow into\nactivity explorer\nin DSPM for AI and the\nAI activities\ntab in activity explorer from the preview version of DSPM, where the data from prompts and responses can be displayed. You can also use the\nAudit\nsolution from the\nMicrosoft Purview portal\nto search and find these auditing events.\nFor more information, see\nAudit logs for Copilot and AI activities\n.\nCommunication compliance and AI interactions\nMicrosoft Purview Communication Compliance\nprovides tools to help you detect and manage regulatory compliance and business conduct violations across various communication channels, which include user prompts and responses for AI apps. It's designed with privacy by default, pseudonymizing usernames and incorporating role-based access controls. The solution helps identify and remediate inappropriate communications, such as sharing sensitive information, harassment, threats, and adult content.\nTo learn more about using communication compliance policies for AI apps, see\nConfigure a communication compliance policy to detect for generative AI interactions\n.\neDiscovery with content search and AI interactions\nMicrosoft Purview eDiscovery\nlets you identify and deliver electronic information that can be used as evidence in legal cases. The eDiscovery tools in Microsoft Purview support searching for content in Exchange Online, OneDrive for Business, SharePoint Online, Microsoft Teams, Microsoft 365 Groups, and Viva Engage teams. You can then prevent the information from deletion and export the information.\nBecause user prompts and responses for AI apps are stored in a user's mailbox, you can create a case and use\nsearch\nwhen a user's mailbox is selected as the source for a search query. For example, select and retrieve this data from the source mailbox by selecting from the query builder\nAdd condition\n>\nType\n>\nContains any of\n>\nEdit\n>\nCopilot activity\n. This query condition includes all Copilot and other AI application activity.\nAfter the search is refined, you can export the results or add to a\nreview set\n. You can review and export information directly from the review set.\nTo learn more about identifying and deleting user AI interaction data, see\nSearch for and delete Copilot data in eDiscovery\n.\nData Lifecycle Management and AI interactions\nMicrosoft Purview Data Lifecycle Management\nprovides tools and capabilities to manage the lifecycle of organizational data by retaining necessary content and deleting unnecessary content. These tools ensure compliance with business, legal, and regulatory requirements.\nUse\nretention policies\nto automatically retain or delete user prompts and responses for AI apps. For detailed information about this retention works, see\nLearn about retention for Copilot & AI apps\n.\nAs with all retention policies and holds, if more than one policy for the same location applies to a user, the\nprinciples of retention\nresolve any conflicts. For example, the data is retained for the longest duration of all the applied retention policies or eDiscovery holds.\nCompliance Manager and AI interactions\nMicrosoft Purview Compliance Manager\nis a solution that helps you automatically assess and manage compliance across your multicloud environment. Compliance Manager can help you throughout your compliance journey, from taking inventory of your data protection risks to managing the complexities of implementing controls, staying current with regulations and certifications, and reporting to auditors.\nTo help you keep compliant with AI regulations, Compliance Manager provides regulatory templates to help you assess, implement, and strengthen your compliance requirements for all generative AI apps. For example, monitoring AI interactions and preventing data loss in AI applications. For more information, see\nAssessments for AI regulations\n.\nOther documentation to help you secure and manage generative AI apps\nBlog post announcement:\nAccelerate AI adoption with next-gen security and governance capabilities\nMicrosoft 365 Copilot:\nMicrosoft 365 Copilot documentation\nApply principles of Zero Trust to Microsoft 365 Copilot\nRelated resources:\nSecure Generative AI with Microsoft Entra\nGovern AI apps and data for regulatory compliance\nBlog posts (April 2025):\nHow to deploy Microsoft Purview DSPM for AI to secure your AI apps\nHow to use DSPM for AI Data Risk Assessment to Address Internal Oversharing\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DSPM for AI",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ai-microsoft-purview-considerations": {
      "content_hash": "sha256:b6ee8063a405328ab8f6f5c2d723e55949e822817423d0cb0ed98dae0875221f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConsiderations for DSPM for AI to manage data security and compliance protections for AI interactions - (classic)\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\nNote\nThis article is for the\nclassic\nversion of Data Security Posture Management that's being replaced with a new version that introduces guided workflows for proactive risk management, and streamlines data security operations so you can more confidently adopt AI across your digital estate.\nThese improvements won't be added to this classic version so we invite you to try the new\nData Security Posture Management\n, currently in preview.\nFor the most part, Data Security Posture Management for AI is easy to use and self-explanatory, guiding you through prerequisites and preconfigured reports and policies. Use this section to complement that information and provide additional details that you might need.\nPrerequisites for Data Security Posture Management for AI\nTo use Data Security Posture Management for AI from the Microsoft Purview portal, you must have the following prerequisites:\nYou have the\nright permissions\n.\nRequired for monitoring interactions with Copilot and agents:\nMicrosoft Purview auditing is enabled for your organization. Although this is the default, you might want to check the instructions for\nTurn auditing on or off\n.\nFor Microsoft 365 Copilot and agents, users are\nassigned a license for Microsoft 365 Copilot\n.\nFor Copilot in Fabric and Security Copilot:\nThe\nenterprise version of Microsoft Purview data governance\n, to support the required APIs.\nA collection policy, such as the one created from the recommendation or remediation action\nSecure interactions for Microsoft Copilot experiences\n.\nRequired for monitoring interactions and applying DLP policies to other AI apps in Edge:\nAn Edge configuration policy is required to activate the Microsoft Purview integration in Edge. For configuration information, see\nActivate your DLP policy in Microsoft Edge\n.\nRequired for monitoring interactions with third-party generative AI sites:\nDevices are\nonboarded to Microsoft Purview\n, required for:\nGaining visibility into sensitive information that's shared with third-party generative AI sites. For example, a user pastes credit card numbers into ChatGPT.\nApplying endpoint DLP policies to warn or block users from sharing sensitive information with third-party generative AI sites. For example, a user identified as elevated risk in Adaptive Protection is blocked with the option to override when they paste credit card numbers into ChatGPT.\nThe\nMicrosoft Purview browser extension\nis deployed to Windows users and required to discover visits to third-party generative AI sites by using an Insider Risk Management policy. The browser extension is also required for Endpoint DLP policies on Windows when you use Chrome.\nFor\nEntra-registered AI apps\n, they are\nintegrated with the Microsoft Purview SDK\nto support all the Microsoft Purview capabilities.\nFor AI apps other than Microsoft 365 Copilot and Microsoft Facilitator, you've set up\npay-as-you-go billing\nfor your organization. When this billing model is applicable for specific configurations, you'll see notifications and instructions in the UI.\nYou'll find more information about the prerequisites for auditing, device onboarding, and the browser extension in Data Security Posture Management for AI: Navigate to\nOverview\n>\nGet started\nsection.\nFor a list of currently supported third-party AI apps, see\nSupported AI sites by Microsoft Purview for data security and compliance protections\n.\nNote\nIf you're using\nadministrative units\n, restricted administrators won't be able to create the one-click policies that apply to all users. You must be an unrestricted administrator to create these policies. Restricted administrators see the results only for users in their assigned administrative unit for the\nPolicies\npage, and in the reports and activity explorer in Microsoft Purview Data Security Posture Management for AI.\nPrerequisites for Fabric data risk assessments\nUse the following instructions to meet the prerequisites to run data risk assessments for Fabric workspaces, and\nbefore you select\nSet config\nin DSPM for AI\n.\nFor steps 1 and 2, use one of the following\nEntra roles for the required permissions\n:\nCloud Application Administrator\nApplication Administrator\nPrivileged Role Administrator\nFor step 3, you must be a\nFabric administrator\n.\nIn the Microsoft Entra admin portal,\ncreate and configure a registered app\nto be the service principal authentication for Fabric.\nAfter you've created this registered app and still in the Entra admin portal, copy and store the\nApplication (client) ID\nand\nClient secret\nvalues that are required to set up data risk assessments in DSPM for AI:\nTo locate the\nApplication (client) ID\n: In the Microsoft Entra admin portal,\nIdentity\n>\nApplications\n>\nApp registrations\n, select the app you created for Fabric. The\nApplication (client) ID\nis displayed on the\nOverview\ntab.\nCreate a client secret for this app\n. Copy and securely save the value immediately. It will only be shown once.\nNow navigate to\nGroups\nto add the registered app as a group member to a new or existing security group. Its type displays as\nEnterprise application\n.\nIn the Fabric admin portal, navigate to\nTenant settings\n>\nAdmin API settings\nand enable the options\nService principals can access read-only admin APIs\nand\nService principals can access admin APIs used for updates\n. For both of these, in the\nApply to:\nsections, select\nSpecific security groups\nand specify the security group that you configured in the previous step. Select\nApply\nto save and apply these tenant settings.\nFor more information about steps 1-2, see\nEnable service principal authentication for admin APIs\n.\nFor more information about the tenant settings and support for information protection in Fabric, see\nTenant settings index\nand\nInformation protection in Microsoft Fabric\n.\nPrerequisites for Microsoft 365 item-level scanning for data risk assessments\nUse the following instructions to create an Entra application with the required permissions for Microsoft 365 item-level scanning in a custom data risk assessment.\nYou must have one of the following\nEntra roles to create and configure the required registered app\n:\nCloud Application Administrator\nApplication Administrator\nPrivileged Role Administrator\nIn the Entra admin portal,\ncreate and configure a registered app\nwith the following settings:\nSupported account types\n:\nAccounts in this organizational directory only\nAPI permissions\n:\nMicrosoft APIs\n>\nMicrosoft Graph\n>\nApplication permissions\nApplication: Application.Read.All\nDirectory: Directory.Read.All\nFiles: Files.ReadWrite.All\nSensitivityLabels: SensitivityLabels.Read.All\nSites: Sites.ReadWrite.All\nUser: User.Read.All\nGrant admin consent for your tenant\nNow\ncreate a client secret for this app\n. Copy and securely save the value immediately. It will only be shown once.\nYou'll also need the registered application's ID, which is displayed as\nApplication (client) ID\nin the\nOverview\ntab.\nOne-click policies from Data Security Posture Management for AI\nAfter the default policies are created, you can view and edit them at any time from their respective solution areas in the portal. For example, you want to scope the policies to specific users during testing, or for business requirements. Or, you want to add or remove classifiers that are used to detect sensitive information. Use the\nPolicies\npage to quickly navigate to the right place in the portal.\nSome policies, such as\nDSPM for AI - Capture interactions for Copilot experiences\nand\nDSPM for AI - Detect sensitive info shared with AI via network\nare\ncollection policies\nthat you can edit, and if necessary, delete like any other collection policy. For more information, see\nAccessing collection policies\n.\nIf you delete any of the policies, their status on the\nPolicies\npage displays\nPendingDeletion\nand continues to show as created in their respective recommendation cards until the deletion process is complete.\nFor sensitivity labels and their policies, view and edit these independently from Data Security Posture Management for AI, by navigating to\nInformation Protection\nin the portal. For more information, use the configuration links in\nDefault labels and policies to protect your data\n.\nFor more information about the supported DLP actions and which platforms support them, see the first two rows in the table from\nEndpoint activities you can monitor and take action on\n.\nFor the default policies that use Adaptive Protection, this capability is turned on if it's not already on, using default risk levels for all users and groups to dynamically enforce protection actions. For more information, see\nQuick setup\nNote\nAny default policies created while Data Security Posture Management for AI was in preview and named Microsoft Purview AI Hub won't be changed. For example, policy names will retain their\nMicrosoft AI Hub -\nprefix.\nDefault policies for data discovery using Data Security Posture Management for AI\nDLP policy:\nDSPM for AI: Detect sensitive info added to AI sites\nSource:\nExtend your insights for data discovery\nThis policy discovers sensitive content pasted or uploaded in Microsoft Edge, Chrome, and Firefox to AI sites. This policy covers all users and groups in your org in audit mode only.\nInsider risk management policy:\nDSPM for AI - Detect when users visit AI sites\nSource:\nExtend your insights for data discovery\nThis policy detects when users use a browser to visit AI sites.\nInsider risk management policy:\nDSPM for AI - Detect risky AI usage\nSource: Recommendation\nDetect risky interactions in AI apps\nThis policy helps calculate user risk by detecting risky prompts and responses in Microsoft 365 Copilot, agents, and other generative AI apps.\nCommunication Compliance:\nDSPM for AI - Unethical behavior in AI apps\nSource: Recommendation\nDetect unethical behavior in AI apps\nThis policy detects sensitive information in prompts and responses in Microsoft 365 Copilot, agents, and other generative AI apps. This policy covers all users and groups in your organization.\nCollection policy:\nDSPM for AI - Capture interactions for Copilot experiences\nSource: Recommendation\nSecure interactions in Microsoft Copilot experiences\nThis policy captures prompts and responses for data security posture and regulatory compliance from Copilot in Fabric, and Security Copilot. Manage them in Microsoft Purview solutions like eDiscovery, Data Lifecycle Management, and more.\nCollection policy:\nDSPM for AI - Detect sensitive info shared with AI via network\nSource: Recommendation\nExtend insights into sensitive data in AI app interactions\nThis policy detects sensitive information shared with AI apps in browsers, applications, APIs, add-ins, and more, using a Secure Access Service Edge (SASE) or Security Service Edge (SSE) integration.\nImportant\nThis policy requires that you manually add one or more Secure Access Service Edge (SASE) or Security Service Edge (SSE) integrations in\nData Loss Prevention settings\n. The detection of AI interactions is dependent on the network partner implementation.\nIf you want to capture prompts and responses in addition to detecting sensitive information, you must edit the collection policy and select the\noption to capture content\n.\nCollection policy:\nDSPM for AI - Capture interactions for enterprise AI apps\nSource: Recommendation\nSecure interactions from enterprise apps\nThis policy captures prompts and responses for regulatory compliance from enterprise AI apps, such as Chat GPT Enterprise and AI apps connected through Microsoft Entra or Microsoft Foundry, so they can be managed in Microsoft Purview solutions like eDiscovery, Data Lifecycle Management, and more.\nCollection policy:\nDSPM for AI - Detect sensitive info shared in AI prompts in Edge\nSource:\nExtend your insights for data discovery\nThis policy detects prompts sent to generative AI apps in Microsoft Edge and discovers sensitive information shared in prompt contents. This policy covers all users and groups in your organization in audit mode only and doesn't capture content.\nDefault policies from data security to help you protect sensitive data used in generative AI\nDLP policy\nDSPM for AI - Block sensitive info from AI sites\nSource: Recommendation\nFortify your data security\nThis policy uses Adaptive Protection to give a block-with-override to elevated risky users attempting to paste or upload sensitive information to other AI apps in Edge, Chrome, and Firefox. This policy covers all users and groups in your org in test mode.\nDLP policy\nDSPM for AI - Block elevated risk users from submitting prompts to AI apps in Microsoft Edge\nSource: Recommendation\nFortify your data security\nUsing Adaptive Protection, this policy blocks elevated, moderate, and minor risk users attempting to put information in AI apps while using Microsoft Edge. Users included in this policy will be blocked from using unprotected browsers because this policy includes\nunmanaged apps\n.\nDLP policy\nDSPM for AI - Block sensitive info from AI apps in Edge\nSource: Recommendation\nFortify your data security\nThis policy detects inline for a selection of common sensitive information types and blocks prompts from being sent to AI apps while using Microsoft Edge. Users included in this policy will be blocked from using unprotected browsers because this policy includes\nunmanaged apps\n.\nDLP policy\nDSPM for AI - Protect sensitive data from Copilot processing\nSource: Recommendation\nProtect items with sensitivity labels from Microsoft 365 Copilot and agent processing\nThis policy blocks Microsoft 365 Copilot and agents from processing items with the sensitivity labels selected in this policy.\nInformation Protection -\nSensitivity labels and policies\nSource: Recommendation\nProtect your data with sensitiivity labels\nThis recommendation creates\ndefault sensitivity labels and sensitivity label policies\n. If you've already configured sensitivity labels and their policies, this configuration is skipped.\nActivity explorer events\nUse the following information to help you understand the events you might see in the activity explorer from Data Security Posture Management for AI. References to a generative AI site can include Microsoft 365 Copilot, Microsoft 365 Copilot Chat, agents, other Microsoft copilots, and third-party AI sites.\nEvent\nDescription\nAI interaction\nUser interacted with a generative AI site. Details include the prompts and responses, except for unmanaged AI apps in Edge where text prompts only are included. For Microsoft 365 Copilot and Microsoft 365 Copilot Chat, this event requires auditing to be turned on. For Copilot in Fabric and Security Copilot, and for non-Copilot AI apps, prompts and responses require a collection policy with content capture selected to capture these interactions.\nAI website visit\nUser browsed to a generative AI site.\nDLP rule match\nA data loss prevention rule was matched when a user interacted with a generative AI site. Includes DLP for Microsoft 365 Copilot.\nSensitive info types\nSensitive information types were found while a user interacted with a generative AI site. For Microsoft 365 Copilot and Microsoft 365 Copilot Chat, this event requires auditing to be turned on but doesn't require any active policies.\nKnown issues:\nThe\nAI interaction\nevent doesn't always display text for the prompt and response. Sometimes, the prompt and response spans consecutive entries. Other scenarios can include:\nMicrosoft Facilitator AI-generated notes, no prompt or response is displayed\nWhen a user doesn't have a mailbox hosted in Exchange Online, no prompt or response is displayed\nThe\nSensitive info types detected\nevent doesn't display the user risk level.\nFor Microsoft Facilitator AI-generated notes,\nAI interaction\nevents can't be linked to\nSensitive info types detected\nevents.\nFor collection policies, no prompt or response is displayed if the option to\ncapture content\nisn't selected in the policy. For example, the one-click policy\nDSPM for AI - Detect sensitive info shared with AI via network\ndoesn't select this option when the policy is automatically created, but you can manually edit the policy and select this option after the policy is created.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DSPM Considerations",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/communication-compliance": {
      "content_hash": "sha256:f063e881b7ba97e9c91337378c24c5ce892b32a9d97db3511832e96dd59920bb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about Communication Compliance\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Communication Compliance\nprovides the tools to help organizations detect regulatory compliance (for example, SEC or FINRA) and business conduct violations such as sensitive or confidential information, harassing or threatening language, and sharing of adult content. Communication Compliance is built with privacy by design. Usernames are pseudonymized by default, role-based access controls are built in, investigators are opted in by an admin, and audit logs are in place to help ensure user-level privacy.\nMicrosoft Purview Communication Compliance is an insider risk solution that helps you minimize communication risks by helping you detect, capture, and act on potentially inappropriate messages in your organization. Predefined and custom policies allow you to check internal and external communications for policy matches so designated reviewers can examine them. Reviewers can investigate email, Microsoft Teams, Microsoft 365 Copilot and Microsoft 365 Copilot Chat, Viva Engage, or third-party communications in your organization and take appropriate actions to make sure they're compliant with your organization's message standards.\nCommunication Compliance policies in Microsoft 365 help you overcome many modern challenges associated with compliance and internal and external communications, including:\nChecking increasing types of communication channels\nThe increasing volume of message data\nRegulatory enforcement and the risk of fines\nAdditionally, there might be a separation of duties between your IT admins and your compliance management team. Communication Compliance supports the separation between configuration of policies and the investigation and review of messages. For example, the IT group for your organization might be responsible for setting up Communication Compliance role permissions, groups, and policies. Investigators and reviewers might be responsible for message triage, review, and mitigation actions.\nFor more information and an overview of the planning process to address compliance and risky activities in your organization, see\nStarting an Insider Risk Management program\n.\nWatch the following video to learn how to fulfill regulatory compliance requirements with Communication Compliance:\nImportant\nCommunication Compliance is currently available in tenants hosted in geographical regions and countries supported by Azure service dependencies. To verify that Communication Compliance is supported for your organization, see\nAzure dependency availability by country/region\n.\nScenarios for Communication Compliance\nCommunication Compliance policies can help you review messages in your organization for several important compliance areas:\nCorporate policies\nUsers must comply with acceptable use, ethical standards, and other corporate policies in all their business-related communications. Communication Compliance policies can detect policy matches and help you take corrective actions to help mitigate these types of incidents. For example, you can check user communications in your organization for human resources concerns such as harassment or the use of potentially inappropriate or offensive language.\nRisk management\nOrganizations are responsible for all communications distributed throughout their infrastructure and corporate network systems. By using Communication Compliance policies to help identify and manage potential legal exposure and risk, you can minimize risks before they damage corporate operations. For example, you can check messages in your organization for unauthorized communications and conflicts of interest about confidential projects such as upcoming acquisitions, mergers, earnings disclosures, reorganizations, or leadership team changes.\nRegulatory compliance\nMost organizations must comply with some type of regulatory compliance standards as part of their normal operating procedures. These regulations often require organizations to implement some type of scoping or oversight process for messaging that is appropriate for their industry. The Financial Industry Regulatory Authority (FINRA) Rule 3110 is a good example of a requirement for organizations to have scoping procedures in place to check user communications and the types of businesses in which it engages. Another example might be a need to review broker-dealer communications in your organization to safeguard against potential insider trading, collusion, or bribery activities. Communication Compliance policies can help your organization meet these requirements by providing a process to both analyze and report on corporate communications. For more information on support for financial organizations, see\nKey compliance and security considerations for US banking and capital markets\n.\nKey feature areas\nCommunication Compliance offers several important features to help address compliance concerns on your messaging platforms:\nIntelligent customizable templates\nFlexible remediation workflows\nActionable insights\nIntelligent customizable templates\nIntelligent customizable templates in Communication Compliance help you apply machine learning to detect communication violations in your organization.\nCustomizable pre-configured templates\n: Policy templates help address the most common communications risks. You can create and update policies faster with predefined templates that analyze and mitigate potentially inappropriate content, sensitive information, conflict of interest, and regulatory compliance issues.\nNew machine learning support\n: Built-in\nclassifiers\nanalyze and mitigate discrimination, threats, harassment, profanity, and potentially inappropriate images. They help reduce misclassified content in communication messages, saving reviewers time during the investigation and remediation process.\nImproved condition builder\n: You can now configure policy conditions through a single, integrated experience in the policy workflow. This update reduces confusion about how conditions apply to policies.\nFlexible remediation workflows\nBuilt-in remediation workflows help you quickly identify and take action on messages with policy matches in your organization. The following new features increase efficiency for investigation and remediation activities:\nFlexible remediation workflow\n: The new remediation workflow helps you quickly take action on policy matches. New options let you escalate messages to other reviewers and send email notifications to users with policy matches.\nConversation policy matching\n: Messages in conversations group by policy matches to give you more visibility about how conversations relate to your communication policies. For example, conversation policy matching in the\nPending\ntab automatically shows all messages in a Teams channel that match your communications policies for analyzing and mitigating potentially inappropriate messages. Other messages in conversations that don't match your communications policies don't display.\nKeyword highlighting\n: Terms that match policy conditions highlight in the message text view to help reviewers quickly analyze and remediate policy alerts.\nOptical character recognition (OCR)\n: You can check, detect, and investigate printed and handwritten text within images embedded or attached to email or Microsoft Teams chat messages.\nNew filters\n: You can investigate and remediate policy alerts faster with message filters for several fields, including sender, recipient, date, domains, and many more.\nImproved message views\n: Investigation and remediation actions are now quicker with new message source and text views. You can now view message attachments to provide complete context when taking remediation actions.\nUser history\n: A historical view of all user message remediation activities, such as past notifications and escalations for policy matches, now provides reviewers with more context during the remediation workflow process. First-time or repeat instances of policy matches for users are now archived and easily viewable.\nPattern detected notification\n: Many harassing and bullying actions take place over time and involve recurring instances of the same behavior by a user. The pattern detected notification displayed in alert details helps raise attention to these alerts and this type of behavior.\nTranslation\n: You can quickly investigate message details in eight languages using translate support in the remediation workflow. Messages in other languages automatically convert to the display language of the reviewer.\nAttachment detection\n: You can check, detect, and investigate linked content (Modern attachments) from OneDrive and Microsoft Teams that match policy classifiers and conditions for Microsoft Teams messages. Attachment content is automatically extracted to a text file for detailed review and action.\nSummarize message content for policy matches\n: Save time for investigators by\nusing Microsoft Copilot in Microsoft Purview\nto summarize lengthy Teams, email, or Viva Engage messages. Copilot in Microsoft Purview creates a summary of the conversation, including recordings, meeting transcripts, and attachments.\nActionable insights\nNew interactive dashboards for alerts, policy matches, actions, and trends help you quickly view the status of pending and resolved alerts in your organization.\nProactive intelligent alerts\n: Get alerts for policy matches that need immediate attention. New dashboards show pending items sorted by severity. Designated reviewers receive new automatic email notifications.\nInteractive dashboards\n: View new dashboards that display policy matches, pending and resolved actions, and trends by users and policy.\nAuditing support\n: Easily export a full log of policy and review activities from the Microsoft Purview portal to help support audit review requests.\nIntegration with Microsoft 365 services\nCommunication Compliance policies check, detect, and capture messages across several communication channels to help you quickly review and remediate compliance issues:\nGenerative AI\n: Use Communication Compliance policies to analyze interactions (prompts and responses) entered into generative AI applications to help detect inappropriate or risky interactions or sharing of confidential information. Coverage is supported for\nMicrosoft 365 Copilot\n, Copilots built using\nMicrosoft Copilot Studio\n, AI applications connected by\nMicrosoft Entra\nor\nMicrosoft Purview Data Map\nconnectors, and more.\nMicrosoft Teams\n: Communication Compliance supports chat communications for public and private\nMicrosoft Teams\nchannels and individual chats as a standalone channel source or with other Microsoft 365 services. You can also detect communications included in meetings transcripts (preview). You need to manually add individual users, distribution groups, or specific Microsoft Teams channels when you select users and groups to apply a Communication Compliance policy to. Teams users can also self-report potentially inappropriate messages in private and group channels and chats for review and remediation.\nExchange Online\n: All mailboxes hosted on\nExchange Online\nin your Microsoft 365 organization are eligible for analyses. Emails and attachments matching Communication Compliance policy conditions are instantly available for investigation and in compliance reports. Exchange Online is now an optional source channel and is no longer required in Communication Compliance policies.\nMicrosoft 365 Copilot and Microsoft 365 Copilot Chat\n: Communication Compliance policies detect interactions (prompts and responses) entered by users into Copilot.\nViva Engage\n: Communication Compliance policies support private messages and public community conversations in\nViva Engage\n. Viva Engage is an optional channel and must be in\nnative mode\nto support checking of messages and attachments.\nThird-party sources\n: You can check messages from\nthird-party sources\nfor data imported into mailboxes in your Microsoft 365 organization. Communication Compliance supports connections to several popular platforms, including Instant Bloomberg and others.\nTo learn more about messaging channel support in Communication Compliance policies, see\nDetect channel signals with Communication Compliance\n.\nWatch the following video to learn how to detect communication risks in Microsoft Teams with Communication Compliance:\nIntegration with Microsoft Purview Insider Risk Management\nWhen users experience employment stressors, they might engage in risky activities. Workplace stress can lead to uncharacteristic or malicious behavior by some users that surfaces as potentially inappropriate behavior on your organization's messaging systems. Counterproductive work behavior can be a precursor to more serious violations, such as sabotaging company assets or leaking sensitive information. By integrating Communication Compliance with\nMicrosoft Purview Insider Risk Management\n, you can detect stressors that indicate an unhealthy workplace environment.\nLearn more about integrating Communication Compliance with Insider Risk Management\nGet started with recommended actions\nWhether you're setting up Communication Compliance for the first time or getting started with creating new policies, the new\nrecommended actions\nexperience can help you get the most out of Communication Compliance capabilities. Recommended actions include setting up permissions, creating distribution groups, creating policies, and more.\nWorkflow\nCommunication Compliance helps you address common pain points associated with complying with internal policies and regulatory compliance requirements. With focused policy templates and a flexible workflow, you can use actionable insights to quickly resolve detected compliance issues.\nBefore you create a policy, decide whether you want to apply an\nadaptive scope\n. For more information, see\nAdaptive policy scopes for compliance solutions\n. If you decide to create an adaptive policy, you must create one or more adaptive scopes before you create your policy, then select them during the create new policy process. For instructions, see\nConfiguration information for adaptive scopes\n.\nIdentifying and resolving compliance issues with Communication Compliance uses the following workflow:\nConfigure\nIn this workflow step, you identify your compliance requirements and configure applicable Communication Compliance policies. Policy templates are a great way to not only quickly configure a new compliance policy but also quickly modify and update policies as your requirements change. For example, you might want to quickly test a policy for potentially inappropriate content on communications for a small group of users before configuring a policy for all users in your organization.\nImportant\nBy default, Global Administrators don't have access to Communication Compliance features. To enable permissions for Communication Compliance features, see\nAssign permissions in Communication Compliance\n.\nYou can choose from the following policy templates in the Microsoft Purview portal:\nDetect inappropriate text\n: Use this template to quickly create a policy that uses built-in classifiers to automatically detect text in messages that might be considered inappropriate, abusive, or offensive.\nDetect inappropriate images\n: Use this template to quickly create a policy that uses built-in classifiers to automatically detect content that contains adult and racy images that might be considered inappropriate in your organization.\nDetect sensitive info types\n: Use this template to quickly create a policy to check communications containing defined sensitive information types or keywords to help make sure that important data isn't shared with people that shouldn't have access.\nDetect financial regulatory compliance\n: Use this template to quickly create a policy to check communications for references to standard financial terms associated with regulatory standards.\nDetect conflict of interest\n: Use this template to quickly create a policy to detect communications between two groups or two users to help avoid conflicts of interest.\nCustom policy\n: Use this template to configure specific communication channels, individual detection conditions, and the amount of content to detect and review in your organization.\nUser-reported messages policy\n: This system policy supports user reported messages from channel, group, and private chat messages. Enabled by default in the Teams admin center.\nTip\nUse\nrecommended actions\nto help you determine if you need a sensitive information type policy or if you need to update existing inappropriate content policies.\nInvestigate\nIn this step, you can look deeper into the issues detected as matching your Communication Compliance policies. This step includes the following actions available in the Microsoft Purview portal:\nAlerts\n: When a group of messages matches a policy condition, an alert is automatically generated. For each alert, you can see the status, the severity, the time detected, and if an eDiscovery (Premium) case is assigned and its status. New alerts are displayed on the Communication Compliance home page and the\nAlerts\npage and are listed in order of severity.\nIssue management\n: For each alert, you can take investigative actions to help remediate the issue detected in the message.\nDocument review\n: During the investigation of an issue, you can use several views of the message to help properly evaluate the detected issue. The views include a conversation summary, text-only, and detail views of the communication conversation.\nReviewing user activity history\n: View the history of user message activities and remediation actions, such as past notifications and escalations, for policy matches.\nFilters\n: Use filters such as sender, recipient, date, and subject to quickly narrow down the message alerts that you want to review.\nRemediate\nRemediate Communication Compliance issues you investigate by using the following options:\nResolve\n: After reviewing an issue, resolve the alert. Resolving an alert removes it from the\nPending\ntab. The action is preserved as an entry on the\nResolved\ntab for the matching policy. Alerts are automatically resolved after you mark the alert as misclassified, send a notice to a user about the alert, or open a new case for the alert.\nTag a message\n: As part of the resolution of an issue, tag a policy match as\nCompliant\n,\nNon-compliant\n, or\nQuestionable\nas it relates to the policies and standards for your organization. You can also\ncreate a custom tag\n. Tagging can help you micro-filter policy alerts for escalations or as part of other internal review processes. You can filter on any tag value.\nNotify the user\n: Often, users accidentally or inadvertently violate a Communication Compliance policy. Use the notify feature to provide a warning notice to the user and to resolve the issue.\nEscalate to another reviewer\n: Sometimes, the initial reviewer of an issue needs input from other reviewers to help resolve the incident. You can easily escalate message issues to reviewers in other areas of your organization as part of the resolution process.\nReport as misclassified\n: Messages incorrectly detected as matches of compliance policies will occasionally slip through to the review process. Mark these types of alerts as misclassified to submit feedback to Microsoft about the misclassification to help improve global classifiers and automatically resolve the issue.\nRemove message in Teams\n: Potentially inappropriate messages can be removed from displaying in Microsoft Teams channels or personal and group chat messages. Those identified messages that are removed are replaced with a notification that the message has been removed for a policy violation.\nEscalate for investigation\n: In the most serious situations, you might need to share Communication Compliance information with other reviewers in your organization. Communication Compliance is tightly integrated with other Microsoft Purview features to help you with end-to-end risk resolution. Escalating a case for investigation allows you to transfer data and management of the case to Microsoft Purview eDiscovery (Premium). eDiscovery (Premium) provides an end-to-end workflow to preserve, collect, review, analyze, and export content that's responsive to your organization's internal and external investigations. It allows legal teams to manage the entire legal hold notification workflow. To learn more about eDiscovery (Premium) cases, see\nOverview of Microsoft Purview eDiscovery (Premium)\n.\nMaintain\nKeeping track and mitigating compliance issues identified by Communication Compliance policies spans the entire workflow process. As alerts are generated and investigation and remediation actions are implemented, you might need to review and update existing policies or create new policies.\nReview and report\n: Use Communication Compliance dashboard widgets, export logs, and events recorded in the unified audit logs to continually evaluate and improve your compliance posture.\nGet insights on policy health\n: Communication Compliance provides warnings and recommendations to improve policy health.\nLearn more about policy health\nReady to get started?\nFor planning information, see\nPlan for Communication Compliance\n.\nCheck out the\ncase study for Contoso\nand see how they quickly configured a Communication Compliance policy to detect potentially inappropriate content in Microsoft Teams, Exchange Online, and Viva Engage communications.\nTo configure Communication Compliance for your Microsoft 365 organization, see\nConfigure Communication Compliance\n.\nMore resources\nFor the latest Ignite videos about Communication Compliance, see the following resources:\nFoster a culture of safety and inclusion with Communication Compliance\nLearn how to reduce communication risks within your organization\nBetter with Microsoft Teams - Learn more about the latest native Teams integrated features in Communication Compliance\nFor a quick overview of Communication Compliance, see the\nDetect workplace harassment and respond with Communication Compliance\nvideo on the\nMicrosoft Mechanics channel\n.\nSee how\nTD Securities is using Communication Compliance\nto address their regulatory obligations and meet their security and stability needs.\nWatch the\nMicrosoft Mechanics video\non how Insider Risk Management and Communication Compliance work together to help minimize data risks from users in your organization.\nTo keep up with the latest Communication Compliance updates, select\nWhat's new\nin the Communication Compliance solution for your organization.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Communication Compliance",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/communication-compliance-policies": {
      "content_hash": "sha256:39db34c12fb6bb5fbff31a39c9779619766c53347385641c367fbe8216c24392",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and manage Communication Compliance policies\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Communication Compliance\nprovides the tools to help organizations detect regulatory compliance (for example, SEC or FINRA) and business conduct violations such as sensitive or confidential information, harassing or threatening language, and sharing of adult content. Communication Compliance is built with privacy by design. Usernames are pseudonymized by default, role-based access controls are built in, investigators are opted in by an admin, and audit logs are in place to help ensure user-level privacy.\nPolicies\nImportant\nPowerShell isn't supported for creating and managing Communication Compliance policies. To create and manage these policies, use the policy management controls in the Communication Compliance solution.\nCreate Communication Compliance policies for Microsoft 365 organizations in the Microsoft Purview portal. Communication Compliance policies define which communications and users are subject to review in your organization, set custom conditions the communications must meet, and specify who should do reviews. Users assigned the\nCommunication Compliance Admins\nrole can set up policies. Anyone with this role can access the\nCommunication Compliance\npage and global settings in Microsoft Purview. If needed, you can export the history of modifications to a policy to a .csv (comma-separated values) file that also includes the status of alerts pending review, escalated items, and resolved items. You can't rename policies. You can delete policies when no longer needed.\nPolicy templates\nPolicy templates are predefined policy settings that you can use to quickly create policies to address common compliance scenarios. Each of these templates has differences in conditions and scope. All templates use the same types of detection signals. You can choose from the following policy templates:\nArea\nPolicy Template\nDetails\nConflict of interest\nDetect conflict of interest\n- Locations: Exchange Online, Microsoft Teams, Viva Engage\n- Direction: Internal\n- Review Percentage: 100%\n- Conditions: None\nCopilot interactions\nDetect Microsoft 365 Copilot and Microsoft 365 Copilot Chat interactions\n- Location: Microsoft 365 Copilot and Microsoft 365 Copilot Chat\n- Direction: Inbound, Outbound, Internal\n- Review Percentage: 100%\n- Conditions: Prompt Shields, Protected material classifiers\nInappropriate content\nDetect inappropriate content\n- Location: Microsoft Teams, Viva Engage\n- Direction: Inbound, Outbound, Internal\n- Review Percentage: 100%\n- Conditions: Hate, Violence, Sexual, Self-harm classifiers\nInappropriate images\nDetect inappropriate images\n- Locations: Exchange Online, Microsoft Teams\n- Direction: Inbound, Outbound, Internal\n- Review Percentage: 100%\n- Conditions: Adult and Racy image classifiers\nInappropriate text\nDetect inappropriate text\n- Locations: Exchange Online, Microsoft Teams, Viva Engage\n- Direction: Inbound, Outbound, Internal\n- Review Percentage: 100%\n- Conditions: Threat, Discrimination, and Targeted harassment classifiers\nRegulatory compliance\nDetect financial regulatory compliance\n- Locations: Exchange Online, Microsoft Teams, Viva Engage\n- Direction: Inbound, Outbound\n- Review Percentage: 10%\n- Conditions: Customer complaints, Gifts & entertainment, Money laundering, Regulatory collusion, Stock manipulation, and Unauthorized disclosure classifiers\nSensitive information\nDetect sensitive info types\n- Locations: Exchange Online, Microsoft Teams, Viva Engage\n- Direction: Inbound, Outbound, Internal\n- Review Percentage: 10%\n- Conditions: Sensitive information, out-of-the-box content patterns, and types, custom dictionary option, attachments larger than 1 MB\nUser-reported messages policy\nNote\nThe\nUser-reported messages\npolicy is implemented for your organization when you purchase a license that includes Microsoft Purview Communication Compliance. However, it can take up to 30 days for this feature to be available after you purchase the license.\nAs part of a layered defense to detect and remediate inappropriate messages in your organization, you can supplement Communication Compliance policies with user-reported messages in Microsoft Teams and Viva Engage (preview). To help foster a safe and compliant work environment, this feature empowers users in your organization to self-report inappropriate internal Teams chat messages and Viva Engage conversations, such as harassing or threatening language, sharing of adult content, and sharing of sensitive or confidential information.\nMicrosoft Teams\nEnabled by default in the\nTeams admin center\n, the\nReport inappropriate content\noption in Teams messages lets users in your organization submit inappropriate internal personal and group chat messages for review by Communication Compliance reviewers for the policy. A default system policy supports these messages and supports reporting messages in Teams group and private chats.\nAzure AI Content Safety's hate, self-harm, sexual, and violence classifiers evaluate user-reported messages. This evaluation helps Communication Compliance Investigators understand any potential risk in user-reported content more quickly so they can take confident action to mitigate risk.\nWhen a user submits a Teams chat message for review, the message is copied to the User-reported message policy. Reported messages initially remain visible to all chat members and there's no notification to chat members or the submitter that a message has been reported in channel, private, or group chats. A user can't report the same message more than once and the message remains visible to all users included in the chat session during the policy review process.\nDuring the review process, Communication Compliance reviewers can perform all the standard\nremediation actions\non the message, including removing the message from the Teams chat. Depending on how the messages are remediated, the message sender and recipients see different notification messages in Teams chats after the review. Any user-reported content that triggers the Content Safety classifiers shows the classifier name that flagged the message and a corresponding severity value is visible in the\nSeverity\ncolumn.\nImportant\nIf a user reports a message that was sent before they were added to a chat, Teams message remediation isn't supported; the Teams message can't be removed from the chat.\nUser-reported messages from Teams chats are the only messages processed by the User-reported message policy and you can only modify the assigned reviewers for the policy. You can't edit all other policy properties. When you create the policy, all members of the\nCommunication Compliance Admins\nrole group (if populated with at least one user) or all members of your organization's\nGlobal Admin\nrole group are assigned as initial reviewers. A randomly selected user from the\nCommunication Compliance Admins\nrole group (if populated with at least one user) or a randomly selected user from your organization's\nGlobal Admin\nrole group is the policy creator.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nAdmins should immediately assign custom reviewers to this policy as appropriate for your organization. This assignment might include reviewers such as your Compliance Officer, Risk Officer, or members of your Human Resources department.\nCustomize the reviewers for chat messages submitted as user-reported messages\nSign in to the\nMicrosoft Purview portal\nusing credentials for an admin account in your Microsoft 365 organization.\nGo to the\nCommunication Compliance\nsolution.\nSelect\nPolicies\nin the left navigation.\nSelect the\nUser-reported messages\npolicy, then select\nEdit\n.\nOn the\nDetect user-reported messages\npane, assign reviewers for the policy. Reviewers must have mailboxes hosted on Exchange Online. When you add reviewers to a policy, they automatically receive an email message that notifies them of the assignment to the policy and provides links to information about the review process.\nSelect\nSave\n.\nThe\nReport inappropriate content\noption is enabled by default and you can control it via Teams messaging policies in the\nTeams Admin Center\n. Users in your organization automatically receive the global policy, unless you create and assign a custom policy. Edit the settings in the global policy or create and assign one or more custom policies to turn on or turn off the\nReport inappropriate content\noption. For more information, see\nManage messaging policies in Teams\n.\nImportant\nIf you use PowerShell to turn on or turn off the\nEnd user reporting\noption in the Teams Admin Center, use\nMicrosoft Teams cmdlets module version 4.2.0\nor later.\nViva Engage\nThe\nReport Conversations\noption is off by default in the Viva Engage admin center. When you turn on this option, you see different options depending on whether you have a license that includes Communication Compliance:\nLicenses that don't include Communication Compliance\n. If you don't have a license that includes Communication Compliance, when you turn on the option, the Viva Engage admin can specify an email address to receive reported conversations. The admin can also enter pre-submission instructions and post-submission confirmations for the user.\nLearn more about enabling the\nReport Conversations\noption if you don't have a license that includes Communication Compliance\nLicenses that do include Communication Compliance\n. If you have a license that includes Communication Compliance, when you turn on the option, any reported conversations automatically route through Communication Compliance for investigation.\nHow upgrades and downgrades in licensing affect the reported conversations workflow\nIf you upgrade from a license that doesn't include Communication Compliance to a license that includes Communication Compliance and turn on the\nReport Conversations\noption, reported conversations automatically route to Communication Compliance. The Viva Engage admin can continue to access earlier reported conversations and can view new reported conversations\nif they're added as an investigator in Communication Compliance\n.\nIf you downgrade from a license that includes Communication Compliance to a license that doesn't include Communication Compliance and turn on the\nReport Conversations\noption, the workflow reverts to the process described in this article for customers that don't have a Communication Compliance license. To continue to use the feature, an admin must turn on the\nReport Conversations\noption in the Viva Engage admin center again and specify an email address to send reported conversations to.\nUser experience for customers that have a license that includes Communication Compliance\nIf you choose to route user-reported conversations through Communication Compliance, you can create pre-submission instructions for the user.\nTo report a conversation in Viva Engage, the user selects the ellipsis (three dots), then selects\nReport conversation\n.\nNote\nThe command name changes to\nReport comment\n,\nReport question\n, or\nReport answer\ndepending on where the user is in Viva Engage or Answers in Viva.\nIf the user submits the report successfully, they see a confirmation message.\nWhen a conversation is reported, the conversation is copied to the Communication Compliance User-reported message policy. The Communication Compliance investigator can review reported conversations in the User Reported policy inbox and can do all the standard\nremediation actions\nfor the conversation.\nTurn on the Report Conversation feature in the Viva Engage admin center\nGo to the Viva Engage admin center.\nOn the\nSettings\npage, select\nReport Conversations\n.\nTurn on the setting.\nUnder\nReport recipient\n, add an email address to route reports to. This email address is used to notify the admin in case there's any problem with the configuration.\nIn the\nPre-submission details or instructions for users\nbox, enter any instructions you want to display for the user.\nIn the\nPost-submission instructions to user\nbox, enter any instructions (optional) that the user will see after reporting a conversation.\nIntegrate Communication Compliance with Microsoft Purview Insider Risk Management\nWhen users experience employment stressors, they might engage in risky activities. Workplace stress can lead to uncharacteristic or malicious behavior by some users that surfaces as potentially inappropriate behavior on your organization's messaging systems. Counterproductive work behavior can be a precursor to more serious violations, such as sabotaging company assets or leaking sensitive information. By integrating Communication Compliance with\nMicrosoft Purview Insider Risk Management\n, you can detect stressors that indicate an unhealthy workplace environment.\nYou can integrate Communication Compliance with Insider Risk Management by automatically creating a Communication Compliance policy from Insider Risk Management. You can create this type of policy in two different ways:\nBy creating an Insider Risk Management trigger for policy templates\nBy selecting Insider Risk Management policy indicators for data-based policy templates\nBy selecting generative AI policy indicators for policy templates\nCreate an Insider Risk Management trigger for policy templates\nCommunication Compliance can provide risk signals detected in applicable messages to Insider Risk Management risky user policies by using a dedicated\nDetect inappropriate text\npolicy. This policy is automatically created if you select it as an option when creating a policy by using the\nData leaks by risky users template\nor the\nSecurity policy violations by risky users template\nin Insider Risk Management. For example, the following screenshot shows the option selected in the\nData leaks by risky users\ntemplate.\nWhen configured for an Insider Risk Management policy, Communication Compliance creates a dedicated policy named\nInsider risk trigger - (date created)\nand automatically includes all organization users in the policy. This policy starts detecting risky behavior in messages by using the Microsoft provided\nThreat, Harassment, and Discrimination trainable classifiers\nand automatically sends these signals to Insider Risk Management. If needed, you can edit this policy to update the scope of included users and the policy conditions and classifiers.\nUsers who send five or more messages classified as potentially risky within 24 hours are automatically brought in-scope for Insider Risk Management policies that include this option. Once in-scope, the Insider Risk Management policy detects potentially risky activities configured in the policy and generates alerts as applicable. It can take up to 48 hours from the time risky messages are sent until the time a user is brought in-scope in an Insider Risk Management policy. If an alert is generated for a potentially risky activity detected by the Insider Risk Management policy, the triggering event for the alert is identified as being sourced from the Communication Compliance risky activity.\nAll users assigned to the\nInsider Risk Management Investigators\nrole group are automatically assigned as reviewers in the dedicated Communication Compliance policy. If Insider Risk Management investigators need to review the associated risky user alert directly on the Communication Compliance alerts page (linked from the Insider Risk Management alert details), you must manually add them to the\nCommunication Compliance Investigators\nrole group.\nBefore integrating Communication Compliance with Insider Risk Management, consider the following guidance when detecting messages containing potentially inappropriate text:\nFor organizations without an existing\nDetect inappropriate text\npolicy\n. The Insider Risk Management policy workflow automatically creates the new\nRisky user in messages - (date created)\npolicy. In most cases, you don't need to take any further action.\nFor organizations with an existing\nDetect inappropriate text\npolicy\n. The Insider Risk Management policy workflow automatically creates the new\nRisky user in messages - (date created)\npolicy. Although you have two Communication Compliance policies for potentially inappropriate text in messages, investigators don't see duplicate alerts for the same activity. Insider Risk Management investigators only see alerts for the dedicated integration policy and Communication Compliance investigators only see the alerts for the existing policy. If needed, you can edit the dedicated policy to change the included users or individual policy conditions as applicable.\nSelect Insider Risk Management policy indicators for data-based policy templates\nThe\nPolicy indicators\nsetting in Insider Risk Management provides Communication Compliance indicators to choose from when using the\nData theft\n,\nData leaks\n,\nData leaks by risky users\n, and\nData leaks by priority users\ntemplates:\nSending financial regulatory text that might be risky\nSending inappropriate images\nSending inappropriate content\nSending messages that contain specific sensitive info types\nFor more information on creating a Communication Compliance policy this way, see\nInsider Risk Management policy indicators settings\n.\nSelecting generative AI policy indicators for policy templates\nThe\nPolicy indicators\nsetting in Insider Risk Management provides generative AI app indicators to choose from when using the\nData leaks\n,\nData leaks by risky users\n,\nData leaks by priority users\n, or\nRisky AI usage\npolicy templates. These Azure AI Content Safety indicators help detect when prompts and responses in AI apps match the following classifiers:\nPrompt Shields\nProtected material detection\nFor more information on creating a Communication Compliance policy this way, see\nInsider Risk Management policy indicators settings\n. For more information on Azure AI Content Security, see\nAzure AI Content Security\n.\nPolicy health (preview)\nThe policy health status gives you insights into potential issues or optimizations for your Communication Compliance policies. At the top of the\nPolicies\npage, you see a summary that lists the total number of policy warnings and recommendations, and the total number of healthy policies. If a specific policy has a warning or recommendations, the\nPolicy health\ncolumn lists a link to the warning or recommendations. When you select the link, a details pane opens on the right side of the screen with the\nPolicy Health\ntab selected, which makes it easy to quickly review the warning or recommendation and take action on it.\nThe\nPolicy Health\ntab has two parts. The upper part of the tab shows general information about the policy, including whether the policy is active, whether it's updated, and general tips. The lower part of the tab shows the specific warning or recommendations. If you're a member of the\nCommunication Compliance\nor\nCommunication Compliance Admins\ngroup, you can take action directly from the warning or recommendation. If you're a member of the\nCommunication Compliance Analysts\nor\nCommunication Compliance Investigators\ngroup, you can see the warning or recommendation so you can prompt your admin to take action.\nWarnings\n: If you don't take action on a warning, the policy stops working. For the policy health preview, there's one warning, related to a policy's\nstorage limit size\n.\nRecommendations\n: Recommendations provide suggestions for optimizing policies. If you ignore a policy recommendation, the policy continues to work. If you're a member of the\nCommunication Compliance\nor\nCommunication Compliance Admins\ngroup, you can act on a recommendation as long as the policy is active and if it's not updating. If you're a member of the\nCommunication Compliance Analysts\nor\nCommunication Compliance Investigators\ngroup, you can see the recommendation and prompt your admin to take action. For the preview, there are two recommendations:\nPotentially reduce false positives by filtering out bulk emails\n: This recommendation prompts you to turn on the\nFilter email blasts setting\n. This setting helps reduce false positives by excluding bulk emails, such as newsletters, and spam, phishing, and malware, from getting flagged by Communication Compliance policies if the policy conditions are matched.\nReduce user scoping blind spots\n: This recommendation prompts you to\nreduce blind spots\nby turning on the\nShow insights and recommendations for users who match this policy's conditions but weren't included in the policy\ncheckbox (used with the\nSelected users\npolicy option).\nHealthy policies\n: If there are no warnings or recommendations for a specific policy, the policy is considered healthy.\nReduce user scoping blind spots\nYou can reduce user-scoping related blind spots by turning on the\nShow insights and recommendations for users who match this policy's conditions but weren't included in the policy\ncheckbox. When you turn on this checkbox, you see insights and recommendations for users who are sending messages that match the policy condition but aren't included in the scope of the policy. In this case, Communication Compliance recommends that you include those users in the scope of the policy so that you can review the messages sent by those users and take actions. You can select the specific users that you want to add or you can extend the policy to all users.\nInsights for these users are aggregated; you can't see the messages sent by them until you add them to the scope of the policy.\nIf an admin doesn't act on a recommendation, the recommendation continues to recur. To turn off recommendations for users outside the scope of the policy, turn off the checkbox.\nPause a policy\nAfter you create a Communication Compliance policy, you can temporarily pause the policy. Use pausing for testing or troubleshooting policy matches, or for optimizing policy conditions. Instead of deleting a policy in these circumstances, pausing a policy also preserves existing policy alerts and messages for ongoing investigations and reviews. Pausing a policy prevents inspection and alert generation for all user message conditions defined in the policy for the time the policy is paused. To pause or restart a policy, you must be a member of the\nCommunication Compliance Admins\nrole group.\nTo pause a policy, go to the\nPolicy\npage, select a policy, then select\nPause policy\nfrom the actions toolbar. On the\nPause policy\npane, confirm you'd like to pause the policy by selecting\nPause\n. In some cases, it can take up to 24 hours for a policy to be paused. Once the policy is paused, the system doesn't create alerts for messages matching the policy. However, messages associated with alerts that you created before pausing the policy remain available for investigation, review, and remediation.\nThe policy status for paused policies can show several states:\nActive\n: The policy is active.\nPaused\n: The policy is fully paused.\nPausing\n: The policy is in the process of being paused.\nResuming\n: The policy in the process of being resumed.\nError in resuming\n: An error was encountered when resuming the policy. For the error stack trace, hover your mouse over the\nError in resuming\nstatus in the Status column on the Policy page.\nError in pausing\n: An error was encountered when pausing the policy. For the error stack trace, hover your mouse over the\nError in pausing\nstatus in the Status column on the Policy page.\nTo resume a policy, go to the\nPolicy\npage, select a policy, then select\nResume policy\nfrom the actions toolbar. On the\nResume policy\npane, confirm you'd like to resume the policy by selecting\nResume\n. In some cases, it can take up to 24 hours for a policy to be resumed. Once the policy is resumed, the system creates alerts for messages matching the policy and makes them available for investigation, review, and remediation.\nCopy a policy\nIf your organization has existing Communication Compliance policies, you might find it helpful to create a new policy from an existing policy. When you copy a policy, you create an exact duplicate of an existing policy, including all included users, all assigned reviewers, and all policy conditions. Some scenarios where copying a policy is helpful include:\nPolicy storage limit reached\n: Active Communication Compliance policies have message storage limits. When the storage limit for a policy is reached, the policy is automatically deactivated. If your organization needs to continue detecting, capturing, and acting on inappropriate messages covered by the deactivated policy, you can quickly create a new policy with an identical configuration.\nDetect and review inappropriate messages for different groups of users\n: Some organizations prefer to create multiple policies with the same configuration but include different groups of users and different reviewers for each policy.\nSimilar policies with small changes\n: For policies with complex configurations or conditions, it might save time to create a new policy from a similar policy.\nTo copy a policy, you must be a member of the\nCommunication Compliance\nor\nCommunication Compliance Admins\nrole groups. After you create a new policy from an existing policy, it can take up to 24 hours to view messages that match the new policy configuration.\nTo copy a policy and create a new policy, complete the following steps:\nSelect the policy you want to copy.\nSelect\nCopy policy\non the command bar or select\nCopy policy\nfrom the action menu for the policy.\nIn the\nCopy policy\npane, accept the default name for the policy in the\nPolicy name\nfield or rename the policy. The policy name for the new policy can't be the same as an existing active or deactivated policy. Complete the\nDescription\nfield as needed.\nIf you don't need further customization of the policy, select\nCopy policy\nto complete the process. If you need to update the configuration of the new policy, select\nCustomize policy\n. This selection starts the policy workflow to help you update and customize the new policy.\nMark a policy as a favorite\nAfter you create a Communication Compliance policy, you can mark the policy as a favorite. When you mark a policy as a favorite, you can filter favorite policies to appear at the top of the policies list. By marking a policy as a favorite, you can also easily sort policies by favorites.\nTo mark a policy as a favorite, you have the following options:\nMark as favorite\n: Enables you to mark selected policies as favorites, so you can easily find the policies that you're most interested in rather than having to search for them.\nSort favorites\n: Sorts the policies by favorites, so your favorite policies appear at the top of the list.\nCustomize columns\n: Choose to list the favorites that you want to see. You can also choose to sort favorite policies in ascending or descending order.\nTo sort policies by groups:\nAll policies\n: This is the default view, displaying all the policies in the list.\nOnly favorites\n: Groups policies by favorites at the top of the list.\nPolicy activity detection\nCommunications are scanned every hour from the time you create a policy. For example, if you create an inappropriate content policy at 11:00 AM, the policy gathers Communication Compliance signals every hour starting from when you created the policy. Editing a policy doesn't change this time. To view the last scan date and Coordinated Universal Time (UTC) for a policy, go to the\nLast policy scan\ncolumn on the\nPolicy\npage. After creating a new policy, you might need to wait up to an hour to view the first policy scan date and time.\nThe following table outlines the time to detection for supported content types:\nContent type\nTime to detection\nEmail attachment\n24 hours\nEmail body content\n1 hour\nEmail metadata\n1 hour\nEmail OCR\n24 hours\nMicrosoft 365 Copilot and Microsoft 365 Copilot Chat body content (prompts and responses)\n1 hour\nTeam attachment\n24 hours\nTeams body content\n1 hour\nTeams metadata\n1 hour\nTeams modern attachment\n24 hours\nTeams OCR\n24 hours\nTeams shared channels\n24 hours\nTeams transcripts\n1 hour\nViva Engage attachment\nUp to 24 hours\nViva Engage body content\n1 hour\nFor existing policies created before July 31, 2022, it might take up to 24 hours to detect messages and review alerts that match these policies. To reduce the latency for these policies,\ncopy the existing policy\nand create a new policy from the copy. If you don't need to retain any data from the older policy, you can pause or delete it.\nTo identify an older policy, review\nLast policy scan\ncolumn on the\nPolicy\npage. Older policies display a full date for the scan while policies created after July 31, 2022 display\n1 hour ago\nfor the scan. To reduce latency, you can also wait until February 28, 2023 for your existing policies to be automatically migrated to the new detection criteria.\nStorage limit notification\nEach Communication Compliance policy has a storage limit size of 100 GB or 1 million messages, whichever limit you reach first. As the policy approaches these limits, the system automatically sends notification emails to users assigned to the\nCommunication Compliance\nor\nCommunication Compliance Admins\nrole groups. The system sends notification messages when the storage size or message count reaches 80, 90, and 95 percent of the limit. When the policy limit is reached, the system automatically deactivates the policy, and the policy stops processing messages for alerts.\nImportant\nIf the system deactivates a policy because it reached the storage and message limits, evaluate how to manage the deactivated policy. If you delete the policy, you permanently delete all messages, associated attachments, and message alerts. If you need to maintain these items for future use, don't delete the deactivated policy.\nTo manage policies that approach the storage and message limits, consider making a copy of the policy to maintain coverage continuity or take the following actions to help minimize current policy storage size and message counts:\nReduce the number of users assigned to the policy. Removing users from the policy or creating different policies for different groups of users can help slow the growth of policy size and total messages.\nExamine the policy for excessive false positive alerts. Add exceptions or make changes to the policy conditions to ignore common false positive alerts.\nMake a copy of the policy if a policy reaches the storage or message limits and deactivates it to continue detecting and taking action for the same conditions and users.\nPolicy settings\nUsers\nYou can select\nAll users\n, define specific users in a Communication Compliance policy, or select an adaptive scope.\nAll users\n: When you select\nAll users\n, you apply the policy to all users and all groups that any user is included in as a member.\nSelect users\n: When you define specific users, you apply the policy to the defined users and any groups the defined users are included in as a member. If you choose the\nSelected users\noption, the\nShow insights and recommendations for users who match this policy's conditions but weren't included in the policy\ncheckbox automatically appears. Leave this checkbox selected if you want to\nreceive recommendations when users outside of the selected users match the policy conditions\n. This setting isn't available if you choose the\nAll users\noption or the\nSelect adaptive scopes\noption.\nSelect adaptive scope\n: An adaptive scope uses a query that you specify to define the membership of users or groups. If you decide to create an adaptive policy, you must\ncreate one or more adaptive scopes\nbefore you create your policy, and then select them when you choose this option. The scopes that you can select depend on the scope types that you add. For example, if you only added a scope type of\nUser\n, you can select\nGroups\n.\nLearn more about the advantages of using an adaptive scope\n.\nDirection\nBy default, the\nDirection is\ncondition appears and you can't remove it. Choose communication direction settings in a policy individually or together:\nInbound\n: Detects communications sent\nto\nscoped users from external and internal senders, including other scoped users in the policy.\nOutbound\n: Detects communications sent\nfrom\nscoped users to external and internal recipients, including other scoped users in the policy.\nInternal\n: Detects communications\nbetween\nthe scoped users or groups in the policy.\nSensitive information types\nYou can include sensitive information types as part of your Communication Compliance policy. Sensitive information types are either predefined or custom data types that help identify and protect credit card numbers, bank account numbers, passport numbers, and more. As part of\nLearn about Microsoft Purview Data Loss Prevention\n, the sensitive information configuration can use patterns, character proximity, confidence levels, and even custom data types to help identify and flag content that might be sensitive. The default sensitive information types are:\nFinancial\nMedical and health\nPrivacy\nCustom information type\nImportant\nSensitive info types have two different ways of defining the max unique instance count parameters. To learn more, see\nCreate custom sensitive information types\n.\nThe Communication Compliance solution supports default sensitive information types and bundled named-entity sensitive information types, which are collections of sensitive information types. For more information about sensitive information details and the patterns included in the default types, see\nSensitive information type entity definitions\n. For information on supported bundled named-entity sensitive information types, see the following articles:\nAll credentials\nAll full names\nAll medical terms and conditions\nAll Physical Addresses\nFor more information about sensitive information details and the patterns included in the default types, see\nSensitive information type entity definitions\n.\nCustom keyword dictionaries\nConfigure custom keyword dictionaries (or lexicons) to easily manage keywords specific to your organization or industry. Keyword dictionaries support up to 100 KB of terms (post-compression) in the dictionary and support any language. The tenant limit is also 100 KB after compression. If needed, you can apply multiple custom keyword dictionaries to a single policy or have a single keyword dictionary per policy. You can source these dictionaries from a file, such as a .CSV or .TXT list, or from\na list you can Import\n. Use custom dictionaries when you need to support terms or languages specific to your organization and policies.\nMicrosoft provided trainable classifiers\nCommunication Compliance policies that use Microsoft provided trainable classifiers inspect and evaluate messages that meet a\nminimum word count requirement\n, depending on the language of the content. Custom trainable classifiers aren't supported. For a complete list of supported languages, word count requirements, and file types for Microsoft provided trainable classifiers, see\nTrainable classifier definitions\n.\nTo identify and take action on messages containing inappropriate language content that doesn't meet the word count requirement, create a\nsensitive information type\nor\ncustom keyword dictionary\nfor Communication Compliance policies detecting this type of content.\nMicrosoft provided trainable classifier\nDescription\nCorporate sabotage\nDetects messages that might mention acts to damage or destroy corporate assets or property. This classifier can help you manage regulatory compliance obligations such as NERC Critical Infrastructure Protection standards or state by state regulations like Chapter 9.05 RCW in Washington state.\nCustomer complaints\nDetects messages that might suggest customer complaints made on your organization's products or services, as required by law for regulated industries. This classifier can help you manage regulatory compliance obligations such as FINRA Rule 4530, FINRA 4513, FINRA 2111, Consumer Financial Protection Bureau, Code of Federal Regulations Title 21: Food and Drugs, and the Federal Trade Commission Act.\nDiscrimination\nDetects potentially explicit discriminatory language and is particularly sensitive to discriminatory language against the African American/Black communities when compared to other communities.\nGifts & entertainment\nDetects messages that might suggest exchanging gifts or entertainment in return for service, which violates regulations related to bribery. This classifier can help you manage regulatory compliance obligations such as Foreign Corrupt Practices Act (FCPA), UK Bribery Act, and FINRA Rule 2320.\nHarassment\nDetects potentially offensive content in multiple languages that targets people regarding race, color, religion, national origin.\nMoney laundering\nDetects signs that might suggest money laundering or engagement in acts to conceal or disguise the origin or destination of proceeds. This classifier can help you manage regulatory compliance obligations such as the Bank Secrecy Act, the USA Patriot Act, FINRA Rule 3310, and the Anti-Money Laundering Act of 2020.\nProfanity\nDetects potentially profane content in multiple languages that would likely offend most people.\nRegulatory collusion\nDetects messages that might violate regulatory anti-collusion requirements such as an attempted concealment of sensitive information. This classifier can help you manage regulatory compliance obligations such as the Sherman Antitrust Act, Securities Exchange Act 1933, Securities Exchange Act of 1934, Investment Advisers Act of 1940, Federal Commission Act, and the Robinson-Patman Act.\nStock manipulation\nDetects signs of possible stock manipulation, such as recommendations to buy, sell, or hold stocks that might suggest an attempt to manipulate the stock price. This classifier can help you manage regulatory compliance obligations such as the Securities Exchange Act of 1934, FINRA Rule 2372, and FINRA Rule 5270.\nThreat\nDetects potential threatening content in multiple languages aimed at committing violence or physical harm to a person or property.\nUnauthorized disclosure\nDetects sharing of information containing content that is explicitly designated as confidential or internal to unauthorized individuals. This classifier can help you manage regulatory compliance obligations such as FINRA Rule 2010 and SEC Rule 10b-5.\nImportant\nMicrosoft provided trainable classifiers might detect a large volume of bulk sender/newsletter content due to a known issue. You can mitigate the detection of large volumes of bulk sender/newsletter content by selecting the\nFilter email blasts\ncheck box\nwhen you create the policy. You can also edit an existing policy to turn on this feature.\nContent safety classifiers based on large language models\nCommunication Compliance includes a set of Azure AI classifiers for Microsoft 365 Copilot, Teams, and Viva Engage communications. These classifiers run on large language models (LLMs) and are highly accurate. They evaluate messages containing three or more words. If the evaluated severity is 4 or higher, the solution displays the message as an alert and adds a\nSeverity\ncolumn to the\nAlerts\ndashboard to make it easier to prioritize alerts. Investigators can sort and filter on the\nSeverity\ncolumn.\nNote\nThe\nSeverity\ncolumn only appears if the policy match comes from one of the classifiers listed in the following table. For all other classifiers, the column is empty.\nThe following table describes the classifiers:\nClassifier\nDescription\nHate\nHate\nrefers to any content that attacks or uses pejorative or discriminatory language with reference to a person or identity group based on certain differentiating attributes of these groups, including but not limited to race, ethnicity, nationality, gender identity and expression, sexual orientation, religion, immigration status, ability status, personal appearance, and body size.\nSexual\nSexual\ndescribes language related to anatomical organs and genitals, romantic relationships, acts portrayed in erotic or affectionate terms, pregnancy, physical sexual acts, including those portrayed as an assault or a forced sexual violent act against oneâs will, prostitution, pornography, and abuse.\nViolence\nViolence\ndescribes language related to physical actions intended to hurt, injure, damage, or kill someone or something; describes weapons, guns and related entities, such as manufactures, associations, legislation, and so on.\nSelf-harm\nSelf-harm\ndescribes language related to physical actions intended to purposely hurt, injure, damage oneâs body, or kill oneself.\nLearn more about Azure AI Content Safety\nConsiderations when using classifiers\nOnly Microsoft 365 Copilot, Teams, and Viva Engage workloads are supported.\nThe solution evaluates only messages containing five or more words. It doesn't evaluate attachments and OCR images.\nThe solution doesn't evaluate Teams meeting transcripts.\nFeedback loop isn't yet supported to submit misclassified items to Microsoft.\nThe solution supports up to 10,000 characters per message.\nLearn about supported languages\nDetect risky generative AI interactions\nCommunication Compliance detects harmful user-generated and AI-generated content in applications and services. This detection includes evaluation of user prompts submitted to generative AI services and the inclusion of known text content that might be sensitive to your organization.\nThe following table describes the classifiers.\nClassifier\nDescription\nPrompt Shield\nDetects adversarial user input attacks such as user prompt injection attacks (jailbreak). User prompt injection attacks deliberately exploit system vulnerabilities to elicit unauthorized behavior from the large language model.\nProtected material\nDetects known text content that might be protected under copyright or branding laws. Detecting the display of protected material in generative AI responses ensures compliance with intellectual property laws and maintains content originality.\nFor more information, see\nLearn more about Azure AI Content Safety\n.\nOptical character recognition (OCR)\nNote\nMicrosoft Purview includes\nOCR (preview) settings\nfor Microsoft Purview Insider Risk Management, Microsoft Purview Data Loss Prevention, Microsoft Purview Data Loss Management, and auto-labeling. Use the OCR (preview) settings to provide image-scanning capabilities for those solutions and technologies. Communication Compliance has its own built-in OCR scanning functionality as described in this section and doesn't support the OCR (preview) settings at this time.\nYou can configure built-in or custom Communication Compliance policies to scan and identify printed or handwritten text from images that might be inappropriate in your organization. Integrated\nAzure Cognitive Services and optical scanning support\nfor identifying text in images help analysts and investigators detect and act on instances where inappropriate conduct might be missed in communications that is primarily nontextual.\nYou can enable optical character recognition (OCR) in new policies from templates, custom policies, or update existing policies to expand support for processing embedded images and attachments. When you enable OCR in a policy created from a policy template, the solution automatically scans embedded or attached images in email and Microsoft Teams chat messages. For images embedded in document files, OCR scanning isn't supported. For custom policies, configure one or more conditional settings associated with keywords, Microsoft provided trainable classifiers, or sensitive info types in the policy to enable the selection of OCR scanning.\nThe solution scans and processes images from 100 KB to 4 MB in the following image formats:\n.jpg/.jpeg (joint photographic experts group)\n.png (portable network graphics)\n.bmp (bitmap)\n.tiff (tag image file format)\nWhen you review pending policy matches for policies with OCR enabled, you see images identified and matched to policy conditions as child items for associated alerts. You can view the original image to evaluate the identified text in context with the original message. It might take up to 48 hours for detected images to be available with alerts.\nChoose conditions for your policies\nThe conditions you choose for a policy apply to communications from both email and third-party sources in your organization (Instant Bloomberg, for example).\nAt this time, the condition names that you choose depend on whether you're creating a new policy or an existing policy:\nFor\nnew policies\n, we recommend using the condition builder. The condition builder supports the\nOR\noperator, which enables you to combine multiple conditions in the same policy to create compound conditions with AND, OR, and NOT operators. This support helps you address complex scenarios for your unique compliance requirements. If you create a new policy with a template, Communication Compliance automatically uses the condition builder.\nLearn more about the condition builder\n.\nNote\nAll exceptions in the condition builder are replaced with a NOT condition. You must include the NOT condition within a nested group.\nFor\nexisting policies\n, use the condition names listed in the first column in the following table.\nTip\nTo save time, you can\ntest certain conditions before creating your policy\n.\nCondition names for existing and new policies\nThe following table lists condition names to use for existing policies vs. new policies (using the condition builder). It also lists how to use each condition.\nCondition name for existing policies\nCondition name for new policies\nHow to use this condition\nAttachment contains any of these words\nAttachment contains none of these words\nAttachment contains words or phrases\nTo apply the policy when certain words or phrases are included or excluded in a message attachment (such as a Word document).\nMake sure to use the following syntax when entering conditional text:\n- Remove all leading and trailing spaces.\n- Add quotation marks before and after each keyword or key phrase.\n- Separate each keyword or key phrase with a comma.\n- Don't include spaces between items separated by a comma.\nExample:\n\"banker\",\"insider trading\",\"confidential 123\"\nEach word or phrase you enter is applied separately (only one word must apply for the policy to apply to the attachment). For more information about entering words or phrases, see the next section\nMatching words and phrases to emails or attachments\n.\nAttachment is any of these file types\nAttachment is none of these file types\nAttachment file extension is\nTo bring communications into scope that include or exclude specific types of attachments, enter the file extensions (such as .exe or .pdf). If you want to include or exclude multiple file extensions, enter file types separated by a comma (example\n.exe,.pdf,.zip\n). Don't include spaces between items separated by a comma. Only one attachment extension must match for the policy to apply.\nAttachment is larger than\nAttachment is not larger than\nAttachment size equals or is larger than\nTo review messages based on the size of their attachments, specify the maximum or minimum size an attachment can be before the message and its attachments are subject to review. For example, for an existing policy, if you specify\nAttachment is larger than\n>\n2.0 MB\n, all messages with attachments 2.01 MB and over are subject to review. You can choose bytes, kilobytes, megabytes, or gigabytes for this condition.\nContent contains any of these sensitive info types\nContent contains sensitive info types\nApply to the policy when any sensitive information types are included or excluded in a message. Each sensitive information type you choose is applied separately and only one of these sensitive information types must apply for the policy to apply to the message. For more information about custom sensitive information types, see\nLearn about sensitive information types\n.\nContent matches any of these classifiers\nContent matches trainable classifiers\nApply to the policy when any trainable classifiers are included or excluded in a message. Some classifiers are predefined in your organization, and custom classifiers must be configured separately before they're available for this condition. For existing policies, only one trainable classifier can be defined as a condition in a policy. If you're using the condition builder for a new policy, you're not limited to a single trainable classifier. For more information about configuring trainable classifiers, see\nLearn about trainable classifiers\n.\nMessage contains any of these words\nMessage contains none of these words\nMessage contains words or phrases\nTo apply the policy when certain words or phrases are included or excluded in a message.\nMake sure to use the following syntax when entering conditional text:\n- Remove all leading and trailing spaces.\n- Add quotation marks before and after each keyword or key phrase.\n- Separate each keyword or key phrase with a comma.\n- Don't include spaces between items separated by a comma.\nExample:\n\"banker\",\"insider trading\",\"confidential 123\"\nEach word or phrase you enter is applied separately (only one word must apply for the policy to apply to the message). For more information about entering words and phrases, see the next section\nMatching words and phrases to emails or attachments\n.\nMessage is classified with any of these labels\nMessage is not classified with any of these labels\nMessage has retention labels applied\nTo apply the policy when certain retention labels are included or excluded in a message. Retention labels must be configured separately and configured labels are chosen as part of this condition. Each label you choose is applied separately (only one of these labels must apply for the policy to apply to the message). For more information about retention labels, see\nLearn about retention policies and retention labels\n.\nMessage is received from any of these domains\nMessage is not received from any of these domains\nSender domain is\nApply the policy to include or exclude specific domains in received messages.\nMake sure to use the following syntax when entering conditional text:\n-Enter each domain and separate multiple domains with a comma.\n-Don't include spaces between items separated by a comma.\n-Remove all leading and trailing spaces.\nEach domain entered is applied separately, only one domain must apply for the policy to apply to the message. If you want to use\nMessage is received from any of these domains\nto look for messages from specific domains, you need to combine this with another condition like\nMessage contains any of these words\n, or\nContent matches any of these classifiers\n, or you might get unexpected results.\nFor existing policies, if you want to scan all emails but want to exclude messages from a specific domain that don't need review (newsletters, announcements, and so on), you must configure a\nMessage is not received from any of these domains\ncondition that excludes the domain (example 'contoso.com,wingtiptoys.com').\nMessage is received from any of these external email addresses\nMessage is not received from any of these external email addresses\nSender is\nApply the policy to include or exclude messages received or not received from specific external email addresses (example someone@outlook.com).\nUse this condition to detect only messages that come from outside the organization (messages that cross the firewall).\nMake sure to use the following syntax when entering email addresses:\n- Enter each email address and separate multiple email addresses with a comma.\n- Don't include spaces between email addresses separated by a comma.\n- Remove all leading and trailing spaces.\n- Remove any single quote or double quotes\nMessage is sent to any of these domains\nMessage is not sent to any of these domains\nRecipient domain is\nApply the policy to include or exclude specific domains in sent messages.\nMake sure to use the following syntax when entering conditional text:\n-Enter each domain and separate multiple domains with a comma.\n-Don't include spaces between items separated by a comma.\n-Remove all leading and trailing spaces.\nEach domain is applied separately; only one domain must apply for the policy to apply to the message.\nFor existing policies, if you want to exclude all emails sent to two specific domains, configure the\nMessage is not sent to any of these domains\ncondition with the two domains (example 'contoso.com,wingtiptoys.com').\nMessage is sent to any of these external email addresses\nMessage is not sent to any of these external email addresses\nRecipient is\nApply the policy to include or exclude messages sent or not sent to specific external email addresses (example someone@outlook.com).\nUse this condition to detect only messages that are sent outside the organization (messages that cross the firewall).\nMake sure to use the following syntax when entering email addresses:\n- Enter each email address and separate multiple email addresses with a comma.\n- Don't include spaces between email addresses separated by a comma.\n- Remove all leading and trailing spaces.\n- Remove any single quote or double quotes\nMessage size is larger than\nMessage size is not larger than\nMessage size equals or is larger than\nTo review messages based on a certain size, use these conditions to specify the maximum or minimum size a message can be before it's subject to review. For example, for an existing policy, if you specify\nMessage size is larger than\n>\n1.0 MB\n, all messages that are 1.01 MB and larger are subject to review. You can choose bytes, kilobytes, megabytes, or gigabytes for this condition.\nImportant\nIf a condition includes a list, don't include spaces between list items. For example, enter \"bias,harassment\" instead of \"bias, harassment\".\nMatching words and phrases to emails or attachments\nEach word you enter and separate with a comma is applied separately (only one word must apply for the policy condition to apply to the email or attachment). For example, let's use the condition\nMessage contains any of these words\nwith the keywords \"banker\", \"confidential\", and \"insider trading\" separated by a comma (banker,confidential,\"insider trading\"). The policy applies to any messages that includes the word \"banker\", \"confidential\", or the phrase \"insider trading\". Only one of these words or phrases must occur for this policy condition to apply. Words in the message or attachment must exactly match what you enter.\nImportant\nWhen importing a custom dictionary file, each word or phrase must be separated with a carriage return and on a separate line. For example:\nbanker\nconfidential\ninsider trading\nTo scan both email messages and attachments for the same keywords, create a\ncustom keyword dictionary\nfor the terms you want to scan. This policy configuration identifies defined keywords that appear in either the email message\nOR\nin the email attachment. Using the standard conditional policy settings (\nMessage contains any of these words\nand\nAttachment contains any of these words\n) to identify terms in messages and in attachments requires the terms to be present in\nBOTH\nthe message and the attachment.\nUse the condition builder to create complex conditions (new policies)\nIf you want to create nested conditions or use the\nOR\noperator in addition to the\nAND\noperator in new policies, use the condition builder. To use multiple operators (both\nAND\nand\nOR\n) in the same condition, you must create a separate group for each operator. Select\nAdd group\nto create a group.\nNote\nTo use the condition builder, you must first opt in. To do this, in the\nConditions\nsection, above the existing condition builder, turn the\nCondition builder\noption on. If you create a new policy by using a template, you don't have to opt in to the condition builder, however. Communication Compliance automatically uses the condition builder for new policies based on templates.\nAll exceptions in the condition builder are replaced with a NOT condition. For example, the existing condition builder includes the\nMessage is not received from any of these domains\ncondition. This condition is renamed to\nSender domain is\nin the condition builder, so to build the\nMessage is not received from any of these domains\ncondition in the condition builder, use the\nSender domain is\ncondition together with the\nNOT\ncondition. You must include the\nNOT\ncondition within a nested group.\nNote\nYou can use conditions with trainable classifiers and sensitive info types as an exception by using the\nNOT\ncondition in a nested group, but keyword highlighting isn't available in this case.\nTo make it easier to see a summary of a complex condition that includes multiple\nAND\nand\nOR\noperators or groups, the condition builder includes a simplified summary view of the condition. To see the summary for a condition you built, turn on the\nQuick Summary\noption.\nFor scenarios that show how to use conditions in policies, see\nScenarios for using conditions in Communication Compliance policies\n.\nReview percentage\nTo reduce the amount of content to review, specify a percentage of all communications governed by a Communication Compliance policy. The system selects a real-time, random sample of content from the total percentage of content that matches chosen policy conditions. If you want reviewers to review all items, configure\n100%\nin a Communication Compliance policy.\nFilter email blasts\nUse the\nFilter email blasts\nsetting to exclude messages sent from email blast services. Messages that match the conditions you specify don't generate alerts. This exclusion includes bulk email, such as newsletters, and spam, phishing, and malware. When you select this option, you can view a\nreport\nthat lists the bulk email senders that the system filtered out. Reports are retained for 60 days.\nNote\nThe list of senders is filtered before the content is analyzed, so there might be senders that don't match the content conditions (there might be extra senders in the report).\nThis setting is on by default for new policies. If the\nFilter email blasts setting\nis off for existing policies, a recommendation is generated to turn on the setting.\nAlert policies\nAfter you configure a policy, the system automatically creates a corresponding alert policy and generates alerts for messages that match conditions defined in the policy. It can take up to 24 hours after creating a policy to start receiving alerts from activity indicators. By default, all policy matches alert triggers are assigned a severity level of medium in the associated alert policy. The system generates alerts for a Communication Compliance policy once the aggregation trigger threshold level is met in the associated alert policy. A single email notification is sent once every 24 hours for any alerts, regardless of the number of individual messages that match policy conditions. For example, Contoso has an inappropriate content policy enabled and for January 1, there were 100 policy matches that generated six alerts. A single email notification for the six alerts is sent at end of January 1.\nFor Communication Compliance policies, the system configures the following alert policy values by default:\nAlert policy trigger\nDefault value\nAggregation\nSimple aggregation\nThreshold\nDefault: 4 activities\nMinimum: 3 activities\nMaximum: 2,147,483,647 activities\nWindow\nDefault: 60 minutes\nMinimum: 60 minutes\nMaximum: 10,000 minutes\nNote\nThe alert policy threshold trigger settings for activities support a minimum value of 3 or higher for Communication Compliance policies.\nYou can change the default settings for triggers on number of activities, period for the activities, and for specific users in alert policies on the\nAlert policies\npage in Microsoft Purview.\nChange the severity level for an alert policy\nTo change the severity level for an alert policy, see\nAlert policies in the Microsoft Defender portal\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create Policies",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/communication-compliance-investigate-remediate": {
      "content_hash": "sha256:dfe702f4b383b9930460a1c43788d17a7ef37425da4c4c718aa2b70a9aad9e99",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nInvestigate and remediate Communication Compliance alerts\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Communication Compliance\nprovides the tools to help organizations detect regulatory compliance (for example, SEC or FINRA) and business conduct violations such as sensitive or confidential information, harassing or threatening language, and sharing of adult content. Communication Compliance is built with privacy by design. Usernames are pseudonymized by default, role-based access controls are built in, investigators are opted in by an admin, and audit logs are in place to help ensure user-level privacy.\nAfter you configure\nCommunication Compliance policies\n, you receive alerts for message issues that match your policy conditions. To view and act on alerts, assign users the following permissions:\nThe\nCommunication Compliance Analysts\nor the\nCommunication Compliance Investigators\nrole group\nReviewer in the policy that is associated with the alert\nAfter you establish required permissions, use the following working instructions to investigate and remediate issues.\nTip\nGet started with Microsoft Security Copilot to explore new ways to work smarter and faster using the power of AI. Learn more about\nMicrosoft Security Copilot in Microsoft Purview\n.\nInvestigate policy matches and alerts\nImportant\nOn June 1, 2025, the new\nPolicy Match Preservation\nsetting goes into effect. On that date, existing policy matches might be permanently deleted based on the time period you select in the\nPolicy Match Preservation\nsetting. New policy matches are preserved for that time period. You have until\nMay 19\nto change the time period if you don't want to use the default setting of\n1 year\n.\nLearn more about the Policy Match Preservation setting\n.\nTo investigate issues detected by your policies, review policy matches and alerts. The Communication Compliance area provides several features to help you quickly investigate policy matches and alerts:\nPolicies page\nWhen you sign in to the\nMicrosoft Purview portal\nwith an admin account in your Microsoft 365 organization, select the\nCommunication Compliance\nsolution, then select the\nPolicies\npage. This page shows Communication Compliance policies configured for your Microsoft 365 organization and links to recommended policy templates.\nNote\nIf your role group is\nscoped by one or more admin units\n, you see a message at the top of the page that you can only view and manage the policies that you're scoped for. To learn more about what you can access, select\nView role groups\nin the banner.\nEach policy listed includes the following columns:\nMessages scanned today\n: The total number of messages that the policy scanned on the current day for users and locations that are in scope of the policy. If there's a policy match, the item is added to the\nNew pending today\ncolumn. The number refreshes automatically once per hour, it doesn't update if you refresh the page. At the end of the UTC day, the count resets to zero.\nTip\nIf the value in the column is 0 or a low number, it might be because the policy is too strict. For example, the policy might be focused on just one user or on just one location that the in-scope user doesn't use. You might see a wide variety of aggregate numbers in this column if your policies have different focuses. For example, one policy might be focused on an entire department of users sending messages from multiple locations while another policy might be focused on just one user or just one location.\nNew pending today\n: Shows the number of policy matches for the current day. This value updates whenever you open the page. You can also select the\nRefresh\nbutton to get the latest count. At the end of the UTC day, the count resets to zero.\nTotal pending\n: The count of policy matches that need review. This value updates whenever you open the page. You can select the\nRefresh\nbutton to get the latest count. After refreshing, this number matches the number on the\nPending\ntab.\nTotal resolved\n: The total number of resolved policy matches. This value updates whenever you open the page. You can select the\nRefresh\nbutton to get the latest count. After refreshing, this number matches the number on the\nResolved\ntab.\nStatus\n: The status of the policy (Active or Deactivated).\nLast modified\n: The date and Coordinated Universal Time (UTC) of the last policy modification.\nLast policy scan\n: The UTC date for the last policy scan.\nTo start remediation actions, select the policy associated with the alert to launch the\nPolicy details\npage. From the\nPolicy details\npage, you can review a summary of the activities, review, and act on policy matches on the\nPending\ntab, summarize a lengthy message by using Microsoft Copilot in Microsoft Purview, or review the history of closed policy matches on the\nResolved\ntab.\nLearn more about remediation actions\n.\nAlerts page\nGo to\nCommunication Compliance\n>\nAlerts\nto display the last 30 days of alerts grouped by policy matches. This view lets you quickly see which Communication Compliance policies generate the most alerts, ordered by severity. An alert isn't the same thing as a policy match. An alert generally consists of multiple policy matches, not just one policy match. After the required number of policy matches is met for a particular alert, the alert is created and email is sent to the alert recipient.\nReports page\n: Go to\nCommunication Compliance\n>\nReports\nto display Communication Compliance report widgets. Each widget provides an overview of Communication Compliance activities and statuses, including access to deeper insights about policy matches and remediation actions.\nTip\nLearn how to analyze interactions entered into generative AI applications\n.\nTips for quickly reviewing policy matches on the Pending or Resolved tab\nWhen you select a message to review on the\nPending\ntab or the\nResolved\ntab, the condition that caused the policy match appears in an alert message bar (yellow banner) at the top of the\nSource\ntab. This alert message bar is a quick way to determine the condition or conditions that caused the policy match. If there are multiple conditions, select\nView all\nin the banner to see all the conditions that caused the policy match. At this time, only Microsoft provided trainable classifiers and sensitive information types are highlighted as conditions in the yellow banner.\nSometimes it's useful to quickly review policy settings without opening a policy. For example, if you're testing multiple policies with different conditions, you might want to save time by reviewing conditions for each policy to determine risk before opening the policy. You can do this by selecting\nPolicy settings\n, which opens a panel where you can view the policy settings. If you're a member of the Communication Compliance or Communication Compliance Admins role group, you can view and change settings from the panel. If you're a member of the Communication Compliance Investigators or Communication Compliance Analysts role group, you can view settings but you can't change them.\nPolicy Match Preservation setting\nWhen a Communication Compliance policy finds a message that matches the policy, the solution stores a\ncopy\nof the message (not the original message). Starting June 1, 2025, you can use the\nPolicy Match Preservation\nsetting to specify how long to save policy matches in Communication Compliance. You can choose\n1 month\n,\n6 months\n,\n1 year\n, or\n7 years\n. The default value is\n1 year\n.\nNote\nYou can also specify a preservation period when you create or edit a policy. The preservation period you select within a policy takes precedence over the global\nPolicy Match Preservation\nsetting.\nWhen the setting goes into effect on April 1, 2025:\nThe value in the\nPolicy Match Preservation\nsetting applies to all existing policy matches. The system automatically deletes policy matches that are older than the selected time period. For example, if the\nPolicy Match Preservation\nsetting is\n1 year\n(the default), the system permanently deletes any policy matches older than 1 year as of September 1. Only the policy matches in Communication Compliance are deleted because they're copies of the original messages. This process doesn't delete original copies from user shards. You can use\nMicrosoft Purview Data Lifecycle Management\nto set up a retention policy for original messages.\nNew policy matches as of September 1 receive a timestamp with the preservation period specified in the setting.\nIf you change the time period in the setting after September 1, the preservation period applies going forward. For example, if you select\n1 year\nas the time period on September 1, then change the setting to\n7 years\non September 3, policy matches from September 1 and September 2 are preserved for 1 year, and policy matches starting on September 3 are preserved for 7 years.\nWhat you need to do\nThe\nPolicy Match Preservation\nsetting becomes available for your organization on April 1, 2025. Between April 1 and May 30, select the time period for preserving policy matches for your organization. The selection isn't applied until June 1, 2025.\nChange the time period for the global\nPolicy Match Preservation\nsetting\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nSelect the\nSettings\nbutton in the upper-right corner of the page, then select\nCommunication Compliance\nto go to the Communication Compliance global settings.\nSelect the\nPolicy Match Preservation\nsetting, then select a new time period.\nSelect\nConfirm\nin the confirmation dialog box.\nChange the policy match preservation time period for a custom policy\nYou can also select a time period for preserving policy matches in the policy workflow for a custom policy. When you set a time period in a custom policy, it takes precedence over the selection in the global\nPolicy Match Preservation\nsetting. This option is useful for policies that are the exception to the norm.\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nCommunication Compliance\nsolution, then select\nPolicies\nin the left navigation.\nSelect the\nMore actions\n(ellipsis) button in the row for the policy you want to change, then select\nEdit\n.\nOn the\nName and describe your policy\npage in the policy workflow, under\nPreserve policy matches\n, make a selection. If you leave the\nGlobal Setting\nselection, the policy uses the time period selected in the global\nPolicy Match Preservation\nsetting. If you choose any other time period, it takes precedence over the selection in the global setting.\nUsing filters\nThe next step is to sort the messages so it's easier for you to investigate. From the\nPolicy details\npage, Communication Compliance supports multilevel filtering for several message fields to help you quickly investigate and review messages with policy matches. You can filter pending and resolved items for each configured policy. You can configure filter queries for a policy or configure and save custom and default filter queries for use in each specific policy. After configuring fields for a filter, you see the filter fields displayed on the top of the message queue that you can configure for specific filter values.\nKey filters (the\nBody/Subject\n,\nDate\n,\nSender\n, and\nTags\nfilters) always display on the\nPending\nand\nResolved\ntabs to make it easy to access those filters.\nFor the\nDate\nfilter, the date and time for events are listed in Coordinated Universal Time (UTC). When filtering messages for views, the requesting user's local date/time determines the results based on the conversion of the user's local date/time to UTC. For example, if a user in U.S. Pacific Daylight Time (PDT) filters a report from [DATE] to [DATE] at 00:00, the report includes messages from [DATE] 07:00 UTC to [DATE] 07:00 UTC. If the same user was in U.S. Eastern Daylight Time (EDT) when filtering at 00:00, the report includes messages from [DATE] 04:00 UTC to [DATE] 04:00 UTC.\nFilter details\nCommunication Compliance filters help you filter and sort messages for quicker investigation and remediation actions. You can filter on the\nPending\nand\nResolved\ntabs for each policy. To save a filter or filter set as a saved filter query, you must configure one or more values as filter selections.\nThe following table outlines filter details:\nFilter\nDetails\nBody/Subject\nThe message body or subject. Use this filter to search for keywords or a keyword phrase in the body or subject of the message. The subject appears in the\nSubject\ncolumn for email messages. For Teams messages, nothing appears in the\nSubject\ncolumn.\nClassifiers\nThe name of built-in and custom classifiers that apply to the message. Some examples include\nTargeted Harassment\n,\nProfanity\n,\nThreat\n, and more.\nDate\nThe date the message was sent or received by a user in your organization. To filter for a single day, select a date range that starts with the day you want results for and end with the following day. For example, to filter results for [DATE], choose a filter date range of [DATE]-[DATE].\nEscalated To\nThe user name of the person included as part of a message escalation action.\nFile class\nThe class of the message based on the message type, either\nmessage\nor\nattachment\n.\nHas attachment\nThe attachment presence in the message.\nItem class\nThe source of the message based on the message type, email, Microsoft Teams chat, Bloomberg, and more. For more information, see\nItem Types and Message Classes\n.\nLanguage\nThe detected language of text in the message. The message is classified according to the language of most the message text. For example, for a message containing both German and Italian text, but most text is German, the message is classified as German (DE). For a list of supported languages, see\nLearn about trainable classifiers\n.\nYou can also filter by more than one language. For example, to filter messages classified as German and Italian, enter 'DE,IT' (the two-digit language codes) in the Language filter search box. To view the detected language classification for a message, select a message, select View message details, and scroll to the\nEmailDetectedLanguage\nfield.\nRecipient domains\nThe domain to which the message was sent; this domain is typically your Microsoft 365 subscription domain by default.\nRecipient\nThe user to which the message was sent.\nNote\n: The\nRecipient\nfield includes recipients in the\nTo\nand\nCC\nfields.\nBCC\nfields aren't supported.\nSender domain\nThe domain that sent the message.\nSender\nThe person who sent the message.\nSize\nThe size of the message in KB.\nTags\nThe tags assigned to a message, either\nQuestionable\n,\nCompliant\n, or\nNoncompliant\n.\nConfigure a filter\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nCommunication Compliance\nsolution.\nSelect\nPolicies\nin the left navigation, then select a policy to see policy matches (if any) for that policy.\nOn the\nPolicy\npage, select either the\nPending\nor\nResolved\ntab to display the items for filtering.\nSelect\nFilters\n.\nSelect one or more filter checkboxes, then select\nApply\n.\nTo save the selected filters as a filter query, select\nSave the query\nafter you configure at least one filter value. Enter a name for the filter query, then select\nSave\n. This filter is available to use for only this policy and is listed in the\nSaved filter queries\nsection of the\nFilters\npage.\nReview and remediate policy matches and alerts\nNo matter where you start to review policy matches or alerts or the filtering you configure, the next step is to take remediation action. Start your remediation process with the following workflow on the\nPolicy\nor\nAlerts\npages.\nNote\nIf you see a policy prefaced with \"DSPM for AI\" (or \"AI hub\" from the preview name), the policy was created in Data Security Posture Management for AI, not in Communication Compliance. For more information about this solution, see\nLearn about Data Security Posture Management (DSPM) for AI\n.\nExamine the message basics\nSometimes it's obvious from the source or subject that you can immediately remediate a message. The message might be spurious or incorrectly matched to a policy and you should resolve it as misclassified. To mark a message as misclassified, select\nResolve\nand\nItem was misclassified\nto leave a note in the item's history that it's misclassified and remove it from the\nPending\nqueue. To share misclassified content with Microsoft, select\nSend message content, attachments, and subject\nto remove it from the\nPending\nqueue and report the items to Microsoft.\nNote\nMisclassified options in the\nResolve\npane don't appear if the condition that caused the policy match isn't based on a trainable classifier.\nReporting misclassified items to Microsoft isn't supported for Content Safety classifiers yet.\nFrom the source or sender information, you might already know how the message should be routed or handled in these circumstances. Consider using\nTag as\nor\nEscalate\nto assign a tag to applicable messages or to send messages to a designated reviewer.\nExamine the message details\nAfter reviewing the message basics, open the message to examine the details and determine further remediation actions.\nTip\nFor lengthy messages, you can\nsave time by summarizing the message (including attachments, transcripts, and recordings) with Copilot in Microsoft Purview\n.\nSelect a message to view the complete message header and body information. Several different options and views are available to help you decide the proper course of action:\nSentiment\n: Messages include a sentiment evaluation (powered by\nAzure Cognitive Service for Language\n) to help investigators quickly prioritize potentially riskier messages to address first. The\nSentiment\ncolumn displays the message sentiment and is enabled in the default view. Messages are flagged with one of the following values:\nValue\nDescription\nPositive\nMessages with\nPositive\nsentiment indicate a lower priority for triaging.\nNegative\nMessages with\nNegative\nsentiment indicate messages to prioritize.\nNeutral\nMessages with\nNeutral\nsentiment are determined to be neither positive nor negative.\nNot available\nNot available\nappears in the column for file formats that aren't supported. For example, sentiment analysis isn't available for any image that's attached to a Teams or email message, text extracted from an OCR image, or text or recordings from a Teams transcript.\nNot available\nalso appears if the message includes more than 5,120 words.\nScanning\nScanning\nappears in the the column when Communication Compliance is trying to determine the appropriate sentiment value for the message.\nAttachments\n: This option allows you to examine Modern attachments that match policy conditions. Modern attachments content is extracted as text and is viewable on the\nPending\ntab. For more information, see the\nCommunication Compliance feature reference\n.\nSource\n: This view is the standard message view commonly seen in most web-based messaging platforms. The header information is formatted in the normal style and the message body supports embedded graphic files and word-wrapped text. If\noptical character recognition (OCR)\nis enabled for the policy, images containing printed or handwritten text that match policy conditional are viewed as a child item for the associated message in this view.\nPlain text\n: Text view that displays a line-numbered text-only view of the message and includes keyword highlighting in messages and attachments for sensitive info type terms, terms identified by built-in classifiers assigned to a policy, or for terms included in a dedicated keyword dictionary assigned to a policy. Keyword highlighting, which is currently available for English language only, can help direct you to the area of interest in long messages and attachments. In some cases, highlighted text might be only in attachments for messages matching policy conditions. Embedded files aren't displayed and the line numbering in this view is helpful for referencing pertinent details among multiple reviewers.\nConversation\n: This view, which is available for Teams chat messages, displays up to five messages before and after a message to help reviewers view the activity in the conversational context. Select\nLoad more\nto load up to 20 messages before and after a message. To download messages, select\nDownload conversation\n. This action downloads an image file of everything you see in the user interface and also a .csv file of all the message metadata (UserId, UserName, and so on).\nThe Conversation view context helps reviewers quickly evaluate messages and make more informed message resolution decisions. Real-time message additions to conversations are displayed, including all inline images, emojis, and stickers available in Teams. Image or text file attachments to messages aren't displayed. Notifications are automatically displayed for messages that have been edited or for messages deleted from the Conversation window. When a message is resolved, the associated conversational messages aren't retained with the resolved message.\nPattern detected\nnotification: Many harassing and bullying actions over time involve recurring instances of the same behavior by a user. The\nPattern detected\nnotification is displayed in the message details and raises attention to the message. Detection of patterns is on a per-policy basis and evaluates behavior over the last 30 days when at least two messages are sent to the same recipient by a sender. Investigators and reviewers can use this notification to identify repeated behavior to evaluate the message as appropriate.\nTranslation\n: This view automatically converts message text to the language configured in the\nDisplayed language\nsetting in the Microsoft 365 subscription for each reviewer. This conversion includes the text for the policy match and everything included in the conversation view (up to five messages before and five messages after the policy match). The\nTranslation\nview helps broaden investigative support for organizations with multilingual users and eliminates the need for additional translation services outside of the Communication Compliance review process. Using Microsoft translation services, Communication Compliance automatically detects if the text is in a different language than the user's current system setting and displays alert message text accordingly. For a complete list of supported languages, see\nMicrosoft Translator Languages\n. Languages listed in the\nTranslator Language List\nare supported in the\nTranslation\nview.\nUser activity\n: This view provides risk profile, policy matches, and user activities captured by\nInsider Risk Management\nand Communication Compliance. This integration helps Communication Compliance investigators quickly see risk severity and the associated activities for the user while investigating and triaging pending policy matches.\nThe\nUser activity\nview displays the\nInsider risk severity\nlevel for the user and has two sections, one for Communication Compliance policy matches and activities and one for Insider Risk Management risk activities. View the risk severity of the user from Insider Risk Management in the\nSource\ntab if data sharing is enabled. For more information, see\nShare Insider Risk Management data with other solutions\n.\nCommunication Compliance policy matches\n: This section displays the total number of communication\nPolicy matches\nand the total number of\nRemediation actions\nfor the user included in this policy match.\nSelect\nView details\nin this section to display a timeline of Communication Compliance activities for the user. This timeline includes:\nTotals for\nPolicy matches\nand\nRemediation actions\nfor the user\nDetails for each activity associated with the user for the past 30 days.\nInsider risk activity\n: This section displays the total number of\nRisk activities\nand the total number of\nUnusual activities\nfor activities associated with this user for Insider Risk Management policies.\nUnusual activities\nare activities for the user that are considered potentially risky, as they're unusual and a departure from their typical activities.\nSelect\nView details\nin this section to display a timeline of insider risk activity for the user. This timeline includes:\nThe insider risk\nseverity level\n.\nTotals for\nAll activities\nand\nUnusual activities\n.\nDetails for each activity associated with the user from the\nActivity explorer\nin Insider Risk Management.\nTo view the insider risk activities in insider risk management, select\nOpen in insider risk management\n.\nTimeline\n: This section displays a history of all communications for user activities. This timeline allows investigators to review all communications for a user, helping to identify any inappropriate handling of confidential information. Only previous policy matches for the user associated with the alert are displayed.\nFor each Copilot interaction, the details for the user prompt and the Copilot response are available for review. The date and time for each interaction are provided in UTC.\nSummarize a message by using Copilot in Microsoft Purview\nYou can use Copilot in Microsoft Purview to get a contextual summary of a Teams, email, or Viva Engage message included in a policy match. The summary is in the context of one or more\nMicrosoft provided trainable classifiers\nthat flag the message (for example, stock manipulation). This feature saves time for investigators if the message content is lengthy.\nCopilot in Microsoft Purview summarizes the entire message, including any video recordings, meetings transcripts, or attachments (docx, pdf, or txt files).\nLimitations\nThe message content must be at least 100 words and less than 15,000 words. If the message content is fewer than 100 words or more than 15,000 words, Copilot in Microsoft Purview doesn't summarize it.\nSummarize items in various languages supported by Security Copilot. For more information, see\nSupported languages in Microsoft Security Copilot\n.\nAt this time, only individual Teams messages can be summarized. If you summarize an individual Teams message, Copilot doesn't pull in the surrounding conversation.\nPrerequisites for using Copilot in Microsoft Purview\nTo summarize a message in Communication Compliance by using Copilot in Microsoft Purview, you must have specific licenses and onboard your organization to Copilot in Microsoft Purview.\nLearn more about Copilot in Microsoft Purview licensing requirements and onboarding\n. You must also be a member of the\nCommunication Compliance\n,\nCommunication Compliance Analysts\n, or\nCommunication Compliance Investigators\nrole.\nSummarize a message\nIn Communication Compliance, go to the\nPolicies\npage, and then open any policy to view policy matches for that policy.\nSelect a message in the list. You can select a parent item or a child item (but it's easier to select the parent item).\nSelect\nSummarize\n. This option appears below the message details. It opens the\nCopilot\npanel on the right side of the screen and displays a summary of the message.\nImportant\nYou might see a generic error message that says \"An error occurred\" after selecting\nSummarize\n. This error message can appear for any of the following reasons:\nYou don't have the\nrequired license\nfor Copilot in Microsoft Purview.\nYou don't have the required Communication Compliance role and/or the Security Copilot contributor role. To use Copilot in Microsoft Purview, you must have one of the following Communication Compliance roles:\nCommunication Compliance\n,\nCommunication Compliance Analysts\n,\nCommunication Compliance Investigators\n. You must also have the\nSecurity Copilot contributor role\n, which should be turned on by default for all users in a Microsoft Entra organization.\nThere's an internal error. Microsoft provides more information for these errors.\nSelect one of the suggested prompts at the bottom of the panel to use Copilot to create the summary. For example, if the classifier that flagged a message is Stock manipulation, select\nSummarize this message and supported attachments in the context of Stock manipulation category detected\n. You can also enter an open-ended question in the \"Ask a question\" box.\na.\nSummarize\n.\nb. Summary generated by\nSummarize\n.\nc. Suggested Copilot prompts.\nd. \"Ask a question\" box for open-ended Copilot questions.\nNote\nOnly message content is summarized. If you ask a question relevant to the message content, Copilot provides a result. If the question isn't relevant to message content, Copilot instructs you to ask a different question.\nIf you want to provide feedback on the summarized content, select the drop-down arrow in the lower-right corner below the summary, and then enter your feedback.\nAfter reviewing the summary, you can remediate the policy match like any other policy match (see next section).\nNote\nCopilot in Microsoft Purview responses are also recorded in\nMicrosoft Security Copilot\n.\nUnderstanding hidden matches\nWhen a Communication Compliance policy triggers, it highlights the exact matches in the\nPlain text\ntab. However, policies can also flag messages where the keywords are hidden and embedded in nonvisible metadata, such as HTML tags or encoded strings. By default, the plain text view doesn't show this content.\nThe following scenarios show where hidden content matches might occur:\nHTML tags\n: Hyperlinks embedded in HTML tags, for example:\n<a href=\"https://example.com\">Click here</a>.\nAlternative text for images\n: Descriptive text for images, for example:\n<img src=\"sunset.png\" alt=\"Sunset over the lake\">\nEncoded strings\n: Encoded strings that represent different content when decoded, for example:\nBase64: U3Vuc2V0IG92ZXIgdGhlIGxha2U=\ndecodes to\nSunset over the lake\nFilename of attachment\n: The file name of the attachment might lead to a policy match but isn't clearly highlighted in the text view.\nOCR:\nText extracted from images using Optical Character Recognition (OCR).\nIf a message doesn't appear to match the conditions you set for the policy, complete the following steps:\nSelect and download the message with the policy match.\nExtract the contents of the zipped folder.\nLocate the .eml file.\nOpen the .eml file with any text editor.\nUse the\nFind\nfunction to search for the individual keywords in the policy conditions to identify where the match occurs.\nReview Microsoft Teams meetings transcripts\nIf you deploy Microsoft Teams in your organization, you can review Teams meetings transcripts for actionable alerts. Teams transcripts are automatically included if you choose Teams as a Microsoft 365 location when you create a custom policy or when you create a policy based on a template.\nScheduled meetings\n: Communication Compliance ignores communication direction for Teams transcripts. If an individual is an invitee or is present in a scheduled (nonrecurring) meeting, the policy includes all of the meeting content, regardless of who says what in the meeting. This approach also helps in situations where a user is attending the meeting through a hub device in a conference room, since it's not always possible to tell whether an offending communication comes from an in-scope user. Since all meeting content is included, an investigator can review the recording of the meeting to determine if the offending communication is by an in-scope user.\nRecurring meetings\n: For recurring meetings, the policy evaluates only the following users:\nUsers who were invited to the meeting\nUsers identified by the transcript as having spoken during the meeting\nUnscheduled meetings\n: For unscheduled meetings (Meet now meetings), the policy evaluates only users who are identified by the transcript as having spoken during the meeting.\nRequirements\nTo review Teams meeting transcripts, you must turn on meeting transcripts for your organization, since meeting transcripts aren't turned on by default.\nLearn more about turning on meeting transcripts for your organization\n.\nLimitations\nYou can set one or more of the following policy conditions:\nContent matches any of these classifiers.\nContent contains any of these sensitive info types.\nMessage contains any of these words.\nMessage contains none of these words.\nAny other policy conditions are ignored.\nLearn more about conditional settings\n.\nNote\nIf you don't set any conditions, the policy captures transcripts for all meetings.\nOnly sensitive info types, keyword lists, and regulatory Microsoft provided trainable classifiers are detected. Regulatory trainable classifiers include:\nCorporate sabotage\nGifts and entertainment\nMoney laundering\nRegulatory collusion\nStock manipulation\nUnauthorized disclosure\nNote\nAll other classifiers, including business conduct classifiers, aren't detected.\nAd-hoc (unscheduled) meetings aren't captured.\nExternal meetings aren't captured if the meeting organizer is outside your organization.\nMeeting recordings started by an uninvited user aren't captured.\nResolve an alert for a communication in a meeting transcript\nAfter you create a policy, an alert triggers when the policy detects a transcript that contains offending content. The alert brings the offending content and background context to the attention of an investigator.\nTo resolve an alert related to a meeting transcript:\nSelect the\nSource\ntab and then review the transcript for the offending content. The\nSource\ntab shows the entire transcript. When you select the\nSource\ntab, the transcript automatically scrolls to the line that contains the policy match. The offensive keyword or phrase is highlighted.\nUse the\nPlain text\ntab to do a line-by-line review of the text, including start and stop times in relation to the overall meeting time. Text is captured 30 seconds before and after the offending communication.\nSelect the\nTranslation\ntab to review translations in up to eight languages for the\nPlain text\ntab. Messages in other languages are automatically converted to the display language of the reviewer.\nSelect the\nUser history\ntab to see a historical view of all user message remediation activities, such as past notifications and escalations for policy matches.\nUse\nResolve\n,\nNotify\n,\nTag as\n,\nEscalate\n, and\nEscalate for investigation\noptions to resolve the alert. To learn more about these options, see\nDecide on a remediation action\n.\nDecide on a remediation action\nAfter reviewing message details, choose from several remediation actions:\nResolve\n: Selecting\nResolve\nimmediately removes the message from the\nPending\nqueue and prevents any further action on the message. When you select\nResolve\n, you close the message without further classification. You can also mark the message as misclassified if the alerting process or any Microsoft provided trainable classifiers incorrectly generated it. The\nResolved\ntab displays all resolved messages.\nTo save investigators time when duplicate policy matches appear across multiple policies, the solution turns on the\nCross-policy resolution\nsetting (preview) by default. When you resolve a policy match, Communication Compliance automatically resolves all instances of the same policy match in any policy where it's detected, regardless of the reviewer's scope. The item history for each policy notes cross-policy resolution actions, and the number of\nResolved\nitems increments in the\nItems and actions per policy\nand\nItems and actions per location\nreports for all related policies.\nWhen the\nCross-policy resolution\nsetting is turned on, this message appears in the\nResolve\npane.\nIf you don't want to automatically resolve all instances of the same policy match when an investigator resolves a policy match, turn off the\nCross-policy resolution\nsetting. Anyone who can resolve messages (anyone with the\nCommunication Compliance\n,\nCommunication Compliance Investigators\n, or\nCommunication Compliance Analyst\nrole) knows if the setting is turned off because the message in the\nResolve\npane disappears. To turn off the setting, in the\nMicrosoft Purview portal\n, select\nSettings\nin the upper-right corner of the page, select\nCommunication Compliance\n, then select the\nCross-policy resolution\nsetting.\nPower Automate\n: Use a Power Automate flow to automate process tasks for a message. By default, Communication Compliance includes the\nNotify manager when a user has a Communication Compliance alert\nflow template that reviewers can use to automate the notification process for users with message alerts. For more information about creating and managing Power Automate flows in Communication Compliance, see the\nConsider Power Automate flows\n.\nTag as\n: Tag the message as\nCompliant\n,\nNoncompliant\n, or\nQuestionable\nas it relates to the policies and standards for your organization. You can also create a\ncustom tag\n. Adding tags and tagging comments helps you micro-filter messages for escalations or as part of other internal review processes. After tagging is complete, you can also choose to resolve the message to move it out of the pending queue. You can filter on any tag value.\nNotify\n: Use\nNotify\nto assign a custom notice template to the message and send a warning notice to the user. Choose the appropriate notice template configured in the\nCommunication Compliance settings\narea and select\nSend\nto email a reminder to the user that sent the message and to resolve the issue.\nEscalate\n: Use\nEscalate\nto choose other people in your organization who should review the message. Choose from a list of reviewers configured in the Communication Compliance policy to send an email notification requesting additional review of the message. The selected reviewer can use a link in the email notification to go directly to items escalated to them for review.\nEscalate for investigation\n: Use\nEscalate for investigation\nto create a new\neDiscovery (Premium) case\nfor single or multiple messages. Provide a name and notes for the new case. The custodian is automatically filled in for you. You don't need any additional permissions to manage the case. Creating a case doesn't resolve or create a new tag for the message. You can select a total of 100 messages when creating an eDiscovery (Premium) case during the remediation process. Messages in all communication channels included in Communication Compliance are supported. For example, you could select 50 Microsoft Teams chats, 25 Exchange Online email messages, and 25 Viva Engage messages when you open a new eDiscovery (Premium) case for a user.\nRemove message in Teams\n: Use\nRemove message in Teams\nto block potentially inappropriate messages and content identified in messages from Microsoft Teams channels and 1:1 and group chats. This action includes Teams chat messages reported by users and chat messages detected using machine-learning and classifier-based Communication Compliance policies. Removed messages and content are replaced with a policy tip that explains that it's blocked and the policy that applies to its removal from view. Recipients are provided a link in the policy tip to learn more about the applicable policy and the review process. The sender receives a policy tip for the blocked message and content but can review the details of the blocked message and content for context regarding the removal.\nCreate a custom tag\nYou can tag a policy match as\nCompliant\n,\nNon-compliant\n, or\nQuestionable\nas it relates to the policies and standards for your organization. If you need more flexibility than the standard tags provide, create a custom tag. For example, you might want to create an\nEscalated\ntag so investigators can let other team members know that a policy match is already escalated. Since you can apply multiple tags to any policy match, using the same example, investigators could apply that tag and also apply the\nNon-compliant\ntag for a policy match.\nKeep the following points in mind for custom tags:\nYou can apply tags to policy matches that appear on the\nPending\ntab.\nYou can apply multiple tags to a policy match.\nYou can create up to 10 custom tags per policy.\nYou create custom tags at the policy level so if you want to use the same custom tag for multiple policies, you must recreate the tag for each policy.\nWhen you apply a custom tag to a policy match:\nThe tag appears in the\nTags\ncolumn in the list of policy matches. If you apply more than one tag, each tag appears in the\nTags\ncolumn.\nThe tag appears in the\nTags\nfilter. You can then select the checkbox for that tag to filter all policy matches by that tag.\nA\nCustom tag\ncolumn appears in the following reports:\nItems and actions per policy\n,\nItems and actions per location\n, and\nActivity by user\n.\nIf you delete a custom tag for a policy:\nIt's removed from any previous items that you tagged with that custom tag.\nYou can no longer filter by that tag.\nTip\nAny action you take with custom tags is tracked in the\nHistory of remediation actions\npane. Select\nView item history\nto display this pane.\nCreate and apply a custom tag for a policy match\nOn\nPolicies\n, select a policy to view the policy matches for that policy.\nSelect the checkbox for the policy match that you want to create a custom tag for. Select the checkboxes for multiple policy matches if you want to apply a custom tag in bulk.\nSelect\nTag as\non the command bar.\nIn the\nTag item\npane, select\nAdd a new tag\n.\nEnter the name of the new tag, then press Enter to add the new tag.\nNote\nA custom tag must be between 3 and 64 characters and can't include special characters. Spaces and hyphens are allowed.\nSelect the checkbox for the new tag to apply it to the policy match.\nIn the\nComment\nbox, add a comment to describe the purpose of the tag (optional).\nSelect\nSave\n.\nEdit or delete a custom tag\nOn\nPolicies\n, select a policy to view the policy matches for that policy.\nSelect the checkbox for the policy match that has the custom tag you want to edit.\nSelect\nTag as\non the command bar.\nIn the\nTag item\npane, select the ellipsis next to the custom tag.\nSelect\nEdit\n, make your changes, or select\nDelete\nto delete the tag.\nImportant\nIf you delete a custom tag, it's removed from any previous items that you tagged with that custom tag. You can no longer filter by that tag.\nSelect\nSave\n.\nUnresolve messages\nWhen you resolve messages, the messages are removed from the\nPending\ntab and displayed in the\nResolved\ntab. Investigation and remediation actions aren't available for messages in the\nResolved\ntab. However, you might need to take extra action on a message that you mistakenly resolved or that needs further investigation after initial resolution. Use the\nUnresolve\ncommand to move one or more messages from the\nResolved\ntab back to the\nPending\ntab.\nUnresolve a message\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nCommunication Compliance\nsolution.\nSelect\nPolicies\nin the left navigation, then select a policy that contains the resolved message to view the policy matches.\nSelect the\nResolved\ntab.\nOn the\nResolved\ntab, select one or more messages.\nOn the command bar, select\nUnresolve\n.\nOn the\nUnresolve item\npane, add any comments, then select\nSave\n.\nSelect the\nPending\ntab to verify that the selected items are displayed.\nArchive message details outside of Communication Compliance (optional)\nExport or download message details if you need to archive the messages in a separate storage solution. If you select one or more policy matches and then select\nDownload\nin the bar over the list, you automatically add the selected messages to a .zip file that you can save in storage outside of Microsoft 365. The size limit for files downloaded by using\nDownload\nis 3 MB.\nExport a collection of message details that exceeds 3 MB in size\nTo download messages that cumulatively exceed 3 MB in size, use\nExport files\n(displayed in the upper-right corner of the\nPolicies\npage). For example, you might want to download policy matches each week for archiving purposes. The download size limit for the\nExport files\ncommand is 3 GB. The maximum number of items depends on whether you select documents (limit of 1,000 items) or users (limit of 50,000). Files are exported to a .zip file that you can then download. The .zip file contains all the message files as well as a summary .TXT file that includes data for the following fields: Document, Doc ID, Custodian, Subject/title, File name, File type, Error, and Message.\nOn the\nExports\ntab, the export has a status of\nIn progress\nor\nReady to download\n. To download a file that has a\nReady to download\nstatus, select the files batch in the\nName\nlist, then select\nDownload export(s)\nover the list.\nYou can either select the policy matches that you want to export, select\nExport files\n, and then select the list of documents or users you want to export, or you can select\nExport files\nand then select the documents, users, and date ranges that you want to export. After you select\nExport\n, it takes a few minutes for the job to complete. You receive an email notification with a link to the\nExports\ntab when the export is ready to download. To download a file that has a\nReady to download\nstatus, select the files batch in the\nName\nlist, then select\nDownload export(s)\nover the list.\nNote\nTo include attachments in exported files, you must select them manually in the list of policy matches. They're not automatically included with their parent message file.\nTip\nYou can also\ncreate and download a Message details report\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Investigate Alerts",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/insider-risk-management": {
      "content_hash": "sha256:06bb1540ff9fbca08570916945a464b81d5877c730c258f096cb5811497022c2",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about Insider Risk Management\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Insider Risk Management\ncorrelates various signals to identify potential malicious or inadvertent insider risks, such as IP theft, data leakage, and security violations. Insider Risk Management enables customers to create policies to manage security and compliance. Built with privacy by design, users are pseudonymized by default, and role-based access controls and audit logs are in place to help ensure user-level privacy.\nMicrosoft Purview Insider Risk Management is a compliance solution that helps minimize internal risks by enabling you to detect, investigate, and act on malicious and inadvertent activities in your organization. With insider risk policies, you can define the types of risks to identify and detect in your organization. You can also set up processes for acting on cases and escalating cases to Microsoft eDiscovery (Premium) if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards.\nFor more information and an overview of the planning process to address potentially risky activities in your organization that might lead to a security incident, see\nStarting an Insider Risk Management program\n.\nWatch the following videos to learn how Insider Risk Management can help your organization prevent, detect, and contain risks while prioritizing your organization values, culture, and user experience:\nInsider Risk Management solution & development\n:\nInsider Risk Management workflow\n:\nCheck out the\nMicrosoft Mechanics video\non how Insider Risk Management and Communication Compliance work together to help minimize data risks from users in your organization.\nImportant\nInsider Risk Management is currently available in tenants hosted in geographical regions and countries supported by Azure service dependencies. To verify that Insider Risk Management is supported for your organization, see\nAzure dependency availability by country/region\n.\nModern risk pain points\nManaging and minimizing risk in your organization starts with understanding the types of risks found in the modern workplace. Some risks come from external events and factors that you can't directly control. Other risks come from internal events and user actions that you can minimize and avoid. Some examples are risks from illegal, inappropriate, unauthorized, or unethical behavior and actions by users in your organization. These behaviors include a broad range of internal risks from users:\nLeaks of sensitive data and data spillage\nConfidentiality violations\nIntellectual property (IP) theft\nFraud\nInsider trading\nRegulatory compliance violations\nUsers in the modern workplace can create, manage, and share data across a broad spectrum of platforms and services. In most cases, organizations have limited resources and tools to identify and mitigate organization-wide risks while also meeting user privacy standards.\nInsider Risk Management uses the full breadth of service and third-party indicators to help you quickly identify, triage, and act on risk activity. By using logs from Microsoft 365 and Microsoft Graph, Insider Risk Management enables you to define specific policies to identify risk indicators. These policies help you identify risky activities and act to mitigate these risks.\nInsider Risk Management centers around the following principles:\nTransparency\n: Balance user privacy versus organization risk with privacy-by-design architecture.\nConfigurable\n: Configurable policies based on industry, geographical, and business groups.\nIntegrated\n: Integrated workflow across Microsoft Purview solutions.\nActionable\n: Provides insights to enable reviewer notifications, data investigations, and user investigations.\nIdentifying potential risks with analytics\nInsider risk analytics enables you to evaluate potential insider risks in your organization without configuring any insider risk policies. This evaluation can help your organization identify potential areas of higher user risk and help determine the type and scope of Insider Risk Management policies you might consider configuring. This evaluation can also help you determine needs for additional licensing or future optimization of existing insider risk policies.\nFor more information about insider risk analytics, see\nInsider Risk Management settings: Analytics\n.\nGet started with recommended actions\nWhether you're setting up Insider Risk Management for the first time or getting started with creating new policies, the new\nrecommended actions\nexperience can help you get the most out of Insider Risk Management capabilities. Recommended actions include setting up permissions, choosing policy indicators, creating a policy, and more.\nWorkflow\nThe Insider Risk Management workflow helps you identify, investigate, and take action to address internal risks in your organization. With focused policy templates, comprehensive activity signaling across the Microsoft 365 service, and alert and case management tools, you can use actionable insights to quickly identify and act on risky behavior.\nIdentifying and resolving internal risk activities and compliance issues with Insider Risk Management uses the following workflow:\nPolicies\nYou create\nInsider Risk Management policies\nby using predefined templates and policy conditions that define which triggering events and risk indicators to examine in your organization. These conditions include how risk indicators are used for alerts, which users are included in the policy, which services are prioritized, and the detection time period.\nTo quickly get started with Insider Risk Management, select from the following policy templates:\nData theft by departing users\nData leaks\nData leaks by priority users\nData leaks by risky users\nPatient data misuse (preview)\nRisky Agents\nRisky AI usage\nRisky browser usage (preview)\nSecurity policy violations\nSecurity policy violations by departing users\nSecurity policy violations by risky users\nSecurity policy violations by priority users\nAlerts\nRisk indicators automatically generate alerts when they match policy conditions. You can see these alerts in the\nAlerts dashboard\nor the\nTriage Agent dashboard\n. These dashboards provide a quick view of all alerts that need review, open alerts over time, and alert statistics for your organization. All policy alerts display the following information to help you quickly identify the status of existing alerts and new alerts that need action:\nID\nUsers\nAlert\nStatus\nAlert severity\nTime detected\nCase\nCase status\nRisk factors\nTriage\nNew user activities that need investigation automatically generate alerts and assign them a\nNeeds review\nstatus. Reviewers can quickly identify, review, evaluate, and triage these alerts.\nResolve alerts by opening a new case, assigning the alert to an existing case, or dismissing the alert. With alert filters, you can quickly identify alerts by status, severity, or time detected. As part of the triage process, reviewers can view alert details for the activities identified by the policy, view user activity associated with the policy match, see the severity of the alert, and review user profile information.\nInvestigate\nQuickly investigate all risky activities for a selected user with\nUser activity reports (preview)\n. These reports let investigators in your organization examine activities for specific users during a defined time period without temporarily or explicitly assigning them to an Insider Risk Management policy. After examining activities for a user, investigators can dismiss individual activities as benign, share or email a link to the report with other investigators, or choose to assign the user temporarily or explicitly to an Insider Risk Management policy.\nCases\nare created for alerts that require deeper review and investigation of the activity details and circumstances around the policy match. The\nCase dashboard\nprovides an all-up view of all active cases, open cases over time, and case statistics for your organization. Reviewers can quickly filter cases by status, the date the case was opened, and the date the case was last updated.\nSelecting a case on the case dashboard opens the case for investigation and review. This step is the heart of the Insider Risk Management workflow. This area synthesizes risk activities, policy conditions, alert details, and user details into an integrated view for reviewers. The primary investigation tools in this area are:\nUser activity\n: An interactive chart automatically displays user risk activity. It plots activities over time and by risk level for current or past risk activities. Reviewers can quickly filter and view the entire risk history for the user and drill into specific activities for more details.\nContent explorer\n: The Content explorer automatically captures and displays all data files and email messages associated with alert activities. Reviewers can filter and view files and messages by data source, file type, tags, conversation, and many more attributes.\nCase notes\n: Reviewers can provide notes for a case in the Case Notes section. This list consolidates all notes in a central view and includes reviewer and date submitted information.\nAdditionally, the new\nAudit log (preview)\nenables you to stay informed of the actions taken on Insider Risk Management features. This resource allows an independent review of the actions taken by users assigned to one or more Insider Risk Management role groups.\nAction\nAfter investigating cases, reviewers can quickly act to resolve the case or collaborate with other risk stakeholders in your organization. If users accidentally or inadvertently violate policy conditions, reviewers can send a simple reminder notice to the user from notice templates you can customize for your organization. These notices might serve as simple reminders or might direct the user to refresher training or guidance to help prevent future risky behavior. For more information, see\nInsider Risk Management notice templates\n.\nIn more serious situations, you might need to share the Insider Risk Management case information with other reviewers or services in your organization. Insider Risk Management tightly integrates with other Microsoft Purview solutions to help you with end-to-end risk resolution.\neDiscovery (Premium)\n: Escalating a case for investigation allows you to transfer data and management of the case to Microsoft Purview eDiscovery (Premium). eDiscovery (Premium) provides an end-to-end workflow to preserve, collect, review, analyze, and export content that's responsive to your organization's internal and external investigations. It allows legal teams to manage the entire legal hold notification workflow. To learn more about eDiscovery (Premium) cases, see\nOverview of Microsoft Purview eDiscovery (Premium)\n.\nOffice 365 Management APIs integration (preview)\n: Insider Risk Management supports exporting alert information to security information and event management (SIEM) services via the Office 365 Management APIs. Having access to alert information in the platform that best fits your organization's risk processes gives you more flexibility in how to act on risk activities. To learn more about exporting alert information with Office 365 Management APIs, see\nExport alerts\n.\nScenarios\nInsider Risk Management can help you detect, investigate, and take action to mitigate internal risks in your organization in several common scenarios:\nData theft by departing users\nWhen users leave an organization, either voluntarily or as the result of termination, legitimate concerns often arise that company, customer, and user data are at risk. Users might innocently assume that project data isn't proprietary, or they might be tempted to take company data for personal gain and in violation of company policy and legal standards. Insider Risk Management policies that use the\nData theft by departing users\npolicy template automatically detect activities typically associated with this type of theft. With this policy, you automatically receive alerts for suspicious activities associated with data theft by departing users so you can take appropriate investigative actions. You need to configure a\nMicrosoft 365 HR connector\nfor your organization for this policy template.\nIntentional or unintentional leak of sensitive or confidential information\nIn most cases, users try their best to properly handle sensitive or confidential information. But occasionally users make mistakes and information is accidentally shared outside your organization or in violation of your information protection policies. In other circumstances, users might intentionally leak or share sensitive and confidential information with malicious intent and for potential personal gain. Insider Risk Management policies created using the following policy templates automatically detect activities typically associated with sharing sensitive or confidential information:\nData leaks\nData leaks by priority users\nData leaks by risky users\nRisk AI usage\nIntentional or unintentional security policy violations (preview)\nUsers typically have a large degree of control when managing their devices in the modern workplace. This control might include permissions to install or uninstall applications needed in the performance of their duties or the ability to temporarily disable device security features. Whether this risk activity is inadvertent, accidental, or malicious, this conduct can pose risk to your organization and is important to identify and act to minimize. To help identify these risky security activities, the following Insider Risk Management security policy violation templates scores security risk indicators and use Microsoft Defender for Endpoint alerts to provide insights for security-related activities:\nSecurity policy violations\nSecurity policy violations by departing users\nSecurity policy violations by priority users\nSecurity policy violations by risky users\nPolicies for users based on position, access level, or risk history\nUsers in your organization might have different levels of risk depending on their position, level of access to sensitive information, or risk history. This structure might include members of your organization's executive leadership team, IT administrators that have extensive data and network access privileges, or users with a past history of risky activities. In these circumstances, closer inspection and more aggressive risk scoring are important to help surface alerts for investigation and quick action. To help identify risky activities for these types of users, you can create priority user groups and create policies from the following policy templates:\nSecurity policy violations by priority users\nData leaks by priority users\nHealthcare (preview)\nFor organizations in the healthcare industry, recent studies found a very high rate of insider-related data breaches. Detecting misuse of patient data and health record information is a critical component of safeguarding patient privacy and complying with compliance regulation such as the Health Insurance Portability and Accountability Act (HIPAA) and the Health Information Technology for Economic and Clinical Health (HITECH) Act. Patient data misuse can range from accessing privileged patient records to accessing records of patients from family or neighbors with malicious intent. To help identify these types of risky activities, the following Insider Risk Management policy template uses the Microsoft 365 HR connector and a healthcare-specific data connector to start scoring risk indicators relating to behaviors that can occur within your electronic heath record (EHR) systems:\nPatient data misuse (preview)\nActions and behaviors by risky users\nEmployment stressor events can impact user behavior in several ways that relate to insider risks. These stressors might be a poor performance review, a position demotion, or the user being placed on a performance review plan. Stressors might also result in potentially inappropriate behavior such as users sending potentially threatening, harassing, or discriminatory language in email and other messages. Though most users don't respond maliciously to these events, the stress of these actions can result in some users behaving in ways that they might not normally consider during normal circumstances. To help identify these types of potentially risky activities, the following Insider Risk Management policy templates can use the HR connector and/or integration with a\ndedicated Communication Compliance policy\nto bring users into scope for Insider Risk Management policies and start scoring risk indicators relating to behaviors that might occur:\nData leaks by risky users\nRisk AI usage\nRisky browser usage (preview)\nSecurity policy violations by risky users\nVisual context for potentially risky user activities with forensic evidence\nHaving visual context is crucial for security teams during forensic investigations to get better insights into potentially risky user activities that might lead to a security incident. This insight might include visual capturing of these activities to help evaluate if they're indeed risky or taken out of context and not potentially risky. For activities that are determined to be risky, having forensic evidence captures can help investigators and your organization better mitigate, understand, and respond to these activities. To help with this scenario,\nenable forensic evidence capturing\nfor online and offline devices in your organization.\nReady to get started?\nSee\nPlan for Insider Risk Management\nto prepare for enabling Insider Risk Management policies in your organization.\nSee\nGet started with Insider Risk Management settings\nto configure global settings for insider risk policies.\nSee\nGet started with Insider Risk Management\nto configure prerequisites, create policies, and start receiving alerts.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Insider Risk Management",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/insider-risk-management-policies": {
      "content_hash": "sha256:30b6c308b463384a332c5c3fc1e388cfc7778465e56d94fbe47d477fe445b97b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and manage Insider Risk Management policies\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Insider Risk Management\ncorrelates various signals to identify potential malicious or inadvertent insider risks, such as IP theft, data leakage, and security violations. Insider Risk Management enables customers to create policies to manage security and compliance. Built with privacy by design, users are pseudonymized by default, and role-based access controls and audit logs are in place to help ensure user-level privacy.\nInsider Risk Management policies determine which users are in scope and which types of risk indicators are configured for alerts. You can quickly create a security policy that applies to all users in your organization or define individual users or groups for management in a policy. Policies support content priorities to focus policy conditions on multiple or specific Microsoft Teams, SharePoint sites, data sensitivity types, and data labels. By using templates, you can select specific risk indicators and customize event thresholds for policy indicators, effectively customizing risk scores, and level and frequency of alerts.\nYou can also configure quick data leak and data theft policies by departing user policies that automatically define policy conditions based on results from the latest analytics. Also, risk score boosters and anomaly detections help identify potentially risky user activity that is of higher importance or unusual. Policy windows allow you to define the time frame to apply the policy to alert activities and are used to determine the duration of the policy once activated.\nFor an overview of how policies created with built-in policy templates can help you quickly act on potential risks, see the\nInsider Risk Management Policies Configuration video\n.\nTip\nGet started with Microsoft Security Copilot to explore new ways to work smarter and faster using the power of AI. Learn more about\nMicrosoft Security Copilot in Microsoft Purview\n.\nPolicy dashboard\nThe\nPolicy dashboard\nlets you quickly see the user and agent policies in your organization, the health of each policy, manually add users to security policies, and view the status of alerts associated with each policy. Your policies are separated into two categories:\nUser policy\nand\nAgent policy\n. Switch between the two to locate relevant policy details.\nAgent policy\ncovers agents from Microsoft Copilot Studio and Microsoft Foundry.\nPolicy name\n: Name assigned to the policy in the policy workflow.\nStatus\n: Health status for each policy. Displays number of policy warnings and recommendations, or a status of\nHealthy\nfor policies without issues. You can select the policy to see the health status details for any warnings or recommendations.\nActive alerts\n: Number of active alerts for each policy.\nConfirmed alerts\n: Total number of alerts that resulted in cases from the policy in the last 365 days.\nActions taken on alerts\n: Total number of alerts that were confirmed or dismissed for the last 365 days.\nPolicy alert effectiveness\n: Percentage determined by total confirmed alerts divided by total actions taken on alerts (which is the sum of alerts that were confirmed or dismissed over the past year).\nPolicy recommendations from analytics\nInsider risk analytics gives you an aggregate view of anonymized user activities related to security and compliance. With this view, you can evaluate potential insider risks in your organization without configuring any insider risk policies. This evaluation helps your organization identify potential areas of higher risk and helps determine the type and scope of Insider Risk Management policies you might consider configuring. If you decide to act on analytics scan results for\ndata leaks\nor\ndata theft\nby departing users policies, you can even configure a quick policy based on these results.\nFor more information about insider risk analytics and policy recommendations, see\nInsider Risk Management settings: Analytics\n.\nNote\nYou must be an unrestricted administrator to access analytics insights.\nLearn how administrative groups affect permissions\n.\nQuick policies\nFor many organizations, getting started with an initial policy can be a challenge. If you're new to Insider Risk Management or are using the recommended actions to get started, use a quick policy to create and configure a new policy. Quick policy settings automatically populate from recommended best practices or on results from the latest analytics scan in your organization. For example, if the analytics check detected potential data leak activities in your organization, the\nDate leaks\nquick policy automatically includes the indicators used to detect those activities.\nYou can choose from the following quick policies:\nCritical assets protection\n: Detects activities involving your organization's most valuable assets. Loss of these assets could result in legal liability, financial loss, or reputational damage.â\nData leaks\n: Detect potential data leaks from all users in your organization, which can range from accidental oversharing of sensitive info to data theft with malicious intent. â\nData theft by departing users\n: Detects potential data theft by users near their resignation or termination date or based on their account being deleted from Microsoft Entra ID.â\nEmail exfiltration\n: Detects when users email sensitive assets outside your organization. For example, users emailing sensitive assets to their personal email address.â\nTo get started, go to\nInsider Risk Management\n>\nPolicies\nand select\nCreate policy\n>\nQuick policy\n. If you're reviewing analytics reports, select\nView details\n>\nGet started\nto get started with a quick policy for the applicable area.\nWhen you start the quick policy workflow, review the policy settings and configure the policy with a single selection. If you need to customize a quick policy, change the conditions after the policy is created. Stay up to date with the detection results for a quick policy by configuring email notifications each time you have a policy warning or each time the policy generates a high severity alert.\nNote\nYou must be an unrestricted administrator to create quick policies.\nLearn how administrative groups affect permissions\n.\nPrioritize content in policies\nInsider Risk Management policies support specifying a higher priority for content depending on where you store it, the type of content, or how you classify it. You can also choose whether to assign risk scores to all activities detected by a policy or only activities that include priority content. Specifying content as a priority increases the risk score for any associated activity, which in turn increases the chance of generating a high severity alert. However, some activities don't generate an alert at all unless the related content contains built-in or custom sensitive info types or you specify it as a priority in the policy.\nFor example, your organization has a dedicated SharePoint site for a highly confidential project. Data leaks for information in this SharePoint site could compromise the project and would have a significant impact on its success. By prioritizing this SharePoint site in a Data leaks policy, you automatically increase risk scores for qualifying activities. This prioritization increases the likelihood that these activities generate an insider risk alert and raises the severity level for the alert.\nAdditionally, you can choose to focus this policy for SharePoint site activity that only includes priority content for this project. Risk scores are assigned and alerts are generated only when specified activities include priority content. Activities without priority content aren't scored, but you can still review them if an alert is generated.\nImportant\nCumulative exfiltration activity always receives a risk score, regardless of whether or not it contains prioritized content.\nThe following policy templates support priority content selection:\nData leaks\nData leaks by priority users\nData leaks by risky users\nData theft by departing users\nRisky AI usage\nNote\nIf you configure a policy to generate alerts only for activity that includes priority content, no changes are applied to risk score boosters.\nWhen you create an Insider Risk Management policy in the policy workflow, you can choose from the following priorities:\nSharePoint sites\n: Assign a higher risk score to any activity associated with all file types in defined SharePoint sites. Users configuring the policy and selecting priority SharePoint sites can select SharePoint sites that they have permission to access. If SharePoint sites aren't available for selection in the policy by the current user, another user with the required permissions can select the sites for the policy later, or the current user should be given access to the required sites.\nSensitive information types\n: Assign a higher risk score to any activity associated with content that contains\nsensitive information types\n.\nSensitivity labels\n: Assign a higher risk score to any activity associated with content that has specific\nsensitivity labels\napplied.\nFile extensions\n: Assign a higher risk score to any activity associated with content that has specific file extensions. Users configuring a data theft/leak policy that selects\nFile extensions to prioritize\nin the policy workflow can define up to 50 file extensions to prioritize in the policy. Entered extensions can include or omit a '.' as the first character of the prioritized extension.\nTrainable classifiers\n: Assign a higher risk score to any activity associated with content that is included in a\ntrainable classifier\n. Users configuring a policy that selects Trainable classifiers in the policy workflow can select up to 5 trainable classifiers to apply to the policy. These classifiers can be existing classifiers that identify patterns of sensitive information like social security, credit card, or bank account numbers or custom classifiers created in your organization.\nSequence detection\nRisk management activities might not occur as isolated events. These risks are frequently part of a larger sequence of events. A sequence is a group of two or more potentially risky activities performed one after the other that might suggest an elevated risk. Identifying these related user activities is an important part of evaluating overall risk. When you select sequence detection for data theft or data leaks policies, you see insights from sequence information activities on the\nUser activity\ntab within an Insider Risk Management case. The following policy templates support sequence detection:\nData leaks\nData leaks by priority users\nData leaks by risky users\nData theft by departing users\nRisky AI usage\nThese Insider Risk Management policies can use specific indicators and the order that they occur to detect each step in a sequence of risk. Selected sequence detections only detect sequences of risk in the order displayed in policy setup workflow. For policies created from the\nData leaks\nand\nData leaks by priority user\ntemplates, you can also select which sequences trigger the policy. File names are used when mapping activities across a sequence. These risks are organized into four main categories of activity:\nCollection\n: Detects download activities by in-scope policy users. Example risk management activities include downloading files from SharePoint sites, third-party cloud services, unallowed domains, or moving files into a compressed folder.\nExfiltration\n: Detects sharing or extraction activities to internal and external sources by in-scope policy users. An example risk management activity includes sending emails with attachments from your organization to external recipients.\nObfuscation\n: Detects the masking of potentially risky activities by in-scope policy users. An example risk management activity includes renaming files on a device.\nClean-up\n: Detects deletion activities by in-scope policy users. An example risk management activity includes deleting files from a device.\nNote\nSequence detection uses indicators that you enable in the global settings for Insider Risk Management. If you don't select appropriate indicators, you can turn on these indicators in the sequence detection step in the policy workflow.\nYou can customize individual threshold settings for each sequence detection type when you configure it in the policy. These threshold settings adjust alerts based on the volume of files associated with the sequence type.\nNote\nA\nsequence\nmight contain one or more events that are excluded from risk scoring based on your settings configuration. For example, your organization might use the\nGlobal exclusions\nsetting\nto exclude .png files from risk scoring since .png files aren't normally risky. But a .png file could be used to obfuscate a malicious activity. For this reason, if an event that's excluded from risk scoring is part of a sequence due to an obfuscation activity, the event is included in the sequence since it might be interesting in the context of the sequence.\nLearn more about how exclusions that are part of a sequence are shown in the Activity explorer\n.\nTo learn more about sequence detection management in the\nUser activity\nview, see\nInsider Risk Management cases: User activity\n.\nCumulative exfiltration detection\nWith privacy on by default, insider risk indicators help identify unusual levels of risk activities when evaluated daily for users that are in-scope for insider risk policies. Cumulative exfiltration detection uses machine learning models to help you identify when exfiltration activities that a user performs over a certain time exceed the normal amount performed by users in your organization for the past 30 days over multiple exfiltration activity types. For example, if a user shared more files than most users over the past month, this activity is detected and classified as a cumulative exfiltration activity.\nInsider Risk Management analysts and investigators might use cumulative exfiltration detection insights to help identify exfiltration activities that might not typically generate\nalerts\nbut are more than what is typical for their organization. Some examples might be departing users slowly exfiltrate data across a range of days, or when users repeatedly share data across multiple channels more than usual for data sharing for your organization, or compared to their peer groups.\nNote\nBy default, cumulative exfiltration detection generates risk scores based on a user's cumulative exfiltration activity compared to their organization norms. You can enable\nCumulative exfiltration detection\noptions in the\nPolicy indicators\nsection of the Insider Risk Management settings page.\nHigher risk scores are assigned to cumulative exfiltration activities for SharePoint sites, sensitive information types, and content with\nsensitivity labels\nconfigured as priority content in a policy or for activity involving labels configured as high priority in\nMicrosoft Purview Information Protection\n.\nCumulative exfiltration detection is enabled by default when using the following policy templates:\nData leaks\nData leaks by priority users\nData leaks by risky users\nData theft by departing users\nImportant\nThe option to only score activities containing priority content doesn't apply to cumulative exfiltration activities. Cumulative exfiltration activity always receives a risk score, regardless of whether or not it contains prioritized content.\nPeer groups for cumulative exfiltration detection\nInsider Risk Management identifies three types of peer groups for analyzing exfiltration activity performed by users. It defines peer groups for users based on the following criteria:\nSharePoint sites\n: Insider Risk Management identifies peer groups based on users who access similar SharePoint sites.\nSimilar organization\n: Users with reports and team members based on organization hierarchy. This option requires that your organization uses Microsoft Entra ID to maintain organization hierarchy.\nSimilar job title\n: Users with a combination of organizational distance and similar job titles. For example, a user with a Senior Sales Manager title with a similar role designation as a Lead Sales Manager in the same organization is identified as similar job title. This option requires that your organization uses Microsoft Entra ID to maintain organization hierarchy, role designations, and job titles. If you don't have Microsoft Entra ID configured for organization structure and job titles, then Insider Risk Management identifies peer groups based on common SharePoint sites.\nWhen you enable cumulative exfiltration detection, your organization agrees to share Microsoft Entra data with the Microsoft Purview portal, including organization hierarchy and job titles. If your organization doesn't use Microsoft Entra ID to maintain this information, detection might be less accurate.\nNote\nCumulative exfiltration detection uses exfiltration indicators that you enable in the global settings for Insider Risk Management and exfiltration indicators that you select in a policy. As such, cumulative exfiltration detection only evaluates the necessary exfiltration indicators. Cumulative exfiltration activities for\nsensitivity labels\nconfigured in priority content generate higher risk scores.\nWhen you enable cumulative exfiltration detection for data theft or data leak policies, insights from cumulative exfiltration activities appear on the\nUser activity\ntab within an Insider Risk Management case. For more information about user activity management, see\nInsider Risk Management cases: User activities\n.\nPolicy health\nNote\nIf your policy is\nscoped by one or more administrative units\n, you can only view policy health for the policies you're scoped for. If you're an unrestricted administrator, you can view policy health for all policies in the tenant.\nThe policy health status gives you insights into potential issues with your Insider Risk Management policies. The\nStatus\ncolumn on the\nPolicies\ntab alerts you to policy issues that might prevent user activity from being reported or explain why the number of activity alerts is unusual. The policy health status also confirms that the policy is healthy and doesn't need attention or configuration changes.\nImportant\nYou must have the\nInsider Risk Management\nor the\nInsider Risk Management Admins\nrole to access policy health.\nIf there are issues with a policy, the policy health status displays notification warnings and recommendations to help you take action to resolve policy issues. These notifications can help you resolve the following issues:\nPolicies with incomplete configuration\n. These issues might include missing users or groups in the policy or other incomplete policy configuration steps.\nPolicies with indicator configuration issues\n. Indicators are an important part of each policy. If you don't configure indicators, or if you select too few indicators, the policy might not evaluate risky activities as expected.\nPolicy triggers aren't working, or policy trigger requirements aren't properly configured\n. Policy functionality might depend on other services or configuration requirements to effectively detect triggering events to activate risk score assignment to users in the policy. These dependencies might include issues with connector configuration, Microsoft Defender for Endpoint alert sharing, or data loss prevention policy configuration settings.\nVolume limits are nearing or over limits\n. Insider Risk Management policies use numerous Microsoft 365 services and endpoints to aggregate risk activity signals. Depending on the number of users in your policies, volume limits might delay identification and reporting of risk activities. Learn more about these limits in the Policy template limits section of this article.\nTo quickly view the health status for a policy, go to the\nPolicy\ntab and check the\nStatus\ncolumn. You see the following policy health status options for each policy:\nHealthy\n: No issues are identified with the policy.\nRecommendations\n: An issue with the policy that might prevent the policy from operating as expected.\nWarnings\n: An issue with the policy that might prevent it from identifying potentially risky activities.\nFor more details about any recommendations or warnings, select a policy on the\nPolicy\ntab to open the policy details card. The\nNotifications\nsection of the details card displays more information about the recommendations and warnings, including guidance on how to address these issues.\nNotification messages\nUse the following table to learn more about recommendations and warning notifications and actions to take to resolve potential issues.\nNotification messages\nPolicy templates\nCauses / Try this action to fix\nDLP policy doesn't meet requirements\n- Data leaks\n- Data leaks by priority users\nDLP policies used as triggering events must be configured to generate high severity alerts.\n1. Edit your DLP policy to assign applicable alerts as\nHigh severity\n.\nOR\n2. Edit this policy and select\nUser performs an exfiltration activity\nas the triggering event.\nDLP policy isn't selected as the triggering event\n- Data leaks\n- Data leaks by priority users\nA DLP policy wasn't selected as a triggering event or the selected DLP policy was deleted.\nEdit the policy and either select an active DLP policy or 'User performs an exfiltration activity' as the triggering event in the policy configuration.\nDLP policy used in this policy is turned off\n- Data leaks\n- Data leaks by priority users\nDLP policy used in this policy is turned off.\n1. Turn the DLP policy assigned to this policy on.\nOR\n2. Edit this policy and either select a new DLP policy or 'User performs an exfiltration activity' as the triggering event in the policy configuration.\nHR connector hasn't uploaded data recently\n- Data theft by departing user\n- Security policy violations by departing user\n- Data leaks by risky users\n- Security policy violations by risky users\nHR connector didn't import data in more than 7 days.\nCheck that your HR connector is configured correctly and sending data.\nHR connector isn't configured or working as expected\n- Data theft by departing user\n- Security policy violations by departing user\n- Data leaks by risky users\n- Security policy violations by risky users\nThere's an issue with the HR connector.\n1. If you're using an HR connector, check that your HR connector is sending correct data\nOR\n2. Select the Microsoft Entra account deleted triggering event.\nMicrosoft Defender for Endpoint alerts aren't being shared with the Microsoft Purview portal\n- Security policy violations\n- Security policy violations by departing users\n- Security policy violations by risky users\n- Security policy violations by priority users\nMicrosoft Defender for Endpoint alerts aren't being shared with the Microsoft Purview portal.\nConfigure sharing of Microsoft Defender for Endpoint alerts.\nNo devices are onboarded\n- Data theft by departing users\n- Data leaks\n- Data leaks by risky users\n- Data Leaks by priority users\nDevice indicators are selected but there aren't any devices onboarded to the Microsoft Purview portal\nCheck whether devices are onboarded and meet requirements.\nNo indicators have been selected for this policy\nAll policy templates\nIndicators weren't selected for the policy\nEdit your policy and select appropriate policy indicators for the policy.\nNo priority user groups are included in this policy\n- Data leaks by priority users\n- Security policy violations by priority users\nPriority user groups aren't assigned to the policy.\nConfigure priority user groups in Insider Risk Management settings and assign priority user groups to the policy.\nNo triggering event has been selected for this policy\nAll policy templates\nA triggering event isn't configured for the policy\nRisk scores won't be assigned to user activities until you edit the policy and select a triggering event.\nNo users or groups are included in this policy\nAll policy templates\nUsers or groups aren't assigned to the policy.\nEdit your policy and select users or groups for the policy.\nPolicy hasn't generated any alerts\nAll policy templates\nYou might want to review your policy configuration so that you're analyzing the most relevant scoring activity.\n1. Confirm that you selected indicators that you want to score. The more indicators selected, the more activities are assigned risk scores.\n2. Review threshold customization for policy. If the thresholds selected don't align with your organization's risk tolerance, adjust the selections so that alerts are created based on your preferred thresholds.\n3. Review the users and groups selected for the policy. Confirm you selected all of the applicable users and groups.\n4. For security violation policies, confirm you selected the alert triage status that you want to score for Microsoft Defender for Endpoint alerts in Intelligent Detections in settings.\nPolicy isn't assigning risk scores to activity\nAll policy templates\nYou might want to review your policy scope and triggering event configuration so that the policy can assign risk scores to activities\n1. Review the users that are selected for the policy. If you have few users selected, you might want to select additional users.\n2. If you're using an HR connector, check that your HR connector is sending the correct data.\n3. If you're using a DLP policy as your triggering event, check your DLP policy configuration to ensure it's configured to be used in this policy.\n4. For security violation policies, review the Microsoft Defender for Endpoint alert triage status selected in Insider risk settings > Intelligent detections. Confirm that the alert filter isn't too narrow.\nTriggering event is repeatedly occurring for over 15% of users in this policy\nAll policy templates\nAdjust the triggering event to help reduce how often users are brought into the policy scope.\nWe're unable to check the status of your HR connector right now, please check again later\n- Data theft by departing user\n- Security policy violations by departing user\n- Data leaks by risky users\n- Security policy violations by risky users\nThe Insider Risk Management solution is unable to check the status of your HR connector.\nCheck that your HR connector is configured correctly and sending data, or come back and check the policy status.\nYou're approaching the maximum limit of users being actively scored for this policy template\nAll policy templates\nEach policy template has a maximum number of included users. See the template limit section details.\nReview the users in the Users tab and remove any users who don't need to be scored anymore.\nYour organization doesn't have a Microsoft Defender for Endpoint subscription\n- Security policy violations\n- Security policy violations by departing users\n- Security policy violations by risky users\n- Security policy violations by priority users\nAn active Microsoft Defender for Endpoint subscription wasn't detected for your organization.\nUntil a Microsoft Defender for Endpoint subscription is added, these policies won't assign risk scores to user activity.\nCreate a new policy\nTo create a new Insider Risk Management policy, generally use the policy workflow in the\nInsider Risk Management\nsolution in the Microsoft Purview portal. You can also create quick policies for general data leaks and data theft by departing users from Analytics checks if applicable.\nComplete\nStep 6: Create an Insider Risk Management policy\nto configure new insider risk policies.\nUpdate a policy\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nPolicies\nin the left navigation.\nOn the policy dashboard, select the policy you want to update.\nOn the policy details page, select\nEdit policy\n.\nOn the\nName and description\npage, update the description for the policy if you want.\nNote\nYou can't edit the\nPolicy template\nor\nName\nfield.\nSelect\nNext\nto continue.\nFollow\nstep 7 of the Create a policy procedure\n.\nCopy a policy\nYou might need to create a new policy that's similar to an existing policy but needs just a few configuration changes. Instead of creating a new policy from scratch, you can copy an existing policy and then modify the areas that need to be updated in the new policy.\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nPolicies\nin the left navigation.\nOn the policy dashboard, select the policy you want to copy.\nOn the policy details page, select\nCopy\n.\nIn the policy workflow, name the new policy, and then update the policy configuration as needed.\nImmediately start scoring user activity\nSome scenarios require assigning risk scores to users with insider risk policies outside of the Insider Risk Management triggering event workflow. Use\nStart scoring activity for users\non the\nPolicies\ntab to manually add one or more users to one or more insider risk policies for a specific amount of time. This action starts assigning risk scores to their activity and bypasses the requirement for a user to have a triggering indicator, like a DLP policy match or an Employment End Date from the HR Connector.\nThe value in the\nReason for scoring activity\nfield appears on the users' activity timeline. The\nUsers\ndashboard displays users you manually add to policies, and alerts are created if the activity meets the policy alert thresholds. You can have up to 4,000 users in scope that you manually add by using the\nStart scoring activity for users\nfeature.\nSome scenarios where you might want to immediately start scoring user activities include:\nYou identify users with risk concerns and want to immediately start assigning risk scores to their activity for one or more of your policies.\nThere's an incident that might require you to immediately start assigning risk scores to involved users' activity for one or more of your policies.\nYou haven't configured your HR connector yet, but you want to start assigning risk scores to user activities for HR events by uploading a .csv file.\nNote\nIt might take several hours for manually added users to appear in the\nUsers\ndashboard. Activities for the previous 90 days for these users might take up to 24 hours to display. To view activities for manually added users, go to the\nUsers\ntab, select the user on the\nUsers\ndashboard, and then open the\nUser activity\ntab on the details pane.\nManually start scoring activity for users in one or more Insider Risk Management policies\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nPolicies\nin the left navigation.\nOn the policy dashboard, select the policies where you want to add users.\nSelect\nStart scoring activity for users\n.\nIn the\nAdd users to multiple policies\npane, enter a reason for adding the users in the\nReason\nfield.\nDefine the number of days to score the user's activity in the\nThis should last for (choose between 5 and 30 days)\nfield.\nEnter the name of the user you want to add, or use the\nSearch user to add to policies\nfield to search for a user, then select the user name. Repeat this process to assign additional users. The list of users you select appears in the users section of the\nAdd users to multiple policies\npane.\nNote\nIf the policy is scoped by\none or more administrative units\n, you can only see users that you're scoped for.\nSelect\nImport\nto import a .csv (comma-separated values) file to import a list of users. The file must be in the following format and must list the user principal names:\nuser principal name\nuser1@domain.com\nuser2@domain.com\nSelect\nAdd users to policies\nto accept the changes.\nStop scoring users in a policy\nTo stop scoring users in a policy, see the\nInsider Risk Management users: Remove users from in-scope assignment to policies\narticle.\nDelete a policy\nImportant\nYou can't undo a policy deletion.\nWhen you delete a policy, you have two options. You can:\nDelete just the policy.\nDelete the policy and all associated alerts and users.\nIf you choose the second option:\nAll alerts generated by that policy are deleted unless they're associated with a case. Associated cases are never deleted when you delete a policy.\nAny user associated with an alert from that policy is removed from the\nUsers\npage.\nIf a user is in scope of more than one policy, you remove the user only from the policy that you're deleting. You don't remove the user from other active policies.\nFor example, you might create a policy for test purposes before rolling it out to your organization. After you finish testing, you can quickly delete the policy and all associated test data so that you can start fresh when you're ready to push the policy live.\nIt can take up to 72 hours to complete a policy deletion.\nNote\nIf you delete a policy associated with Insider Risk Management\nAdaptive Protection\n, you see a warning that Adaptive Protection stops assigning insider risk levels to users until you choose a different policy in Adaptive Protection. This warning appears because Adaptive Protection must be associated with a policy to be in effect.\nTo delete a policy\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nPolicies\nin the left navigation.\nOn the policy dashboard, select the policy you want to delete.\nSelect\nDelete\non the dashboard toolbar.\nChoose one of the following options:\nSelect\nDelete only the policy\n.\nSelect\nDelete the policy and all associated alerts and users\n.\nImportant\nYou can't undo a policy deletion.\nSelect\nConfirm\n.\nYou see a message in the upper part of the screen that tells you if the deletion was successful or whether it's pending.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create Insider Risk Policies",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/insider-risk-management-settings-policy-indicators": {
      "content_hash": "sha256:75afdb923b1c273be3c13c33afcfcd88b0cf2d610f398dfdd24170e848abfcfa",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConfigure policy indicators in Insider Risk Management\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Insider Risk Management\ncorrelates various signals to identify potential malicious or inadvertent insider risks, such as IP theft, data leakage, and security violations. Insider Risk Management enables customers to create policies to manage security and compliance. Built with privacy by design, users are pseudonymized by default, and role-based access controls and audit logs are in place to help ensure user-level privacy.\nInsider risk policy templates in Microsoft Purview Insider Risk Management define the type of risk activities that you want to detect and investigate. Each policy template is based on specific indicators that correspond to specific triggers and risk activities. All global indicators are disabled by default;\nyou must select one or more indicators to configure an Insider Risk Management policy\n.\nPolicies collect signals and trigger alerts when users perform activities related to the indicators.\nTypes of events and indicators\nInsider Risk Management uses different types of events and indicators to collect signals and create alerts:\nTriggering events\n: Events that determine if a user is active in an Insider Risk Management policy. If you add a user to an Insider Risk Management policy that doesn't have a triggering event, the policy doesn't evaluate the user as a potential risk. For example, User A is added to a policy created from the\nData theft by departing users\npolicy template and the policy and Microsoft 365 HR connector are properly configured. Until User A has a termination date reported by the HR connector, the policy doesn't evaluate User A for potential risk. Another example of a triggering event is if a user has a\nHigh\nseverity data loss prevention (DLP) policy alert when using\nData leaks\npolicies.\nGlobal settings indicators\n: Indicators enabled in global settings for Insider Risk Management define both the indicators available for configuration in policies and the types of events signals collected by Insider Risk Management. For example, if a user copies data to personal cloud storage services or portable storage devices and you select these indicators only in global settings, you can review the user's potentially risky activity in the Activity explorer. If you don't define this user in an Insider Risk Management policy, the policy doesn't evaluate the user as a potential risk and therefore doesn't assign a risk score or generate an alert.\nPolicy indicators\n: Indicators included in Insider Risk Management policies determine a risk score for an in-scope user. You enable policy indicators from indicators defined in global settings. The policy indicators activate only after a triggering event occurs for a user. Examples of policy indicators include:\nA user copies data to personal cloud storage services or portable storage devices.\nA user account is removed from Microsoft Entra ID.\nA user shares internal files and folders with unauthorized external parties.\nYou can use certain policy indicators and sequences to customize triggering events for specific policy templates. When you configure these indicators or sequences in the policy workflow for the\nGeneral data leaks\nor\nData leaks by priority users\ntemplates, you get more flexibility and customization for your policies and when users are in-scope for a policy. You can also define risk management activity thresholds for these triggering indicators for more fine-grained control in a policy.\nDefine the insider risk policy indicators that are enabled in all insider risk policies\nSelect\nSettings\n, then select\nPolicy indicators\n.\nSelect one or more policy indicators.\nThe indicators you select on the\nPolicy indicators\nsettings page can't be individually configured when creating or editing an insider risk policy in the policy workflow.\nNote\nIt might take several hours for new manually added users to appear in the\nUsers dashboard\n. Activities for the previous 90 days for these users might take up to 24 hours to display. To view activities for manually added users, select the user on the\nUsers dashboard\nand open the\nUser activity\ntab in the details pane.## Two types of policy indicators: built-in indicators and custom indicators\nIndicators and pay-as-you-go billing\nSome indicators included in Insider Risk Management require that you enable the\npay-as-you-go billing model\nfor your organization. Depending on your configured billing model, a notification might be displayed prompting you to configure pay-as-you-go billing to use these indicators.\nBuilt-in indicators vs. custom indicators\nPolicy indicators are organized into two tabs:\nBuilt-in indicators\n: Insider Risk Management includes many built-in indicators for various scenarios that you can use right away in your policies. Choose the indicators that you want to activate, then customize indicator thresholds for each indicator level when you create an insider risk policy. This article describes the built-in indicators in more detail.\nCustom indicators\n: Use custom indicators together with the\nInsider Risk Indicators (preview) connector\nto bring non-Microsoft detections to Insider Risk Management. For example, you might want to extend your detections to include Salesforce and Dropbox and use them alongside the built-in detections provided by the Insider Risk Management solution, which is focused on Microsoft workloads (SharePoint Online and Exchange Online, for example).\nLearn more about creating a custom indicator\nBuilt-in indicators\nInsider Risk Management includes the following built-in indicators.\nOffice indicators\nThese indicators include policy indicators for SharePoint sites, Microsoft Teams, and email messaging.\nCloud storage indicators\nImportant\nTo use this indicator, enable\npay-as-you-go billing\nin your organization.\nThese indicators include policy indicators for Google Drive, Box, and Dropbox that you can use to detect techniques used to determine the environment, gather and steal data, and disrupt the availability or compromise the integrity of a system. To select from\ncloud storage indicators\n, you must\nfirst connect to the relevant cloud storage apps in Microsoft Defender\n.\nAfter configuring these indicators, you can turn off indicators for the apps you don't want to use in settings. For example, you can select a content download indicator for Box and Google Drive, but not Dropbox.\nCloud service indicators\nImportant\nTo use this indicator, enable\npay-as-you-go billing\nin your organization.\nThese indicators include policy indicators for Amazon S3 and Azure (SQL Server and Storage) that you can use to detect techniques used to avoid detection or risky activities. These techniques might include:\nDisabling trace logs\nUpdating or deleting SQL Server firewall rules\nTechniques used to steal data, such as sensitive documents\nTechniques used to disrupt the availability or compromise the integrity of a system\nTechniques used to gain higher-level permissions to systems and data.\nTo select from\ncloud service indicators\n, you must\nfirst connect to the relevant source service apps in Microsoft Defender\n.\nNetwork indicators\nImportant\nTo use this indicator, enable\npay-as-you-go billing\nin your organization.\nThese indicators include HTTP and HTTPS network traffic from third party network security solutions. You can identify sensitive items that are being shared through these interactions. Detection of these activities requires creation of\ncollection policy\nas a pre-requisite. Learn more about\nnetwork data security\n.\nMicrosoft Entra ID indicators\nThese indicators include risk detections from\nMicrosoft Entra ID Protection\n. Risk detections are a powerful resource that can include any suspicious or anomalous activity related to a user account in the directory. Microsoft Entra ID Protection risk detections can be linked to an individual user or sign-in event.\nUser risk detections might flag a legitimate user account as at risk when a potential threat actor gains access to an account by compromising their credentials or when they detect some type of anomalous user activity. Sign-in risk detections represent the probability that a given authentication request isn't the authorized owner of the account.\nTo maintain relevance of the indicators to Insider Risk Management policies, only Microsoft Entra alerts in a\nConfirmedCompromised\nor\nRemediated\nstatus state are evaluated. To learn more about the risk detections in Microsoft Entra ID Protection, see\nRisks detections in Microsoft Entra ID Protection\n.\nMicrosoft Fabric indicators\nImportant\nTo use this indicator, enable\npay-as-you-go billing\nin your organization.\nThese indicators include policy indicators for Microsoft Power BI that you can use to detect techniques used to figure out the environment (such as viewing Power BI reports and dashboards) and techniques used to gather data of interest (such as downloading Power BI reports).\nGenerative AI apps indicators (preview)\nThese indicators include policy indicators for numerous generative AI applications. Use these indicators in policies to analyze interactions (prompts and responses) entered into these applications and help detect inappropriate or risky interactions or sharing of confidential information. These indicators include the following generative AI applications:\nMicrosoft Copilot experiences\n: Support for user interactions in\nCopilot in Microsoft Fabric\n,\nMicrosoft Security Copilot\n,\nMicrosoft Copilot Studio\n, any connected or cloud AI application.\nImportant\nTo use this indicator for non-Microsoft 365 AI data, enable\npay-as-you-go billing\nin your organization. Non-Microsoft 365 AI data includes information from other generative AI applications from Microsoft and other connected external AI applications. This data type includes\nCopilot in Microsoft Fabric\n,\nMicrosoft Security Copilot\n,\nMicrosoft Copilot Studio\n, and any connected or cloud AI application. There aren't any pay-as-you-go billing requirements or charges for Microsoft 365 detecting inappropriate or risky interaction for Microsoft 365 Copilot data.\nEnterprise AI apps\n: Non-Copilot AI applications connected using\nMicrosoft Entra\nand\nMicrosoft Purview Data Map\nconnectors.\nImportant\nTo use this indicator, enable\npay-as-you-go billing\nin your organization.\nOther AI applications\n: AI applications that users in your organization discover from their browser activity.\nAzure AI Content Safety indicators\n: Support for\nCommunication Compliance indicators\nto identify prompts and responses matching classifiers provided by Azure AI Content Safety like\nPrompt shields\nand\nProtected Materials\n.\nImportant\nWhen you select this indicator, you create a Communication Compliance policy. If you modify this policy in Communication Compliance, you might need to pay for\npay-as-you-go billing\n.\nCommunication Compliance indicators\nThese indicators include policy indicators that detect employment stressor events, such as emotional outbursts, bullying, failure to take criticism, inability to work or communicate with a team or group, discrimination, violent threats, extremist behavior, and so on. Insider Risk Management works together with the\nMicrosoft Purview Communication Compliance solution\nto detect these types of stressors that indicate an unhealthy workplace environment. Employment stressor events can impact user behavior for risky personas (whether initiators or targets of bad behavior) in several ways that relate to insider risks. Counterproductive work behavior can be a precursor to more serious violations, such as sabotaging company assets or leaking sensitive information.\nAdditionally, you can choose to detect messages matching specific\nsensitivity information types (SITs)\n. Including sensitive information inadvertently or maliciously included in messages to user risk scores and their activity history provides investigators with more information to help quickly take actions to mitigate potential data leakage. You can select up to 30 SITs for a policy. Some scenarios might include helping to detect:\nForeign recruitment\nState actor poaching\nSharing sensitive information like secret formulas, financial reports, and other proprietary property\nSharing passwords\nNote\nYou can also\nuse a Communication Compliance policy as a trigger\n.\nHow it works\nYou can choose from these Communication Compliance indicators:\nSending inappropriate content\nSending financial regulatory text that might be risky\nSending inappropriate images\nYou can also choose to detect sensitive information types included in messages.\nWhen you select\nCreate policy\nfrom the\nCommunication Compliance indicators\nsection:\nA single policy is created in Communication Compliance that detects messages in Microsoft Exchange Online, Microsoft Teams, Microsoft Viva Engage, and Microsoft 365 Copilot and Microsoft 365 Copilot Chat. The Communication Compliance policy is based on the indicators and SITs you select. Each indicator is associated with specific\ntrainable classifiers\nused by Communication Compliance. For more information, see\nContent safety classifiers based on large language models\n.\nTip\nSelect the information icon next to each indicator to see the trainable classifiers that the indicator uses.\nIn Communication Compliance, the trainable classifiers and SITs are listed as conditions for the policy.\nThe Communication Compliance policy is named \"Insider risk indicator\" plus the timestamp, for example: \"Insider risk indicator 24-05-01T09.27.17Z\" or \"Insider risk SIT indicator 24-05-01T09.27.17Z\".\nAnyone with the\nInsider Risk Investigators\nrole in Insider Risk Management is automatically added as a reviewer for the Communication Compliance policy.\nNote\nAfter creating the Communication Compliance policy, to add a reviewer to the policy, you must\nadd the reviewer manually to the\nCommunication Compliance Investigators\nrole group\n.\nIf you turn off all of the indicators in the\nPolicy indicators\nsetting, you pause the Communication Compliance policy. The policy is reenabled if you turn any of the indicators back on.\nYou make the Communication Compliance indicators available for new and existing policies in Insider Risk Management that are based on the\nData theft\nor\nData leaks\ntemplates.\nIf content sent in a message matches any of the trainable classifiers, it results in a policy match in Communication Compliance that can be\nremediated from the\nPolicies\npage\n.\nIndicators included in Insider Risk Management policies determine a risk score for an in-scope user. They activate only after a triggering event occurs for a user.\nCommunication Risk\ninsights appear in the\nActivity explorer\nand\nUser activity\ntabs in Insider Risk Management. If you drill down into a policy match from the\nActivity explorer\nor\nUser activity\ntab, you can learn more about the activity and access a link that opens the Communication Compliance policy. In the Communication Compliance policy, you can see the content of the messages that were sent.\nNote\nYou must have the\nCommunication Compliance\nrole or the\nCommunication Compliance Investigators\nrole to access the Communication Compliance link.\nEnable Communication Compliance indicators in Insider Risk Management\nIn Insider Risk Management, go to\nSettings\n>\nPolicy indicators\n, then scroll to the\nCommunication Compliance indicators (preview)\nsection.\nUnder\nDetect messages matching specific trainable classifiers (preview)\n, select\nCreate policy\n.\nThe policy you create is in Communication Compliance, and the Communication Compliance indicators become available in the\nPolicy indicators\nsetting.\nNote\nIf you already created a Communication Compliance policy but paused it, selecting\nCreate policy\nresumes the Communication Compliance policy. In this case, the\nStatus\ncolumn in the Communication Compliance\nPolicies\nlist shows \"Resuming\".\nSelect one or more of the Communication Compliance indicators in the\nPolicy indicators\nsetting.\nNote\nIf you already created a Communication Compliance policy and you select different indicators, the Communication Compliance policy changes to reflect the appropriate trainable classifiers. Turning off all indicators pauses the Communication Compliance policy.\nSelect\nSave\n.\nTo use the indicators,\ncreate a new insider risk policy\nor\nedit an existing policy\n. The indicators appear on the\nIndicators\npage of the policy workflow. You can adjust thresholds for the indicators as you would for any other indicators in an Insider Risk Management policy.\nNote\nAt this time, real-time analytics for indicator threshold settings aren't available for the Communication Compliance indicators.\nData loss prevention alerts indicators\nThese indicators include policy indicators that integrate with\ndata loss prevention (DLP)\npolicies. By selecting DLP policies as indicators in Insider Risk Management policies, you can automatically detect if a user has existing alerts in connected DLP policies. DLP policies help protect sensitive information and reduce the risks of oversharing data with inappropriate users or organizations.\nWhen an Insider Risk Management alert is generated for a user, you can quickly determine if the user has any high risk alerts associated with DLP policies in your organization without having to navigate to DLP solution in the Microsoft Purview portal. You can review and evaluate the Insider Risk Management activity and associated DLP alerts within Insider Risk Management in a unified view.\nConfigure DLP alerts indicators\nStep 1\n: To enable the DLP alerts as indicators, complete the following steps:\nIn Insider Risk Management settings, select\nPolicy indicators\nand then select the\nBuilt-in Indicators\ntab.\nNavigate to\nData loss prevention (DLP) indicators\nSelect\nAdd DLP policies\nSelect the DLP policies that you want to see alerts for in Insider Risk Management.\nSelect\nAdd\n.\nSelect the\nGenerating alerts from selected DLP policies\ncheckbox.\nSelect\nSave\n.\nStep 2\n: To assign DLP alerts indicators to a specific Insider Risk Management policy, complete the following steps:\nCreate a custom policy\nusing one of the following templates:\nData theft by departing users\nData leaks\nData leaks by priority users\nData leaks by risky users\nRisky AI usage\nConfigure the policy as applicable until you reach the\nIndicators\npage.\nOn the\nIndicators\npage, navigate to\nData loss prevention (DLP) indicators\n.\nSelect the\nGenerating alerts from selected DLP policies\ncheckbox.\nComplete the policy configuration workflow and save the new policy.\nDevice indicators\nThese policy indicators include activities such as sharing files over the network or with devices. Indicators include activities involving all file types, excluding executable (.exe) and dynamic link library (.dll) file activity. If you select\nDevice indicators\n, the system processes activity for devices with Windows 10 Build 1809 or higher and macOS (three latest released versions) devices. For both Windows and macOS devices, you must\nfirst onboard devices\n. Device indicators also include browser signal detection to help your organization detect and act on exfiltration signals for nonexecutable files viewed, copied, shared, or printed in Microsoft Edge and Google Chrome. For more information on configuring Windows devices for integration with insider risk, see\nEnable device indicators and onboard Windows devices\nin this article. For more information on configuring macOS devices for integration with insider risk, see\nEnable device indicators and onboard macOS devices\nin this article. For more information about browser signal detection, see\nLearn about and configure Insider Risk Management browser signal detection\n.\nImportant\nDevice indicators are included in\ncollection policy\nevaluations. When you configure and deploy a collection policy, if there's a mismatch between an Insider Risk Management policy that includes device indicators and a collection policy in your organization, the collection policy configuration takes precedence. This configuration means that if you configure an Insider Risk Management policy to monitor a specific activity for devices, but you configure the collection policy to filter out that device activity, the device activity isn't collected and isn't available for review in Insider Risk Management.\nMicrosoft Defender for Endpoint indicators (preview)\nThese indicators come from Microsoft Defender for Endpoint and relate to unapproved or malicious software installation or bypassing security controls. To receive alerts in Insider Risk Management, you must have an active Defender for Endpoint license and insider risk integration enabled. For more information on configuring Defender for Endpoint for Insider Risk Management integration, see\nConfigure advanced features in Microsoft Defender for Endpoint\n.\nHealth record access indicators\nThese policy indicators cover patient medical record access. For example, attempted access to patient medical records in your electronic medical records (EMR) system logs can be shared with Insider Risk Management healthcare policies. To receive these types of alerts in Insider Risk Management, you must have a healthcare-specific data connector and the\nHR data connector\nconfigured.\nPhysical access indicators\nThese policy indicators cover physical access to sensitive assets. For example, attempted access to a restricted area in your physical badging system logs can be shared with Insider Risk Management policies. To receive these types of alerts in Insider Risk Management, you must have priority physical assets enabled in Insider Risk Management and the\nPhysical badging data connector\nconfigured. To learn more about configuring physical access, see the\nPriority physical access section\nin this article.\nMicrosoft Defender for Cloud Apps indicators\nThese policy indicators come from shared alerts from Defender for Cloud Apps. Automatically enabled anomaly detection in Defender for Cloud Apps immediately starts detecting and collating results, targeting numerous behavioral anomalies across your users and the machines and devices connected to your network. To include these activities in Insider Risk Management policy alerts, select one or more indicators in this section. To learn more about Defender for Cloud Apps analytics and anomaly detection, see\nGet behavioral analytics and anomaly detection\n.\nRisky Agents indicators (preview)\nThese policy indicators cover agent interactions with users and sensitive or risky resources. Risky agent prompts, agent generated sensitive responses, accessing sensitive or priority SharePoint files, agents accessing risky websites, or agents using tools with sensitive information are included.\nRisky AI usage indicators (preview)\nThese policy indicators cover Microsoft AI tools and applications. Risky prompt behavior from users and AI-generated responses that include sensitive information are both included in these indicators. For example, attempted sharing of sensitive information in an AI tool or application by a user is considered risky activity. Similarly, an AI tool or application returning a response that contains sensitive information is also considered risky behavior.\nRisky browsing indicators (preview)\nThese policy indicators cover browsing activity related to websites that are considered malicious or risky and pose potential insider risk that might lead to a security or compliance incident. Risky browsing activity refers to users who visit potentially risky websites, such as those associated with malware, pornography, violence, and other unallowed activities. To include these risk management activities in policy alerts, select one or more indicators in this section. To learn about configuring browser exfiltration signals, see\nInsider Risk Management browser signal detection\n.\nCumulative exfiltration detection indicators\nThese indicators detect when a user's exfiltration activities across all exfiltration channels over the last 30 days exceed organization or peer group norms. For example, if a user is in a sales role and communicates regularly with customers and partners outside of the organization, their external email activity is likely higher than the organization's average. However, the user's activity might not be unusual compared to the user's teammates, or others with similar job titles. A risk score is assigned if the user's cumulative exfiltration activity is unusual and exceeds organization or peer group norms.\nNote\nPeer groups are defined based on organization hierarchy, access to shared SharePoint resources, and job titles in Microsoft Entra ID. If you enable cumulative exfiltration detection, your organization agrees to share Microsoft Entra data with the Microsoft Purview portal, including organization hierarchy and job titles. If your organization doesn't use Microsoft Entra ID to maintain this information, detection might be less accurate.\nRisk score boosters\nThese indicators raise the risk score for activity for the following reasons:\nActivity that is above the user's usual activity for that day\n: Scores are boosted if the detected activity deviates from the user's typical behavior.\nUser had a previous case resolved as a policy violation\n: Scores are boosted if the user had a previous case in Insider Risk Management that was resolved as a policy violation.\nUser is a member of a priority user group\n: Scores are boosted if the user is a member of a priority user group.\nUser is detected as a potential high impact user\n: When you enable this indicator, users are automatically flagged as potential high-impact users based on the following criteria:\nThe user interacts with more sensitive content compared to others in the organization.\nThe user's level in the organization's Microsoft Entra hierarchy.\nThe total number of users reporting to the user based on the Microsoft Entra hierarchy.\nThe user is a member of a Microsoft Entra built-in role with elevated permissions.\nNote\nWhen you enable the potential high impact user risk score booster, you agree to share Microsoft Entra data with the Microsoft Purview portal. If your organization doesn't use sensitivity labels or has not configured organization hierarchy in Microsoft Entra ID, this detection might be less accurate. If a user is detected as both a member of a priority user group and also a potential high-impact user, their risk score is only boosted once.\nIn some cases, you might want to limit the insider risk policy indicators that apply to insider risk policies in your organization. You can turn off the policy indicators for specific areas by disabling them from all insider risk policies in global settings. You can only modify triggering events for policies created from the\nData leaks\nor\nData leaks by priority users\ntemplates. Policies created from all other templates don't have customizable triggering indicators or events.\nCustom indicators\nUse the\nCustom Indicators\ntab to create a custom indicator to use as a trigger or as a policy indicator in your policies.\nNote\nTo create a custom indicator to import third-party indicator data, you must first\ncreate an Insider Risk Indicators connector\n(preview).\nIn Insider Risk Management settings, select\nPolicy indicators\nand then select the\nCustom Indicators\ntab.\nSelect\nAdd custom indicator\n.\nEnter an indicator name and a description (optional).\nIn the\nData connector\nlist, select the Insider Risk Indicator connector that you created previously.\nWhen you select a data connector:\nThe name of the source column that you select when you create the connector appears in the\nSource column from mapping file\nfield. If you don't select a source column when you create the connector,\nNone\nappears in this field and you don't need to make a selection.\nIn the\nValues in source column\nlist, select the value that you want to assign to the custom indicator. These values relate to the source column that you specified when you created the connector. For example, if you create a single connector that includes data for two indicators (Salesforce and Dropbox), you see those values in the list.\nIf you want to use a column to set threshold values, in the\nData from mapping file\nlist, select the column that you want to use for the threshold setting; otherwise, select the\nUse only as a triggering event without any thresholds\noption.\nNote\nOnly fields that have a\nNumber\ndata type appear in the\nData from mapping file\nlist, since a\nNumber\ndata type is required to set a threshold value. The data type is specified when you set up the connector.\nSelect\nAdd indicator\n. The indicator is added to the\nCustom Indicators\nlist.\nNow you can\nuse the custom indicator\nin any\nData theft\nor\nData leaks\npolicies that you create or edit.\nIf you use the custom indicator as a trigger, select your custom trigger on the\nTriggers\npage when you create or edit the policy.\nIf you use the custom indicator as a policy indicator, select your custom indicator on the\nIndicators\npage when you create or edit the policy.\nNote\nAfter selecting your custom trigger or indicator, make sure to set a custom threshold (don't use the default thresholds). You can't set trigger thresholds on a custom indicator if you select the\nUse only as a triggering event without any thresholds\noption.\nAfter adding the custom indicator to your policies, the triggers and insights generated based on the custom indicators appear in the\nAlerts dashboard\n,\nActivity explorer\n, and\nUser timeline\n.\nImportant\nWait 24 hours before\nuploading the data\nafter you update the custom indicators and the associated policies. It can take several hours to sync all components. If you immediately upload the data while the updates are syncing, some data might not be scored for risk.\nCreate a variant of a built-in indicator\nYou can\ncreate detection groups\nand use them with variants of built-in indicators to tailor detections for different sets of users. For example, to reduce the number of false positives for email activities, you might want to create a variant of the\nSending email with attachments to recipients outside the organization\nbuilt-in indicator to only detect email sent to personal domains. A variant inherits all the properties of the built-in indicator. You can modify the variant with exclusions or inclusions.\nIn Insider Risk Management settings, select\nPolicy indicators\n.\nSelect\nNew indicator variant (preview)\n. This step opens the\nNew indicator variant (preview)\npane on the right side of the screen.\nIn the\nBase indicator\nlist, select the indicator that you want to create a variant for.\nNote\nYou can create up to ten variants for each built-in indicator and a total of 100 variants across all indicators. If you already created ten variants for a particular built-in indicator, the built-in indicator appears grayed out in the list. Some built-in indicators (Microsoft Defender for Endpoint indicators, for example) don't support variants.\nAdd a name for the variant (or accept the suggested name). A variant name can't be more than 110 characters.\nAdd a description for the variant (optional). The description appears in the policy to help you differentiate it from other indicators or indicator variants. A description for a variant can't be more than 256 characters.\nUnder\nDetection group\n, select one of the following options:\nIgnore activity involving items in selected groups\n. Select this option if you want to capture everything except for a few\nexclusions\n. For example, you might want to use this option to capture all outgoing email except for email sent to specific domains.\nOnly detect activity involving items in selected groups\n. Select this option if you want to specify\ninclusions\nto capture. For example, select this option if you want to capture only email sent to certain domains.\nNote\nIf you didn't already\ncreate a detection group\n, you can't select an option in the\nDetection group\nsection.\nIn theâ¯\nSelect one or more detection groups\nâ¯list, select the detection groups that you want to apply to the variant. Detection groups are listed under the appropriate detection type heading to help you find the appropriate group. For a single variant, you can add up to five detection groups of a single type. For example, you can add up to five groups of domains, five groups of file types, and so on.\nNote\nOnly detection groups that are applicable to the variant appear in the list. For example, a file type detection group won't appear for the\nSharing SharePoint folders with people outside the organization\nindicator since it's not applicable.\nSelect\nSave\n.\nIn the\nNext steps\ndialog box, if you want to apply the new variant to a specific policy, select the\nPolicies page\nlink.\nTip\nTo make sure that a variant captures all the important activities that you want to detect, you can apply the built-in indicator and the variant of the built-in indicator in the same policy. You can then observe the activities that each indicator captures in alerts and then use only the variant indicator after making sure everything is detected.\nUse a variant in a policy\nGo to the\nIndicators\npage of the policy workflow.\nFind the built-in indicator that includes one or more variants. A small blue box in the variant checkbox marks built-in indicators that have variants. A list appears at the end of the indicator descriptor text to show the number of selected variants. Open the list to see the variants.\nNote\nIf you select one or more checkboxes in the variant list, the first-level checkbox for the built-in indicator becomes a solid blue checkbox. If you don't select any of the boxes in the variant list, the first-level checkbox is blank.\nSelect\nNext\n.\nIn the\nCustomize thresholds\npage, you can customize threshold values for variants individually.\nInvestigate insights provided by variants\nWhen you add variants to policies, the dashboard generates alerts. An investigator can view more details in the\nActivity explorer\nand\nUser activity\ntabs.\nEdit a variant\nSelect the blue text at the end of the indicator description text. For example, select\n+2\nvariants as shown in the following screenshot example.\nIn the\nView/edit indicators\npage, select\nEdit\n.\nMake your changes.\nVariant limitations\nYou can create up to three variants for each built-in indicator.\nYou can add up to five detection groups of a single type for a single variant. For example, you can add a maximum of five groups of domains, five groups of file types, and so on.\nVariants don't support sequences, cumulative exfiltration activities, the risk score booster, or\nreal-time analytics\nfor the detections group preview.\nHow variants are prioritized against global exclusions and priority content\nInsider Risk Management scopes activities in the following priority order:\nGlobal exclusions\nVariant scoping exclusion/inclusion\nPriority content\nEnable device indicators and onboard Windows devices\nTo enable the detection of risk activities on Windows devices and include policy indicators for these activities, your Windows devices must meet the following requirements, and you must complete the following onboarding steps.\nLearn more about device onboarding requirements\nStep 1: Prepare your endpoints\nMake sure that the Windows 10 devices you plan to report in Insider Risk Management meet these requirements.\nThe device must run Windows 10 x64 build 1809 or later and have the\nWindows 10 update (OS Build 17763.1075)\nfrom February 20, 2020 installed.\nThe user account used to sign in to the Windows 10 device must be an active Microsoft Entra account. The Windows 10 device might be\nMicrosoft Entra ID\n, Microsoft Entra hybrid, joined, or registered.\nInstall the Microsoft Edge browser on the endpoint device to detect actions for the cloud upload activity. See\nDownload the new Microsoft Edge based on Chromium\n.\nNote\nEndpoint DLP now supports virtualized environments, which means that the Insider Risk Management solution supports virtualized environments through endpoint DLP.\nLearn more about support for virtualized environments in endpoint DLP\nStep 2: Onboard devices\nTo detect Insider Risk Management activities on a device, you must enable device checking and onboard your endpoints. You perform both actions in Microsoft Purview.\nTo enable devices that you didn't onboard yet, download the appropriate script and deploy it as outlined in this article.\nIf you already onboarded devices into\nMicrosoft Defender for Endpoint\n, they appear in the managed devices list.\nOnboard devices\nUse this deployment scenario to enable devices that aren't onboarded yet when you want to detect insider risk activities on Windows devices.\nSign in to the\nMicrosoft Purview portal\nwith an admin account in your Microsoft 365 organization.\nSelect\nSettings\nin the upper-right corner of the page.\nUnder\nDevice onboarding\n, select\nDevices\n. The list is empty until you onboard devices.\nSelect\nTurn on device onboarding\n.\nNote\nWhile it usually takes about 60 seconds to enable device onboarding, allow up to 30 minutes before engaging with Microsoft Support.\nSelect how you want to deploy to these devices from the\nDeployment method\nlist, then select\nDownload package\n.\nFollow the appropriate procedures in\nOnboarding tools and methods for Windows machines\n. This link takes you to a landing page where you can access Microsoft Defender for Endpoint procedures that match the deployment package you selected in step 5:\nOnboard Windows machines using Group Policy\nOnboard Windows machines using Microsoft Endpoint Configuration Manager\nOnboard Windows machines using Mobile Device Management tools\nOnboard Windows machines using a local script\nOnboard non-persistent virtual desktop infrastructure (VDI) machines\nWhen you finish and onboard the endpoint device, it appears in the devices list. The endpoint device starts reporting audit activity logs to Insider Risk Management.\nNote\nThis experience is under license enforcement. Without the required license, data isn't visible or accessible.\nIf devices are already onboarded to Microsoft Defender for Endpoint\nIf you already deployed Microsoft Defender for Endpoint and endpoint devices are reporting in, the endpoint devices appear in the managed devices list. To expand coverage, onboard new devices into Insider Risk Management by going to\nStep 2: Onboarding devices\n.\nEnable device indicators and onboard macOS devices\nYou can onboard macOS devices (Catalina 10.15 or later) into Microsoft 365 to support Insider Risk Management policies by using either Intune or JAMF Pro. For more information and configuration guidance, see\nOnboard macOS devices into Microsoft 365 overview (preview)\n.\nIndicator level settings\nWhen you create a policy by using the policy workflow, you can configure how the daily number of risk events influences the risk score for insider risk alerts. These indicator settings help you control how the number of occurrences of risk events in your organization affect the risk score and the associated alert severity for these events.\nFor example, suppose you decide to enable SharePoint indicators in the insider risk policy settings and select custom thresholds for SharePoint events when configuring indicators for a new insider risk\nData leaks\npolicy. In the insider risk policy workflow, you configure three different daily event levels for each SharePoint indicator to influence the risk score for alerts associated with these events.\nFor the first daily event level, set the threshold to:\n10 or more events per day\nfor a lower impact to the risk score for the events\n20 or more events per day\nfor a medium impact to the risk score for the events\n30 or more events per day\nfor a higher impact to the risk score for the events\nThese settings mean:\nIf there are 1-9 SharePoint events that take place after the triggering event, risk scores are minimally impacted and tend not to generate an alert.\nIf there are 10-19 SharePoint events that take place after a triggering event, the risk score is inherently lower and alert severity levels tend to be at a low level.\nIf there are 20-29 SharePoint events that take place after a triggering event, the risk score is inherently higher and alert severity levels tend to be at a medium level.\nIf there are 30 or more SharePoint events that take place after a triggering event, the risk score is inherently higher and alert severity levels tend to be at a high level.\nAnother option for policy thresholds is to assign the policy triggering event to risk management activity that is over the typical daily number of users. Instead of being defined by specific threshold settings, each threshold is dynamically customized for anomalous activities detected for in-scope policy users. If threshold activity for anomalous activities is supported for an individual indicator, you can select\nActivity is above user's usual activity for the day\nin the policy workflow for that indicator. If this option isn't listed, anomalous activity triggering isn't available for the indicator. If the\nActivity is above user's usual activity for the day\noption is listed for an indicator, but isn't selectable, you need to enable this option in\nInsider risk settings\n>\nPolicy indicators\n.\nUse real-time analytics recommendations to set thresholds\nUse real-time analytics (preview) to get a guided, data-driven threshold configuration experience. With this experience, you can quickly select the right thresholds for policy indicators. The guided experience helps you efficiently adjust the selection of indicators and thresholds for activity occurrences so you don't have too few or too many policy alerts.\nWhen you turn on analytics:\nThe\nApply thresholds specific to your users' activity\noption is enabled on the\nIndicators\npage of the policy workflow. Select this option if you want Insider Risk Management to provide indicator threshold recommendations based on the previous 10 days of user activity in your organization.\nNote\nTo use this option, you must select at least one built-in policy indicator. Insider Risk Management doesn't provide recommended thresholds for\ncustom indicators\nor\nvariants of built-in indicators\n.\nIf you select the\nChoose your own thresholds\noption on the\nIndicators\npage of the policy workflow, the defaults for the threshold settings are based on recommended threshold values (based on activity in your organization) instead of the built-in default values. You also see a gauge, a list of the top five indicators, and insights for each indicator.\nA.\nThe gauge shows the approximate number of scoped users whose activities from the previous 10 days exceeded the\nlowest daily thresholds\nfor at least one of the selected built-in indicators for the policy. This gauge helps you estimate the number of alerts that might be generated if all users included in the policy were assigned risk scores.\nB.\nThe top five indicators list is sorted by the number of users exceeding the\nlowest daily thresholds\n. If your policies generate too many alerts, focus on these indicators to reduce \"noise.\"\nC.\nInsights for each indicator are displayed for the set of threshold settings for that indicator. The insight shows the approximate number of users whose activities from the previous 10 days exceeded the specified\nlow thresholds\nfor the indicator. For example, if the low threshold setting for\nDownloading content from SharePoint\nis set to 100, the insight shows the number of users in the policy who performed more than 100 download activities on average in the previous 10 days.\nNote\nGlobal exclusions (intelligent detections)\nare taken into account for real-time analytics.\nAdjust threshold settings manually\nIf you select the\nChoose your own thresholds\noption and manually adjust a threshold setting for a specific indicator, the insight for the indicator updates in real time. This feature helps you configure the appropriate thresholds for each indicator to achieve the highest level of alert effectiveness before activating your policies.\nTo save time and make it easier to understand the impact of manual changes to threshold values, select the\nView impact\nlink in the insight to display the\nUsers exceeding daily thresholds for indicator\ngraph. This graph provides sensitivity analysis for each policy indicator.\nImportant\nThis graph isn't available if you select the\nInclude specific users\noption when you create the policy. You must select the\nInclude all users and groups\noption.\nUse this graph to analyze the activity patterns of users in your organization for the selected indicator. For example, in the preceding illustration, the threshold indicator for\nSharing SharePoint files with people outside the organization\nis set to\n38\n. The graph shows how many users performed actions that exceeded that threshold value and the distribution of low, medium, and high severity alerts for those actions. Select a bar to see insights for each value. For example, in the previous illustration, the bar for the\n50\nvalue is selected and the insight shows that at that threshold value, approximately 22 users each performed at least 50 events on at least one day in the past 10 days.\nPrerequisites for using real-time analytics\nTo use real-time analytics (preview), you must\nenable insider risk analytics insights\n. After you enable analytics, it can take 24 to 48 hours for insights and recommendations to appear.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Insider Risk Indicators",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/insider-risk-management-activities": {
      "content_hash": "sha256:6f8c2d48fd4c112dce2dc3d4b906dacb1e660dfb960f9d72aa9e5aeac661f51e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nInvestigate Insider Risk Management activities\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Purview Insider Risk Management\ncorrelates various signals to identify potential malicious or inadvertent insider risks, such as IP theft, data leakage, and security violations. Insider Risk Management enables customers to create policies to manage security and compliance. Built with privacy by design, users are pseudonymized by default, and role-based access controls and audit logs are in place to help ensure user-level privacy.\nInvestigating potentially risky user activities is an important step in minimizing insider risks for your organization. These risks might be activities that generate alerts from Insider Risk Management policies. They can also be risks from compliance-related activities detected by policies but don't immediately create Insider Risk Management alerts for users.\nYou can investigate these types of activities by using\nUser activity reports\nor with the\nTriage Agent in Insider Risk Management\nand\nStandard alert\ndashboards.\nTriaging alerts\nInvestigating and acting on alerts in Insider Risk Management includes the following steps:\nReview the dashboards for alerts\n. On the Standard dashboard,\nfilter\nby alert\nStatus\nto locate\nNeeds review\nalerts. You can also use\nspotlighted alerts\non the dashboard to quickly see prioritized alerts. On the Alert Triage Agent dashboard, select the\nNeeds attention\nfilter to view alerts with the highest prioritization.\nStart with the alerts with the highest severity\n.\nFilter\nby alert\nSeverity\nif needed to help locate these types of alerts.\nSelect an alert to discover more information and to review the alert details\n. Review details and connections associated with the alert:\nUse the\nActivity explorer tab\nto review a timeline of the associated potentially risky behavior and to identify all risk activities for the alert.\nUse the\nData risk graph\nto review connections and details about users and files for the alert.\nAct on the alert\n. You can either confirm and\ncreate a case\nfor the alert or dismiss and resolve the alert.\nYou can triage alerts by going to the\nAlert details\npage for an alert in either dashboard. On the\nAlert details\npage, you can review information about the alert. You can confirm the alert and create a new case, confirm the alert and add to an existing case, or dismiss the alert.\nThis page also includes the current status for the alert and the alert risk severity level, listed as\nHigh\n,\nMedium\n, or\nLow\n. The severity level might increase or decrease over time if the alert isn't triaged. For false positives, you can select multiple alerts and dismiss them in bulk by selecting\nDismiss alerts\n.\nUse Copilot to summarize an alert\nSelect\nSummarize with Copilot\nor the Copilot icon to quickly summarize an alert and prioritize the alerts that need further investigation. You can summarize selected alerts without opening the alert or after viewing the details of the alert. When you summarize an alert with Microsoft Copilot in Microsoft Purview, a\nCopilot\npane appears on the right side of the screen with an alert summary.\nThe alert summary includes all the essential details about the alert, such as the policy that triggered the alert, the activity that generated the alert, the triggering event, the user involved, their last working date (if applicable), any key user attributes, and the user's top risk factors. Copilot in Microsoft Purview consolidates information about the user from all their alerts and in-scope policies and emphasizes the user's top risk factors.\nSuggested prompts automatically show to help further refine your summary and provide additional insights to the activities associated with the alert. Choose from the following suggested prompts:\nList all the data exfiltration activities involving this user\n.\nList all the sequential activities involving this user\n.\nDid the user engage in any unusual behavior?\nShow key actions performed by the user in the last 10 days\n.\nSummarize user's last 30 days of activity\n.\nTip\nYou can also use the\nstandalone version of Microsoft Security Copilot to investigate Insider Risk Management, Microsoft Purview Data Loss Prevention (DLP), and Microsoft Defender XDR alerts\n.\nSpotlight (preview)\nThe alert\nSpotlight\non the\nAlerts\ndashboard helps you prioritize alerts to triage. Every generated alert has a risk score, a list of activities performed, tags, and triggers. Alert spotlighting uses this information to determine if an alert is spotlighted.\nAn alert is automatically spotlighted if it has a risk score of 85 or higher and if at least three of the following conditions are met:\nOne insight from the following table matches the highest insight of the alert.\nThe alert contains priority content or the user is detected as a\npotential high impact user\n.\nThe user is\nmanually brought into scope\n.\nAlert activity contains two or more high-confidence insights from the following table.\nCategory\nIndicator (high confidence insights)\nDevice indicator\n- Creating or transferring files to a network share\n- Creating or copying files to USB\n- Using a browser to upload files to the web\nOffice indicator\n- Sharing SharePoint files with people outside the organization\n- Sharing SharePoint folders with people outside the organization\n- Sharing file links with people outside organization in a Teams chat\nPolicy\n- Content to prioritize\n- Start scoring activity for users\nRisk score booster\n- User is detected as a potential high impact user\nSequence detection\n- Download from Microsoft 365 location then exfiltrate\n- Download from Microsoft 365 location, exfiltrate, then delete\n- Download from Microsoft 365 location, obfuscate, then exfiltrate\nTriage Agent in Insider Risk Management dashboard\nWhen you enable the\nTriage Agent in Insider Risk Management\nin your organization, the agent reviews alerts and displays them on the Triage Agent dashboard. This dashboard automatically includes prioritized alerts and filters to help Insider Risk Management analysts quickly investigate and resolve issues.\nYou can customize the dashboard columns and filter alerts triaged by the agent by priority, date, alert status, or alert scope. To view the Triage Agent dashboard, select\nTriage Agent\nat the top of the dashboard page.\nSelect an alert to display the Agent summary and overview details for the alert. Select\nView details\nto view details for the alert and for access to the details sections like the risk factors, the Activity explorer, and more.\nIf you disagree with the\nAgent categorization\n, select\nCategorization Feedback\n(preview) to provide feedback on why the categorization is incorrect.\nImportant\nThe file risk section of the Triage Agent has been deprecated.\nCheck out the\nInsider Risk Management Alerts Triage Experience video\nfor an overview of how alerts provide details, context, and related content for risky activity and how to make your investigation process more effective.\nStandard alert dashboard\nInsider Risk Management alerts are automatically generated by risk indicators defined in Insider Risk Management policies and displayed on the Standard alert dashboard. These alerts give compliance analysts and investigators an all-up view of the current risk status and allow your organization to triage and take actions for discovered potential risks. By default, policies generate a certain number of low, medium, and high severity alerts, but you can\nincrease or decrease the alert volume\nto suit your needs. Additionally, you can configure the\nalert threshold for policy indicators\nwhen creating a new policy with the policy creation tool. To view the Standard dashboard, select\nStandard\nat the top of the dashboard page.\nNote\nFor any generated alerts, Insider Risk Management generates a single aggregated alert per user. The system adds any new insights for that user to the same alert.\nImportant\nIf you\nscope your policies by one or more administrative units\n, you can only see alerts for the users you're scoped for. For example, if an administrative scope applies to just users in Germany, you can only see alerts for users in Germany. Unrestricted administrators can see all alerts for all users in the organization.\nRestricted administrators can't access alerts for the users assigned to them through security groups or distribution groups added in administrative units. Such user alerts are visible only to unrestricted administrators. Microsoft recommends adding users directly to administrative units to ensure their alerts are also visible to restricted administrators with administrative units assigned.\nFilter alerts, save a view of a filter set, customize columns, or search for alerts\nDepending on the number and type of active Insider Risk Management policies in your organization, reviewing a large queue of alerts can be challenging. To help you keep track of alerts, you can:\nFilter alerts by various attributes.\nSave a view of a filter set to reuse later.\nDisplay or hide columns.\nSearch for an alert.\nView alert reports.\nFilter alerts\nSelect\nAdd filter\n.\nSelect one or more of the following attributes:\nAttribute\nDescription\nActivity that generated the alert\nDisplays the top potentially risky activity and policy match during the activity evaluation period that leads to the alert. This value can update over time.\nAlert dismissal reason\nThe reason for dismissing the alert.\nAssigned to\nThe admin that the alert is assigned to for triaging (if assigned).\nPolicy\nThe name of the policy.\nRisk factors\nThe risk factors that help determine how risky a user's activity might be. The possible values are\nCumulative exfiltration activities\n,\nActivities include priority content\n,\nSequence activities\n,\nActivities include unallowed domains\n,\nMember of a priority user group\n, and\nPotential high impact user\n.\nSeverity\nThe user's risk severity level. The options are\nHigh\n,\nMedium\n, and\nLow\n.\nStatus\nStatus of the alert. The options are\nConfirmed\n,\nDismissed\n,\nNeeds review\n, and\nResolved\n.\nTime detected (UTC)\nThe start and end dates for when the alert was created. The filter searches for alerts between UTC 00:00 on the start date and UTC 00:00 on the end date.\nTriggering event\nThe event that brought the user into scope of the policy. The triggering event can change over time.\nThe attributes that you select are added to the filter bar.\nSelect an attribute in the filter bar, then select a value to filter by. For example, select the\nTime detected (UTC)\nattribute, enter or select the dates in the\nStart date\nand\nEnd date\nfields, then select\nApply\n.\nTip\nTo start over at any point, select\nReset all\non the filter bar.\nSave a view of a filter set to reuse later\nAfter applying the filters as described in the preceding procedure, select\nSave\n, enter a name for the filter set, then select\nSave\n.\nThe filter set is added as a card. It includes a number that shows the count of alerts that meet the criteria in the filter set.\nNote\nYou can save up to five filter sets. To delete a filter set, select the ellipsis (three dots) in the upper-right corner of the card, then select\nDelete\n.\nTo reapply a saved filter set, select the card for the filter set.\nDisplay or hide columns\nOn the right side of the page, select\nCustomize columns\n.\nSelect or clear the checkboxes for the columns you want to display or hide.\nThe column settings are saved across sessions and across browsers.\nSearch for alerts\nUse the\nSearch\ncontrol to search for a user principal name (UPN), an assigned admin name, or an Alert ID.\nView alert reports\nGo to\nInsider Risk Management\n>\nReports\n>\nAlerts\nto view\nreports\nfor generated alerts, alerts by region, alerts by triggering event, and more.\nHeader/summary section of the Alert details page\nThis section in the\nAlert details\npage is only available when selecting an alert from the Standard dashboard and contains general information about the user and alert. You can use this information for context while reviewing detailed information about the detected risk management activity included in the alert for the user:\nActivity that generated this alert\n: Displays the top potentially risky activity and policy match during the activity evaluation period that led to the alert being generated.\nTriggering event\n: Displays the most recent triggering event that prompted the policy to start assigning risk scores to the user's activity. If you configure\nintegration with Communication Compliance\nfor\nData leaks by risky users\nor\nSecurity policy violations by risky users\npolicies, the triggering event for these alerts is scoped to Communication Compliance activity.\nUser details\n: Displays general information about the user assigned to the alert. If anonymization is enabled, the username, email address, alias, and organization fields are anonymized.\nUser alert history\n: Displays a list of alerts for the user for the last 30 days. Includes a link to view the complete alert history for the user.\nNote\nWhen a user is detected as a potential high impact user, this information is highlighted in the alert header in the\nUser details\npage. The user details also include a summary with the reasons the user is detected as such. To learn more about setting policy indicators for potential high impact users, see\nInsider Risk Management settings\n.\nAlerts generated from policies scoped to only activities that include\npriority content\ninclude the\nOnly activity with priority content was scored for this alert\nnotification in this section.\nTip\nTo get a quick overview of an alert, select\nSummarize\non the alert details page. When you select\nSummarize\n, a\nCopilot\npane appears on the right side of the page with an alert summary. The alert summary includes all the essential details about the alert, such as the policy that was triggered, the activity that generated the alert, the triggering event, the user involved, their last working date (if applicable), any key user attributes, and the user's top risk factors. Copilot in Microsoft Purview consolidates information about the user from all their alerts and in-scope policies and emphasizes the user's top risk factors. You can also\nsummarize the alert from the Alerts queue without having to open the alert by using\nCopilot\n. Or use the\nstandalone version of Microsoft Security Copilot to investigate Insider Risk Management, Microsoft Purview Data Loss Prevention (DLP), and Microsoft Defender XDR alerts\n.\nAgent summary tab\nThis section in the\nAlert details\npage is only available when selecting an alert from the Triage Agent in Insider Risk Management dashboard. Agent summary information includes details on the categorization for the alert and details about the associated risks used in the triage process.\nAll risk factors tab\nThis tab in the\nAlert details\npage is available for alerts in both dashboard views. It opens the summary of risk factors for the user's alert activity. Risk factors help you determine how risky the user's risk management activity is during your review. The risk factors include summaries for:\nCumulative exfiltration activities\n: Events associated with cumulative exfiltration activities.\nHealth record access\n: Potentially risky activities for events associated with accessing health records.\nPriority content\n: Potentially risky activities associated with priority content.\nRisky browser usage\n: Potentially risky activities for events associated with browsing to potentially inappropriate websites.\nSequences of activities\n: Detected potentially risky activities associated with risk sequences.\nTop exfiltration activities\n: Exfiltration activities with the highest number of events for the alert.\nUnallowed domains\n: Potentially risky activities for events associated with unallowed domains.\nUnusual activity for this user\n: Specific activities for the user that are considered potentially risky, as they're unusual and a departure from their typical activities.\nWith these filters, you only see alerts with these risk factors, but the activity that generated an alert might not fall into any of these categories. For example, an alert containing sequence activities might be generated simply because the user copied a file to a USB device.\nContent detected\nThis section on the\nAll risk factors\ntab includes content associated with the risk activities for the alert and summarizes activity events by key areas. Selecting an activity link opens the Activity explorer and displays more details about the activity.\nActivity explorer tab\nNote\nActivity explorer is available in the alert management area for users with triggering events after this feature is available in your organization.\nThe\nActivity explorer\ntab is available for alerts in both dashboard views. It provides risk investigators and analysts with a comprehensive analytics tool that provides detailed information about alerts. With the Activity explorer, reviewers can quickly review a timeline of detected potentially risky activity and identify and filter all risk activities associated with alerts.\nUse the Activity explorer\nWhen reviewing activities in the Activity explorer, investigators and analysts can select a specific activity and open the activity details pane. The pane displays detailed information about the activity that investigators and analysts can use during the alert triage process. Detailed information might provide context for the alert and assist with identifying the full scope of the risk activity that triggered the alert.\nWhen selecting an activity's events from the activity timeline, the number of activities displayed in the explorer might not match the number of activity events listed in the timeline. Examples of why this difference might occur include:\nCumulative exfiltration detection\n: Cumulative exfiltration detection analyzes event logs but applies a model that includes deduplicating similar activities to compute cumulative exfiltration risk. Additionally, you might see a difference in the number of potentially risky activities displayed in the Activity explorer if you make changes to your existing policy or settings. For example, if you modify allowed/unallowed domains or add new file type exclusions after a policy is created and potentially risky activity matches occur, the cumulative exfiltration detection activities differ from the results before the policy or settings changes. Cumulative exfiltration detection activity totals are based on the policy and settings configuration at the time of computation and don't include activities prior to the policy and settings changes.\nEmails to external recipients\n: Potentially risky activity for emails sent to external recipients is assigned a risk score based on the number of emails sent, which might not match the activity event logs.\nSequences that contain events excluded from risk scoring\nA\nsequence\nmight contain one or more events that are excluded from risk scoring based on your settings configuration. For example, your organization might use the\nGlobal exclusions\nsetting\nto exclude .png files from risk scoring since .png files aren't normally risky. But a .png file could be used to obfuscate a malicious activity. For this reason, if an event that's excluded from risk scoring is part of a sequence due to an obfuscation activity, the event is included in the sequence since it might be interesting in the context of the sequence.\nThe Activity explorer displays the following information for excluded events in sequences:\nIf a sequence contains a step where\nall\nevents are excluded, the insight includes just the activity name and date. Select the\nView the excluded events\nlink to filter for the excluded events in the Activity explorer. The User activity scatter plot icon has a risk score of 0 if all events are excluded.\nIf a sequence has an insight where\nsome\nevents are excluded, the event information for the nonexcluded events is displayed, but the event count doesn't include the excluded events. Select the\nView the excluded events\nlink to filter for the excluded events in the Activity explorer.\nIf you select a\nsequence link\nfor an insight, you can drill down into the sequence of events in the activity details pane, including any events that were excluded from scoring. An event excluded from scoring is marked as\nExcluded\n.\nFilter alerts in the Activity explorer\nTo filter alerts in the Activity explorer for column information, select\nFilters\n. You can filter alerts by one or more attributes listed in the details pane for the alert. Activity explorer also supports customizable columns to help investigators and analysts focus the dashboard on the information most important to them.\nUse the\nActivity scope\n,\nRisk factor\n, and\nReview status\nfilters to display and sort activities and insights for the following areas.\nActivity scope\n: Filters all scored activities for the user.\nAll scored activity for this user\nOnly scored activity in this alert\nRisk factor\n: Filters for risk factor activity applicable for all policies assigning risk scores This includes all activity for all policies for included users.\nUnusual activity\nIncludes events with priority content\nIncludes events with unallowed domain\nSequence activities\nCumulative exfiltration activities\nHealth record access activities\nRisky browser usage\nReview status\n: Filters activity review status.\nAll\nNot yet reviewed (filters out any activity that was part of a dismissed or resolved alert)\nUser activity tab\nThe\nUser activity\ntab is available for alerts in both dashboard views. It's one of the most powerful tools for internal risk analysis and investigation for alerts and cases in the Insider Risk Management solution. This tab is structured to enable quick review of all activities for a user, including a historical timeline of all alerts, alert details, the current risk score for the user, and the sequence of risk events.\nCase actions\n: The case action toolbar provides options for resolving the case. When viewing a case, you can resolve the case, send an email notice to the user, or escalate the case for a data or user investigation.\nRisk activity chronology\n: The full chronology of all risk alerts associated with the case, including all the details available in the corresponding alert bubble.\nFilters and sorting (preview)\n:\nRisk category\n: Filter activities by the following risk categories:\nActivities with risk scores > 15 (unless in a sequence)\nand\nSequence activities\n.\nActivity Type\n: Filter activities by the following types:\nAccess\n,\nDeletion\n,\nCollection\n,\nExfiltration\n,\nInfiltration\n,\nObfuscation\n,\nSecurity\n,\nCustom Indicator\n,\nDefense Evasion\n,\nPrivilege Escalation\n,\nCommunication Risk\n,\nUser Compromise Risk\n, and\nAI Usage\n.\nSort by\n: List the timeline of potentially risky activities by\nDate occurred\nor\nRisk score\n.\nTime filters\n: By default, the User activity chart displays the last three months of potentially risky activities. You can easily filter the chart view by selecting the\n6 Months\n,\n3 Months\n, or\n1 Month\ntabs on the bubble chart.\nRisk sequence\n: The chronological order of potentially risky activities is an important aspect of risk investigation. Identifying these related activities is an important part of evaluating overall risk for your organization. Alert activities that are related are displayed with connecting lines to highlight that these activities are associated with a larger risk area. Sequences are also identified in this view by an icon positioned over the sequence activities relative to the risk score for the sequence. Hover over the icon to see the date and time of the risky activity associated with this sequence. This view of activities can help investigators 'connect the dots' for risk activities that could have been viewed as isolated or one-off events. Select the icon or any bubble in the sequence to display details for all the associated risk activities. Details include:\nName\nof the sequence.\nDate\nor\nDate range\nof the sequence.\nRisk score\nfor the sequence. This score is the numerical score for the sequence of the combined alert risk severity levels for each related activity in the sequence.\nNumber of events associated with each alert in the sequence\n. Links to each file or email associated with each potentially risky activity are also available.\nShow activities in sequence\n. Displays the sequence as a highlight line on the bubble chart and expands the alert details to display all related alerts in the sequence.\nRisk alert activity and details\n: Potentially risky activities are visually displayed as colored bubbles in the User activity chart. Bubbles are created for different categories of risk. Select a bubble to display the details for each potentially risky activity. Details include:\nDate\nof the risk activity.\nThe\nrisk activity category\n. For example,\nEmail(s) with attachments sent outside the organization\nor\nFile(s) downloaded from SharePoint Online\n.\nRisk score\nfor the alert. This score is the numerical score for the alert risk severity level.\nNumber of events associated with the alert. Links to each file or email associated with the risk activity are also available.\nCumulative exfiltration activities\n: Select to view a visual chart of how activity is building over time for the user.\nRisk activity legend\n: Across the bottom of the user activity chart, a color-coded legend helps you quickly determine risk category for each alert.\nData risk graph tab\nImportant\nYou cannot use this feature with the\nanonymized usernames privacy setting\nenabled.\nThe\nData risk graph\ntab is available for alerts in both dashboard views. Powered by integration with\nMicrosoft Sentinel\n, the data risk graph lets you view connections between impacted assets, users, and their activities in an interactive graph experience.\nFor more information about data risk graphs, see\nData risk graph in Insider Risk Management\n.\nSave a view of a filter to reuse later\nIf you create a filter and customize columns for the filter, you can save a view of your changes so that you or others can quickly filter for the same changes again later. When you save a view, you save both the filters and columns. When you load the view, it loads both saved filters and columns.\nCreate a filter and customize columns.\nTip\nTo start over at any point, select\nReset\n. To change columns that you customized, select\nReset columns\n.\nWhen you have the filter the way you want it, select\nSave this view\n, enter a name for the view, and then select\nSave\n.\nNote\nThe maximum length for a view name is 40 characters and you can't use any special characters.\nTo reuse the view of the filter later, select\nViews\n, and then select the view you want to open from the\nRecommended views\ntab (shows the most-used views) or the\nCustom views\ntab (the most frequently used filters are displayed at the top of the list).\nWhen you select a view this way, it resets all the existing filters and replaces them with the view that you selected.\nAlert status and severity\nNote\nInsider Risk Management throttles trigger processing to help protect and optimize your risk investigation and review experience. This throttling guards against issues that might result in an overload of policy alerts, such as misconfigured data connectors or data loss prevention policies. Insider Risk Management doesn't process signals received beyond the throttling limits.\nLearn more about limits in Insider Risk Management\n.\nYou can triage alerts into one of the following statuses:\nConfirmed\n: An alert confirmed and assigned to a new or existing case.\nDismissed\n: An alert dismissed as benign in the triage process. You can provide a reason for the alert dismissal and include notes that are available in the user's alert history to provide additional context for future reference or for other reviewers. Reasons could range from expected activities, nonimpactful events, simply reducing the number of alert activities for the user, or a reason related to the alert notes. Reason classification choices include\nActivity is expected for this user\n,\nActivity is impactful enough for me to investigate further\n, and\nAlerts for this user contain too much activity\n.\nNeeds review\n: A new alert where triage actions haven't yet been taken.\nResolved\n: An alert that is part of a closed and resolved case.\nAlert risk scores automatically calculate from several risk activity indicators. These indicators include the type of risk activity, the number, and the frequency of the activity occurrence, the history of users' risk activity, and the addition of activity risks that might boost the seriousness of the potentially risky activity. The alert risk score drives the programmatic assignment of a risk severity level for each alert and can't be customized. If you don't triage alerts and risk activities continue to accrue to the alert, the risk severity level can increase. Risk analysts and investigators can use alert risk severity to help triage alerts in accordance with your organization's risk policies and standards.\nAlert risk severity levels are:\nHigh severity\n: The potentially risky activities and indicators for the alert pose significant risk. The associated risk activities are serious, repetitive, and correlate strongly to other significant risk factors.\nMedium severity\n: The potentially risky activities and indicators for the alert pose a moderate risk. The associated risk activities are moderate, frequent, and have some correlation to other risk factors.\nLow severity\n: The potentially risky activities and indicators for the alert pose a minor risk. The associated risk activities are minor, more infrequent, and don't correlate to other significant risk factors.\nDismiss multiple alerts (preview)\nTo save triage time, analysts and investigators can dismiss multiple alerts at once. With the\nDismiss alerts\ncommand bar option, you can select one or more alerts with a\nNeeds review\nstatus on the dashboard and quickly dismiss these alerts as benign. You can select up to 400 alerts to dismiss at one time.\nDismiss an insider risk alert\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nAlerts\nin the left navigation.\nOn the\nAlerts dashboard\n, select the alerts that have a\nNeeds review\nstatus.\nOn the Alerts command bar, select\nDismiss alerts\n.\nOn the\nDismiss alerts\ndetail pane, review the user and policy details associated with the selected alerts.\nSelect\nDismiss alerts\nto resolve the alerts as benign.\nReports for alerts\nTo see reports for alerts, go to the\nReports\npage. Each report widget on the\nReports\npage displays information for the last 30 days:\nTotal alerts that need review\n: The total number of alerts needing review and triage, including a breakdown by alert severity.\nOpen alerts over past 30 days\n: The total number of alerts created by policy matches over the last 30 days, sorted by high, medium, and low alert severity levels.\nAverage time to resolve alerts\n: A summary of useful alert statistics:\nAverage time to resolve high severity alerts, listed in hours, days, or months.\nAverage time to resolve medium severity alerts, listed in hours, days, or months.\nAverage time to resolve low severity alerts, listed in hours, days, or months.\nAssign an alert\nIf you're an administrator and a member of the\nInsider Risk Management\n,\nInsider Risk Management Analysts\n, or\nInsider Risk Management Investigators\nrole group, you can assign ownership of an alert to yourself or to an Insider Risk Management user with one of the same roles. After you assign an alert, you can reassign it to a user with any of the same roles. You can only assign an alert to one admin at a time.\nNote\nIf you\nscope your policies by one or more administrative units\n, you can only give ownership of an alert to Insider Risk Management users with the appropriate role group permissions. The user highlighted in the alert must be in scope of the admin unit. For example, if an administrative scope applies to just users in Germany, the Insider Risk Management user can only see alerts for users in Germany. Unrestricted administrators can see all alerts for all users in the organization.\nAfter you assign an admin, you can search by admin.\nNote\nAdmins contained within a Microsoft Entra security group aren't supported for alert assignment. Admins must be directly assigned to one of the required roles.\nIf you're using a custom group, make sure that the custom group contains the\nCase management\nrole\n. The\nInsider Risk Management Analysts\nand the\nInsider Risk Management Investigators\nrole groups both contain the\nCase management\nrole, but if you're using a custom group, you must explicitly add the\nCase management\nrole to the group.\nAssign an alert from the Alerts dashboard\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nAlerts\nin the left navigation.\nOn the\nAlerts dashboard\n, select the alerts that you want to assign.\nIn the command bar over the alerts queue, select\nAssign\n.\nIn the\nAssign owner\npane on the right side of the screen, search for an admin with the appropriate permissions, then select the checkbox for that admin.\nSelect\nAssign\n.\nAssign an alert from the Alerts detail page\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nAlerts\nin the left navigation.\nSelect an alert.\nIn the detail pane for the alert, in the upper-right corner of the page, select\nAssign\n.\nIn the\nSuggested contacts\nlist, select the appropriate admin.\nCreate a case for an alert\nCreate a case for an alert to investigate potentially risky activity.\nSign in to the\nMicrosoft Purview portal\nwith credentials for an admin account in your Microsoft 365 organization.\nGo to the\nInsider Risk Management\nsolution.\nSelect\nAlerts\nin the left navigation.\nOn the\nAlerts dashboard\n, select the alert you want to confirm and create a new case for.\nOn the\nAlerts details pane\n, select\nActions\n>\nConfirm alerts & create case\n.\nIn the\nConfirm alert and create insider risk case\ndialog box, enter a name for the case, select users to add as contributors, and add comments as applicable. Comments automatically add to the case as a case note.\nSelect\nCreate case\nto create a new case.\nAfter you create the case, investigators and analysts can manage and act on the case. For more information, see the\nInsider Risk Management case\narticle.\nRetention and item limits\nAs Insider Risk Management alerts age, their value to minimize potentially risky activity diminishes for most organizations. Conversely, active cases and associated artifacts (alerts, insights, activities) always provide value and don't have an automatic expiration date. This retention policy includes all future alerts and artifacts in an active status for any user associated with an active case.\nTo minimize the number of older items that provide limited current value, the following retention and limits apply for Insider Risk Management alerts, cases, and user reports:\nItem\nRetention/Limit\nActive cases (and associated artifacts)\nIndefinite retention, never expire\nAlerts with Needs review status\n120 days from alert creation, then automatically deleted\nMaximum number of active cases\n100\nResolved cases (and associated artifacts)\n120 days from case resolution, then automatically deleted\nUser activities reports\n120 days from report creation, then automatically deleted\nBest practices for managing your alert volume\nReviewing, investigating, and acting on potentially risky insider alerts are important parts of minimizing insider risks in your organization. Quickly taking action to minimize the impact of these risks can potentially save time, money, and regulatory or legal ramifications for your organization.\nLearn about best practices for managing your Insider Risk Management alert queue\n.\nSee also\nBest practices for managing your Insider Risk Management alert queue\nTake action on insider risk cases\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Investigate Alerts",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/import-hr-data": {
      "content_hash": "sha256:4c77a7904ca787407100fb1b03c452f0e1fa6d8da4646e289975cd76681c127f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSet up a connector to import HR data\nFeedback\nSummarize this article for me\nYou can set up a data connector to import human resources (HR) data related to events such as a user's resignation or a change in a user's job level. The insider risk management solution uses the HR data to generate risk indicators that help you identify possible malicious activity or data theft by users inside your organization.\nSetting up a connector for HR data that insider risk management policies use to generate risk indicators involves creating a CSV file that contains the HR data, creating an app in Microsoft Entra for authentication, creating an HR data connector in the\nMicrosoft Purview portal\n, and running a script (on a scheduled basis) that ingests the HR data in CSV files to the Microsoft cloud so it's available to the insider risk management solution.\nBefore you begin\nDetermine which HR scenarios and data to import to Microsoft 365. This determination helps you decide how many CSV files and HR connectors you need to create, and how to generate and structure the CSV files. The insider risk management policies you want to implement determine the HR data you import. For more information, see Step 1.\nDetermine how to retrieve or export the data from your organization's HR system (regularly) and add it to the CSV files that you create in Step 1. The script that you run in Step 4 uploads the HR data in the CSV files to the Microsoft cloud.\nAssign the Data Connector Admin role to the user who creates the HR connector in Step 3. This role is required to add connectors on the\nData connectors\npage in the Microsoft Purview portal. Multiple role groups include this role by default. For a list of these role groups, see\nRoles in Microsoft Defender for Office 365 and Microsoft Purview compliance\n. Alternatively, an admin in your organization can create a custom role group, assign the Data Connector Admin role, and add the appropriate users as members. For instructions, see:\nPermissions in the Microsoft Purview portal\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\nUnderstand that the sample script you run in Step 4 uploads your HR data to the Microsoft cloud so that the insider risk management solution can use it. This sample script isn't supported under any Microsoft standard support program or service. It's provided AS IS without warranty of any kind. Microsoft further disclaims all implied warranties including, without limitation, any implied warranties of merchantability or of fitness for a particular purpose. You assume all risk arising from the use or performance of the sample script and documentation. In no event shall Microsoft, its authors, or anyone else involved in the creation, production, or delivery of the scripts be liable for any damages whatsoever (including, without limitation, damages for loss of business profits, business interruption, loss of business information, or other pecuniary loss) arising out of the use of or inability to use the sample scripts or documentation, even if Microsoft has been advised of the possibility of such damages.\nKnow that this connector is available in GCC environments in the Microsoft 365 US Government cloud. Third-party applications and services might involve storing, transmitting, and processing your organization's customer data on third-party systems that are outside of the Microsoft 365 infrastructure and therefore aren't covered by the Microsoft Purview and data protection commitments. Microsoft makes no representation that use of this product to connect to third-party applications implies that those third-party applications are FEDRAMP compliant. For step-by-step instructions for setting up an HR connector in a GCC environment, see\nSet up a connector to import HR data in US Government\n.\nAdd the\nwebhook.ingestion.office.com\ndomain to your firewall allowlist for your organization.\nStep 1: Prepare a CSV file with your HR data\nFirst, create a CSV file that contains the HR data the connector imports to Microsoft 365. The insider risk solution uses this data to generate potential risk indicators. You can import data for the following HR scenarios to Microsoft 365:\nEmployee resignation. Information about employees who leave your organization.\nJob level changes. Information about job level changes for employees, such as promotions and demotions.\nPerformance reviews. Information about employee performance.\nPerformance improvement plans. Information about performance improvement plans for employees.\nEmployee profile (preview). General information about an employee.\nThe type of HR data to import depends on the insider risk management policy and corresponding policy template you want to implement. The following table shows which HR data type each policy template requires:\nPolicy template\nHR data type\nData theft by departing users\nEmployee resignations\nData leaks\nNot applicable\nData leaks by priority users\nNot applicable\nData leaks by risky users\nJob level changes, Performance reviews, Performance improvement plans\nSecurity policy violations\nNot applicable\nSecurity policy violations by departing users\nEmployee resignations\nSecurity policy violations by priority users\nNot applicable\nSecurity policy violations by risky users\nJob level changes, Performance reviews, Performance improvement plans\nOffensive language in email\nNot applicable\nHealthcare policy\nEmployee profile\nFor more information about policy templates for insider risk management, see\nInsider risk management policies\n.\nFor each HR scenario, provide the corresponding HR data in one or more CSV files. The number of CSV files to use for your insider risk management implementation is discussed later in this section.\nAfter you create the CSV file with the required HR data, store it on the local computer where you run the script in Step 4. Implement an update strategy to make sure the CSV file always contains the most current information so that whatever you run the script, the most current HR data is uploaded to the Microsoft cloud and accessible to the insider risk management solution.\nImportant\nThe column names described in the following sections aren't required parameters, but only examples. You can use any column name in your CSV files. However, you\nmust\nmap the column names you use in a CSV file to the data type when you create the HR connector in Step 3. Also note that the sample CSV files in the following sections are shown in NotePad view. It's much easier to view and edit CSV files in Microsoft Excel.\nThe following sections describe the required CSV data for each HR scenario.\nCSV file for employee resignation data\nHere's an example of a CSV file for employee resignation data.\nUserPrincipalName,ResignationDate,LastWorkingDate\nsarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,2019-04-29T15:18:02.4675041+05:30\npilarp@contoso.com,2019-04-24T09:15:49Z,2019-04-29T15:18:02.7117540\nThe following table describes each column in the CSV file for employee resignation data.\nColumn\nDescription\nUserPrincipalName\nThe Microsoft Entra UserPrincipalName (UPN) used to identify the terminated user.\nResignationDate\nSpecifies the date the user's employment is officially terminated or the user resigns from your organization. For example, this date might be when the user gives their notice about leaving your organization. This date might be different from the date of the person's last day of work. Use the following date format:\nyyyy-mm-ddThh:mm:ss.nnnnnn| -hh:mm\n, which is the\nISO 8601 date and time format\n.\nLastWorkingDate\nSpecifies the last day of work for the terminated user. This date can't be more than six months prior or one year in advance from the time of upload. Use the following date format:\nyyyy-mm-ddThh:mm:ss.nnnnnn| -hh:mm\n, which is the\nISO 8601 date and time format\n.\nCSV file for job level changes data\nHere's an example of a CSV file for job level changes data.\nUserPrincipalName,EffectiveDate,OldLevel,NewLevel\nsarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,Level 61 - Sr. Manager,Level 60- Manager\npillar@contoso.com,2019-04-23T15:18:02.4675041+05:30,Level 62 - Director,Level 60- Sr. Manager\nThe following table describes each column in the CSV file for job level changes data.\nColumn\nDescription\nUserPrincipalName\nThe Microsoft Entra UserPrincipalName (UPN) used to specify the user's email address.\nEffectiveDate\nSpecifies the date that the user's job level is officially changed. Use the following date format:\nyyyy-mm-ddThh:mm:ss.nnnnnn+ | -hh:mm\n, which is the\nISO 8601 date and time format\n.\nRemarks\nSpecifies the remarks that evaluator provides about the change of job level. You can enter a limit of 200 characters. This parameter is optional. You don't have to include it in the CSV file.\nOldLevel\nSpecifies the user's job level before it was changed. This is a free-text parameter and can contain hierarchical taxonomy for your organization. This parameter is optional. You don't have to include it in the CSV file.\nNewLevel\nSpecifies the user's job level after it was changed. This is a free-text parameter and can contain hierarchical taxonomy for your organization. This parameter is optional. You don't have to include it in the CSV file.\nCSV file for performance review data\nHere's an example of a CSV file for performance data.\nUserPrincipalName,EffectiveDate,Remarks,Rating\nsarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,Met expectations but bad attitude,2-Below expectation\npillar@contoso.com,2019-04-23T15:18:02.4675041+05:30, Multiple conflicts with the team\nThe following table describes each column in the CSV file for performance review data.\nColumn\nDescription\nUserPrincipalName\nThe Microsoft Entra UserPrincipalName (UPN) used to specify the user's email address.\nEffectiveDate\nSpecifies the date that the user is officially informed about the result of their performance review. This date can be the date when the performance review cycle ends. Use the following date format:\nyyyy-mm-ddThh:mm:ss.nnnnnn+ | -hh:mm\n, which is the\nISO 8601 date and time format\n.\nRemarks\nSpecifies any remarks that evaluator provides to the user for the performance review. This is a text parameter with a limit of 200 characters. This parameter is optional. You don't have to include it in the CSV file.\nRating\nSpecifies the rating provided for the performance review. This is a text parameter and can contain any free-form text that your organization uses to recognize the evaluation. For example, \"3 Met expectations\" or \"2 Below average\". This is a text parameter with a limit of 25 characters. This parameter is optional. You don't have to include it in the CSV file.\nCSV file for performance improvement plan data\nHere's an example of a CSV file for the data for the performance improvement plan data.\nUserPrincipalName,EffectiveDate,ImprovementRemarks,PerformanceRating\nsarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,Met expectation but bad attitude,2-Below expectation\npillar@contoso.com,2019-04-23T15:18:02.4675041+05:30, Multiple conflicts with the team\nThe following table describes each column in the CSV file for performance review data.\nColumn\nDescription\nUserPrincipalName\nThe Microsoft Entra UserPrincipalName (UPN) used to specify the user's email address.\nEffectiveDate\nSpecifies the date when the user is officially informed about their performance improvement plan. You must use the following date format:\nyyyy-mm-ddThh:mm:ss.nnnnnn+ | -hh:mm\n, which is the\nISO 8601 date and time format\n.\nRemarks\nSpecifies any remarks that evaluator provides about the performance improvement plan. This is a text parameter with a limit of 200 characters. This is an optional parameter. You don't have to include it in the CSV file.\nRating\nSpecifies any rating or other information related to the performance review. This is a text parameter and can contain any free form text that your organization uses to recognize the evaluation. For example, \"3 Met expectations\" or \"2 Below average\". This is a text parameter with limit of 25 characters. This is an optional parameter. You don't have to include it in the CSV file.\nCSV file for employee profile data (preview)\nNote\nThe capability to create an HR connector for employee profile data is in public preview. To create an HR connector that supports employee profile data, go to the\nData connectors\npage in the Microsoft Purview portal, select the\nConnectors\ntab, then select\nAdd a connector\n>\nHR\n. Follow the steps to create a connector in\nStep 3: Create the HR connector\n.\nHere's an example of a CSV file for employee profile data.\nUserPrincipalName,UserName,EmployeeFirstName,EmployeeLastName,EmployeeAddLine1,EmployeeAddLine2,EmployeeCity,EmployeeState,EmployeeZipCode,EmployeeDept,EmployeeType,EmployeeRole\njackq@contoso.com,jackq,jack,qualtz,50 Oakland Ave,#206,City,Florida,32104,Orthopaedic,Regular,Nurse\nThe following table describes each column in the CSV file for employee profile data.\nColumn\nDescription\nUserPrincipalName\n*\nThe Microsoft Entra UserPrincipalName (UPN) used to specify the user's email address.\nEmployeeFirstName\n*\nFirst name of the employee.\nEmployeeLastName\n*\nLast name of the employee.\nEmployeeAddressLine1\n*\nStreet address of the employee.\nEmployeeAddressLine2\nSecondary address information, such as apartment number, for employee.\nEmployeeCity\nCity of residence for employee.\nEmployeeState\nState of residence for employee.\nEmployeeZipCode\n*\nZip code of residence for employee.\nEmployeeCountry\nCountry of residence for employee.\nEmployeeDepartment\nEmployee's department in the organization.\nEmployeeType\nEmployment type for employee, such as Regular, Exempt, or Contractor.\nEmployeeRole\nEmployees's role, designation, or job title in the organization.\nNote\n*\nThis column is mandatory. If a mandatory column is missing, the CSV file isn't validated and other data in the file isn't imported.\nWe recommend that you create an HR connector that only imports employee profile data. For this connector, frequently refresh the employee profile data, preferably every 15 to 20 days. Employee profile records are deleted if you don't update them in the past 30 days.\nDetermining how many CSV files to use for HR data\nIn Step 3, you can choose to create separate connectors for each HR data type or a single connector for all data types. You can use separate CSV files that contain data for one HR scenario (like the examples of the CSV files described in the previous sections). Alternatively, you can use a single CSV file that contains data for two or more HR scenarios. Here are some guidelines to help you determine how many CSV files to use for HR data.\nIf the insider risk management policy that you want to implement requires multiple HR data types, consider using a single CSV file that contains all the required data types.\nThe method for generating or collecting the HR data might determine the number of CSV files. For example, if the different types of HR data used to configure an HR connector are located in a single HR system in your organization, then you might be able to export the data to a single CSV file. But if data is distributed across different HR systems, then it might be easier to export data to different CSV files. For example, employee resignation data might be located in a different HR system than job level or performance review data. In this case, it might be easier to have separate CSV files rather than having to manually combine the data into a single CSV file. So, how you retrieve or export data from your HR systems might determine how many CSV files you need.\nAs a general rule, the data types in a CSV file determine the number of HR connectors that you need to create. For example, if a CSV file contains all the data types required to support your insider risk management implementation, then you only need one HR connector. But if you have two separate CSV files that each contain a single data type, then you have to create two HR connectors. An exception to this rule is that if you add an\nHRScenario\ncolumn to a CSV file (see the next section), you can configure a single HR connector that can process different CSV files.\nFor each CSV file, you can ingest up to 500 records at once. To ingest a larger number of records, upload multiple CSV files, each with fewer than 500 records.\nConfiguring a single CSV file for multiple HR data types\nYou can add multiple HR data types to a single CSV file. This configuration is useful if the insider risk management solution you're implementing requires multiple HR data types or if the data types are located in a single HR system in your organization. Having fewer CSV files always allows you to have fewer HR connectors to create and manage.\nHere are requirements for configuring a CSV file with multiple data types:\nAdd the required columns (and optional columns if you use them) for each data type and the corresponding column name in the header row. If a data type doesn't correspond to a column, leave the value blank.\nAdd an\nHRScenario\ncolumn to the CSV file. The HR connector uses this column to identify which rows in the CSV file contain which type HR data. The values in this column identify the type of HR data in each row. For example, values that correspond to the HR scenarios could be `Resignation`, `Job level change`, `Performance review`, `Performance improvement plan`, and `Employee profile`.\nIf you have multiple CSV files that contain an\nHRScenario\ncolumn, make sure that each file uses the same column name and the same values that identify the specific HR scenarios.\nThe following example shows a CSV file that contains the\nHRScenario\ncolumn. The values in the HRScenario column identify the type of data in the corresponding row. The following sample covers four HR scenarios `Resignation`, `Job level change`, `Performance review`, and `Performance improvement plan`.\nHRScenario,EmailAddress,ResignationDate,LastWorkingDate,EffectiveDate,Remarks,Rating,OldLevel,NewLevel\nResignation,sarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,2019-04-29T15:18:02.4675041+05:30,,,,\nResignation,pilarp@contoso.com,2019-04-24T09:15:49Z,2019-04-29T15:18:02.7117540,,,,\nJob level change,sarad@contoso.com,2019-04-23T15:18:02.4675041+05:30,,,,,Level 61 Sr. Manager, Level 60 Manager\nJob level change,pillarp@contoso.com,2019-04-23T15:18:02.4675041+05:30,,,,,Level 62 Director,Level 60 Sr Manager\nPerformance review,sarad@contoso.com,,,2019-04-23T15:18:02.4675041+05:30,Met expectation but bad attitude,2 Below expectations,,\nPerformance review,pillarp@contoso.com,,,2019-04-23T15:18:02.4675041+05:30, Multiple conflicts with the team,,\nPerformance improvement plan,sarad@contoso.com,,,2019-04-23T15:18:02.4675041+05:30,Met expectations but bad attitude,2 Below expectations,,\nPerformance improvement plan,pillarp@contoso.com,,,2019-04-23T15:18:02.4675041+05:30,Multiple conflicts with the team,,\nNote\nYou can use any name for the column that identifies HR data type because you map the name of the column in your CSV file as the column that identifies the HR data type when you set up the connector in Step 3. You also map the values used for the data type column when you set up the connector.\nAdding the HRScenario column to a CSV file that contains a single data type\nBased on your organization's HR systems and how you export HR data to a CSV file, you might need to create multiple CSV files that each contain a single HR data type. In this case, you can still create a single HR connector to import data from different CSV files. To do this, add an HRScenario column to the CSV file and specify the HR data type. Then, you can run the script for each CSV file but use the same job ID for the connector. For more information, see\nStep 4\n.\nStep 2: Create an app in Microsoft Entra ID\nNext, create and register a new app in Microsoft Entra ID. The app corresponds to the HR connector that you create in Step 3. When you create this app, Microsoft Entra ID can authenticate the HR connector when it runs and attempts to access your organization. This app also authenticates the script that you run in Step 4 to upload your HR data to the Microsoft cloud. During the creation of this Microsoft Entra app, save the following information. You use these values in Step 3 and Step 4.\nMicrosoft Entra application ID (also called the\napp ID\nor\nclient ID\n)\nMicrosoft Entra application secret (also called the\nclient secret\n)\nTenant ID (also called the\ndirectory Id\n)\nFor step-by-step instructions for creating an app in Microsoft Entra ID, see\nRegister an application with the Microsoft identity platform\n.\nStep 3: Create the HR connector\nThe next step is to create an HR connector in the Microsoft Purview portal. After you run the script in Step 4, the HR connector that you create will ingest the HR data from the CSV file to your Microsoft 365 organization. Before you create a connector, be sure that you have a list of the HR scenarios and the corresponding CSV column names for each one. You have to map the data required for each scenario to the actual column names in your CSV file when configuring the connector. Alternatively, you can upload a sample CSV file when configuring the connector and the workflow help you map the name of the columns to the required data types.\nAfter you complete this step, be sure to copy the job ID that's generated when you create the connector. You use the job ID when you run the script.\nSign in to the\nMicrosoft Purview portal\n.\nSelect\nSettings\n>\nData connectors\n.\nSelect\nMy connectors\n, then select\nAdd connector\n.\nFrom the list, choose\nHR (preview)\n.\nOn the\nSetup the connection\npage, do the following and then select\nNext\n:\nType or paste the Microsoft Entra application ID for the Azure app that you created in Step 2.\nType a name for the HR connector.\nOn the HR scenarios page, select one or more HR scenarios that you want to import data for and then select\nNext\n.\nOn the file mapping method page, select a file type if necessary, and then select one of the following options and then select\nNext\n.\nUpload a sample file\n. If you select this option, select\nUpload sample file\nto upload the CSV file that you prepared in Step 1. This option allows you to quickly select column names in your CSV file from a drop-down list to map them to the data types for the HR scenarios that you previously selected.\nOR\nManually provide the mapping details\n. If you select this option, you have to type the name of the columns in your CSV file to map them to the data types for the HR scenarios that you previously selected.\nOn the File mapping details page, do one of the following, depending on whether you uploaded a sample CSV file and whether you're configuring the connector for a single HR scenario or for multiple scenarios. If you uploaded a sample file, you don't have to type the column names. You pick them from a dropdown list.\nIf you selected a single HR scenario in the previous step, then type the column header names (also called\nparameters\n) from the CSV file that you created in Step 1 in each of the appropriate boxes. The column names that you type aren't case-sensitive, but be sure to include spaces if the column names in your CSV file include spaces. As previously explained, the names you type in these boxes must match the parameter names in your CSV file. For example, the following screenshot shows the parameter names from the sample CSV file for the employee resignation HR scenario shown in Step 1.\nIf you selected multiple data types in the previous step, then you need to enter identifier column name that will identify the HR data type in your CSV file. After entering the identifier column name, type the value that identifies this HR data type, and type the column header names for selected data types from the CSV file(s) that you created in Step 1 in each of the appropriate boxes for each selected data type. As previously explained, the names that you type in these boxes must match the column names in your CSV file.\nOn the\nReview\npage, review your settings and then select\nFinish\nto create the connector.\nA status page is displayed that confirms the connector was created. This page contains two important things that you need to complete the next step to run the sample script to upload your HR data.\nJob ID.\nYou'll need this job ID to run the script in the next step. You can copy it from this page or from the connector flyout page.\nLink to sample script.\nSelect the\nhere\nlink to go to the GitHub site to access the sample script (the link opens a new window). Keep this window open so that you can copy the script in Step 4. Alternatively, you can bookmark the destination or copy the URL so you can access it again when you run the script. This link is also available on the connector flyout page.\nSelect\nDone\n.\nThe new connector is displayed in the list on the\nConnectors\ntab.\nSelect the HR connector that you just created to display the flyout page, which contains properties and other information about the connector.\nIf you haven't already done so, you can copy the values for the\nAzure App ID\nand\nConnector job ID\n. You'll need these to run the script in the next step. You can also download the script from the flyout page (or download it using the link in the next step.)\nYou can also select\nEdit\nto change the Azure App ID or the column header names that you defined on the\nFile mapping\npage.\nStep 4: Run the sample script to upload your HR data\nImportant\nYou must add the\nwebhook.ingestion.office.com\ndomain to your firewall allowlist for your organization. If you block this domain, the script doesn't run.\nThe last step in setting up an HR connector is to run a sample script that uploads the HR data in the CSV file (that you created in Step 1) to the Microsoft cloud. Specifically, the script uploads the data to the HR connector. After you run the script, the HR connector that you created in Step 3 imports the HR data to your Microsoft 365 organization where other compliance tools, such as the Insider risk management solution, can access it. After you run the script, consider scheduling a task to run it automatically on a daily basis so the most current employee termination data is uploaded to the Microsoft cloud. For more information, see\nSchedule the script to run automatically\n.\nGo to the window that you left open from the previous step to access the GitHub site with the sample script. Alternatively, open the bookmarked site or use the URL that you copied. You can also access the script\nhere\n.\nSelect the\nRaw\nbutton to display the script in text view.\nCopy all the lines in the sample script and save them to a text file.\nModify the sample script for your organization, if necessary.\nSave the text file as a Windows PowerShell script file by using a filename suffix of\n.ps1\n; for example,\nHRConnector.ps1\n. Alternatively, you can use the GitHub filename for the script, which is\nupload_termination_records.ps1\n.\nOpen a command prompt on your local computer, and go to the directory where you saved the script.\nRun the following command to upload the HR data in the CSV file to the Microsoft cloud; for example:\n.\\HRConnector.ps1 -tenantId <tenantId> -appId <appId> -appSecret <appSecret> -jobId <jobId> -filePath '<filePath>'\nThe following table describes the parameters to use with this script and their required values. The information you obtained in the previous steps is used in the values for these parameters.\nParameter\nDescription\ntenantId\nThis is the ID for your Microsoft 365 organization that you obtained in Step 2. You can also obtain the tenant ID for your organization on the\nOverview\nblade in the Microsoft Entra admin center. This value identifies your organization.\nappId\nThis is the Microsoft Entra application ID for the app that you created in Microsoft Entra ID in Step 2. This value is used by Microsoft Entra ID for authentication when the script attempts to access your Microsoft 365 organization.\nappSecret\nThis is the Microsoft Entra application secret for the app that you created in Microsoft Entra ID in Step 2. This value is also used for authentication.\njobId\nThis is the job ID for the HR connector that you created in Step 3. This value associates the HR data that is uploaded to the Microsoft cloud with the HR connector.\nfilePath\nThis is the file path for the file (stored on the same system as the script) that you created in Step 1. Try to avoid spaces in the file path; otherwise use single quotation marks.\nHere's an example of the syntax for the HR connector script using actual values for each parameter:\n.\\HRConnector.ps1 -tenantId d5723623-11cf-4e2e-b5a5-01d1506273g9 -appId 29ee526e-f9a7-4e98-a682-67f41bfd643e -appSecret MNubVGbcQDkGCnn -jobId b8be4a7d-e338-43eb-a69e-c513cd458eba -filePath 'C:\\Users\\contosoadmin\\Desktop\\Data\\employee_termination_data.csv'\nIf the upload is successful, the script displays the\nUpload Successful\nmessage.\nNote\nIf you have problems running the previous command because of execution policies, see\nAbout Execution Policies\nand\nSet-ExecutionPolicy\nfor guidance about setting execution policies.\nStep 5: Monitor the HR connector\nAfter you create the HR connector and run the script to upload your HR data, you can view the connector and upload status in the Microsoft Purview portal. If you schedule the script to run automatically on a regular basis, you can also view the current status after the last time the script ran.\nSign in to the\nMicrosoft Purview portal\n.\nSelect\nSettings\n>\nData connectors\n.\nSelect\nMy connectors\n, then select the HR connector that you created to display the flyout page. This page contains the properties and information about the connector.\nUnder\nProgress\n, select the\nDownload log\nlink to open (or save) the status log for the connector. This log contains information about each time the script runs and uploads the data from the CSV file to the Microsoft cloud.\nThe\nRecordsSaved\nfield indicates the number of rows in the CSV file that you uploaded. For example, if the CSV file contains four rows, the value of the\nRecordsSaved\nfields is 4, if the script successfully uploads all the rows in the CSV file.\nIf you didn't run the script in Step 4, a link to download the script is displayed under\nLast import\n. You can download the script and then follow the steps to run the script.\n(Optional) Step 6: Schedule the script to run automatically\nTo make sure tools like the insider risk management solution always have access to the latest HR data from your organization, schedule the script to run automatically on a recurring basis, such as once a day. This schedule requires updating the HR data in the CSV file on a similar (if not the same) schedule so that it contains the latest information about employees who leave your organization. The goal is to upload the most current HR data so that the HR connector can make it available to the insider risk management solution.\nUse the Task Scheduler app in Windows to automatically run the script every day.\nOn your local computer, select the Windows\nStart\nbutton and then type\nTask Scheduler\n.\nSelect the\nTask Scheduler\napp to open it.\nIn the\nActions\nsection, select\nCreate Task\n.\nOn the\nGeneral\ntab, type a descriptive name for the scheduled task, such as\nHR Connector Script\n. You can also add an optional description.\nUnder\nSecurity options\n, do the following steps:\nDecide whether to run the script only when you're logged on to the computer or run it when you're logged on or not.\nMake sure that the\nRun with the highest privileges\ncheckbox is selected.\nSelect the\nTriggers\ntab, select\nNew\n, and then do the following steps:\nUnder\nSettings\n, select the\nDaily\noption, then choose a date and time to run the script for the first time. The script runs every day at the same specified time.\nUnder\nAdvanced settings\n, make sure the\nEnabled\ncheckbox is selected.\nSelect\nOk\n.\nSelect the\nActions\ntab, select\nNew\n, and then do the following steps:\nIn the\nAction\ndropdown list, make sure that\nStart a program\nis selected.\nIn the\nProgram/script\nbox, select\nBrowse\n, go to the following location, and select it so the path displays in the box:\nC:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\n.\nIn the\nAdd arguments (optional)\nbox, paste the same script command that you ran in Step 4. For example,\n.\\HRConnector.ps1 -tenantId \"d5723623-11cf-4e2e-b5a5-01d1506273g9\" -appId \"c12823b7-b55a-4989-faba-02de41bb97c3\" -appSecret \"MNubVGbcQDkGCnn\" -jobId \"e081f4f4-3831-48d6-7bb3-fcfab1581458\" -filePath \"C:\\Users\\contosoadmin\\Desktop\\Data\\employee_termination_data.csv\"\nIn the\nStart in (optional)\nbox, paste the folder location of the script that you ran in Step 4. For example,\nC:\\Users\\contosoadmin\\Desktop\\Scripts\n.\nSelect\nOk\nto save the settings for the new action.\nIn the\nCreate Task\nwindow, select\nOk\nto save the scheduled task. You might be prompted to enter your user account credentials.\nThe new task appears in the Task Scheduler Library.\nThe last time the script ran and the next time it's scheduled to run displays. You can double-select the task to edit it.\nYou can also verify the last time the script ran on the flyout page of the corresponding HR connector in the compliance center.\n(Optional) Step 7: Upload data by using Power Automate templates\nYou can upload HR data by using Power Automate templates and define triggers. For example, you can configure a Power Automate template to trigger when new HR connector files are available in SharePoint or OneDrive locations. You can also streamline this process by storing confidential information like Microsoft Entra application secret (created in\nStep 2\n) in Azure Key Vault and use it with Power Automate for authentication.\nComplete the following steps to automatically upload HR data when new files become available on OneDrive for Business:\nDownload the\nImportHRDataforIRM.zip\npackage from the\nGitHub site\n.\nIn\nPower Automate\n, go to\nMy flows\n.\nSelect\nImport\nand upload the\nImportHRDataforIRM.zip\npackage.\nAfter the package is uploaded, update the content (name and OneDrive for Business connection), and select\nImport\n.\nSelect\nOpen flow\nand update the parameters. The following table describes the parameters to use in this Power Automate Flow and their required values. Use the information you obtained in the previous steps for these values.\nParameter\nDescription\nApp ID\nThis is the Microsoft Entra application ID for the app that you created in Microsoft Entra ID in\nStep 2\n. Microsoft Entra ID uses this application ID for authentication when the script attempts to access your Microsoft 365 organization.\nApp Secret\nThis is the Microsoft Entra application secret for the app that you created in Microsoft Entra ID in\nStep 2\n. This application secret is used for authentication.\nFile location\nThis is the OneDrive for Business location where Power Automate monitors for 'new file created' activities to trigger this flow.\nJob ID\nIdentifier for the HR connector created in\nStep 3\n. This identifier associates the HR data uploaded to the Microsoft cloud with the HR connector.\nTenant ID\nIdentifier for your Microsoft 365 organization obtained in\nStep 2\n. You can also obtain the tenant ID for your organization on the\nOverview\nblade in the Microsoft Entra admin center. This identifier is used to identify your organization.\nURI\nVerify that the value for this parameter is\nhttps://webhook.ingestion.office.com/api/signals\nSelect\nSave\n.\nGo to\nFlow overview\nand select\nTurn on\n.\nTest the flow manually by uploading a new file to your OneDrive for Business folder and verify that it ran successfully. This process might take a few minutes after the upload before the flow is triggered.\nYou can now monitor the HR connector as described in\nStep 5\n.\nIf needed, you can update the flow to create triggers based on file availability and modification events on SharePoint and other data sources supported by Power Automate Flows.\nExisting HR connectors\nOn December 13, 2021, we released the employee profile data scenario for HR connectors. If you created an HR connector before this date, we migrate the existing instances or your organization's HR connectors so your HR data continues to be imported to the Microsoft cloud. You don't have to do anything to maintain this functionality. You can keep using these connectors without disruption.\nIf you want to implement the employee profile data scenario, create a new HR connector and configure it as required. After you create a new HR connector, run the script by using the job ID of the new connector and CSV files with\nemployee profile data\npreviously described in this article.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "HR Data Connector",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/sensitive-information-type-learn-about": {
      "content_hash": "sha256:89f96f3a769727abf9268aac7e97662084230190725b677db32e91e2429ec809",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about sensitive information types\nFeedback\nSummarize this article for me\nIdentifying and classifying sensitive items that are under your organization's control is the first step in the\nInformation Protection discipline\n. Microsoft Purview provides three ways of identifying items so that they can be classified:\nmanually, by users\nvia automated pattern recognition, as with sensitive information types\nvia\nmachine learning\nSensitive information types (SITs) are pattern-based classifiers. They detect sensitive information like social security, credit card, or bank account numbers to identify sensitive items, see\nSensitive information type entity definitions\nfor a complete list of all SITs.\nMicrosoft provides a large number of preconfigured SITs or you can create your own.\nLicensing\nE5 license is required to make use of credential scanning SITs. For a list of all the credential scanning SITs, see\nAll credentials sensitive information types\n. This SIT contains all the credential scanning SITs that are available in the portal. Each member of this SIT is a credential scanning SIT and can be used as a standalone. For a list of many Microsoft created SITs, see\nSensitive information type entity definitions\n.\nSensitive information types are used in\nMicrosoft Purview Data Loss Prevention policies\nSensitivity labels\nRetention labels\nInsider risk management\nCommunication compliance\nAuto-labeling policies\nMicrosoft Priva\nCategories of sensitive information types\nBuilt in sensitive information types\nMicrosoft created these SITs and they show up in the Purview portal by default. These SITs can't be edited, but you can use them as templates by copying them to create custom sensitive information types. See,\nSensitive information type entity definitions\nfor a full list of all SITs.\nNamed entity sensitive information types\nNamed entity SITs also show up in the Purview portal by default. They detect person names, physical addresses, and medical terms and conditions. They can't be edited or copied. For more information, see\nLearn about named entities\n.\nNamed entity SITs come in two types:\nun-bundled\nThese named entity SITs have a narrower focus, such as a single country or region, or a single class of terms. Use them when you need a data loss prevention (DLP) policy with a narrower detection scope. See,\nExamples of named entity SITs\n.\nbundled\nBundled named entity SITs detect all possible matches in a class, such as\nAll physical addresses\n. Use them as broad criteria in your DLP policies for detecting sensitive items. See,\nExamples of named entity SITs\n.\nCustom sensitive information types\nIf the preconfigured sensitive information types don't meet your needs, you can create your own custom sensitive information types that you fully define or you can copy one of the built-in ones and modify it. For more information, see\nCreate a custom sensitive information type in the Microsoft Purview portal\n.\nExact data match sensitive information types\nAll exact data match (EDM)-based SITs are created from scratch. You use them to detect items that have exact values, which you define in a database of sensitive information. For more information, see\nLearn about exact data match based sensitive information types\n.\nFundamental parts of a sensitive information type\nEvery sensitive information type (SIT) entity consists of the following fields:\nName:\nIndicates how the sensitive information type is referred to.\nDescription:\nExplanation of what the sensitive information type is looking for.\nPattern:\nDefines what a SIT detects. It consists of the following components: primary element, supporting elements, confidence level, and proximity.\nThe following table describes each component of the patterns used in defining sensitive information types.\nPattern component\nDescription\nPrimary element\nThe main element that the sensitive information type is looking for. It can be a\nregular expression\nwith or without a checksum validation, a\nkeyword list\n, a\nkeyword dictionary\n, or a\nfunction\n.Each of these types of elements can either be selected from the list of existing SITs or can be custom-defined by a user with admin permissions. Once an element is defined, it appears in the list of existing elements, along with those that come built-in.\nSupporting element\nAn element that acts as corroborative evidence. When included, supporting elements help increase the confidence level with respect to the accuracy of detected matches. For example, if the primary element is defined as\nSSN\n(composed of nine digits), and the keyword\nSocial Security Number (SSN)\nis used as a supporting element when found in proximity to\nSSN\n, the confidence that the\nSSN\ndetected is truly a Social Security number is higher than if the\nSocial Security Number (SSN)\nkeyword is not present.\nA supporting element can be a regular expression (with or without a checksum validation), a keyword list, or a keyword dictionary.\nConfidence Level\nThere are three confidence levels with respect to detected matches: high, medium, and low. The confidence level reflects how much supporting evidence is detected along with the primary element. The more supporting evidence a detected item contains, the higher the confidence that a matched item contains the sensitive info you're looking for. For more information about confidence levels, see the video included later in this article.\nProximity\nSpecifies how close a supporting element is to a primary element, in terms of the number of characters between them.\nUnderstanding proximity\nThe following diagram shows how match detection works with respect to proximity. In this example, the primary element is the\nSSN\nfield and the SIT definition requires that each instance of an\nSSN\nvalue must be within a specified proximity to at least one of the following elements:\nAccountNumber\nName\nDateOfBirth\nIn the diagram, we see that the data being checked includes three different instances of the\nSSN\nfield:\nSSN1\n,\nSSN2\n,\nSSN3\n, and\nSSN4\n.\n.\nTo understand how proximity works, letâs start by taking a look at some sample detection criteria. Here, were want to detect nine-digit social security numbers. The detection criteria require that a nine-digit regular expression (primary element) is found in conjunction with supporting evidence (among the\nAccountNumber\n,\nName\n, and\nDateOfBirth\nfields) that appears within 250 characters (the\nproximity\n).\nAs illustrated in the diagram, only the primary elements\nSSN1\nand\nSSN4\nmeet the detection criteria described. Let's take a closer look.\nIn the case of\nSSN1\n, the\nAccountNumber\nvalue is within the specified proximity window of 250 characters, so a match is detected.\nIn both the cases of\nSSN2\nand\nSSN3\n, none of the supporting elements occur within 250 characters of the primary element, so those values aren't detected as a match. However, as you look at the proximity window for\nSSN2\nin the diagram, you might ask:\nWhy isn't there a match for\nSSN2\n? Doesn't the\nSSN2\nproximity window extend to the\nName\nelement?\nThis is a good question. The answer is:\nNot quite\n. While the proximity window\nextends into\nthe\nName\nvalue, it doesn't include the\nentire\nvalue, so the pattern doesn't match.\nFinally, in the case of\nSSN4\n, there are two supporting elements within the proximity window, both\nName\nand\nDateOfBirth\n, so this pattern matches as well.\nLearn more about confidence levels in this short video.\nExample sensitive information type\nArgentina national identity (DNI) number\nFormat\nEight digits separated by periods\nPattern\nEight digits:\ntwo digits\na period\nthree digits\na period\nthree digits\nChecksum\nNo\nDefinition\nA DLP policy has medium confidence that it has detected this type of sensitive information if, within a proximity of 250 characters:\nThe regular expression Regex_argentina_national_id finds content that matches the pattern.\nA keyword from Keyword_argentina_national_id is found.\n<!-- Argentina National Identity (DNI) Number -->\n<Entity id=\"eefbb00e-8282-433c-8620-8f1da3bffdb2\" recommendedConfidence=\"75\" patternsProximity=\"250\">\n <Pattern confidenceLevel=\"75\">\n <IdMatch idRef=\"Regex_argentina_national_id\"/>\n <Match idRef=\"Keyword_argentina_national_id\"/>\n </Pattern>\n</Entity>\nKeywords\nKeyword_argentina_national_id\nArgentina National Identity number\nIdentity\nIdentification National Identity Card\nDNI\nNational Registry of Persons (NIC)\nDocumento Nacional de Identidad\nRegistro Nacional de las Personas\nIdentidad\nIdentificaciÃ³n\nMore on confidence levels\nIn a sensitive information type entity definition,\nconfidence level\nreflects how much supporting evidence is detected in addition to the primary element. The more supporting evidence an item contains, the higher the confidence that a matched item contains the sensitive info you're looking for. For example, matches with a high confidence level contain more supporting evidence in close proximity to the primary element, whereas matches with a low confidence level would contain little to no supporting evidence in close proximity.\nA high confidence level returns the fewest false positives but might result in more false negatives. Low or medium confidence levels return more false positives but few to zero false negatives.\nlow confidence\n: Matched items contain the fewest false negatives but the most false positives. Low confidence returns all low, medium, and high confidence matches. The low confidence level has a value of 65.\nmedium confidence\n: Matched items contain an average number of false positives and false negatives. Medium confidence returns all medium, and high confidence matches. The medium confidence level has a value of 75.\nhigh confidence\n: Matched items contain the fewest false positives but the most false negatives. High confidence only returns high confidence matches and has a value of 85.\nYou should use high confidence level patterns with low counts, say five to 10, and low confidence patterns with higher counts, say 20 or more.\nNote\nIf you have existing policies or custom sensitive information types (SITs) defined using number-based confidence levels (also known as\naccuracy\n), they'll automatically be mapped to the three discrete confidence levels; low confidence, medium confidence, and high confidence, across the Security @ Compliance Center UI.\nAll policies with minimum accuracy or custom SIT patterns with confidence levels of between 76 and 100 will be mapped to high confidence.\nAll policies with minimum accuracy or custom SIT patterns with confidence levels of between 66 and 75 will be mapped to medium confidence.\nAll policies with minimum accuracy or custom SIT patterns with confidence levels less than or equal to 65 will be mapped to low confidence.\nCreating custom sensitive information types\nYou can choose from several options to create custom sensitive information types.\nUse the UI\n- You can set up a custom sensitive information type using the Purview portal UI. With this method, you can use regular expressions, keywords, and keyword dictionaries. To learn more, see\nCreate a custom sensitive information type\n.\nUse EDM\n- You can set up custom sensitive information types using Exact Data Match (EDM)-based classification. This method enables you to create a dynamic sensitive information type using a secure database that you can refresh periodically. See\nLearn about exact data match based sensitive information types\n.\nUse PowerShell\n- You can set up custom sensitive information types using PowerShell. Although this method is more complex than using the UI, you have more configuration options. See\nCreate a custom sensitive information type in Security & Compliance PowerShell\n.\nTuning trainable classifiers\nEndpoint DLP classifies files based on all sensitive information types available in the tenant, including custom sensitive information types, regardless of their utilization in any DLP policies. This can cause excessive classification traffic if the sensitive information types aren't well tuned and end up matching many files. You should optimize all custom sensitive information types. Do this by removing unused sensitive information types and redesigning SITs if they match most of the files in your organization. For guidance on utilizing SIT Regex validators to tune SITs, see:\nSensitive information type REGEX validators and additional check\nDouble byte character set support\nImproved confidence levels are available for immediate use within Microsoft Purview Data Loss Prevention services, information protection, Communication Compliance, data lifecycle management, and records management.\nInformation Protection now supports double byte character set languages for:\nChinese (simplified)\nChinese (traditional)\nKorean\nJapanese\nThis support is available for sensitive information types. For more information, see\nInformation protection support for double byte character sets release notes\n.\nSingle byte character set support\nTo detect patterns containing Chinese/Japanese characters and single byte characters or to detect patterns containing Chinese/Japanese and English, define two variants of the keyword or regex.\nFor example, to detect a keyword like \"æºå¯çdocument\", use two variants of the keyword; one with a space between the Japanese and English text and another without a space between the Japanese and English text. So, the keywords to be added in the SIT should be \"æºå¯ç document\" and \"æºå¯çdocument\". Similarly, to detect a phrase \"æ±äº¬ãªãªã³ããã¯2020\", two variants should be used; \"æ±äº¬ãªãªã³ããã¯ 2020\" and \"æ±äº¬ãªãªã³ããã¯2020\".\nAlong with Chinese/Japanese/double byte characters, if the list of keywords/phrases also contains non-Chinese/Japanese words also (for instance, English only), you should create two dictionaries/keyword lists. One for keywords containing Chinese/Japanese/double byte characters and another one for English-only keywords. For example, if you want to create a keyword dictionary/list with three phrases \"Highly confidential\", \"æ©å¯æ§ãé«ã\" and \"æºå¯çdocument\", the you should create two keyword lists.\nHighly confidential\næ©å¯æ§ãé«ã, æºå¯çdocument and æºå¯ç document\nWhile creating a regex using a double byte hyphen or a double byte period, make sure to escape both the characters like you would escape a hyphen or period in a regex. Here's a sample regex for reference:\n(?<!\\d)([4][0-9]{3}[\\-?\\-\\t]*[0-9]{4}\nWe recommend using string match instead of word match in a keyword list.\nTest sensitive information type\nYou can test the SIT by uploading a sample file. The test results show the number of matches for each confidence level. You can test built-in SITs, custom SITs, trainable classifiers, and exact data match.\nTest Built-in and Custom sensitive information type\nTest exact data match sensitive information type.\nTo test any custom or default SIT tenant, there must be at least one Exchange Online license added to the tenant. Otherwise, the Test SIT option will be greyed out when any SIT is selected.\nProvide match/not a match accuracy feedback in sensitive info types\nYou can view the number of matches a SIT has in\nSensitive info types\nand\nContent explorer\n. You can also provide feedback on whether an item is actually a match or not using the\nMatch\n,\nNot a Match\nfeedback mechanism and use that feedback to tune your SITs. For more information, see\nIncrease classifier accuracy\n.\nFor further information\nSensitive information type entity definitions\nCreate a custom sensitive information type\nCreate a custom sensitive information type in PowerShell\nTo learn how to use sensitive information types to comply with data privacy regulations, see\nDeploy information protection for data privacy regulations with Microsoft 365\n(aka.ms/m365dataprivacy).\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Sensitive Information Types",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/create-a-custom-sensitive-information-type": {
      "content_hash": "sha256:4d0afaa2b7dd9998cbca1b78db08ccb5cc944e12a70ec56f0e9e7c400166920c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate custom sensitive information types\nFeedback\nSummarize this article for me\nIf the preconfigured sensitive information types (SITs) don't meet your needs, you can create and define customized SITs that meet your needs. You can also copy and then edit a built-in SIT.\nThe custom SITs are added to the\nMicrosoft.SCCManaged.CustomRulePack\nrule package.\nThere are two methods for creating a new SIT:\nCreate a new SIT from scratch\nCopy and modify an existing SIT\nBefore you begin\nYou should be familiar with sensitive information types and what they're composed of. To get this understanding, see,\nLearn about sensitive information types\n. It's critical to understand the roles of:\nregular expressions\n- Microsoft 365 sensitive information types uses the Boost.RegEx 5.1.3 engine\nkeyword lists - you can create your own as you define your sensitive information type or choose from existing keyword lists\nkeyword dictionary\nSensitive information type functions\nconfidence levels\nFamiliarize yourself with\nSensitive information type limits\n.\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nImportant\nMicrosoft Customer Service & Support can't assist with creating custom classifications or regular expression patterns. Support engineers can provide limited support for the feature, such as, providing sample regular expression patterns for simulation purposes, or helping to troubleshoot an existing regular expression pattern that's not triggering as expected. However, they can't provide assurances that any custom content-matching development fulfills your requirements or obligations.\nCreate a custom SIT from scratch\nNote\nMicrosoft Purview supports creating custom SITs that use double-byte character languages, such as Chinese, Japanese, and Korean. Because these languages don't use delimiters the way that single-byte languages do, Purview adds a space between each word in languages that use double-byte characters. It also removes special characters, such as punctuation.\nUse the following procedure to fully define a brand new sensitive information type.\nSign in to the\nMicrosoft Purview portal\n.\nIn the Microsoft Purview portal, navigate to\nInformation Protection\n>\nClassifiers\n>\nSensitive info types\nand choose\nCreate sensitive info type\n.\nFill in values for\nName\nand\nDescription\nand choose\nNext\n.\nChoose\nCreate pattern\n. You can create multiple patterns, each with different elements and confidence levels, as you define your new sensitive information type.\nChoose the default confidence level for the pattern. The values are\nLow confidence\n,\nMedium confidence\n, and\nHigh confidence\n.\nChoose and define the\nPrimary element\n. The primary element can be a\nRegular expression\nwith an optional validator, a\nKeyword list\n, a\nKeyword dictionary\n, or one of the preconfigured\nFunctions\n. For more information on the SIT functions used for data loss prevention, see\nSensitive information type functions\n. For more information on the date and the checksum validators, see\nSensitive Information Type regular expression validators\n.\nImportant\nDon't use positional regex anchors, like\n^\nand\n$\nin custom SITs as the SIT is unlikely to behave as intended when these anchors are part of the regular expression. If they are used, when the content is scanned there are no guarantees about where in the content will correspond to the starting and ending anchors.\nFill in a value for\nCharacter proximity\n.\n(Optional) Add supporting elements if you have any. Supporting elements can be a regular expression with an optional validator, a keyword list, a keyword dictionary or one of the predefined functions. Supporting elements can have their own\nCharacter proximity\nconfiguration.\n(Optional) Add any\nadditional checks\nfrom the list of available checks.\nChoose\nCreate\n.\nChoose\nNext\n.\nChoose the\nrecommended confidence level\nfor this sensitive information type.\nCheck your settings and choose\nSave\n.\nImportant\nMicrosoft 365 uses the search crawler to identify and classify sensitive information in SharePoint and OneDrive sites. To identify your new custom sensitive information type in existing content, the content must be recrawled. Content is crawled based on a schedule, but you can manually recrawl content for a site collection, list, or library. For more information, see\nManually request crawling and reindexing of a site, a library, or a list\n.\nThe\nSensitive info types\ntab of the\nClassifiers\npage, lists all of the sensitive information types. Choose\nRefresh\nand then or use the search tool or browse the list to find your new SIT.\nCopy and modify an existing SIT\nThis procedure explains how to copy and modify an existing SIT using the Purview Portal.\nAlternatively, you can copy and modify custom SITs using PowerShell and using Purview's Exact Data Match (EDM) capabilities. To learn more about those methods, see:\nCreate a custom sensitive information type in Microsoft Purview PowerShell\nLearn about exact data match based sensitive information types\nNote\nThese SITs can't be copied:\nCanada driver's license number\nEU driver's license number\nEU national identification number\nEU passport number\nEU social security number or equivalent identification\nEU tax identification number\nInternational classification of diseases (ICD-10-CM)\nInternational classification of diseases (ICD-9-CM)\nU.S. driver's license number\nWhen you have 10 text processors or restricted text processors, such as keyword lists, regex, keyword dictionaries, or functions, you won't be able to copy the SIT from the UI directly. Instead, you need to use PowerShell for this task. To learn more about how to clone or copy your SIT using PowerShell, see\nModify a custom sensitive information type using PowerShell\nCopy and modify an existing SIT using the Microsoft Purview portal\nSign in to the\nMicrosoft Purview portal\n.\nInformation Protection\n>\nClassifiers\n>\nSensitive info types\nand select the sensitive information type that you want to copy.\nThe overview page for the sensitive information type opens. Choose\nCopy\n. When the copy is ready, a message stating that the copy was created appears with an option to edit it. Choose\nYes\n.\nGive your new sensitive information type a new\nName\nand\nDescription\n.\nYou can choose to create a new pattern, or edit or remove some or all of the existing patterns.\nTo create a new pattern, choose\nCreate\n.\nTo edit an existing pattern, choose the\nEdit\n(pencil) icon next to the pattern you want to change.\nTo remove a pattern, choose the\nDelete\nicon next to the pattern you want to remove.\nWhen creating or editing a pattern, choose the default confidence level for the pattern. The values are\nLow confidence\n,\nMedium confidence\n, and\nHigh confidence\n.\nChoose and define\nPrimary element\n. The primary element can be a\nRegular expression\n, a\nKeyword list\n, a\nKeyword dictionary\n, or one of the preconfigured\nFunctions\n. See,\nSensitive information type functions\n.\nFill in a value for\nCharacter proximity\n.\n(Optional) If you have\nSupporting elements\nor any\nadditional checks\nyou want to run, add them. If needed, you can organize your\nSupporting elements\ninto groups.\nIf you're creating a new pattern, choose\nCreate\n. If you're editing an existing pattern, choose\nUpdate\n.\nChoose\nNext\n.\nConfirm the confidence level selection for this sensitive information type and then choose\nNext\n.\nReview your settings and then choose\nSave\n.\nYour new sensitive information type is created. At the confirmation message, choose *\nDone\nNote\nMicrosoft Purview Information Protection supports double byte character set languages for:\nChinese (simplified)\nChinese (traditional)\nKorean\nJapanese\nThis support is available for sensitive information types. For more information, see\nInformation protection support for double byte character sets release notes (preview)\n.\nTip\nTo detect patterns containing Chinese/Japanese characters and single byte characters, or to detect patterns containing Chinese/Japanese and English, define two variants of the keyword or regex.\nFor example, to detect a keyword like \"æºå¯çdocument\", use two variants of the keyword; one with a space between the Japanese and English text and another without a space between the Japanese and English text. So, the keywords to be added in the SIT should be \"æºå¯ç document\" and \"æºå¯çdocument\". Similarly, to detect a phrase \"æ±äº¬ãªãªã³ããã¯2020\", two variants should be used; \"æ±äº¬ãªãªã³ããã¯ 2020\" and \"æ±äº¬ãªãªã³ããã¯2020\".\nAlong with Chinese/Japanese/double byte characters, if the list of keywords/phrases also contain non Chinese/Japanese words also (for instance, English only), creating two dictionaries/keyword lists is recommended. Create one for keywords containing Chinese/Japanese/double byte characters and another for English-only.\nFor example, if you want to create a keyword dictionary/list with three phrases \"Highly confidential\", \"æ©å¯æ§ãé«ã\", and \"æºå¯çdocument\", you should create two keyword lists.\nHighly confidential\næ©å¯æ§ãé«ã, æºå¯çdocument and æºå¯ç document\nWhile creating a regex using a double byte hyphen or a double byte period, make sure to escape both the characters in the same way that you would escape a hyphen or period in a regex. Here's a sample regex for reference:\n(?<!\\d)([4][0-9]{3}[\\-?\\-\\t]*[0-9]{4})\nDouble-byte special characters shouldn't be used in the keyword.\nWe recommend using a string match instead of a word match in a keyword list.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Custom SITs",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/create-a-keyword-dictionary": {
      "content_hash": "sha256:0f7b00896df63400e5dcb7df4ed7a30eebeb54358beebcabc1f231f49ad1a6be",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate a keyword dictionary\nFeedback\nSummarize this article for me\nMicrosoft Purview can identify, monitor, and protect your sensitive items. Identifying sensitive items sometimes requires looking for keywords, particularly when identifying generic content (such as healthcare-related communication), or inappropriate or explicit language. Although you can create keyword lists when you\ncreate custom sensitive information types\n, keyword lists are limited in size and if you're\ncreating them in PowerShell\n, require modifying XML to create or edit them.\nIn contrast, keyword dictionaries provide simpler management of keywords and at a larger scale, supporting up to 1 MB of terms (post-compression) in the dictionary. Additionally, keyword dictionaries can support any language. The tenant limit is also 1 MB after compression. A post-compression limit of 1 MB means that all dictionaries combined across a tenant can have close to one million characters.\nKeyword dictionary limits\nYou can create keyword dictionary, subject to a combined size limit of 1MB (post compression) per tenant. To find out how many keyword dictionaries you have in your tenant, follow the procedures in\nConnect to the Security & Compliance PowerShell\nto connect to your tenant and then run this PowerShell script:\n$rawFile = $env:TEMP + \"\\rule.xml\"\n\n$kd = Get-DlpKeywordDictionary\n$ruleCollections = Get-DlpSensitiveInformationTypeRulePackage\n[System.IO.File]::WriteAllBytes((Resolve-Path $rawFile), $ruleCollections.SerializedClassificationRuleCollection)\n$UnicodeEncoding = New-Object System.Text.UnicodeEncoding\n$FileContent = [System.IO.File]::ReadAllText((Resolve-Path $rawFile), $unicodeEncoding)\n\nif($kd.Count -gt 0)\n{\n$count = 0\n$entities = $FileContent -split \"Entity id\"\nfor($j=1;$j -lt $entities.Count;$j++)\n{\nfor($i=0;$i -lt $kd.Count;$i++)\n{\n$Matches = Select-String -InputObject $entities[$j] -Pattern $kd[$i].Identity -AllMatches\n$count = $Matches.Matches.Count + $count\nif($Matches.Matches.Count -gt 0) {break}\n}\n}\n\nWrite-Output \"Total Keyword Dictionary SIT:\"\n$count\n}\nelse\n{\n$Matches = Select-String -InputObject $FileContent -Pattern $kd.Identity -AllMatches\nWrite-Output \"Total Keyword Dictionary SIT:\"\n$Matches.Matches.Count\n}\n\nRemove-Item $rawFile\nBasic steps to creating a keyword dictionary\nMost commonly you compile your keywords for your dictionary in a file, such as a .csv or .txt list. You upload the dictionary file into a SIT during creation or editing or import them via a PowerShell cmdlet. Alternately, you can start from an existing or from an existing\nKeyword dictionary\n. Lastly, you can enter keywords manually in the\nAdd keyword dictionary\ndialog. When you create a keyword dictionary, you follow the same core steps:\nCreate a keyword dictionary using the Microsoft Purview portal\nUse these steps to create or import keywords for a custom dictionary:\nSign in to the\nMicrosoft Purview portal\nInformation Protection\n>\nClassifiers\n>\nSensitive info types\n.\nSelect\n+ Create sensitive info type\nand then enter a\nName\nand\nDescription\nfor your sensitive info type. Choose\nNext\n.\nOn the\nDefine patterns for this sensitive info type\npage, choose\n+ Create pattern\n.\nIn the\nNew pattern\nwindow, select a\nConfidence level\n.\nChoose\nAdd a Primary element\nand select\nKeyword dictionary\n.\nOn the\nAdd a keyword dictionary\nflyout, you can:\nUpload a dictionary\nfile in\nTXT\nor\nCSV\nformat.\nChoose from existing dictionaries\n.\nor create a new dictionary by entering keywords manually and giving it a name.\nStill in the\nNew Pattern\nwindow, for\nCharacter proximity\n, specify how far away (in number of characters) that any supporting elements must be to be detected. The closer the primary and supporting elements are to each other, the more likely the detected content is going to be what you're looking for.\nAdd the\nSupporting elements\nyou wish to use to increase the accuracy of detecting what you're looking for.\nAdd any\nAdditional checks\nand then choose\nCreate\n.\nChoose\nNext\nto continue creating your sensitive information type. When you're finished, choose\nDone\n.\nCreate a keyword dictionary from a file using PowerShell\nOften when you need to create a large dictionary, it's so you can use keywords from a file or a list exported from some other source. In the example that follows, you create a keyword dictionary containing a list of diseases to screen in external email. To begin, you need to\nconnect to Security & Compliance PowerShell\n.\nCopy your keywords into a text file and make sure that each keyword is on a separate line.\nSave the text file with Unicode encoding. In Notepad, navigate to >\nSave As\n>\nEncoding\n>\nUnicode\n.\nRead the file into a variable by running this cmdlet:\n$fileData = [System.IO.File]::ReadAllBytes('<filename>')\nCreate the dictionary by running this cmdlet:\nNew-DlpKeywordDictionary -Name <name> -Description <description> -FileData $fileData\nUsing keyword dictionaries in custom sensitive information types and DLP policies\nKeyword dictionaries can be used as part of the match requirements for a custom sensitive information type, or as a sensitive information type themselves. Both require you to create a\ncustom sensitive information type\n. Follow the instructions in the linked article to create a sensitive information type. Once you have the XML, you need the GUID identifier from the XML in order to use the dictionary.\n<Entity id=\"9e5382d0-1b6a-42fd-820e-44e0d3b15b6e\" patternsProximity=\"300\" recommendedConfidence=\"75\">\n <Pattern confidenceLevel=\"75\">\n <IdMatch idRef=\". . .\"/>\n </Pattern>\n</Entity>\nTo get the identity of your dictionary, run this command and copy the\nIdentity\nproperty value:\nGet-DlpKeywordDictionary -Name \"Diseases\"\nThe output of the command looks like this:\nRunspaceId : 138e55e7-ea1e-4f7a-b824-79f2c4252255\nIdentity : 8d2d44b0-91f4-41f2-94e0-21c1c5b5fc9f\nName : Diseases\nDescription : Names of diseases and injuries from ICD-10-CM lexicon\nKeywordDictionary : aarskog's syndrome, abandonment, abasia, abderhalden-kaufmann-lignac, abdominalgia, abduction contracture, abetalipo\nproteinemia, abiotrophy, ablatio, ablation, ablepharia,abocclusion, abolition, aborter, abortion, abortus, aboulomania,\nabrami's disease, abramo\nIsValid : True\nObjectState : Unchanged\nPaste the\nidentity\nvalue into the XML for your custom sensitive information type as the\nidRef\n. Next, upload the XML file. Your dictionary now appears in your list of sensitive information types and you can use it right in your policy, specifying how many keywords are required to match.\n<Entity id=\"d333c6c2-5f4c-4131-9433-db3ef72a89e8\" patternsProximity=\"300\" recommendedConfidence=\"85\">\n <Pattern confidenceLevel=\"85\">\n <IdMatch idRef=\"8d2d44b0-91f4-41f2-94e0-21c1c5b5fc9f\" />\n </Pattern>\n </Entity>\n <LocalizedStrings>\n <Resource idRef=\"d333c6c2-5f4c-4131-9433-db3ef72a89e8\">\n <Name default=\"true\" langcode=\"en-us\">Diseases</Name>\n <Description default=\"true\" langcode=\"en-us\">Detects various diseases</Description>\n </Resource>\n </LocalizedStrings>\nNote\nMicrosoft 365 Information Protection supports double-byte character set languages for:\nChinese (simplified)\nChinese (traditional)\nKorean\nJapanese\nThis support is available for sensitive information types. See,\nInformation protection support for double byte character sets release notes (preview)\nfor more information.\nTip\nTo detect patterns containing Chinese/Japanese characters and single byte characters or to detect patterns containing Chinese/Japanese and English, define two variants of the keyword or regex.\nFor example, to detect a keyword like \"æºå¯çdocument\", use two variants of the keyword; one with a space between the Japanese and English text and another without a space between the Japanese and English text. So, the keywords to be added in the SIT should be \"æºå¯ç document\" and \"æºå¯çdocument\". Similarly, to detect a phrase \"æ±äº¬ãªãªã³ããã¯2020\", two variants should be used; \"æ±äº¬ãªãªã³ããã¯ 2020\" and \"æ±äº¬ãªãªã³ããã¯2020\".\nAlong with Chinese/Japanese/double byte characters, if the list of keywords/phrases also contains non-Chinese/Japanese words also (for instance, stand-alone English words), you should create two dictionaries/keyword lists. One for keywords containing Chinese/Japanese/double byte characters and another one for English words.\nFor example, if you want to create a keyword dictionary/list with three phrases \"Highly confidential\", \"æ©å¯æ§ãé«ã\" and \"æºå¯çdocument\", you should create two keyword lists.\nHighly confidential\næ©å¯æ§ãé«ã, æºå¯çdocument and æºå¯ç document\nWhile creating a regex using a double byte hyphen or a double byte period, make sure to escape both the characters like one would escape a hyphen or period in a regex. Here's a sample regex for reference:\n(?<!\\d)([4][0-9]{3}[\\-?\\-\\t]*[0-9]{4}\nWe recommend using a string match instead of a word match in a keyword list.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Keyword Dictionaries",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/create-custom-sensitive-information-types-with-exact-data-match-based-classification": {
      "content_hash": "sha256:27065afd94d2d5ad230b23ecc9c1a7f72b658ccbe3b5d08c45489f726ed01e3e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about exact data match based sensitive information types\nFeedback\nSummarize this article for me\nSensitive information types\n(SITs) are used to help identify sensitive data so that you can prevent it from being inadvertently or inappropriately shared. They're also used to help in locating relevant data in eDiscovery, and to apply governance actions to certain types of information. You define a custom SIT based on:\npatterns\nkeyword evidence such as\nemployee\n,\nsocial security number\n, or\nID\ncharacter proximity to evidence in a particular pattern\nconfidence levels\nBut what if you want a custom SIT that uses exact or nearly exact data values, instead of one that finds matches based on generic patterns? With Exact Data Match (EDM) based classification, you can create a custom sensitive information type that is designed to:\nbe dynamic and easily refreshed\nresult in fewer false positives\nwork with structured sensitive data\nhandle sensitive information more securely, not sharing it with anyone, including Microsoft\nbe used with several Microsoft cloud services\nEDM-based classification enables you to create custom SITs that refer to exact values in a database of sensitive information. The database can be refreshed daily and can contain up to 100 million rows of data. So, as employees, patients, and clients come and go, and as records change, your custom sensitive information types remain current and applicable. And, you can use EDM-based classification with policies, such as\nMicrosoft Purview Data Loss Prevention policies\nor\nMicrosoft Cloud App Security file policies\n.\nThe following diagram shows the fundamental workings of EDM classification:\nNote\nMicrosoft Purview Information Protection supports the following languages that use double-byte character sets:\nChinese (simplified)\nChinese (traditional)\nKorean\nJapanese\nThis support is available for sensitive information types. For more information, see\nInformation protection support for double byte character sets: Release Notes (preview)\n.\nWhat's different in an EDM SIT\nWhen you work with EDM SITs, it's helpful to understand a few concepts that are unique to them.\nSchema\nA\nschema\nis an XML file. Microsoft Purview uses the schema to determine whether or not your data contains strings that match those that your sensitive information types are designed to detect.\nThe schema XML file defines:\nThe name of the schema, later referred to as the\nDataStore\n.\nThe field names that your sensitive information source table contains. There's a 1:1 mapping of schema field names to the column names in the sensitive information source table.\nWhich corroborative evidence fields require multi-token match mode.\nWhich data fields are searchable.\nWhether or not configurable matches are supported for each field. A\nconfigurable match\nis one with parameters that modify a search, such as ignoring delimiters and case in searched values.\nSensitive information source table\nThe sensitive information source table contains the values that the EDM SIT looks for. The table is made up of columns and rows. The column headers are the field names, the rows are instances of items and each cell in a row contains the values for that item instance for that field.\nHere's a simple example of a sensitive information source table.\nFirst Name\nLast Name\nDate of Birth\nIsaiah\nLanger\n05-05-1960\nAna\nBowman\n11-24-1971\nOscar\nWard\n02-12-1998\nRule package\nEvery sensitive information type has a rule package. You use the rule package in an EDM SIT to define the various components of your EDM SIT. The following table provides a description of each component.\nComponent\nDescription\nMatch\nSpecifies the primary element (data field) to be used in exact lookup. It can be a regular expression with or without a checksum validation, a keyword list, a keyword dictionary, or a function.\nClassification\nSpecifies the sensitive information type match that triggers an EDM lookup.\nSupporting elements\nElements that, when found, provide evidence that helps increase the confidence of the match. For example, the occurrence of a last name in close proximity to an actual social security number. A supporting element can be a regular expression with or without a checksum validation, a keyword list, a keyword dictionary, or a single- or multi-token string match.\nConfidence level\n(High, Medium, Low)\nIndication of how much supporting evidence is detected in addition to the primary element. The more supporting evidence an item contains, the higher the confidence that a matched item contains the sensitive info you're looking for. For more information about confidence levels, see\nFundamental parts of a sensitive information type\n.\nProximity\nThe number of characters between primary and supporting element.\nYou supply your own schema and data\nMicrosoft Purview comes with many built-in SITs\nthat are predefined. These SITs come with schemas, REGEX patterns, keywords, and confidence levels. However, with EDM SITs, you're responsible for defining the schema, as well as the primary and secondary fields that identify sensitive items. Because the schema and primary and secondary data values are all highly sensitive, you encrypt them via a\nhash\nfunction that includes a randomly generated or self-supplied\nsalt\nvalue. Only the hashed values are uploaded to the service, so your sensitive data is never in the open.\nPrimary and secondary support elements\nWhen you create an EDM SIT, you define a\nprimary element\nfield in the rule package. EDM then searches all of your content for the primary element. So that EDM can detect them, primary elements must be discoverable through an existing SIT.\nNote\nFor a complete list of the available SITs., see\nSensitive information type entity definitions\nYou need to find a built-in SIT that detects the sensitive information that you want your EDM SIT to detect. For example, if your EDM SIT schema has\nU.S. social security number\nas the primary element, when you create your EDM schema, you'd associated it with the\nU.S. Social Security Number (SSN)\nSIT. Primary elements must follow a defined pattern in order to be detected.\nWhen the primary element is found in a scanned item, EDM then looks for\nsecondary\nelements (also called\nsupporting\nelements). Unlike primary elements, secondary elements have the option of following a pattern. If secondary elements contain multiple tokens, those elements need to either be associated with a SIT that can detect that content or that can be configured for multi-token matching. In all cases, secondary elements must be within a certain proximity to the primary element in order for a match to be detected.\nHow matching works\nEDM works by comparing strings in your documents and emails against values in the sensitive information source table. It uses this comparison to determine whether the values in the scanned content are present in the table. The determination is done by comparing one-way cryptographic hashes.\nTip\nYou can use both EDM SITs and the predefined SITs that they are based on, together in DLP rules to improve the detection of sensitive data. Use the EDM SIT with higher confidence levels, and the predefined SIT with lower confidence levels. For example, use an EDM SIT that looks for social security number and other supporting data with strict requirements with high confidence. If configured for high-confidence matches, EDM generates a DLP match when only a few instances are detected. To trigger a DLP match when greater numbers of occurrences are detected, use a built-in SIT, such as the\nU.S. Social Security Number\n.\nHow supporting elements work with EDM\nAs discussed in\nWhat's different in an EDM SIT\n, supporting elements are\nelements that, when found, provide evidence that helps increase the confidence of the match\n.\nWith support for EDM SITs, you can look for and detect supporting elements that are composed of multiple fields. Supporting element matches can consist of keyword lists, keyword dictionaries, single alphanumeric strings, or multi-token strings.\nLetâs look at an example. Presume that you want to detect U.S. Social Security numbers. To increase the match confidence, your supporting elements include\nfirst name\n,\nlast name\n, and\ndate of birth\n(DoB). So, your source table looks something like this:\nSSN\nFirstName\nLastName\nDoB\n987-65-4320\nIsaiah\nLanger\n05-05-1960\n078-05-1120\nAna\nBowman\n11-24-1971\n219-09-9999\nOscar\nWard\n02-12-1998\nWhen looking for matching supporting elements in a protected file, your EDM SIT checks for each supporting element (both individually and in combination) once the primary element is detected.\nFor instance, say that the first social security number is detected. The exact data match functionality next looks for combinations of supporting elements across all the columns in your source table:\nIsaiah\nLanger\n05-05-1960\nIsaiah Langer\nIsaiah 05-05-1960\nLanger 05-05-1960\nIsaiah Langer 05-05-1960\nMulti-token matching\nMulti-token matching is designed to be used when your corroborative evidence field contains multi-token values but matching such values to a SIT isn't easily accomplished. For instance, when you have an\nAddress\nfield containing values like\n1 Microsoft Way, Redmond, WA\nor\n123 Main Street, New York, NY\n.\nThis feature allows EDM to compare the hashes of consecutive words in the content with the hashes of the multi-token fields in your data source. If they're identical, EDM produces a match. This way, EDM can detect multi-token fields such as names, addresses, medical conditions, or any other corroborative evidence fields that might contain more than one word, as long as they're marked as multi-token in your EDM schema.\nFor example, if you select multi-token matching as the match option, you get two additional benefits:\nYour policies will detect content that matches multiple fields across the columns in your source table.\nYour source table can include fields with string values that consist of a preconfigured number of words. The following table shows a sample source table:\nSSN\nName\nStreet Address\n987-65-4320\nIsaiah Langer\n1432 Lincoln Road\n078-05-1120\nAna Bowman\n8250 First Street\n219-09-9999\nOscar Ward\n424 205th Avenue\nWith multi-token matching, the\nName\nand\nStreet Address\nfields are matched both as independent supporting element strings and in combination as individual fields. So, when matched as multi-token strings as supporting elements for Social Security number 987-65-4320, the matches are:\nIsaiah Langer\n1432 Lincoln Road\nWhen matched in combination, the match is like this:\nIsaiah Langer + 1432 Lincoln Road\nMulti-token matching is also supported for double-byte character sets, which generally don't use spaces to separate words.\nServices that EDM supports\nService\nLocations\nMicrosoft Purview Data Loss Prevention\n- SharePoint\n- OneDrive\n- Teams Chat\n- Exchange Online\n- Devices\nMicrosoft Defender for Cloud Apps\n- SharePoint\n- OneDrive\nAuto-labeling (service side)\n- SharePoint\n- OneDrive\n- Exchange Online\nAuto-labeling (client side)\n- Word\n- Excel\n- PowerPoint\n- Exchange desktop clients\nCustomer Managed Key\n- SharePoint\n- OneDrive\n- Teams Chat\n- Exchange Online\n- Word\n- Excel\n- PowerPoint\n- Exchange desktop clients\n- Devices\neDiscovery\n- SharePoint\n- OneDrive\n- Teams Chat\n- Exchange Online\n- Word\n- Excel\n- PowerPoint\n- Exchange desktop clients\nInsider Risk Management\n- SharePoint\n- OneDrive\n- Teams Chat\n- Exchange Online\n- Word\n- Excel\n- PowerPoint\n- Exchange desktop clients\nSee also\nGet started with exact data match based sensitive information types\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Exact Data Match",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/classifier-learn-about": {
      "content_hash": "sha256:4c5058851385d6c017b717bdc1e7e9f52820dea1f5aa444c97238c658d8ddacb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about trainable classifiers\nFeedback\nSummarize this article for me\nTrainable Classifiers\nThis categorization method is well suited to content that can't be easily identified using either the manual or automated pattern-matching methods. This method of categorization is designed to use a classifier to identify an item based on what the item is, not by elements that are in the item (pattern matching). A classifier learns how to identify a type of content by looking at hundreds of examples of the content you want to detect.\nNote\nIn Preview:\nYou can view the trainable classifiers in content explorer by expanding\nTrainable Classifiers\nin the filters panel. The trainable classifiers automatically display the number of incidents found in SharePoint, Teams, and OneDrive, without requiring any labeling.\nIf you don't want to use this feature, you must file a request with Microsoft Support. This request disables the display of your sensitive data that isn't used in any labeling policies within Content Explorer. You can disable scanning of your data as well. If scanning is turned off, sensitivity labeling and DLP policies with those classifiers don't work.\nWhere you can use classifiers\nUse classifiers as a condition for:\nAuto-labeling Office files with sensitivity labels\nAutomatically applying a retention label policy based on a condition\nCommunication compliance\nsupports Microsoft provided trainable classifiers only.\nSensitivity label conditions. (See\nAutomatically apply a sensitivity label to Microsoft 365 data\n)\nData loss prevention\nImportant\nClassifiers only work with items that aren't encrypted.\nTypes of classifiers\nMicrosoft provided Pretrained classifiers\n- Microsoft created and pretrained multiple classifiers that you can start using without training them. These classifiers appear with the status of\nReady to use\n.\nCustom trainable classifiers\n- If you need to identify and categorize your content beyond what the pretrained classifiers cover, you can create and train your own classifiers.\nFor a complete list of all pretrained classifiers, see\nTrainable classifiers definitions\n.\nCustom classifiers\nImportant\nLanguage limitation:\nSupport for custom classifiers is limited to English.\nWhen the Microsoft provided pretrained classifiers don't meet your needs, you can create and train your own classifiers. There's more work involved with creating your own, but they're better tailored to your organization's needs.\nTo create a custom trainable classifier, you start by feeding it one set of examples that are definitely in the category, and another set of examples that are definitely not. Microsoft Purview processes those examples and the classifier then makes predictions as to whether any given item falls into the category you're building. You then confirm the results, sorting out the true positives, true negatives, false positives, and false negatives to help increase the accuracy of its predictions.\nWhen you publish the classifier, it sorts through items in locations like SharePoint, Exchange, and OneDrive, and classifies the content.\nFor example, you can create trainable classifiers for:\nLegal documents - such as attorney client privilege, closing sets, statement of work\nStrategic business documents - like press releases, merger and acquisition, deals, business or marketing plans, intellectual property, patents, design docs\nPricing information - like invoices, price quotes, work orders, bidding documents\nFinancial information - such as organizational investments, quarterly or annual results\nProcess flow for creating custom classifiers\nThe following flow diagram illustrates the process for creating and publishing a classifier for use in compliance solutions, such as retention policies and communication supervision. For more detail on creating a custom trainable classifier, see\nGet started with trainable classifiers\n.\nTip\nIf you create a new SharePoint site and folder for your seed data, allow at least an hour for that location to be indexed before creating the trainable classifier that uses that seed data.\nRetraining classifiers\nRetraining published custom classifiers isn't supported. If you need to improve the accuracy of a trainable classifier you published, remove the classifier and\nstart over with larger sample sets\n.\nTo improve the accuracy of an unpublished classifier, review the test results, update the data set with additional data, and restart the training.\nSee also\nRetention labels\nLearn about data loss prevention\nSensitivity labels\nSensitive information type entity definitions\nDocument finger printing\nLearn about exact data match based sensitive information types\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Trainable Classifiers",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/retention": {
      "content_hash": "sha256:292a3c48e8e1a58a59d5f27cebed1194b430dc686a6ebf0e4e8d101ece489673",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about retention policies and retention labels\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nNote\nIf you're seeing messages about retention policies in Teams or have questions about retention labels in your apps, contact your IT department for information about how they have been configured for you. In the meantime, you might find the following articles helpful:\nTeams messages about retention policies\nApply retention labels to files in SharePoint or OneDrive\nThe information on this page is for IT administrators who can create retention policies and retention labels for compliance reasons.\nFor most organizations, the volume and complexity of their data is increasing dailyâemail, documents, instant messages, and more. Effectively managing or governing this information is important because you need to:\nComply proactively with industry regulations and internal policies\nthat require you to retain content for a minimum period of timeâfor example, the Sarbanes-Oxley Act might require you to retain certain types of content for seven years.\nReduce your risk in the event of litigation or a security breach\nby permanently deleting old content that you're no longer required to keep.\nHelp your organization to share knowledge effectively and be more agile\nby ensuring that your users work only with content that's current and relevant to them.\nRetention settings that you configure can help you achieve these goals. Managing content commonly requires two actions:\nAction\nPurpose\nRetain content\nPrevent permanent deletion and remain available for eDiscovery\nDelete content\nPermanently delete content from your organization\nWith these two retention actions, you can configure retention settings for the following outcomes:\nRetain-only: Retain content forever or for a specified period of time.\nDelete-only: Permanently delete content after a specified period of time.\nRetain and then delete: Retain content for a specified period of time and then permanently delete it.\nThese retention settings work with content in place that saves you the additional overheads of creating and configuring additional storage when you need to retain content for compliance reasons. In addition, you don't need to implement customized processes to copy and synchronize this data.\nUse the following sections to learn more about how retention policies and retention labels work, when to use them, and how they supplement each other. But if you're ready to get started and deploy retention settings for some common scenarios, see\nGet started with data lifecycle management\n.\nHow retention settings work with content in place\nWhen content has retention settings assigned to it, that content remains in its original location. Most of the time, people continue to work with their documents or mail as if nothing's changed. But if they edit or delete content that's included in the retention policy, a copy of the content is automatically retained.\nFor SharePoint and OneDrive sites: The copy is retained in the\nPreservation Hold\nlibrary.\nFor Exchange mailboxes: The copy is retained in the\nRecoverable Items\nfolder.\nFor Teams, Viva Engage messages, Copilot and AI apps: The copy is retained in a hidden folder named\nSubstrateHolds\nas a subfolder in the Exchange\nRecoverable Items\nfolder.\nNote\nBecause the Preservation Hold library is included in the site's storage quota, you might need to increase your storage when you use retention settings for SharePoint, OneDrive, and Microsoft 365 groups.\nThese secure locations and the retained content aren't visible to most people. In most cases, people don't even need to know that their content is subject to retention settings.\nFor more detailed information about how retention settings work for different workloads, see the following articles:\nLearn about retention for SharePoint and OneDrive\nLearn about retention for Teams\nLearn about retention for Viva Engage\nLearn about retention for Exchange\nLearn about retention for Copilot\nRetention policies and retention labels\nTo assign your retention settings to content, use\nretention policies\nand\nretention labels with label policies\n. You can use just one of these methods, or combine them.\nUse a retention policy to assign the same retention settings for content at a site or mailbox level, and use a retention label to assign retention settings at an item level (folder, document, email).\nFor example, if all documents in a SharePoint site should be retained for five years, it's more efficient to do this with a retention policy than apply the same retention label to all documents in that site. However, if some documents in that site should be retained for five years and others retained for 10 years, a retention policy wouldn't be able to do this. When you need to specify retention settings at the item level, use retention labels.\nUnlike retention policies, retention settings from retention labels travel with the content if it's moved to a different location within your Microsoft 365 tenant. In addition, retention labels have the following capabilities that retention policies don't support:\nOptions to start the retention period from when the content was labeled or based on an event, in addition to the age of the content or when it was last modified.\nUse\ntrainable classifiers\nto identify content to label.\nApply a default label for SharePoint items or Exchange messages.\nSupported actions at the end retention period:\nDisposition review\nto review the content before it's permanently deleted.\nAutomatically apply another retention label\nMark the content as a\nrecord\nas part of the label settings, and always have\nproof of disposition\nwhen content is deleted at the end of its retention period.\nRetention policies\nRetention policies can be applied to the following locations:\nExchange mailboxes\nSharePoint classic and communication sites\nOneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nExchange public folders\nTeams channel messages (standard channels,\nshared channels\n, and private channels\npost-migration\n)\nTeams chats\nTeams private channel messages (\npre-migration\nonly)\nMicrosoft Copilot experiences\nEnterprise AI apps\nOther AI apps\nViva Engage community messages\nViva Engage user messages\nNote\nIf you have existing retention policies for Teams chats and Copilot interactions, they continue to be supported, although they can't be edited when your tenant supports the separate locations. At this point, any new retention policies must use the new locations.\nYou can efficiently apply a single policy to multiple locations, or to specific locations or users.\nFor the start of the retention period, you can choose when the content was created or, supported only for files and the SharePoint, OneDrive, and Microsoft 365 Groups locations, when the content was last modified.\nItems inherit the retention settings from their container specified in the retention policy. If they are, then moved outside that container when the policy is configured to retain content, a copy of that item is retained in the workload's secured location. However, the retention settings don't travel with the content in its new location. If that's required, use retention labels instead of retention policies.\nRetention labels\nUse retention labels for different types of content that require different retention settings. For example:\nTax forms that need to be retained for a minimum period of time.\nPress materials that need to be permanently deleted when they reach a specific age.\nCompetitive research that needs to be retained for a specific period and then permanently deleted.\nWork visas that must be marked as a record so that they can't be edited or deleted.\nIn all these cases, retention labels let you apply retention settings for governance control at the item level (document or email).\nWith retention labels, you can:\nEnable people in your organization to apply a retention label manually\nto content in Outlook and Outlook on the web, OneDrive, SharePoint, and Microsoft 365 groups. Users often know best what type of content they're working with, so they can classify it and have the appropriate retention settings applied.\nApply retention labels to content automatically\nif it matches specific conditions, that includes cloud attachments that are shared in email or Teams, or when the content contains:\nSpecific types of sensitive information.\nSpecific keywords that match a query you create.\nPattern matches for a trainable classifier.\nStart the retention period from when the content was labeled\nfor documents in SharePoint sites and OneDrive accounts, and for email items.\nStart the retention period when an event occurs\n, such as employees leave the organization, or contracts expire.\nApply a default retention label to a document library, folder, or document set\nin SharePoint, so that all documents that are stored in that location inherit the default retention label.\nMark items as a record\nas part of your\nrecords management\nstrategy. When this labeled content remains in Microsoft 365, further restrictions are placed on the content that might be needed for regulatory reasons. For more information, see\nCompare restrictions for what actions are allowed or blocked\n.\nRetention labels, unlike\nsensitivity labels\n, don't persist if the content is moved outside Microsoft 365.\nDynamically mitigate the risk of accidental or malicious deletes\nIn preview, you can use this solution with Insider Risk Management so that retention labels are automatically applied with\nAdaptive Protection\n.\nWhen you enable Adaptive Protection for your tenant, retention labels are automatically applied to unlabeled content if it's deleted by users who have been identified as an\nelevated risk\n. If these users delete content from SharePoint, OneDrive, or Exchange, a retention label is automatically applied to that content to retain it for 120 days. As a result, that content remains accessible for search and eDiscovery from the\nsecured locations used by the workload\n.\nNote\nIf you enabled and configured Adaptive Protection before this integration with data lifecycle management released, you'll need to opt-in to create this auto-labeling policy. See the instructions at the end of this section.\nWhen these items are retained with Adaptive Protection, the following auditing events are generated and identify the user and item:\nFor SharePoint and OneDrive:\nRetained file proactively\nFor Exchange:\nRetained email item proactively\nAfter the 120 days expire, the items then become eligible for permanent deletion. To learn more about when permanent deletion occurs, see\nHow retention works for SharePoint and OneDrive\nand\nHow retention works for Exchange\n.\nUnlike other labeling scenarios, users don't see the retention label, and you don't need to create or manage the retention label or auto-labeling retention policy. At this time, you can't change the retention period or assign different policies based on the different risk levels, or for different locations. The single retention label and auto-labeling retention policy for your tenant aren't visible in the Microsoft Purview portal.\nIf you're using Adaptive Protection but don't want to automatically retain content in this way, you can turn off the auto-labeling policy without affecting other Adaptive Protection policies. Use the same control if you need to turn on the auto-labeling retention policy for Adaptive Protection, and confirm the status.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nSettings\n>\nSolution settings\n>\nData lifecycle management\n>\nAdaptive protection\n.\nFor\nAdaptive protection in Data Lifecycle Management\n, turn the setting off, confirm your choice, and select\nSave\n.\nAny retention labels that were applied as a result of Adaptive Protection are removed so that the items can then become eligible for permanent deletion.\nYou won't be able to turn on this setting unless Adaptive Protection is turned on for your tenant. If your account has the\nrequired permissions\n, you'll see an option to take you to the insider risk management solution where you can turn on and configure Adaptive Protection.\nOverride holds to reclaim disk space or permanently delete sensitive information\nAlso like adaptive protection, priority cleanup for files or mailbox items similarly applies retention labels under the covers. The labels are automatically configured and applied when you create a priority cleanup policy that identifies items with a query that you specify. This policy can override existing holds for retention and eDiscovery.\nPriority cleanup is specific to data lifecycle management and isn't supported for labeled items that are marked as records. Typical uses depend on the workload:\nFor SharePoint and OneDrive, you can use priority cleanup to periodically delete large files, such as Teams meeting recordings and transcripts. These files are regularly created if you're using the popular Copilot in Teams recap feature, and might be automatically retained with a retention policy that retains all items for many years. However, these specific files typically have little business value after 1-3 months, and you want to regularly delete them to save disk space. You can also use priroty cleanup to delete files in the Preservation Hold library that can prevent OneDrive accounts from being deleted after a user leaves the organization.\nFor Exchange, you can use priority cleanup to delete items when this action is required for security or privacy. For example, after a data spillage incident.\nFor more information and configuration instructions, see the following articles:\nOverride holds to clean up files for Copilot and reclaim storage\nExpedite the permanent deletion of sensitive information from mailboxes\n.\nClassifying content without applying any actions\nAlthough the main purpose of retention labels is to retain or delete content, you can also use retention labels without turning on any retention or other actions. In this case, you can use a retention label simply as a text label, without enforcing any actions.\nFor example, you can create and apply a retention label named \"Review later\" with no actions, and then use that label to find that content later.\nUsing a retention label as a condition in a DLP policy\nYou can specify a retention label as a condition in a Microsoft Purview Data Loss Prevention (DLP) policy for documents in SharePoint. For example, configure a DLP policy to prevent documents from being shared outside the organization if they have a specified retention label applied to it.\nFor more information, see\nCreate and Deploy data loss prevention policies\n.\nRetention labels and policies that apply them\nWhen you publish retention labels, they're included in a\nretention label policy\nthat makes them available for admins and users to apply to content. As the following diagram shows:\nA single retention label can be included in multiple retention label policies.\nRetention label policies specify the locations to publish the retention labels. A single label retention policy can include multiple locations.\nYou can also create one or more\nauto-apply retention label policies\n, each with a single retention label. With this policy, a retention label is automatically applied when conditions that you specify in the policy are met.\nRetention label policies and locations\nRetention labels can be published to different locations, depending on what the retention label does.\nIf the retention label is...\nThen the label policy can be applied to...\nPublished to admins and end users\nExchange, SharePoint, OneDrive, Microsoft 365 Groups\nAuto-applied based on sensitive information types, keywords or a query, or trainable classifiers\nExchange, SharePoint, OneDrive, Microsoft 365 Groups\nAuto-applied to cloud attachments\nSharePoint, OneDrive, Microsoft 365 Groups\nExchange public folders, Skype, Teams and Viva Engage messages don't support retention labels. To retain and delete content from these locations, use retention policies instead.\nOnly one retention label at a time\nUnlike\nsensitivity labels\n, you can't configure priorities for retention labels. Use the following information to understand label behavior for retention labels.\nAs with sensitivity labels, an item such as an email or document can have only a single retention label applied to it at a time. A retention label can be applied\nmanually\nby an end user or admin, or automatically by using any of the following methods:\nAuto-apply retention label policy\nA Microsoft Syntex model\nDefault retention label for SharePoint or Outlook\nOutlook rules\nPower Automate compliance action\nof\nApply a retention label on the item\nIf there are multiple auto-apply retention label policies that could apply a retention label, and the content meets the conditions of more than one of these policies, you can't control which retention label will be selected. However, in some cases, the retention label for the oldest auto-apply retention label policy (by date created) is selected. This happens only when the matching policies don't include multiple instances of the same type of condition (sensitive information types, specific keywords or searchable properties, or trainable classifiers).\nFor standard retention labels (they don't mark items as a\nrecord or regulatory record\n):\nAdmins and end users can manually change or remove an existing retention label that's applied on content.\nWhen items already have a retention label applied, the existing label won't be automatically removed or replaced by another retention label with the following exceptions:\nAt the end of the retention period, the existing label is configured to automatically\napply a different retention label\n, or the existing label is configured to\nrun a Power Automate flow\nwith the compliance action of\nRelabel an item at the end of retention\n.\nYou use the Power Automate compliance action of\nApply a retention label on the item\n. If the item already has a retention label applied, it will be replaced.\nThe existing label was applied as a default label. When you use a default label, there are some scenarios when it can be replaced by another default label, or automatically removed. For more information, see\nDefault labels for SharePoint and Outlook\n.\nFor retention labels that mark items as a record or a regulatory record:\nThese retention labels are never automatically changed during their configured retention period, even if the existing label was applied as a default label, or identified for\npriority cleanup\n.\nOnly admins for the container can manually change or remove retention labels that mark items as a record, but can't manually change or remove retention labels that mark items as a regulatory record. For more information, see\nCompare restrictions for what actions are allowed or blocked\n.\nAt the end of the retention period, an existing label can be replaced if it's configured to mark items as a record and automatically\napply a different retention label\nor to\nrun a Power Automate flow\nwith the compliance action of\nRelabel an item at the end of retention\n. You can't use these relabeling methods if the existing label is configured to mark items as a regulatory record.\nWill an existing label be overridden or removed?\nUse the following tables to help you quickly identify whether an existing retention label on items can be overridden by another retention label, or removed so that it's no longer labeled.\nNote\nUnless a labeled item is marked as a record or regulatory record, it can always be overridden by\npriority cleanup\nthat under the covers, applies a retention label to delete the item.\nA standard retention label refers to a retention label that isn't configured to mark items as records or regulatory records.\nWill a label be overridden?\nWill a label be removed?\nNew label application method\nStandard retention label\nMarks items as records\nMarks items as regulatory records\nManually applied\nYes\nYes\n1\nif admin for the container\nNo\nApplied with Power Automate actions\nYes\nYes\n1\nNot applicable\nApplied with the\nChange label\nlabel setting\nYes\nYes\nNot applicable\nApplied with the\nRelabel\ndisposition review action\nYes\nYes\nNo\nApplied with auto-apply retention label policy\nNo\nNo\nNot applicable\nApplied with Microsoft Syntex model\nNo\nNo\nNo\nOutlook rules\nNo\nNo\nNo\nInherited from default label for SharePoint\nYes if originally applied by another default label\n2\nNo\nNo\nInherited from default label for Outlook\nYes if originally applied by another default label\nNo\nNo\nFootnotes:\n1\nThe record must be\nlocked\n.\n2\nAn exception is if you move the item to another location with a different default label, then the original label isn't overwritten. Only if you then change the default label for this new location will the original default label be overwritten.\nNew labeling action\nStandard retention label\nMarks items as records\nMarks items as regulatory records\nManually remove\nYes\nYes\n1\nif admin for the container\nNo\nPower Automate relabel action\n- No label specified\nYes\nYes\n1\nNot applicable\nAuto-apply retention label policy\nNo\nNo\nNot applicable\nMicrosoft Syntex model\nNo\nNo\nNo\nOutlook rules\nNo\nNo\nNo\nAfter inherited from default label\n- Item then moved to location with a default label\nSharePoint: No\nOutlook: Yes\n2\nSharePoint: No\nOutlook: No\nSharePoint: No\nOutlook: No\nAfter inherited from default label\n- Default label then removed from the location\nSharePoint: No\nOutlook: Yes\nSharePoint: No\nOutlook: No\nSharePoint: No\nOutlook: No\nDelete label from the Microsoft Purview portal\nYes\n3\nNot applicable\nNot applicable\nFootnotes:\n1\nThe record must be\nlocked\n.\n2\nRolling out the end of June 2023, a\ndefault label isn't removed when it's moved to the\nDeleted Items\nfolder\n.\n3\nApplies only when the label can be deleted because it isn't included in any retention label policy, and isn't configured for event-based retention.\nMonitoring retention labels\nUse the\nMicrosoft Purview portal\nto monitor how retention labels are being used in your tenant, and identify where your labeled items are located:\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nOverview\nYou can then drill down to see details by selecting\nView details\nthat loads\ncontent explorer\nand\nactivity explorer\n.\nFor more information, including important prerequisites, see\nLearn about data classification\n.\nTip\nConsider using some of the other data classification insights, such as trainable classifiers and sensitive info types, to help you identify content that you might need to retain or delete, or manage as records.\nUsing Content Search to find all content with a specific retention label\nAfter retention labels are applied to content, either by users or auto-applied, you can use content search to find all items that have a specific retention label applied.\nWhen you create a content search, choose the\nRetention label\ncondition, and then enter the complete retention label name or part of the label name and use a wildcard. For more information, see\nKeyword queries and search conditions for Content Search\n.\nCompare capabilities for retention policies and retention labels\nUse the following table to help you identify whether to use a retention policy or retention label, based on capabilities.\nCapability\nRetention policy\nRetention label\nRetention settings that can retain and then delete, retain-only, or delete-only\nYes\nYes\nWorkloads supported:\n- Exchange\n- SharePoint\n- OneDrive\n- Microsoft 365 groups\n- Skype for Business\n- Teams\n- Copilot and AI apps\n- Viva Engage\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes, except public folders\nYes\nYes\nYes\nNo\nNo\nNo\nRetention applied automatically\nYes\nYes\nAutomatically apply different retention settings at the end of the retention period\nNo\nYes\nRetention applied based on conditions\n- sensitive info types, KeyQL queries and keywords, trainable classifiers, cloud attachments\nNo\nYes\nRetention settings applied manually\nNo\nYes\nEnd-user interaction\nNo\nYes\nPersists if the content is moved\nNo\nYes, within your Microsoft 365 tenant\nDeclare item as a record\nNo\nYes\nStart the retention period when labeled or based on an event\nNo\nYes\nRun a Power Automate flow at the end of the retention period\nNo\nYes\nDisposition review\nNo\nYes\nProof of disposition for up to seven years\nNo\nYes, when you use disposition review or item is marked as a record\nAudit admin activities\nYes\nYes\nAudit retention actions\nNo\nYes\n*\nIdentify items subject to retention:\n- Content Search\n- Data classification page, content explorer, activity explorer\nNo\nNo\nYes\nYes\nFootnote:\n*\nFor retention labels that don't mark the content as a record or regulatory record, auditing events are limited to when an item in SharePoint or OneDrive has a label applied, changed, or removed. Or, when a retention label is used with\npriority-cleanup\n. For auditing details for retention labels, see the\nAuditing retention actions\nsection on this page.\nCombining retention policies and retention labels\nYou don't have to choose between using retention policies only or retention labels only. Both methods can be used together and in fact, complementary each other for a more comprehensive solution.\nThe following examples are just some of the ways in which you can combine retention policies and retention labels for the same location.\nFor more information about how retention policies and retention labels work together and how to determine their combined outcome, see the section on this page that explains the\nprinciples of retention and what takes precedence\n.\nExample for users to override automatic deletion\nScenario: By default, content in users' OneDrive accounts is automatically deleted after five years but users must have the option to override this for specific documents.\nYou create and configure a retention policy that automatically deletes content five years after it's last modified, and apply the policy to all OneDrive accounts.\nYou create and configure a retention label that keeps content forever and add this to a label policy that you publish to all OneDrive accounts. You explain to users how to manually apply this label to specific documents that should be excluded from automatic deletion if not modified after five years.\nExample to retain items for longer\nScenario: By default, SharePoint items are automatically retained and then deleted after five years, but documents in specific libraries must be retained for 10 years.\nYou create and configure a retention policy that automatically retains and then deletes content after five years, and apply the policy to all SharePoint and Microsoft 365 Groups instances.\nYou create and configure a retention label that automatically retains content for 10 years. You add this label to a label policy that you publish to all SharePoint and Microsoft 365 Groups instances so that SharePoint admins can then apply it as a default label to be inherited by all items in specific document libraries.\nExample to delete items in a shorter time period\nScenario: By default, emails aren't retained but are automatically deleted after 10 years. However, emails related to a specific project that has a prerelease code name must be automatically deleted after one year.\nYou create and configure a retention policy that automatically deletes content after 10 years, and apply the policy to all Exchange recipients.\nYou create and configure a retention label that automatically deletes content after one year. Options for applying this label to relevant emails include:\nYou create an auto-labeling policy that identifies content by using the project code name as the keyword, and apply the policy to all Exchange recipients\nYou publish the label and instruct users involved in the project how to create an automatic rule in Outlook that applies this label\nYou publish the label and instruct users to create a folder in Outlook for all emails related to the project and they apply the published label to the folder, and then create an Outlook rule to move all project-related emails to this folder\nHow long it takes for retention settings to apply\nWhen you submit retention policies for workloads and label policies to automatically apply a retention label, allow up to seven days for the retention settings to be applied to content:\nHow long it takes for retention policies to take effect\nHow long it takes for retention labels to take effect\nSimilarly, allow up to seven days for retention labels to be visible in apps after you publish the labels:\nWhen retention labels become available to apply\nOften, the policies take effect and labels are visible quicker than seven days. But with many potential variables that can impact this process, it's best to plan for the maximum of seven days.\nAdaptive or static policy scopes for retention\nWhen you create a retention policy or retention label policy, you must choose between adaptive and static to define the scope of the policy.\nAn\nadaptive scope\nuses a query that you specify, so the membership isn't static but dynamic by running daily against the attributes or properties that you specify for the selected locations. You can use multiple adaptive scopes with a single policy.\nExample: Emails and OneDrive documents for executives require a longer retention period than standard users. You create a retention policy with an adaptive scope that uses the Microsoft Entra attribute job title of \"Executive,\" and then select the Exchange email and OneDrive accounts locations for the policy. There's no need to specify email addresses or OneDrive URLs for these users because the adaptive scope automatically retrieves these values. For new executives, there's no need to reconfigure the retention policy because these new users with their corresponding values for email and OneDrive are automatically picked up.\nA\nstatic scope\ndoesn't use queries and is limited in configuration in that it can apply to all instances for a specified location, or use inclusion and exclusions for specific instances for that location. These three choices are sometimes referred to as \"org-wide,\" \"includes,\" and \"excludes\" respectively.\nExample: Emails and OneDrive documents for executives require a longer retention period than standard users. You create a retention policy with a static scope that selects the Exchange email and OneDrive accounts locations for the policy. For the Exchange email location, you're able to identify a group that contains just the executives, so you specify this group for the retention policy, and the group membership with the respective email addresses is retrieved when the policy is created. For the OneDrive accounts location, you must identify and then specify individual OneDrive URLs for each executive. For new executives, you must reconfigure the retention policy to add the new email addresses and OneDrive URLs. You must also update the OneDrive URLs anytime there is a change in an executive's UPN.\nOneDrive URLs are particularly challenging to reliably specify because by default, these URLs aren't created until the user accesses their OneDrive for the first time. And if a user's UPN changes, which you might not know about, their OneDrive URL automatically changes.\nAdvantages of using adaptive scopes over static scopes:\nNo limits on the\nnumber of items per policy\n. Although adaptive policies are still subject to the\nmaximum number of policies per tenant\nlimitations, the more flexible configuration will likely result in far fewer policies.\nYou can apply specific retention settings to just inactive mailboxes. This configuration isn't possible with a static scope because at the time the policy is assigned, static scopes don't support the specific inclusion of recipients with inactive mailboxes.\nFor more advantages of using adaptive scopes, see\nAdaptive scopes\n.\nAdvantages of using static scopes over adaptive scopes:\nSimpler configuration if you want all instances automatically selected for a workload.\nFor \"includes\" and \"excludes,\" this choice can be a simpler configuration initially if the numbers of instances that you have to specify are low and don't change. However, when these number of instances start to increase and you have frequent changes in your organization that require you to reconfigure your policies, adaptive scopes can be simpler to configure and easier to maintain.\nThe\nSkype for Business\nand\nExchange public folders\nlocations don't support adaptive scopes. For those locations, you must use a static scope.\nFor configuration information, see\nConfiguring adaptive scopes\n.\nCurrently, adaptive scopes don't support\nPreservation Lock to restrict changes to retention policies and retention label policies\n.\nPolicy lookup\nYou can configure multiple retention policies for Microsoft 365 locations, as well as multiple retention label policies that you publish or auto-apply. To find the policies for retention that are assigned to specific users, sites, and Microsoft 365 groups, use\nPolicy lookup\nfrom the\nData lifecycle management\nor\nRecords management\nsolutions in the Microsoft Purview portal.\nFor example, from the Microsoft Purview portal:\nYou must specify the exact email address for a user, exact URL for a site, or exact email address for a Microsoft 365 group. You can't use wildcards, or partial matches, for example.\nThe option for sites includes OneDrive accounts. For information how to specify the URL for a user's OneDrive account, see\nGet a list of all user OneDrive URLs in your organization\n.\nThe principles of retention, or what takes precedence?\nUnlike retention labels, you can apply more than one retention policy to the same content. Each retention policy can result in a retain action and a delete action. Additionally, that item could also be subject to these actions from a retention label.\nIn this scenario, when items can be subject to multiple retention settings that could conflict with one another, what takes precedence to determine the outcome?\nThe outcome isn't which single retention policy or single retention label wins, but how long an item is retained (if applicable) and when an item is deleted (if applicable). These two actions are calculated independently from each other, from all the retention settings applied to an item.\nFor example, an item might be subject to one retention policy that is configured for a delete-only action, and another retention policy that is configured to retain and then delete. Consequently, this item has just one retain action but two delete actions. The retention and deletion actions could be in conflict with one another and the two deletion actions might have a conflicting date. The principles of retention explain the outcome.\nBy default, retention always takes precedence over permanent deletion, and the longest retention period wins. These two simple rules always decide how long an item is retained unless it's subject to\npriority cleanup\nthat might be needed to expedite permanent deletion for exceptional circumstances.\nIf you're not using priority cleanup, there are a few more factors that determine when an item is permanently deleted, which include the delete action from a retention label always takes precedence over the delete action from a retention policy.\nUse the following flow to understand the retention and deletion outcomes for a single item that isn't subject to priority cleanup, where each level acts as a tie-breaker for conflicts, from top to bottom. If the outcome is determined by the first level because there are no further conflicts, there's no need to progress to the next level, and so on.\nImportant\nIf you are using retention labels: Before applying the principles to determine the outcome of multiple retention settings on the same item, make sure you know\nwhich retention label is applied\n.\nBefore explaining each principle in more detail, it's important to understand the difference between the retention period for the item vs. the specified retention period in the retention policy or retention label. That's because although the default configuration is to start the retention period when an item is created, so that the end of the retention period is fixed for the item, files also support the configuration to start the retention period from when the file is last modified. With this alternative configuration, every time the file is modified, the start of the retention period is reset, which extends the end of the retention period for the item. Retention labels also support starting the retention period when labeled and at the start of an event.\nTo apply the principles in action with a series of Yes and No questions, you can also use the\nretention flowchart\n.\nExplanation for the four different principles:\nRetention wins over deletion.\nContent won't be permanently deleted when it also has retention settings to retain it. While this principle ensures that content is preserved for compliance reasons, the delete process can still be initiated (user-initiated or system-initiated) and consequently, might remove the content from users' main view. However, permanent deletion is suspended. For more information about how and where content is retained, use the following links for each workload:\nHow retention works for SharePoint and OneDrive\nHow retention works with Microsoft Teams\nHow retention works with Viva Engage\nHow retention works for Exchange\nHow retention works with Copilot & AI apps\nExample for this first principle\n: An email message is subject to a retention policy for Exchange that is configured to delete items three years after they are created, and it also has a retention label applied that is configured to retain items five years after they are created.\nThe email message is retained for five years because this retention action takes precedence over deletion. The email message is permanently deleted at the end of the five years because of the delete action that was suspended while the retention action was in effect.\nThe longest retention period wins.\nIf content is subject to multiple retention settings that retain content for different periods of time, the content is retained until the end of the longest retention period for the item.\nNote\nIt's possible for a retention period of five years in a retention policy or label wins over a retention period of seven years in a retention policy or label, because the 5-year period is configured to start based on when the file is last modified, and the 7-year period is configured to start from when the file is created.\nExample for this second principle\n: Documents in the Marketing SharePoint site are subject to two retention policies. The first retention policy is configured for all SharePoint sites to retain items for five years after they are created. The second retention policy is configured for specific SharePoint sites to retain items for 10 years after they are created.\nDocuments in this Marketing SharePoint site are retained for 10 years because that's the longest retention period for the item.\nExplicit wins over implicit for deletions.\nWith conflicts now resolved for retention, only conflicts for deletions remain:\nA retention label (however it was applied) provides explicit retention in comparison with retention policies, because the retention settings are applied to an individual item rather than implicitly assigned from a container. This means that a delete action from a retention label always takes precedence over a delete action from any retention policy.\nExample for this third principle (label)\n: A document is subject to two retention policies that have a delete action of five years and 10 years respectively, and also a retention label that has a delete action of seven years.\nThe document is permanently deleted after seven years because the delete action from the retention label takes precedence.\nWhen you have retention policies only: If a retention policy for a location uses an adaptive scope or a static scope that includes specific instances (such as specific users for Exchange email) that retention policy takes precedence over a static scope that is configured for all instances for the same location.\nA static scope that is configured for all instances for a location is sometimes referred to as an \"org-wide policy\". For example,\nExchange mailboxes\nand the default setting of\nAll mailboxes\n. Or,\nSharePoint classic and communication sites\nand the default setting of\nAll sites\n. When retention policies aren't org-wide but have been configured with an adaptive scope or a static scope that includes specific instances, they have equal precedence at this level.\nExample 1 for this third principle (policies)\n: An email message is subject to two retention policies. The first retention policy is unscoped and deletes items after 10 years. The second retention policy is scoped to specific mailboxes and deletes items after five years.\nThe email message is permanently deleted after five years because the deletion action from the scoped retention policy takes precedence over the org-wide retention policy.\nExample 2 for this third principle (policies)\n: A document in a user's OneDrive account is subject to two retention policies. The first retention policy is scoped to include this user's OneDrive account and has a delete action after 10 years. The second retention policy is scoped to include this user's OneDrive account and has a delete action after seven years.\nWhen this document will be permanently deleted can't be determined at this level because both retention policies are scoped to include specific instances.\nThe shortest deletion period wins.\nApplicable to determine when items will be deleted from retention policies and the outcome couldn't be resolved from the previous level: Content is permanently deleted at the end of the shortest retention period for the item.\nNote\nIt's possible that a retention policy that has a retention period of seven years wins over a retention policy of five years because the first policy is configured to start the retention period based on when the file is created, and the second retention policy from when the file is last modified.\nExample for this fourth principle\n: A document in a user's OneDrive account is subject to two retention policies. The first retention policy is scoped to include this user's OneDrive account and has a delete action of 10 years after the file is created. The second retention policy is scoped to include this user's OneDrive account and has a delete action of seven years after the file is created.\nThis document will be permanently deleted after seven years because that's the shortest retention period for the item from these two scoped retention policies.\nItems subject to eDiscovery hold also fall under the first principle of retention; they cannot be permanently deleted by any retention policy or retention label. When that hold is released, the principles of retention continue to apply to them. For example, they could then be subject to an unexpired retention period or a delete action.\nPrinciples of retention examples that combine retain and delete actions\nThe following examples are more complex to illustrate the principles of retention when different retain and delete actions are combined. To make the examples easier to follow, all retention policies and labels use the default setting of starting the retention period when the item is created so the end of the retention period is the same for the item.\nAn item has the following retention settings applied to it:\nA retention policy for delete-only after five years\nA retention policy that retains for three years and then deletes\nA retention label that retains-only for seven years\nOutcome\n: The item is retained for seven years because retention takes precedence over deletion and seven years is the longest retention period for the item. At the end of this retention period, the item is permanently deleted because of the delete action from the retention policies.\nAlthough the two retention policies have different dates for the delete actions, the earliest that the item can be permanently deleted is at the end of the longest retention period, which is longer than both deletion dates.\nAn item has the following retention settings applied to it:\nAn org-wide retention policy that deletes-only after ten years\nA retention policy scoped with specific instances that retains for five years and then deletes\nA retention label that retains for three years and then deletes\nOutcome\n: The item is retained for five years because that's the longest retention period for the item. At the end of that retention period, the item is permanently deleted because of the delete action of three years from the retention label. Deletion from retention labels takes precedence over deletion from all retention policies. In this example, all conflicts are resolved by the third level.\nUse Preservation Lock to restrict changes to policies\nSome organizations might need to comply with rules defined by regulatory bodies such as the Securities and Exchange Commission (SEC) Rule 17a-4, which requires that after a policy for retention is turned on, it cannot be turned off or made less restrictive.\nPreservation Lock ensures your organization can meet such regulatory requirements because it locks a retention policy or retention label policy so that no oneâincluding an administratorâcan turn off the policy, delete the policy, or make it less restrictive.\nYou apply Preservation Lock after the retention policy or retention label policy is created. For more information and instructions, see\nUse Preservation Lock to restrict changes to retention policies and retention label policies\n.\nReleasing a policy for retention\nProviding your policies for retention don't have a Preservation Lock, you can delete your policies at any time, which effectively turns off the retention settings for a retention policy, and retention labels can no longer be applied from retention label policies. Any previously applied retention labels remain with their configured retention settings and for these labels, you can still update the retention period when it's not based on when items were labeled.\nYou can also keep a policy, but change the location status to off, or disable the policy. Another option is to reconfigure the policy so it no longer includes specific users, sites, groups, and so on.\nAdditional information for specific locations:\nSharePoint sites and OneDrive accounts:\nWhen you release a retention policy for SharePoint sites and OneDrive accounts, any content that's subject to retention from the policy continues to be retained for 30 days to prevent inadvertent data loss. During this 30-day grace period deleted files are still retained (files continue to be added to the Preservation Hold library), but the timer job that periodically cleans up the Preservation Hold library is suspended for these files so you can restore them if necessary.\nAn exception to this 30-day grace period is when you update the policy to exclude one or more sites for SharePoint or accounts for OneDrive; in this case, the timer job deletes files for these locations in the Preservation Hold library without the 30-day delay.\nFor more information about the Preservation Hold library, see\nHow retention works for SharePoint and OneDrive\n.\nBecause of the behavior during the grace period, if you re-enable the policy or change the location status back to on within 30 days, the policy resumes without any permanent data loss during this time.\nExchange email and Microsoft 365 Groups\nWhen you release a retention policy for mailboxes that are\ninactive\nat the time the policy is released:\nIf the retention policy is explicitly applied to a mailbox, the retention settings no longer apply. With no retention settings applied, an inactive mailbox becomes eligible for automatic deletion in the usual way.\nAn explicit retention policy requires either an adaptive policy scope, or a static policy scope with an include configuration that specified an active mailbox at the time the policy was applied and later became inactive\nIf the retention policy is implicitly applied to a mailbox and the configured retention action is to retain, the retention policy continues to apply and an inactive mailbox never becomes eligible for automatic deletion. When the retain action no longer applies because the retention period has expired, the Exchange admin can now\nmanually delete the inactive mailbox\nAn implicit retention policy requires a static policy scope with the\nAll mailboxes\n(for Exchange email) or\nAll groups\n(for Microsoft 365 Groups) configuration.\nFor more information about inactive mailboxes that have retention policies applied, see\nInactive mailboxes and Microsoft 365 retention\n.\nAuditing retention configuration and actions\nWhen\nauditing is enabled\n, auditing events for retention are supported for both administration configuration (retention policies and retention labels) and retention actions (retention labels only).\nAuditing retention configuration\nAdministrator configuration for retention policies and retention labels is logged as auditing events when a retention policy or label is created, reconfigured, or deleted.\nFor the full list of auditing events, see\nRetention policy and retention label activities\n.\nAuditing retention actions\nRetention actions that are logged as auditing events are available only for retention labels and not for retention policies:\nSpecific to\npriority cleanup\n, use the\nCleanup ID\nassigned to the priority cleanup policy as a keyword search term in the auditing log to find\nrelated activities\n.\nSpecific to\nAdaptive Protection when a retention label is applied to an item\n:\nFor SharePoint and OneDrive, from\nRetention policy and retention label activities\n, select\nRetained file proactively\nFor Exchange, from\nRetention policy and retention label activities\n, select\nRetained email item proactively\nWhen a retention label is applied, changed, or removed from an item in SharePoint or OneDrive:\nFrom\nFile and page activities\n, select\nChanged retention label for a file\nWhen a labeled item in SharePoint is marked as a record, and it is unlocked or locked by a user:\nFrom\nFile and page activities\n, select\nChanged record status to unlocked\nand\nChanged record status to locked\nWhen a retention label that marks content as a record or regulatory record is applied to an item in Exchange:\nFrom\nExchange mailbox activities\n, select\nLabeled message as a record\nWhen a labeled item in SharePoint, OneDrive, or Exchange is marked as a record or regulatory record, and it is permanently deleted:\nFrom\nFile and page activities\n, select\nDeleted file marked as a record\nWhen a disposition reviewer takes action for an item that's reached the end of its retention period:\nFrom\nDisposition review activities\n, select\nApproved disposal\n,\nExtended retention period\n,\nRelabeled item\n, or\nAdded reviewers\nPowerShell cmdlets for retention policies and retention labels\nUse\nSecurity & Compliance PowerShell\nfor Purview retention cmdlets that support configuration at scale, scripting for automation, or might be necessary for advanced configuration scenarios.\nFor a list of available cmdlets, and to identify which ones are supported for the different locations, see\nPowerShell cmdlets for retention policies and retention labels\n.\nWhen to use retention policies and retention labels or eDiscovery holds\nAlthough retention settings and\nholds that you create with an eDiscovery case\ncan both prevent data from being permanently deleted, they are designed for different scenarios. To help you understand the differences and decide which to use, use the following guidance:\nRetention settings that you specify in retention policies and retention labels are designed for a long-term data lifecycle management strategy to retain or delete data for compliance requirements. The scope is usually broad with the main focus being the location and content rather than individual users. The start and end of the retention period is configurable, with the option to automatically delete content without additional administrator intervention.\nHolds for eDiscovery cases are designed for a limited duration to preserve data for a legal investigation. The scope is specific with the focus being content owned by identified users. The start and end of the preservation period isn't configurable but dependent on individual administrator actions, without an option to automatically delete content when the hold is released.\nSummary to compare retention with holds:\nConsideration\nRetention\neDiscovery holds\nBusiness need:\nCompliance\nLegal\nTime scope:\nLong-term\nShort-term\nFocus:\nBroad, content-based\nSpecific, user-based\nStart and end date configurable:\nYes\nNo\nContent deletion:\nYes (optional)\nNo\nAdministrative overheads:\nLow\nHigh\nIf content is subject to both retention settings and an eDiscovery hold, preserving content for the eDiscovery hold always takes precedence. In this way, the\nprinciples of retention\nexpand to eDiscovery holds because they preserve data until an administrator manually releases the hold. However, despite this precedence, don't use eDiscovery holds for long-term data lifecycle management. If you are concerned about automatic deletion of data, you can configure retention settings to retain items forever, or use\ndisposition review\nwith retention labels.\nIf you are using older eDiscovery tools to preserve data, see the following resources:\nExchange:\nIn-Place Hold and Litigation Hold\nHow to identify the type of hold placed on an Exchange Online mailbox\nSharePoint and OneDrive:\nAdd content to a case and place sources on hold in the eDiscovery Center\nRetirement of legacy eDiscovery tools\nUse retention policies and retention labels instead of older features\nIf you need to retain or delete content in Microsoft 365 for data lifecycle management, we recommend you use Microsoft 365 retention policies and retention labels instead of the following older features.\nIf you currently use these older features, they'll usually work side by side with Microsoft 365 retention policies and retention labels. Check their specific documentation for any restrictions. However, we recommend that going forward, you use Microsoft 365 retention policies and retention labels to benefit from a single solution to manage both retention and deletion of content across multiple workloads in Microsoft 365.\nTip\nFor SharePoint, see the following resources:\nUse Microsoft Purview risk and compliance solutions instead of the older information management and records management features in SharePoint for Microsoft 365\nMigration strategies for moving to Microsoft Purview risk and compliance solutions\nOlder features from Exchange Online:\nRetention tags and retention policies\n, also known as\nmessaging records management (MRM)\n(deletion only)\nHowever, if you use the following MRM features, be aware that they aren't currently supported by Microsoft 365 retention policies:\nAn archive policy for\narchive mailboxes\nto automatically move emails from a user's primary mailbox to their archive mailbox after a specified period of time. An archive policy (with any settings) can be used in conjunction with a Microsoft 365 retention policy that applies to a user's primary and archive mailbox.\nRetention policies applied by an admin to specific folders within a mailbox. A Microsoft 365 retention policy applies to all folders in the mailbox. However, an admin can configure different retention settings by using retention labels that a user can apply to folders in Outlook as a\ndefault retention label\n.\nJournaling\n(retention and archive)\nMight be required to integrate with third-party solutions and copies of email messages and their data communication are stored outside Exchange Online. Because you're moving data outside Microsoft 365, you must take extra precautions to secure it and also resolve any duplications that might result from this solution. It is your responsibility to monitor and follow up on any nondelivery receipts to the journaling mailbox that can occur because of external and dependent services. You don't have these additional administrative overheads when you use Microsoft 365 retention and other Microsoft Purview compliance solutions that also aren't limited to just email messages.\nLitigation hold\n(retention only)\nAlthough Litigation holds are still supported, we recommend you use Microsoft 365 retention or eDiscovery holds,\nas appropriate\n.\nOlder features from SharePoint and OneDrive:\nDocument deletion policies\n(deletion only)\nConfiguring in place records management\n(retention only)\nUse policies for site closure and deletion\n(deletion only)\nInformation management policies\n(deletion only)\nIf you have configured SharePoint sites for content type policies or information management policies to retain content for a list or library, those policies are ignored while a retention policy or retention label policy is in effect.\nRelated information\nSharePoint Online Limits\nLimits and specifications for Microsoft Teams\nResources to help you meet regulatory requirements for data lifecycle management and records management\nConfiguration guidance\nSee\nGet started with data lifecycle management\n. This article has information about subscriptions, permissions, and links to end-to-end configuration guidance for retention scenarios.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data Retention",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/retention": {
      "content_hash": "sha256:292a3c48e8e1a58a59d5f27cebed1194b430dc686a6ebf0e4e8d101ece489673",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about retention policies and retention labels\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nNote\nIf you're seeing messages about retention policies in Teams or have questions about retention labels in your apps, contact your IT department for information about how they have been configured for you. In the meantime, you might find the following articles helpful:\nTeams messages about retention policies\nApply retention labels to files in SharePoint or OneDrive\nThe information on this page is for IT administrators who can create retention policies and retention labels for compliance reasons.\nFor most organizations, the volume and complexity of their data is increasing dailyâemail, documents, instant messages, and more. Effectively managing or governing this information is important because you need to:\nComply proactively with industry regulations and internal policies\nthat require you to retain content for a minimum period of timeâfor example, the Sarbanes-Oxley Act might require you to retain certain types of content for seven years.\nReduce your risk in the event of litigation or a security breach\nby permanently deleting old content that you're no longer required to keep.\nHelp your organization to share knowledge effectively and be more agile\nby ensuring that your users work only with content that's current and relevant to them.\nRetention settings that you configure can help you achieve these goals. Managing content commonly requires two actions:\nAction\nPurpose\nRetain content\nPrevent permanent deletion and remain available for eDiscovery\nDelete content\nPermanently delete content from your organization\nWith these two retention actions, you can configure retention settings for the following outcomes:\nRetain-only: Retain content forever or for a specified period of time.\nDelete-only: Permanently delete content after a specified period of time.\nRetain and then delete: Retain content for a specified period of time and then permanently delete it.\nThese retention settings work with content in place that saves you the additional overheads of creating and configuring additional storage when you need to retain content for compliance reasons. In addition, you don't need to implement customized processes to copy and synchronize this data.\nUse the following sections to learn more about how retention policies and retention labels work, when to use them, and how they supplement each other. But if you're ready to get started and deploy retention settings for some common scenarios, see\nGet started with data lifecycle management\n.\nHow retention settings work with content in place\nWhen content has retention settings assigned to it, that content remains in its original location. Most of the time, people continue to work with their documents or mail as if nothing's changed. But if they edit or delete content that's included in the retention policy, a copy of the content is automatically retained.\nFor SharePoint and OneDrive sites: The copy is retained in the\nPreservation Hold\nlibrary.\nFor Exchange mailboxes: The copy is retained in the\nRecoverable Items\nfolder.\nFor Teams, Viva Engage messages, Copilot and AI apps: The copy is retained in a hidden folder named\nSubstrateHolds\nas a subfolder in the Exchange\nRecoverable Items\nfolder.\nNote\nBecause the Preservation Hold library is included in the site's storage quota, you might need to increase your storage when you use retention settings for SharePoint, OneDrive, and Microsoft 365 groups.\nThese secure locations and the retained content aren't visible to most people. In most cases, people don't even need to know that their content is subject to retention settings.\nFor more detailed information about how retention settings work for different workloads, see the following articles:\nLearn about retention for SharePoint and OneDrive\nLearn about retention for Teams\nLearn about retention for Viva Engage\nLearn about retention for Exchange\nLearn about retention for Copilot\nRetention policies and retention labels\nTo assign your retention settings to content, use\nretention policies\nand\nretention labels with label policies\n. You can use just one of these methods, or combine them.\nUse a retention policy to assign the same retention settings for content at a site or mailbox level, and use a retention label to assign retention settings at an item level (folder, document, email).\nFor example, if all documents in a SharePoint site should be retained for five years, it's more efficient to do this with a retention policy than apply the same retention label to all documents in that site. However, if some documents in that site should be retained for five years and others retained for 10 years, a retention policy wouldn't be able to do this. When you need to specify retention settings at the item level, use retention labels.\nUnlike retention policies, retention settings from retention labels travel with the content if it's moved to a different location within your Microsoft 365 tenant. In addition, retention labels have the following capabilities that retention policies don't support:\nOptions to start the retention period from when the content was labeled or based on an event, in addition to the age of the content or when it was last modified.\nUse\ntrainable classifiers\nto identify content to label.\nApply a default label for SharePoint items or Exchange messages.\nSupported actions at the end retention period:\nDisposition review\nto review the content before it's permanently deleted.\nAutomatically apply another retention label\nMark the content as a\nrecord\nas part of the label settings, and always have\nproof of disposition\nwhen content is deleted at the end of its retention period.\nRetention policies\nRetention policies can be applied to the following locations:\nExchange mailboxes\nSharePoint classic and communication sites\nOneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nExchange public folders\nTeams channel messages (standard channels,\nshared channels\n, and private channels\npost-migration\n)\nTeams chats\nTeams private channel messages (\npre-migration\nonly)\nMicrosoft Copilot experiences\nEnterprise AI apps\nOther AI apps\nViva Engage community messages\nViva Engage user messages\nNote\nIf you have existing retention policies for Teams chats and Copilot interactions, they continue to be supported, although they can't be edited when your tenant supports the separate locations. At this point, any new retention policies must use the new locations.\nYou can efficiently apply a single policy to multiple locations, or to specific locations or users.\nFor the start of the retention period, you can choose when the content was created or, supported only for files and the SharePoint, OneDrive, and Microsoft 365 Groups locations, when the content was last modified.\nItems inherit the retention settings from their container specified in the retention policy. If they are, then moved outside that container when the policy is configured to retain content, a copy of that item is retained in the workload's secured location. However, the retention settings don't travel with the content in its new location. If that's required, use retention labels instead of retention policies.\nRetention labels\nUse retention labels for different types of content that require different retention settings. For example:\nTax forms that need to be retained for a minimum period of time.\nPress materials that need to be permanently deleted when they reach a specific age.\nCompetitive research that needs to be retained for a specific period and then permanently deleted.\nWork visas that must be marked as a record so that they can't be edited or deleted.\nIn all these cases, retention labels let you apply retention settings for governance control at the item level (document or email).\nWith retention labels, you can:\nEnable people in your organization to apply a retention label manually\nto content in Outlook and Outlook on the web, OneDrive, SharePoint, and Microsoft 365 groups. Users often know best what type of content they're working with, so they can classify it and have the appropriate retention settings applied.\nApply retention labels to content automatically\nif it matches specific conditions, that includes cloud attachments that are shared in email or Teams, or when the content contains:\nSpecific types of sensitive information.\nSpecific keywords that match a query you create.\nPattern matches for a trainable classifier.\nStart the retention period from when the content was labeled\nfor documents in SharePoint sites and OneDrive accounts, and for email items.\nStart the retention period when an event occurs\n, such as employees leave the organization, or contracts expire.\nApply a default retention label to a document library, folder, or document set\nin SharePoint, so that all documents that are stored in that location inherit the default retention label.\nMark items as a record\nas part of your\nrecords management\nstrategy. When this labeled content remains in Microsoft 365, further restrictions are placed on the content that might be needed for regulatory reasons. For more information, see\nCompare restrictions for what actions are allowed or blocked\n.\nRetention labels, unlike\nsensitivity labels\n, don't persist if the content is moved outside Microsoft 365.\nDynamically mitigate the risk of accidental or malicious deletes\nIn preview, you can use this solution with Insider Risk Management so that retention labels are automatically applied with\nAdaptive Protection\n.\nWhen you enable Adaptive Protection for your tenant, retention labels are automatically applied to unlabeled content if it's deleted by users who have been identified as an\nelevated risk\n. If these users delete content from SharePoint, OneDrive, or Exchange, a retention label is automatically applied to that content to retain it for 120 days. As a result, that content remains accessible for search and eDiscovery from the\nsecured locations used by the workload\n.\nNote\nIf you enabled and configured Adaptive Protection before this integration with data lifecycle management released, you'll need to opt-in to create this auto-labeling policy. See the instructions at the end of this section.\nWhen these items are retained with Adaptive Protection, the following auditing events are generated and identify the user and item:\nFor SharePoint and OneDrive:\nRetained file proactively\nFor Exchange:\nRetained email item proactively\nAfter the 120 days expire, the items then become eligible for permanent deletion. To learn more about when permanent deletion occurs, see\nHow retention works for SharePoint and OneDrive\nand\nHow retention works for Exchange\n.\nUnlike other labeling scenarios, users don't see the retention label, and you don't need to create or manage the retention label or auto-labeling retention policy. At this time, you can't change the retention period or assign different policies based on the different risk levels, or for different locations. The single retention label and auto-labeling retention policy for your tenant aren't visible in the Microsoft Purview portal.\nIf you're using Adaptive Protection but don't want to automatically retain content in this way, you can turn off the auto-labeling policy without affecting other Adaptive Protection policies. Use the same control if you need to turn on the auto-labeling retention policy for Adaptive Protection, and confirm the status.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nSettings\n>\nSolution settings\n>\nData lifecycle management\n>\nAdaptive protection\n.\nFor\nAdaptive protection in Data Lifecycle Management\n, turn the setting off, confirm your choice, and select\nSave\n.\nAny retention labels that were applied as a result of Adaptive Protection are removed so that the items can then become eligible for permanent deletion.\nYou won't be able to turn on this setting unless Adaptive Protection is turned on for your tenant. If your account has the\nrequired permissions\n, you'll see an option to take you to the insider risk management solution where you can turn on and configure Adaptive Protection.\nOverride holds to reclaim disk space or permanently delete sensitive information\nAlso like adaptive protection, priority cleanup for files or mailbox items similarly applies retention labels under the covers. The labels are automatically configured and applied when you create a priority cleanup policy that identifies items with a query that you specify. This policy can override existing holds for retention and eDiscovery.\nPriority cleanup is specific to data lifecycle management and isn't supported for labeled items that are marked as records. Typical uses depend on the workload:\nFor SharePoint and OneDrive, you can use priority cleanup to periodically delete large files, such as Teams meeting recordings and transcripts. These files are regularly created if you're using the popular Copilot in Teams recap feature, and might be automatically retained with a retention policy that retains all items for many years. However, these specific files typically have little business value after 1-3 months, and you want to regularly delete them to save disk space. You can also use priroty cleanup to delete files in the Preservation Hold library that can prevent OneDrive accounts from being deleted after a user leaves the organization.\nFor Exchange, you can use priority cleanup to delete items when this action is required for security or privacy. For example, after a data spillage incident.\nFor more information and configuration instructions, see the following articles:\nOverride holds to clean up files for Copilot and reclaim storage\nExpedite the permanent deletion of sensitive information from mailboxes\n.\nClassifying content without applying any actions\nAlthough the main purpose of retention labels is to retain or delete content, you can also use retention labels without turning on any retention or other actions. In this case, you can use a retention label simply as a text label, without enforcing any actions.\nFor example, you can create and apply a retention label named \"Review later\" with no actions, and then use that label to find that content later.\nUsing a retention label as a condition in a DLP policy\nYou can specify a retention label as a condition in a Microsoft Purview Data Loss Prevention (DLP) policy for documents in SharePoint. For example, configure a DLP policy to prevent documents from being shared outside the organization if they have a specified retention label applied to it.\nFor more information, see\nCreate and Deploy data loss prevention policies\n.\nRetention labels and policies that apply them\nWhen you publish retention labels, they're included in a\nretention label policy\nthat makes them available for admins and users to apply to content. As the following diagram shows:\nA single retention label can be included in multiple retention label policies.\nRetention label policies specify the locations to publish the retention labels. A single label retention policy can include multiple locations.\nYou can also create one or more\nauto-apply retention label policies\n, each with a single retention label. With this policy, a retention label is automatically applied when conditions that you specify in the policy are met.\nRetention label policies and locations\nRetention labels can be published to different locations, depending on what the retention label does.\nIf the retention label is...\nThen the label policy can be applied to...\nPublished to admins and end users\nExchange, SharePoint, OneDrive, Microsoft 365 Groups\nAuto-applied based on sensitive information types, keywords or a query, or trainable classifiers\nExchange, SharePoint, OneDrive, Microsoft 365 Groups\nAuto-applied to cloud attachments\nSharePoint, OneDrive, Microsoft 365 Groups\nExchange public folders, Skype, Teams and Viva Engage messages don't support retention labels. To retain and delete content from these locations, use retention policies instead.\nOnly one retention label at a time\nUnlike\nsensitivity labels\n, you can't configure priorities for retention labels. Use the following information to understand label behavior for retention labels.\nAs with sensitivity labels, an item such as an email or document can have only a single retention label applied to it at a time. A retention label can be applied\nmanually\nby an end user or admin, or automatically by using any of the following methods:\nAuto-apply retention label policy\nA Microsoft Syntex model\nDefault retention label for SharePoint or Outlook\nOutlook rules\nPower Automate compliance action\nof\nApply a retention label on the item\nIf there are multiple auto-apply retention label policies that could apply a retention label, and the content meets the conditions of more than one of these policies, you can't control which retention label will be selected. However, in some cases, the retention label for the oldest auto-apply retention label policy (by date created) is selected. This happens only when the matching policies don't include multiple instances of the same type of condition (sensitive information types, specific keywords or searchable properties, or trainable classifiers).\nFor standard retention labels (they don't mark items as a\nrecord or regulatory record\n):\nAdmins and end users can manually change or remove an existing retention label that's applied on content.\nWhen items already have a retention label applied, the existing label won't be automatically removed or replaced by another retention label with the following exceptions:\nAt the end of the retention period, the existing label is configured to automatically\napply a different retention label\n, or the existing label is configured to\nrun a Power Automate flow\nwith the compliance action of\nRelabel an item at the end of retention\n.\nYou use the Power Automate compliance action of\nApply a retention label on the item\n. If the item already has a retention label applied, it will be replaced.\nThe existing label was applied as a default label. When you use a default label, there are some scenarios when it can be replaced by another default label, or automatically removed. For more information, see\nDefault labels for SharePoint and Outlook\n.\nFor retention labels that mark items as a record or a regulatory record:\nThese retention labels are never automatically changed during their configured retention period, even if the existing label was applied as a default label, or identified for\npriority cleanup\n.\nOnly admins for the container can manually change or remove retention labels that mark items as a record, but can't manually change or remove retention labels that mark items as a regulatory record. For more information, see\nCompare restrictions for what actions are allowed or blocked\n.\nAt the end of the retention period, an existing label can be replaced if it's configured to mark items as a record and automatically\napply a different retention label\nor to\nrun a Power Automate flow\nwith the compliance action of\nRelabel an item at the end of retention\n. You can't use these relabeling methods if the existing label is configured to mark items as a regulatory record.\nWill an existing label be overridden or removed?\nUse the following tables to help you quickly identify whether an existing retention label on items can be overridden by another retention label, or removed so that it's no longer labeled.\nNote\nUnless a labeled item is marked as a record or regulatory record, it can always be overridden by\npriority cleanup\nthat under the covers, applies a retention label to delete the item.\nA standard retention label refers to a retention label that isn't configured to mark items as records or regulatory records.\nWill a label be overridden?\nWill a label be removed?\nNew label application method\nStandard retention label\nMarks items as records\nMarks items as regulatory records\nManually applied\nYes\nYes\n1\nif admin for the container\nNo\nApplied with Power Automate actions\nYes\nYes\n1\nNot applicable\nApplied with the\nChange label\nlabel setting\nYes\nYes\nNot applicable\nApplied with the\nRelabel\ndisposition review action\nYes\nYes\nNo\nApplied with auto-apply retention label policy\nNo\nNo\nNot applicable\nApplied with Microsoft Syntex model\nNo\nNo\nNo\nOutlook rules\nNo\nNo\nNo\nInherited from default label for SharePoint\nYes if originally applied by another default label\n2\nNo\nNo\nInherited from default label for Outlook\nYes if originally applied by another default label\nNo\nNo\nFootnotes:\n1\nThe record must be\nlocked\n.\n2\nAn exception is if you move the item to another location with a different default label, then the original label isn't overwritten. Only if you then change the default label for this new location will the original default label be overwritten.\nNew labeling action\nStandard retention label\nMarks items as records\nMarks items as regulatory records\nManually remove\nYes\nYes\n1\nif admin for the container\nNo\nPower Automate relabel action\n- No label specified\nYes\nYes\n1\nNot applicable\nAuto-apply retention label policy\nNo\nNo\nNot applicable\nMicrosoft Syntex model\nNo\nNo\nNo\nOutlook rules\nNo\nNo\nNo\nAfter inherited from default label\n- Item then moved to location with a default label\nSharePoint: No\nOutlook: Yes\n2\nSharePoint: No\nOutlook: No\nSharePoint: No\nOutlook: No\nAfter inherited from default label\n- Default label then removed from the location\nSharePoint: No\nOutlook: Yes\nSharePoint: No\nOutlook: No\nSharePoint: No\nOutlook: No\nDelete label from the Microsoft Purview portal\nYes\n3\nNot applicable\nNot applicable\nFootnotes:\n1\nThe record must be\nlocked\n.\n2\nRolling out the end of June 2023, a\ndefault label isn't removed when it's moved to the\nDeleted Items\nfolder\n.\n3\nApplies only when the label can be deleted because it isn't included in any retention label policy, and isn't configured for event-based retention.\nMonitoring retention labels\nUse the\nMicrosoft Purview portal\nto monitor how retention labels are being used in your tenant, and identify where your labeled items are located:\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nOverview\nYou can then drill down to see details by selecting\nView details\nthat loads\ncontent explorer\nand\nactivity explorer\n.\nFor more information, including important prerequisites, see\nLearn about data classification\n.\nTip\nConsider using some of the other data classification insights, such as trainable classifiers and sensitive info types, to help you identify content that you might need to retain or delete, or manage as records.\nUsing Content Search to find all content with a specific retention label\nAfter retention labels are applied to content, either by users or auto-applied, you can use content search to find all items that have a specific retention label applied.\nWhen you create a content search, choose the\nRetention label\ncondition, and then enter the complete retention label name or part of the label name and use a wildcard. For more information, see\nKeyword queries and search conditions for Content Search\n.\nCompare capabilities for retention policies and retention labels\nUse the following table to help you identify whether to use a retention policy or retention label, based on capabilities.\nCapability\nRetention policy\nRetention label\nRetention settings that can retain and then delete, retain-only, or delete-only\nYes\nYes\nWorkloads supported:\n- Exchange\n- SharePoint\n- OneDrive\n- Microsoft 365 groups\n- Skype for Business\n- Teams\n- Copilot and AI apps\n- Viva Engage\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nYes, except public folders\nYes\nYes\nYes\nNo\nNo\nNo\nRetention applied automatically\nYes\nYes\nAutomatically apply different retention settings at the end of the retention period\nNo\nYes\nRetention applied based on conditions\n- sensitive info types, KeyQL queries and keywords, trainable classifiers, cloud attachments\nNo\nYes\nRetention settings applied manually\nNo\nYes\nEnd-user interaction\nNo\nYes\nPersists if the content is moved\nNo\nYes, within your Microsoft 365 tenant\nDeclare item as a record\nNo\nYes\nStart the retention period when labeled or based on an event\nNo\nYes\nRun a Power Automate flow at the end of the retention period\nNo\nYes\nDisposition review\nNo\nYes\nProof of disposition for up to seven years\nNo\nYes, when you use disposition review or item is marked as a record\nAudit admin activities\nYes\nYes\nAudit retention actions\nNo\nYes\n*\nIdentify items subject to retention:\n- Content Search\n- Data classification page, content explorer, activity explorer\nNo\nNo\nYes\nYes\nFootnote:\n*\nFor retention labels that don't mark the content as a record or regulatory record, auditing events are limited to when an item in SharePoint or OneDrive has a label applied, changed, or removed. Or, when a retention label is used with\npriority-cleanup\n. For auditing details for retention labels, see the\nAuditing retention actions\nsection on this page.\nCombining retention policies and retention labels\nYou don't have to choose between using retention policies only or retention labels only. Both methods can be used together and in fact, complementary each other for a more comprehensive solution.\nThe following examples are just some of the ways in which you can combine retention policies and retention labels for the same location.\nFor more information about how retention policies and retention labels work together and how to determine their combined outcome, see the section on this page that explains the\nprinciples of retention and what takes precedence\n.\nExample for users to override automatic deletion\nScenario: By default, content in users' OneDrive accounts is automatically deleted after five years but users must have the option to override this for specific documents.\nYou create and configure a retention policy that automatically deletes content five years after it's last modified, and apply the policy to all OneDrive accounts.\nYou create and configure a retention label that keeps content forever and add this to a label policy that you publish to all OneDrive accounts. You explain to users how to manually apply this label to specific documents that should be excluded from automatic deletion if not modified after five years.\nExample to retain items for longer\nScenario: By default, SharePoint items are automatically retained and then deleted after five years, but documents in specific libraries must be retained for 10 years.\nYou create and configure a retention policy that automatically retains and then deletes content after five years, and apply the policy to all SharePoint and Microsoft 365 Groups instances.\nYou create and configure a retention label that automatically retains content for 10 years. You add this label to a label policy that you publish to all SharePoint and Microsoft 365 Groups instances so that SharePoint admins can then apply it as a default label to be inherited by all items in specific document libraries.\nExample to delete items in a shorter time period\nScenario: By default, emails aren't retained but are automatically deleted after 10 years. However, emails related to a specific project that has a prerelease code name must be automatically deleted after one year.\nYou create and configure a retention policy that automatically deletes content after 10 years, and apply the policy to all Exchange recipients.\nYou create and configure a retention label that automatically deletes content after one year. Options for applying this label to relevant emails include:\nYou create an auto-labeling policy that identifies content by using the project code name as the keyword, and apply the policy to all Exchange recipients\nYou publish the label and instruct users involved in the project how to create an automatic rule in Outlook that applies this label\nYou publish the label and instruct users to create a folder in Outlook for all emails related to the project and they apply the published label to the folder, and then create an Outlook rule to move all project-related emails to this folder\nHow long it takes for retention settings to apply\nWhen you submit retention policies for workloads and label policies to automatically apply a retention label, allow up to seven days for the retention settings to be applied to content:\nHow long it takes for retention policies to take effect\nHow long it takes for retention labels to take effect\nSimilarly, allow up to seven days for retention labels to be visible in apps after you publish the labels:\nWhen retention labels become available to apply\nOften, the policies take effect and labels are visible quicker than seven days. But with many potential variables that can impact this process, it's best to plan for the maximum of seven days.\nAdaptive or static policy scopes for retention\nWhen you create a retention policy or retention label policy, you must choose between adaptive and static to define the scope of the policy.\nAn\nadaptive scope\nuses a query that you specify, so the membership isn't static but dynamic by running daily against the attributes or properties that you specify for the selected locations. You can use multiple adaptive scopes with a single policy.\nExample: Emails and OneDrive documents for executives require a longer retention period than standard users. You create a retention policy with an adaptive scope that uses the Microsoft Entra attribute job title of \"Executive,\" and then select the Exchange email and OneDrive accounts locations for the policy. There's no need to specify email addresses or OneDrive URLs for these users because the adaptive scope automatically retrieves these values. For new executives, there's no need to reconfigure the retention policy because these new users with their corresponding values for email and OneDrive are automatically picked up.\nA\nstatic scope\ndoesn't use queries and is limited in configuration in that it can apply to all instances for a specified location, or use inclusion and exclusions for specific instances for that location. These three choices are sometimes referred to as \"org-wide,\" \"includes,\" and \"excludes\" respectively.\nExample: Emails and OneDrive documents for executives require a longer retention period than standard users. You create a retention policy with a static scope that selects the Exchange email and OneDrive accounts locations for the policy. For the Exchange email location, you're able to identify a group that contains just the executives, so you specify this group for the retention policy, and the group membership with the respective email addresses is retrieved when the policy is created. For the OneDrive accounts location, you must identify and then specify individual OneDrive URLs for each executive. For new executives, you must reconfigure the retention policy to add the new email addresses and OneDrive URLs. You must also update the OneDrive URLs anytime there is a change in an executive's UPN.\nOneDrive URLs are particularly challenging to reliably specify because by default, these URLs aren't created until the user accesses their OneDrive for the first time. And if a user's UPN changes, which you might not know about, their OneDrive URL automatically changes.\nAdvantages of using adaptive scopes over static scopes:\nNo limits on the\nnumber of items per policy\n. Although adaptive policies are still subject to the\nmaximum number of policies per tenant\nlimitations, the more flexible configuration will likely result in far fewer policies.\nYou can apply specific retention settings to just inactive mailboxes. This configuration isn't possible with a static scope because at the time the policy is assigned, static scopes don't support the specific inclusion of recipients with inactive mailboxes.\nFor more advantages of using adaptive scopes, see\nAdaptive scopes\n.\nAdvantages of using static scopes over adaptive scopes:\nSimpler configuration if you want all instances automatically selected for a workload.\nFor \"includes\" and \"excludes,\" this choice can be a simpler configuration initially if the numbers of instances that you have to specify are low and don't change. However, when these number of instances start to increase and you have frequent changes in your organization that require you to reconfigure your policies, adaptive scopes can be simpler to configure and easier to maintain.\nThe\nSkype for Business\nand\nExchange public folders\nlocations don't support adaptive scopes. For those locations, you must use a static scope.\nFor configuration information, see\nConfiguring adaptive scopes\n.\nCurrently, adaptive scopes don't support\nPreservation Lock to restrict changes to retention policies and retention label policies\n.\nPolicy lookup\nYou can configure multiple retention policies for Microsoft 365 locations, as well as multiple retention label policies that you publish or auto-apply. To find the policies for retention that are assigned to specific users, sites, and Microsoft 365 groups, use\nPolicy lookup\nfrom the\nData lifecycle management\nor\nRecords management\nsolutions in the Microsoft Purview portal.\nFor example, from the Microsoft Purview portal:\nYou must specify the exact email address for a user, exact URL for a site, or exact email address for a Microsoft 365 group. You can't use wildcards, or partial matches, for example.\nThe option for sites includes OneDrive accounts. For information how to specify the URL for a user's OneDrive account, see\nGet a list of all user OneDrive URLs in your organization\n.\nThe principles of retention, or what takes precedence?\nUnlike retention labels, you can apply more than one retention policy to the same content. Each retention policy can result in a retain action and a delete action. Additionally, that item could also be subject to these actions from a retention label.\nIn this scenario, when items can be subject to multiple retention settings that could conflict with one another, what takes precedence to determine the outcome?\nThe outcome isn't which single retention policy or single retention label wins, but how long an item is retained (if applicable) and when an item is deleted (if applicable). These two actions are calculated independently from each other, from all the retention settings applied to an item.\nFor example, an item might be subject to one retention policy that is configured for a delete-only action, and another retention policy that is configured to retain and then delete. Consequently, this item has just one retain action but two delete actions. The retention and deletion actions could be in conflict with one another and the two deletion actions might have a conflicting date. The principles of retention explain the outcome.\nBy default, retention always takes precedence over permanent deletion, and the longest retention period wins. These two simple rules always decide how long an item is retained unless it's subject to\npriority cleanup\nthat might be needed to expedite permanent deletion for exceptional circumstances.\nIf you're not using priority cleanup, there are a few more factors that determine when an item is permanently deleted, which include the delete action from a retention label always takes precedence over the delete action from a retention policy.\nUse the following flow to understand the retention and deletion outcomes for a single item that isn't subject to priority cleanup, where each level acts as a tie-breaker for conflicts, from top to bottom. If the outcome is determined by the first level because there are no further conflicts, there's no need to progress to the next level, and so on.\nImportant\nIf you are using retention labels: Before applying the principles to determine the outcome of multiple retention settings on the same item, make sure you know\nwhich retention label is applied\n.\nBefore explaining each principle in more detail, it's important to understand the difference between the retention period for the item vs. the specified retention period in the retention policy or retention label. That's because although the default configuration is to start the retention period when an item is created, so that the end of the retention period is fixed for the item, files also support the configuration to start the retention period from when the file is last modified. With this alternative configuration, every time the file is modified, the start of the retention period is reset, which extends the end of the retention period for the item. Retention labels also support starting the retention period when labeled and at the start of an event.\nTo apply the principles in action with a series of Yes and No questions, you can also use the\nretention flowchart\n.\nExplanation for the four different principles:\nRetention wins over deletion.\nContent won't be permanently deleted when it also has retention settings to retain it. While this principle ensures that content is preserved for compliance reasons, the delete process can still be initiated (user-initiated or system-initiated) and consequently, might remove the content from users' main view. However, permanent deletion is suspended. For more information about how and where content is retained, use the following links for each workload:\nHow retention works for SharePoint and OneDrive\nHow retention works with Microsoft Teams\nHow retention works with Viva Engage\nHow retention works for Exchange\nHow retention works with Copilot & AI apps\nExample for this first principle\n: An email message is subject to a retention policy for Exchange that is configured to delete items three years after they are created, and it also has a retention label applied that is configured to retain items five years after they are created.\nThe email message is retained for five years because this retention action takes precedence over deletion. The email message is permanently deleted at the end of the five years because of the delete action that was suspended while the retention action was in effect.\nThe longest retention period wins.\nIf content is subject to multiple retention settings that retain content for different periods of time, the content is retained until the end of the longest retention period for the item.\nNote\nIt's possible for a retention period of five years in a retention policy or label wins over a retention period of seven years in a retention policy or label, because the 5-year period is configured to start based on when the file is last modified, and the 7-year period is configured to start from when the file is created.\nExample for this second principle\n: Documents in the Marketing SharePoint site are subject to two retention policies. The first retention policy is configured for all SharePoint sites to retain items for five years after they are created. The second retention policy is configured for specific SharePoint sites to retain items for 10 years after they are created.\nDocuments in this Marketing SharePoint site are retained for 10 years because that's the longest retention period for the item.\nExplicit wins over implicit for deletions.\nWith conflicts now resolved for retention, only conflicts for deletions remain:\nA retention label (however it was applied) provides explicit retention in comparison with retention policies, because the retention settings are applied to an individual item rather than implicitly assigned from a container. This means that a delete action from a retention label always takes precedence over a delete action from any retention policy.\nExample for this third principle (label)\n: A document is subject to two retention policies that have a delete action of five years and 10 years respectively, and also a retention label that has a delete action of seven years.\nThe document is permanently deleted after seven years because the delete action from the retention label takes precedence.\nWhen you have retention policies only: If a retention policy for a location uses an adaptive scope or a static scope that includes specific instances (such as specific users for Exchange email) that retention policy takes precedence over a static scope that is configured for all instances for the same location.\nA static scope that is configured for all instances for a location is sometimes referred to as an \"org-wide policy\". For example,\nExchange mailboxes\nand the default setting of\nAll mailboxes\n. Or,\nSharePoint classic and communication sites\nand the default setting of\nAll sites\n. When retention policies aren't org-wide but have been configured with an adaptive scope or a static scope that includes specific instances, they have equal precedence at this level.\nExample 1 for this third principle (policies)\n: An email message is subject to two retention policies. The first retention policy is unscoped and deletes items after 10 years. The second retention policy is scoped to specific mailboxes and deletes items after five years.\nThe email message is permanently deleted after five years because the deletion action from the scoped retention policy takes precedence over the org-wide retention policy.\nExample 2 for this third principle (policies)\n: A document in a user's OneDrive account is subject to two retention policies. The first retention policy is scoped to include this user's OneDrive account and has a delete action after 10 years. The second retention policy is scoped to include this user's OneDrive account and has a delete action after seven years.\nWhen this document will be permanently deleted can't be determined at this level because both retention policies are scoped to include specific instances.\nThe shortest deletion period wins.\nApplicable to determine when items will be deleted from retention policies and the outcome couldn't be resolved from the previous level: Content is permanently deleted at the end of the shortest retention period for the item.\nNote\nIt's possible that a retention policy that has a retention period of seven years wins over a retention policy of five years because the first policy is configured to start the retention period based on when the file is created, and the second retention policy from when the file is last modified.\nExample for this fourth principle\n: A document in a user's OneDrive account is subject to two retention policies. The first retention policy is scoped to include this user's OneDrive account and has a delete action of 10 years after the file is created. The second retention policy is scoped to include this user's OneDrive account and has a delete action of seven years after the file is created.\nThis document will be permanently deleted after seven years because that's the shortest retention period for the item from these two scoped retention policies.\nItems subject to eDiscovery hold also fall under the first principle of retention; they cannot be permanently deleted by any retention policy or retention label. When that hold is released, the principles of retention continue to apply to them. For example, they could then be subject to an unexpired retention period or a delete action.\nPrinciples of retention examples that combine retain and delete actions\nThe following examples are more complex to illustrate the principles of retention when different retain and delete actions are combined. To make the examples easier to follow, all retention policies and labels use the default setting of starting the retention period when the item is created so the end of the retention period is the same for the item.\nAn item has the following retention settings applied to it:\nA retention policy for delete-only after five years\nA retention policy that retains for three years and then deletes\nA retention label that retains-only for seven years\nOutcome\n: The item is retained for seven years because retention takes precedence over deletion and seven years is the longest retention period for the item. At the end of this retention period, the item is permanently deleted because of the delete action from the retention policies.\nAlthough the two retention policies have different dates for the delete actions, the earliest that the item can be permanently deleted is at the end of the longest retention period, which is longer than both deletion dates.\nAn item has the following retention settings applied to it:\nAn org-wide retention policy that deletes-only after ten years\nA retention policy scoped with specific instances that retains for five years and then deletes\nA retention label that retains for three years and then deletes\nOutcome\n: The item is retained for five years because that's the longest retention period for the item. At the end of that retention period, the item is permanently deleted because of the delete action of three years from the retention label. Deletion from retention labels takes precedence over deletion from all retention policies. In this example, all conflicts are resolved by the third level.\nUse Preservation Lock to restrict changes to policies\nSome organizations might need to comply with rules defined by regulatory bodies such as the Securities and Exchange Commission (SEC) Rule 17a-4, which requires that after a policy for retention is turned on, it cannot be turned off or made less restrictive.\nPreservation Lock ensures your organization can meet such regulatory requirements because it locks a retention policy or retention label policy so that no oneâincluding an administratorâcan turn off the policy, delete the policy, or make it less restrictive.\nYou apply Preservation Lock after the retention policy or retention label policy is created. For more information and instructions, see\nUse Preservation Lock to restrict changes to retention policies and retention label policies\n.\nReleasing a policy for retention\nProviding your policies for retention don't have a Preservation Lock, you can delete your policies at any time, which effectively turns off the retention settings for a retention policy, and retention labels can no longer be applied from retention label policies. Any previously applied retention labels remain with their configured retention settings and for these labels, you can still update the retention period when it's not based on when items were labeled.\nYou can also keep a policy, but change the location status to off, or disable the policy. Another option is to reconfigure the policy so it no longer includes specific users, sites, groups, and so on.\nAdditional information for specific locations:\nSharePoint sites and OneDrive accounts:\nWhen you release a retention policy for SharePoint sites and OneDrive accounts, any content that's subject to retention from the policy continues to be retained for 30 days to prevent inadvertent data loss. During this 30-day grace period deleted files are still retained (files continue to be added to the Preservation Hold library), but the timer job that periodically cleans up the Preservation Hold library is suspended for these files so you can restore them if necessary.\nAn exception to this 30-day grace period is when you update the policy to exclude one or more sites for SharePoint or accounts for OneDrive; in this case, the timer job deletes files for these locations in the Preservation Hold library without the 30-day delay.\nFor more information about the Preservation Hold library, see\nHow retention works for SharePoint and OneDrive\n.\nBecause of the behavior during the grace period, if you re-enable the policy or change the location status back to on within 30 days, the policy resumes without any permanent data loss during this time.\nExchange email and Microsoft 365 Groups\nWhen you release a retention policy for mailboxes that are\ninactive\nat the time the policy is released:\nIf the retention policy is explicitly applied to a mailbox, the retention settings no longer apply. With no retention settings applied, an inactive mailbox becomes eligible for automatic deletion in the usual way.\nAn explicit retention policy requires either an adaptive policy scope, or a static policy scope with an include configuration that specified an active mailbox at the time the policy was applied and later became inactive\nIf the retention policy is implicitly applied to a mailbox and the configured retention action is to retain, the retention policy continues to apply and an inactive mailbox never becomes eligible for automatic deletion. When the retain action no longer applies because the retention period has expired, the Exchange admin can now\nmanually delete the inactive mailbox\nAn implicit retention policy requires a static policy scope with the\nAll mailboxes\n(for Exchange email) or\nAll groups\n(for Microsoft 365 Groups) configuration.\nFor more information about inactive mailboxes that have retention policies applied, see\nInactive mailboxes and Microsoft 365 retention\n.\nAuditing retention configuration and actions\nWhen\nauditing is enabled\n, auditing events for retention are supported for both administration configuration (retention policies and retention labels) and retention actions (retention labels only).\nAuditing retention configuration\nAdministrator configuration for retention policies and retention labels is logged as auditing events when a retention policy or label is created, reconfigured, or deleted.\nFor the full list of auditing events, see\nRetention policy and retention label activities\n.\nAuditing retention actions\nRetention actions that are logged as auditing events are available only for retention labels and not for retention policies:\nSpecific to\npriority cleanup\n, use the\nCleanup ID\nassigned to the priority cleanup policy as a keyword search term in the auditing log to find\nrelated activities\n.\nSpecific to\nAdaptive Protection when a retention label is applied to an item\n:\nFor SharePoint and OneDrive, from\nRetention policy and retention label activities\n, select\nRetained file proactively\nFor Exchange, from\nRetention policy and retention label activities\n, select\nRetained email item proactively\nWhen a retention label is applied, changed, or removed from an item in SharePoint or OneDrive:\nFrom\nFile and page activities\n, select\nChanged retention label for a file\nWhen a labeled item in SharePoint is marked as a record, and it is unlocked or locked by a user:\nFrom\nFile and page activities\n, select\nChanged record status to unlocked\nand\nChanged record status to locked\nWhen a retention label that marks content as a record or regulatory record is applied to an item in Exchange:\nFrom\nExchange mailbox activities\n, select\nLabeled message as a record\nWhen a labeled item in SharePoint, OneDrive, or Exchange is marked as a record or regulatory record, and it is permanently deleted:\nFrom\nFile and page activities\n, select\nDeleted file marked as a record\nWhen a disposition reviewer takes action for an item that's reached the end of its retention period:\nFrom\nDisposition review activities\n, select\nApproved disposal\n,\nExtended retention period\n,\nRelabeled item\n, or\nAdded reviewers\nPowerShell cmdlets for retention policies and retention labels\nUse\nSecurity & Compliance PowerShell\nfor Purview retention cmdlets that support configuration at scale, scripting for automation, or might be necessary for advanced configuration scenarios.\nFor a list of available cmdlets, and to identify which ones are supported for the different locations, see\nPowerShell cmdlets for retention policies and retention labels\n.\nWhen to use retention policies and retention labels or eDiscovery holds\nAlthough retention settings and\nholds that you create with an eDiscovery case\ncan both prevent data from being permanently deleted, they are designed for different scenarios. To help you understand the differences and decide which to use, use the following guidance:\nRetention settings that you specify in retention policies and retention labels are designed for a long-term data lifecycle management strategy to retain or delete data for compliance requirements. The scope is usually broad with the main focus being the location and content rather than individual users. The start and end of the retention period is configurable, with the option to automatically delete content without additional administrator intervention.\nHolds for eDiscovery cases are designed for a limited duration to preserve data for a legal investigation. The scope is specific with the focus being content owned by identified users. The start and end of the preservation period isn't configurable but dependent on individual administrator actions, without an option to automatically delete content when the hold is released.\nSummary to compare retention with holds:\nConsideration\nRetention\neDiscovery holds\nBusiness need:\nCompliance\nLegal\nTime scope:\nLong-term\nShort-term\nFocus:\nBroad, content-based\nSpecific, user-based\nStart and end date configurable:\nYes\nNo\nContent deletion:\nYes (optional)\nNo\nAdministrative overheads:\nLow\nHigh\nIf content is subject to both retention settings and an eDiscovery hold, preserving content for the eDiscovery hold always takes precedence. In this way, the\nprinciples of retention\nexpand to eDiscovery holds because they preserve data until an administrator manually releases the hold. However, despite this precedence, don't use eDiscovery holds for long-term data lifecycle management. If you are concerned about automatic deletion of data, you can configure retention settings to retain items forever, or use\ndisposition review\nwith retention labels.\nIf you are using older eDiscovery tools to preserve data, see the following resources:\nExchange:\nIn-Place Hold and Litigation Hold\nHow to identify the type of hold placed on an Exchange Online mailbox\nSharePoint and OneDrive:\nAdd content to a case and place sources on hold in the eDiscovery Center\nRetirement of legacy eDiscovery tools\nUse retention policies and retention labels instead of older features\nIf you need to retain or delete content in Microsoft 365 for data lifecycle management, we recommend you use Microsoft 365 retention policies and retention labels instead of the following older features.\nIf you currently use these older features, they'll usually work side by side with Microsoft 365 retention policies and retention labels. Check their specific documentation for any restrictions. However, we recommend that going forward, you use Microsoft 365 retention policies and retention labels to benefit from a single solution to manage both retention and deletion of content across multiple workloads in Microsoft 365.\nTip\nFor SharePoint, see the following resources:\nUse Microsoft Purview risk and compliance solutions instead of the older information management and records management features in SharePoint for Microsoft 365\nMigration strategies for moving to Microsoft Purview risk and compliance solutions\nOlder features from Exchange Online:\nRetention tags and retention policies\n, also known as\nmessaging records management (MRM)\n(deletion only)\nHowever, if you use the following MRM features, be aware that they aren't currently supported by Microsoft 365 retention policies:\nAn archive policy for\narchive mailboxes\nto automatically move emails from a user's primary mailbox to their archive mailbox after a specified period of time. An archive policy (with any settings) can be used in conjunction with a Microsoft 365 retention policy that applies to a user's primary and archive mailbox.\nRetention policies applied by an admin to specific folders within a mailbox. A Microsoft 365 retention policy applies to all folders in the mailbox. However, an admin can configure different retention settings by using retention labels that a user can apply to folders in Outlook as a\ndefault retention label\n.\nJournaling\n(retention and archive)\nMight be required to integrate with third-party solutions and copies of email messages and their data communication are stored outside Exchange Online. Because you're moving data outside Microsoft 365, you must take extra precautions to secure it and also resolve any duplications that might result from this solution. It is your responsibility to monitor and follow up on any nondelivery receipts to the journaling mailbox that can occur because of external and dependent services. You don't have these additional administrative overheads when you use Microsoft 365 retention and other Microsoft Purview compliance solutions that also aren't limited to just email messages.\nLitigation hold\n(retention only)\nAlthough Litigation holds are still supported, we recommend you use Microsoft 365 retention or eDiscovery holds,\nas appropriate\n.\nOlder features from SharePoint and OneDrive:\nDocument deletion policies\n(deletion only)\nConfiguring in place records management\n(retention only)\nUse policies for site closure and deletion\n(deletion only)\nInformation management policies\n(deletion only)\nIf you have configured SharePoint sites for content type policies or information management policies to retain content for a list or library, those policies are ignored while a retention policy or retention label policy is in effect.\nRelated information\nSharePoint Online Limits\nLimits and specifications for Microsoft Teams\nResources to help you meet regulatory requirements for data lifecycle management and records management\nConfiguration guidance\nSee\nGet started with data lifecycle management\n. This article has information about subscriptions, permissions, and links to end-to-end configuration guidance for retention scenarios.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Retention Overview",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/create-retention-policies": {
      "content_hash": "sha256:7d5500d7789e4372f72cbeb649a3c4c1c6f9772fc675aac3a3cff4f655ccf1ad",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and configure retention policies\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nUse a retention policy to manage the data for your organization by deciding proactively whether to retain content, delete content, or retain and then delete the content.\nA retention policy lets you do this very efficiently by assigning the same retention settings at the container level to be automatically inherited by content in that container. For example, all items in SharePoint sites, all email messages in users' Exchange mailboxes, all channel messages for teams that are used with Microsoft Teams. If you're not sure whether to use a retention policy at the container level or a retention label at the item level, see\nRetention policies and retention labels\n.\nFor more information about retention policies and how retention works in Microsoft 365, see\nLearn about retention policies and retention labels\n.\nNote\nThe information on this page is for compliance administrators. If you are not an administrator and want to understand how retention policies have been configured for the apps that you use, contact your help desk, IT department, or administrator. If you're seeing messages about retention policies in Teams chats and channel messages, you might find it helpful to review\nTeams messages about retention policies\n.\nBefore you begin\nTo make sure you have permissions to create and edit retention policies, see the\npermissions information for data lifecycle management\n.\nDecide before you create your retention policy whether it will be\nadaptive\nor\nstatic\n. For more information, see\nAdaptive or static policy scopes for retention\n. If you decide to use an adaptive policy, you must create one or more adaptive scopes before you create your retention policy, and then select them during the create retention policy process. For instructions, see\nConfiguration information for adaptive scopes\n.\nTo retain prompts and responses for AI apps other than Microsoft 365 Copilot and Copilot Studio, you must first have a collection policy for these AI apps, and that policy includes the setting to capture content. For more information, see\nCollection Policies solution overview\n.\nIf you're creating a retention policy for Teams and use\nprivate channels\n, make sure you're aware of the\nmigration of private channel messages in 2025\nso you know whether to select\nTeams private channel messages\nor\nTeams channel messages\nas the location.\nCreate and configure a retention policy\nAlthough a retention policy can support multiple services that are identified as \"locations\" in the retention policy, you can't create a single retention policy that includes all the supported locations:\nExchange mailboxes\nSharePoint sites\nor\nSharePoint classic and communication sites\nOneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nExchange public folders\nTeams channel messages\nTeams chats\nTeams private channel messages\n(applicable\npre-migration\nonly)\nMicrosoft Copilot experiences\nEnterprise AI apps\nOther AI apps\nViva Engage community messages\nViva Engage user messages\nIf you select the Teams or Viva Engage locations when you create a retention policy, the other locations are automatically excluded. This means that the instructions to follow depend on whether you need to include the Teams or Viva Engage locations.\nNote\nWhen you use adaptive policies instead of static policies, you can configure a single retention policy to include both Teams and Viva Engage locations. This isn't the case for static policies where Teams and Viva Engage locations require their own retention policy.\nWhen you've more than one retention policy, and when you also use retention labels, see\nThe principles of retention, or what takes precedence?\nto understand the outcome when multiple retention settings apply to the same content.\nSelect the tab for instructions to create a retention policy for Teams, Copilots, AI apps, Viva Engage, or the other supported services (Exchange, SharePoint, OneDrive, Microsoft 365 Groups, Skype for Business):\nRetention policy for Teams & AI apps\nRetention policy for Viva Engage\nRetention policy for all other services\nNote\nFor AI apps other than Microsoft 365 Copilot and Copilot Studio, see\nBefore you begin\nabout the prerequisite of collection policies.\nRetention policies for Teams support\nshared channels\n. When you configure retention settings for the\nTeams channel message\nlocation, if a team has any shared channels, they inherit retention settings from their parent team.\nRetention policies also support newly created call data records, which are system-generated messages that contain\nmetadata for meetings and calls\n. All call data records are always included with the\nTeams chats\nlocation, even call data records for Teams channel messages and Teams private channel messages.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto start the\nCreate retention policy\nconfiguration, and name your new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nTeams chats\nbut not\nTeams channel messages\n.\nIf you chose\nStatic\n: On the\nChoose locations to apply the policy\npage, select one or more locations:\nTeams channel message\n: Messages from standard and shared channel chats, and standard and shared channel meetings. Includes messages from private channel chats and private channel meetings\npost-migration\nonly.\nTeams chats\n: For Teams, messages from private 1:1 chats, group chats, meeting chats, and chat with yourself.\nTeams private channel messages\n: Applicable\npre-migration\nonly. Messages from private channel chats and private channel meetings. If you select this option, you can't select the other Teams locations in the same retention policy.\nMicrosoft Copilot experiences\n: For built-in and custom Copilot experiences, all user prompts responses. Includes Microsoft 365 Copilot, Security Copilot, Copilot in Fabric, Copilot Studio.\nEnterprise AI apps\n: For non-Copilot Enterprise AI apps onboarded or connected to your org using methods like Entra registration or data connectors, all user prompts and responses. Includes Entra-registered AI apps, ChatGPT Enterprise, Microsoft Foundry.\nOther AI Apps\n: For other supported AI apps, all user prompts and responses. includes ChatGPT, Google Gemini, Microsoft Bing, DeepSeek.\nBy default,\nall teams and all users are selected\n, but you can refine this by selecting the\nChoose\nand\nExclude\noptions\n.\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\n.\nComplete the configuration and save your settings.\nFor guidance when to use retention policies for Teams and understand the end user experience, see\nManage retention policies for Microsoft Teams\nfrom the Teams documentation.\nFor technical details about how retention works for Teams and Copilot data, including what elements of messages are supported for retention and timing information with example walkthroughs, see\nLearn about retention for Microsoft Teams\nand\nLearn about retention for Copilot\n.\nKnown configuration issues for Teams retention policies\nAlthough you can select the option to start the retention period when items were last modified, the value of\nWhen items were created\nis always used. For messages that are edited, a copy of the original message is saved with its original timestamp to identify when this pre-edited message was created, and the post-edited message has a newer timestamp.\nWhen you select\nEdit\nfor the Teams chats location, you might see guests and non-mailbox users. Retention policies aren't designed for these users, so don't select them.\nTo include newly created call data records for Teams channel messages and Teams private channel messages, you must select the\nTeams chats\nlocation, instead of the\nTeams channel messages\nand\nTeams private channel messages\nlocations.\nAdditional retention policy needed to support Teams\nTeams is more than just chats and channel messages. If you have teams that were created from a Microsoft 365 group (formerly Office 365 group), you should additionally configure a retention policy that includes that Microsoft 365 group by using the\nMicrosoft 365 Group mailboxes & sites\nlocation. This retention policy applies to content in the group's mailbox, site, and files. Files include\nTeams meeting recordings\nand\ntranscripts\nfrom channel meetings.\nTo retain or delete Teams meeting recordings with their transcripts from user chats, you'll need a retention policy that includes the organizer's OneDrive account as the location.\nIf you have team sites that aren't connected to a Microsoft 365 group, which includes sites for Teams shared channels and Teams private channels, you need a retention policy that includes the\nSharePoint classic and communication sites\nor\nOneDrive accounts\nlocations to retain and delete files in Teams:\nFiles that are shared in chat are stored in the OneDrive account of the user who shared the file.\nFiles that are uploaded to channels are stored in the SharePoint site for the team.\nTip\nYou can apply a retention policy to the files of just a specific team when it's not connected to a Microsoft 365 group by selecting the SharePoint site for the team, and the OneDrive accounts of users in the Team.\nIt's possible that a retention policy that's applied to Microsoft 365 groups, SharePoint sites, or OneDrive accounts could delete a file that's referenced in a Teams chat or channel message before those messages get deleted. In this scenario, the file still displays in the Teams message, but when users select the file, they get a \"File not found\" error. This behavior isn't specific to retention policies and could also happen if a user manually deletes a file from SharePoint or OneDrive.\nNote\nRetention policies for Viva Engage do not inform users when messages are deleted as a result of a retention policy.\nTo use this feature, your Viva Engage network must be\nNative Mode\n, not Hybrid Mode.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto create a new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nViva Engage user messages\nbut not\nViva Engage community messages\n.\nIf you chose\nStatic\n: On the\nChoose locations to apply the policy\npage, toggle on one or both of the locations for Viva Engage:\nViva Engage community message\nand\nViva Engage user messages\n.\nBy default, all communities and users are selected, but you can refine this by specifying communities and users to be included or excluded.\nFor Viva Engage user messages:\nIf you leave the default at\nAll users\n, Azure B2B guest users are not included.\nIf you select\nEdit\nfor\nAll users\n, you can apply a retention policy to external users if you know their account.\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\n.\nComplete the configuration and save your settings.\nFor technical details about how retention works for Viva Engage, including what elements of messages are supported for retention and timing information with example walkthroughs, see\nLearn about retention for Viva Engage\n.\nKnown configuration issues for Viva Engage retention policies\nAlthough you can select the option to start the retention period when items were last modified, the value of\nWhen items were created\nis always used. For messages that are edited, a copy of the original message is saved with its original timestamp to identify when this pre-edited message was created, and the post-edited message has a newer timestamp.\nWhen you select\nEdit\nfor the Viva Engage user messages location, you might see guests and non-mailbox users. Retention policies aren't designed for these users, so don't select them.\nAdditional retention policies needed to support Viva Engage\nViva Engage is more than just community messages and private messages. To retain and delete email messages for your Viva Engage network, configure an additional retention policy that includes any Microsoft 365 groups that are used for Viva Engage, by using the\nMicrosoft 365 Group mailboxes & sites\nlocation.\nThis location will also include files that are uploaded to Viva Engage communities. These files are stored in the group-connected SharePoint site for the Viva Engage community.\nIt's possible that a retention policy that's applied to SharePoint sites could delete a file that's referenced in a Viva Engage message before those messages get deleted. In this scenario, the file still displays in the Viva Engage message, but when users select the file, they get a \"File not found\" error. This behavior isn't specific to retention policies and could also happen if a user manually deletes a file from SharePoint.\nUse the following instructions for retention policies that apply to any of these services:\nExchange: Email and public folders\nSharePoint: Sites and SharePoint Embedded containers\nOneDrive: Accounts\nMicrosoft 365 groups\nSkype for Business\nNote\nIf your organization is using\nadministrative units\nand you're a restricted administrator assigned one or more adminsitrative units, you won't be able to configure a retention policy that includes SharePoint sites or Exchange public folders. For these locations, you must be an unrestricted administrator.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto start the\nCreate retention policy\nconfiguration, and name your new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option. Adaptive policies don't support the locations for Exchange public folders or Skype for Business.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nExchange mailboxes\nbut not\nSharePoint sites\n.\nIf you chose\nStatic\n: On the\nChoose locations\npage, toggle on or off any of the locations except the locations for Teams and Viva Engage. For each location, you can leave it at the default to\napply the policy to the entire location\n, or\nspecify includes and excludes\n.\nInformation specific to locations:\nExchange mailboxes and Exchange public folders\nSharePoint sites and OneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\non this page.\nComplete the configuration and save your settings.\nSeparate an existing 'Teams chats and Copilot interactions' policy\nPreviously, retention policies used the location\nTeams chats and Copilot interactions\nthat combined Teams chat and Copilot interactions. There are now separate retention locations for Teams chat and Copilot interactions.\nYou can separate Teams chats from Copilot interactions from an existing retention policy.\nYou can create new retention policies for just Teams chats, or for just Copilot interactions.\nUse the following PowerShell commands to separate an existing retention policy for\nTeams chats and Copilot interactions\n:\nTo make your existing retention policy for the\nolder locations\na Teams chat only policy:\nSet-RetentionCompliancePolicy -Identity \"<policy name>\" -Applications \"User:TeamsChatUserInteractions\"\nOr, if you have an existing retention policy for\nnewer locations\n, such as Teams private channel messages and Viva Engage, you can add Teams chat to it:\nSet-AppRetentionCompliancePolicy -Identity \"<policy name>\" -Applications \"User:TeamsChatUserInteractions\"\nTo add Microsoft 365 Copilot interactions to an existing retention policy for\nnewer locations\n, such as Teams private channel messages and Viva Engage:\nSet-AppRetentionCompliancePolicy -Identity â<policy name>â -Applications \"User:M365Copilot\"\nFor new retention policies, select the new locations, such as\nTeams chat\nor\nMicrosoft Copilot Experiences\n.\nNote\nIf you have existing retention policies for\nTeams chats and Copilot interactions\n, they continue to be supported, although they can't be edited when your tenant supports the separate locations. At this point, any new retention policies must use the new locations.\nHow long it takes for retention policies to take effect\nWhen you create and submit a retention policy, it can take up to seven days for the retention policy to be applied:\nFirst, the retention policy needs to be distributed to the locations that you selected, and then applied to content. You can always check the distribution status of the retention policy by selecting it from the\nRetention policies\npage in the Microsoft Purview portal. From the flyout pane, if you see\n(Error)\nincluded in the status, and in the details for the locations see a message that it's taking longer than expected to deploy the policy or to try redeploying the policy, try running the\nSet-AppRetentionCompliancePolicy\nor\nSet-RetentionCompliancePolicy\nPowerShell command to retry the policy distribution:\nConnect to Security & Compliance PowerShell\n.\nRun one of the following commands:\nFor the policy locations\nTeams private channel messages\n,\nViva Engage user messages\nand\nViva Engage community messages\n:\nSet-AppRetentionCompliancePolicy -Identity <policy name> -RetryDistribution\nFor all other policy locations, such as\nExchange mailboxes\n,\nSharePoint classic and communication sites\n, and\nTeams channel messages\n:\nSet-RetentionCompliancePolicy -Identity <policy name> -RetryDistribution\nUpdating retention policies\nWhen settings from the retention policy are already applied to content, a change in configuration to the policy will be automatically applied to this content in addition to content that's newly identified.\nSome settings can't be changed after the policy is created and saved, which include the name of the retention policy, the scope type (adaptive or static), and the retention settings except the retention period.\nIf you no longer need the retention settings that you've configured, see\nReleasing a policy for retention\n.\nTroubleshooting retention policies\nIf your retention policies aren't working as expected or you see errors related to your retention policies, use the following troubleshooting resources:\nIdentify errors in Microsoft 365 retention and retention label policies\nResolve errors in Microsoft 365 retention and retention label policies\nNext steps\nIf some items for Exchange, SharePoint, OneDrive, or Microsoft 365 Groups need different retention settings from the retention policy settings you've configured,\ncreate retention labels for these exceptions\n.\nHowever, if you're looking to manage high-value items for business, legal, or regulatory record-keeping requirements,\nuse file plan to create and manage retention labels\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Retention Policies",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/create-retention-labels-data-lifecycle-management": {
      "content_hash": "sha256:6592f280db33840c629afcac8b7f48b86672977d96d3231aff99b2e805604b4c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate retention labels for exceptions to your retention policies\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nAs part of your data governance strategy to retain what you need and delete what you don't, you might need to create a few retention labels for items that need exceptions to your retention policies.\nWhereas retention policies automatically apply to all items at the container level (such as SharePoint sites, user mailboxes, and so on), retention labels apply to individual items, such as a SharePoint document or an email message.\nMake sure you understand the\nprinciples of retention\nbefore you use retention labels to supplement a retention policy for specific SharePoint, OneDrive, or Exchange items. Typically, you'll use retention labels to retain specific items longer than an applied retention policy, but they can also be used to override automatic deletion at the end of the retention period, or apply a different deletion period.\nAs a typical example: The majority of content on your SharePoint sites need to be retained for three years, which is covered with a retention policy. But you have some contract documents that must be retained for seven years. These exceptions can be addressed with retention labels. After assigning the retention policy to all SharePoint sites, you apply the retention labels to the contract documents. All SharePoint items will be retained for three years, and just the contract documents will be retained for seven years.\nFor more examples of how retention labels can be used as exceptions to retention policies, see\nCombining retention policies and retention labels\n.\nRetention labels also support more capabilities than retention policies. For more information, see\nCompare capabilities for retention policies and retention labels\n.\nUse the following information to help you create retention labels to supplement retention policies as part of your data lifecycle management strategy.\nNote\nCreate retention labels from the\nRecords management\nsolution rather than\nData lifecycle management\nif you need to use retention labels to manage high-value items for business, legal, or regulatory record-keeping requirements. For example, you want to use event-based retention or disposition review. For instructions, see\nUse file plan to create and manage retention labels\n.\nBefore you begin\nTo make sure you have permissions to create and edit retention labels and their policies, see\nPermissions for retention policies and retention labels\n.\nHow to create retention labels for data lifecycle management\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nRetention labels\n.\nSelect\nCreate a label\nand follow the prompts to create the retention label. Be careful what name you choose, because this can't be changed after the label is saved.\nFor more information about the retention settings, see\nSettings for retaining and deleting content\n.\nAfter you have created the label and you see the options to publish the label, auto-apply the label, or just save the label: Select\nJust save the label for now\n, and then select\nDone\n.\nRepeat these steps to create any more retention labels that you need for different retention settings.\nTo edit an existing label, select it, and then select the\nEdit label\noption to start the Edit retention label configuration that lets you change the label descriptions and any eligible settings.\nMost settings can't be changed after the label is created and saved, which include the label name, and the retention settings except the retention period.\nNext steps\nNow you've created retention labels, they are ready to be added to items by publishing the labels, or automatically applying them:\nPublish retention labels and apply them in apps\nApply a retention label to content automatically\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Retention Labels",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/retention-policies-sharepoint": {
      "content_hash": "sha256:395c8d40e0c4ea6f82716c5c710911d7784fd8f802ae98c32958af7b9570f42b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about retention for SharePoint and OneDrive\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nThe information in this article supplements\nLearn about retention\nbecause it has information that's specific to SharePoint and OneDrive.\nFor other workloads, see:\nLearn about retention for Microsoft Teams\nLearn about retention for Viva Engage\nLearn about retention for Exchange\nLearn about retention for Copilot\nWhat's included for retention and deletion\nNote\nIn preview,\nMicrosoft Facilitator AI-generated notes in meetings\nare supported by retention policies and retention labels.\nAll files stored in SharePoint (and SharePoint Embedded) or OneDrive sites can be retained by applying a retention policy or retention label. For SharePoint,\narchived sites\nare supported in addition to active sites.\nThe following files can be deleted:\nWhen you use a retention policy: All files in document libraries, which include any automatically created SharePoint document libraries, such as\nSite Assets\n.\nWhen you use retention labels: All files in all document libraries, and all files at the root level that aren't in a folder.\nTip\nWhen you use a\nquery with an auto-apply policy for a retention label\n, you can exclude specific document libraries by using the following entry:\nNOT(DocumentLink:\"<URL to document library>\")\nFiles that can be retained and deleted include those used by Microsoft Loop and Copilot Pages. For these apps, content can be stored in SharePoint Embedded containers. Although the containers aren't SharePoint sites, for the purposes of retention and deletion, they behave the same as SharePoint sites. For more information about where the files are stored, see\nOverview of Loop storage\n.\nList items aren't supported by retention policies but are supported by retention labels with the exception of items in system lists. These are hidden lists used by SharePoint to manage the system and include the master page catalog, solution catalog, and data sources. When retention labels are applied to supported list items, they will always be retained according to the retention settings, but not deleted if they are hidden from search.\nWhen you apply a retention label to a supported list item that has a document attachment:\nFor a standard retention label (doesn't declare the item to be a record):\nThe document attachment doesn't automatically inherit the retention settings of the label, but can be labeled independently.\nFor a retention label that declares the item a record:\nThe document attachment automatically inherits the retention settings from the label if the document isn't already labeled.\nRetention settings from both retention policies and retention labels don't apply to organizing structures that include libraries, lists, folders, and Loop workspaces.\nFor retention policies and label policies: SharePoint sites must be indexed for the retention settings to be applied. However, if items in SharePoint document libraries are configured to not appear in search results, this configuration doesn't exclude files from the retention settings.\nIf a site is configured with the\nSet-SPOSite\nparameter\nLockState\nthat's set to NoAccess or ReadOnly, items in that site can't be deleted with this site configuration.\nHow retention works for SharePoint and OneDrive\nTo store content that needs to be retained, SharePoint and OneDrive create a Preservation Hold library if one doesn't exist for the site. The Preservation Hold library is a hidden system location that isn't designed to be used interactively but instead, automatically stores files when this is needed for compliance reasons. It's not supported to edit, delete, or move these automatically retained files yourself. Or, change or remove retention labels and sensitivity labels for these files. Instead, use compliance tools, such as those supported by\neDiscovery\nto access the content in these files.\nThe Preservation Hold library works in the following way to support retention policies and retention labels:\nWhen a user changes an item that's subject to retention from a retention policy or a retention label that marks items as a record, or deletes any item subject to retention, the original content is copied to the Preservation Hold library. This behavior lets the user change or delete the content in their app, while keeping a copy of the original for compliance reasons.\nRetention item\nUser edit or delete action\nCopy created in the Preservation Hold library\nRetention policy\nEdit item\nDelete item\nYes\n*\nYes\nStandard retention label (doesnât mark items as records or regulatory records)\nEdit item\nDelete item\nNo\nYes\nRetention label that marks items as records\nEdit unlocked item\nEdit locked item\nDelete item\nYes\nNot applicable â\naction blocked\nNot applicable â\naction blocked\nRetention label that marks items as regulatory records\nEdit item\nDelete item\nNot applicable â\naction blocked\nNot applicable â\naction blocked\nFootnote\n:\n*\nNew content isn't copied to the Preservation Hold library the first time it's edited. To retain all versions of a file,\nversioning\nmust be turned on for the site.\nThis behavior for copying files into the Preservation Hold library applies to content that exists when the retention settings were applied. In addition, for retention policies, any new content that's created or added to the site after it was included in the policy will be retained in the Preservation Hold library.\nA timer job periodically runs on the Preservation Hold library. For content that has been in the Preservation Hold library for more than 30 days, this job compares the content to all queries used by the retention settings for that content. Content that is older than their configured retention period and isn't awaiting\ndisposition review\nis then deleted from the Preservation Hold library, and from the original location if it's still there. This timer job runs every seven days, which means that together with the minimal 30 days, it can take up to 37 days for content to be deleted from the Preservation Hold library.\nUsers see an error message if they try to delete a library, list, or site that's subject to retention.\nUsers also see an error message if they try to delete a labeled item in any of the following circumstances. The item isn't copied to the Preservation Hold library but remains in the original location:\nThe records management setting that allows users to delete labeled items is turned off.\nTo check or change this setting, go to the records management settings in the Microsoft Purview portal:\nSettings\n> **Solution settings **> Records Management >\nRetention Labels\n>\nDeleting content labeled for retention\n. There are separate settings for OneDrive and SharePoint.\nAlternatively, and if you don't have access these settings in the portals, you can use\nAllowFilesWithKeepLabelToBeDeletedSPO\nand\nAllowFilesWithKeepLabelToBeDeletedODB\nfrom\nGet-PnPTenant\nand\nSet-PnPTenant\n.\nThe retention label marks items as a record and it's\nlocked\n.\nOnly when the record is unlocked, does a copy of the last version get stored in the Preservation Hold library.\nThe retention label marks items as a\nregulatory record\n, which always prevents the item from being edited or deleted.\nAfter retention settings are assigned to content in a OneDrive account, SharePoint site, or SharePoint Embedded container for a Loop workspace, the paths the content takes depend on whether the retention settings are to retain and delete, to retain only, or delete only. In the explanations that follow, modified content is moved to the Preservation Hold library for retention policies, and retention labels that mark items as records (and the content is unlocked). Items that are modified with retention labels that don't mark items as records don't create copies in the Preservation Hold library, but do when items are deleted.\nWhen the retention settings are to retain and delete:\nIf the content is modified or deleted\nduring the retention period, a copy of the original content as it existed when the retention settings were assigned is created in the Preservation Hold library. There, the timer job identifies items whose retention period has expired. Those items are moved to the second-stage Recycle Bin, where they're permanently deleted at the end of 93 days. The second-stage Recycle Bin isn't visible to end users (only the first-stage Recycle Bin is), but site collection admins can view and restore content from there.\nNote\nTo help prevent inadvertent data loss, we no longer permanently delete content from the Preservation Hold library. Instead, we permanently delete content only from the Recycle Bin, so all content from the Preservation Hold library now goes through the second-stage Recycle Bin.\nIf the content is not modified or deleted\nduring the retention period, the timer job moves this content to the first-stage Recycle Bin at the end of the retention period. If a user deletes the content from there or empties this Recycle Bin (also known as purging), the document is moved to the second-stage Recycle Bin. A 93-day retention period spans both the first- and second-stage recycle bins. At the end of 93 days, the document is permanently deleted from wherever it resides, in either the first-stage or second-stage Recycle Bin. The Recycle Bin isn't indexed and therefore unavailable for searching. As a result, an eDiscovery search can't find any Recycle Bin content on which to place a hold.\nNote\nBecause of the\nfirst principle of retention\n, permanent deletion is always suspended if the same item must be retained because of another retention policy or retention label, or it's under eDiscovery holds for legal or investigative reasons.\nWhen the retention settings are retain-only, or delete-only, the contents paths are variations of retain and delete:\nContent paths for retain-only retention settings\nIf the content is modified or deleted\nduring the retention period: A copy of the original document is created in the Preservation Hold library and retained until the end of the retention period, when the copy in the Preservation Hold library is moved to the second-stage Recycle Bin and is permanently deleted after 93 days.\nIf the content is not modified or deleted\nduring the retention period: Nothing happens before and after the retention period; the document remains in its original location.\nContent paths for delete-only retention settings\nIf the content is deleted\nduring the configured period: The document is moved to first-stage Recycle Bin. If a user deletes the document from there or empties this Recycle Bin, the document is moved to the second-stage Recycle Bin. A 93-day retention period spans both the first-stage and second-stage recycle bins. At the end of 93 days, the document is permanently deleted from wherever it resides, in either the first-stage or second-stage Recycle Bin. If the content is modified during the configured period, it follows the same deletion path after the configured period.\nIf the content is not deleted\nduring the configured period: At the end of the configured period in the retention policy, the document is moved to the first-stage Recycle Bin. If a user deletes the document from there or empties this Recycle Bin (also known as purging), the document is moved to the second-stage Recycle Bin. A 93-day retention period spans both the first-stage and second-stage recycle bins. At the end of 93 days, the document is permanently deleted from wherever it resides, in either the first-stage or second-stage Recycle Bin. The Recycle Bin isn't indexed and therefore unavailable for searching. As a result, an eDiscovery search can't find any Recycle Bin content on which to place a hold.\nHow retention works with cloud attachments\nCloud attachments are embedded links to files that users share, or referenced in interactions for Microsoft 365 Copilot and Microsoft 365 Copilot Chat. They can be retained and deleted when your users share them in Outlook emails and Teams or Viva Engage messages, and they are referenced in interactions with Copilot. When you\nautomatically apply a retention label to cloud attachments\n, the retention label is applied to a copy of the shared file, which is stored in the Preservation Hold library.\nFor this scenario, we recommend you configure the label setting to start the retention period based on when the item is labeled. If you do configure the retention period based on when the item is created or last modified, this date is taken from the original file at the time of sharing. If you configure the start of retention to be when last modified, this setting has no effect for this copy in the Preservation Hold library.\nHowever, if the original file is modified and then shared again, a new copy of the file as a new version is saved and labeled in the Preservation Hold library.\nIf the original file is shared again but not modified, the labeled date of the copy in the Preservation Hold library is updated. This action resets the start of the retention period and is why we recommend you configure the start of the retention period to be based on when the item is labeled.\nBecause the retention label isn't applied to the original file, the labeled file is never modified or deleted by a user. The labeled file remains in the Preservation Hold library until the timer job identifies that its retention period has expired. If the retention settings are configured to delete items, the file is then moved to the second-stage Recycle Bin, where it's permanently deleted at the end of 93 days:\nThe copy that's stored in the Preservation Hold library is typically created within an hour from the cloud attachment being shared.\nTo safeguard against the original file being deleted or moved by users before the copy can be created and labeled, files in locations included in the auto-labeling policy are automatically copied into the Preservation Hold library if they are deleted or moved. These files have a temporary retention period of one day and then follow the standard cleanup process described on this page. When the original file has been deleted or moved, the copy for retaining cloud attachments uses this version of the file. The automatic and temporary retention of deleted or moved files in the Preservation Hold library is unique to auto-labeling policies for cloud attachments.\nHow retention works with OneNote content\nWhen you apply a retention policy to a location that includes OneNote content, or a retention label to a OneNote folder, the different OneNote sections inherit the retention settings as individual files. Pages from each section are contained within the file and inherit the retention settings from their parent section.\nBecause of this structure, each section will be individually retained and deleted (with all its pages), according to the retention settings you specify.\nOnly sections are impacted by the retention settings that you specify. For example, although you see a\nModified\ndate for each individual notebook, this date isn't used by Microsoft 365 retention.\nHow retention works with document versions\nVersioning is a feature of all document lists and libraries in SharePoint and OneDrive. By default, versioning retains a minimum of 500 major versions, although you can change this limit. For more information, see\nEnable and configure versioning for a list or library\nand\nHow versioning works in lists and libraries\n.\nWhen a document with versions is subject to retention settings to retain that content, and it's not marked as a record, how the versions are stored in the Preservation Hold library changed in July 2022 to improve performance. Now, all versions of that file are retained in a single file in the Preservation Hold library. Before the change, versions were copied to the Preservation Hold library as separate files, and after the change, remain as separate files.\nNote\nVersions that are from a record continue to be copied to the Preservation Hold library as separate files, which means that they can expire independently from each other and the current version.\nIf the label doesn't mark the item as a record and retention settings are configured to delete the item at the end of the retention period:\nIf the retention period is based on when the content was created, when labeled, or when an event starts, each version has the same expiration date as the original document. The original document and its versions all expire at the same time.\nIf the retention period is based on when the content was last modified:\nAfter the change where all versions of the file are retained in a single file in the Preservation Hold library\n: Each version has the same expiration date as the last version of the document. The last version of the document and its versions all expire at the same time.\nBefore the change where versions were copied to the Preservation Hold library as separate files\n: Each version has its own expiration date based on when the original document was modified to create that version. The original document and its versions expire independently of each other.\nWhen the retention action is to delete the document, all versions not in the Preservation Hold library are deleted at the same time according to the current version.\nFor items that are subject to a retention policy (or an eDiscovery hold), the versioning limits for the document library are ignored until the retention period of the document is reached (or the eDiscovery hold is released). In this scenario, old versions aren't automatically purged and users are prevented from deleting versions.\nThat's not the case for retention labels when the content isn't subject to a retention policy (or an eDiscovery hold). Instead, the versioning limits are honored so that older versions are automatically deleted to accommodate new versions, but users are still prevented from deleting versions.\nHow retention works with Microsoft 365 Archive\nFor administrators, there's very little change to how retention policies and retention labels work and are managed for sites that use\nMicrosoft 365 Archive\n. For example, the default policy configuration of all sites automatically includes archived sites as well as active sites. An active site that's included in a retention policy and then changed to be an archive site will continue to be subject to the configuration settings in the retention policy. The same applies to labeled items in a site that becomes archived. You can create a new retention policy for an archived site, and auto-apply retention labels for archived sites. Items still support disposition review, Power Automate actions, simulation mode is supported, policy lookup, adaptive scopes, and Microsoft Graph API to programmatically apply and manage retention labels are all supported for archived sites.\nThe one exception is for\ncloud attachments\n, where an item that's currently in an archived site won't be retained with an auto-apply retention label policy. Cloud attachments that were retained from an active site continue to to be subject to the configuration settings in the retention label.\nBecause users can't view and interact with items in archived sites, the user actions usually supported for retention labels won't be possible. For example, manually applying or removing retention labels, locking and unlocking records, editing of record properties that include the name and description. Similarly, although the Microsoft Purview portal supports disposition review, the contents of an item under disposition review can't be displayed and the URL link to the item won't work.\nWhen a user leaves the organization\nSharePoint\n:\nWhen a user leaves your organization, any content created by that user isn't affected because SharePoint is considered a collaborative environment, unlike a user's mailbox or OneDrive account.\nOneDrive\n:\nIf a user leaves your organization, any files that are subject to a retention policy or has a retention label will remain subject to the retention settings for the duration of the retention period specified in the policy or label. During that time, all sharing access continues to work and the content continues to be discoverable by Content Search and eDiscovery.\nWhen the retention period expires and the retention settings included a delete action, content moves into the Site Collection Recycle Bin and isn't accessible to anyone except the admin.\nConfiguration guidance\nIf you're new to configuring retention in Microsoft 365, see\nGet started with data lifecycle management\n.\nIf you're ready to configure a retention policy or retention label for Exchange, see the following instructions:\nCreate and configure retention policies\nPublish retention labels and apply them in apps\nApply a retention label to content automatically\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Retention for SharePoint",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/disposition": {
      "content_hash": "sha256:1950d3e01aeca6b70a9f80c93afdc38aadc886f4676e2b694b45c7f1825f430b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nDisposition of content\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nUse the\nDisposition\npage from\nRecords Management\nin the Microsoft Purview portal to manage disposition reviews and view the metadata of\nitems marked as records\nthat have been automatically deleted at the end of their retention period.\nPrerequisites for viewing content dispositions\nTo manage disposition reviews and confirm that items marked as records have been deleted, you must have sufficient permissions and auditing must be enabled. Also be aware of any\nlimitations\nfor disposition.\nPermissions for disposition\nTo successfully access\nDisposition\nin the Microsoft Purview portal, users must have the\nDisposition Management\nrole. This role is included in the\nRecords Management\ndefault role group.\nNote\nBy default, a global admin isn't granted the\nDisposition Management\nrole.\nTo grant users just the permissions they need for disposition reviews without granting them permissions to view and configure other features for retention and records management, create a custom role group (for example, named \"Disposition Reviewers\") and grant this group the\nDisposition Management\nrole.\nFor instructions to add users to the default roles or create your own role groups, see\nPermissions in the Microsoft Purview portal\n.\nAdditionally:\nTo view the contents of items during the disposition process, add users to the\nContent Explorer Content Viewer\nrole group. If users don't have the permissions from this role group, they can still select a disposition review action to complete the disposition review, but must do so without being able to view the item's contents from the mini-preview pane in the Microsoft Purview portal.\nBy default, each person that accesses the\nDisposition\npage sees only items that they're assigned to review. For a records management administrator to see all items assigned to all users, and all retention labels that are configured for disposition review: From the Microsoft Purview portal, navigate to\nSettings\n>\nSolution settings\n> **Records Management ** >\nDisposition\nto select and then enable a mail-enabled security group that contains the administrator accounts. Permissions are then granted to the group members, but not the group owner.\nMicrosoft 365 groups and security groups that aren't mail-enabled don't support this feature and don't display in the list to select. If you need to create a new mail-enabled security group, use the link to the\nMicrosoft 365 admin center\nto create the new group.\nImportant\nAfter you've enabled the group, you can't change it in the Microsoft Purview portal. See the next section for how to enable a different group by using PowerShell.\nThe Records Management settings are visible only to record management administrators.\nEnabling another security group for disposition\nAfter you've enabled a security group for disposition from the\nRecords Management settings\nin the Microsoft Purview portal, you can't disable this permission for the group or replace the selected group in the portal. However, you can enable another mail-enabled security group by using the\nEnable-ComplianceTagStorage\ncmdlet.\nFor example:\nEnable-ComplianceTagStorage -RecordsManagementSecurityGroupEmail dispositionreviewers@contosoi.com\nEnable auditing\nMake sure that auditing is enabled at least one day before the first disposition action. For more information, see\nSearch the audit log\n.\nDisposition reviews\nWhen content reaches the end of its retention period, there are several reasons why you might want to review that content and confirm whether it can be permanently deleted (\"disposed\"). For example, instead of deleting the content, you might need to:\nSuspend the deletion of relevant content for litigation or an audit.\nAssign a different retention period to the content, perhaps because the original retention settings were a temporary or provisional solution.\nMove the content from its existing location to an archive location, for example, if that content has research or historical value.\nWhen a disposition review is triggered at the end of the retention period, your chosen reviewers receive an email notification that they have content to review. These reviewers can be individual users or members of a mail-enabled security group. When you use a mail-enabled security group, only group members and not the group owner receive the email notifications.\nYou can customize the notification email that reviewers receive, including instructions in different languages. For multi-language support, you must specify the translations yourself and this custom text is displayed to all reviewers irrespective of their locale.\nUsers receive an initial email notification per label at the end of the item's retention period, with a reminder per label once a week of all disposition reviews that they're assigned. They can click the link in the notification and reminder emails to go directly to the records management\nDisposition\npage in the Microsoft Purview portal to review the content and take an action. Alternately, the reviewers can navigate to this\nDisposition\npage in the Microsoft Purview portal. Then:\nReviewers see only the disposition reviews that are assigned to them, whereas administrators who are added to the selected security group for records manager see all disposition reviews.\nReviewers can add new users to the same disposition review. Note that this action does not automatically grant these added users the\nrequired permissions\n.\nFor the disposition review process, a mini-review pane for each item shows a preview of the content if they have permissions to see it. If they don't have permissions, they can select the content link and request permissions. This mini-review pane also has tabs for additional information about the content:\nDetails\nto display indexed properties, where it's located, who created it and when, and who last modified it and when.\nHistory\nthat shows the history of any disposition review actions to date, with reviewer comments if available.\nA disposition review can include content in Exchange mailboxes, SharePoint sites, and OneDrive accounts. Content pending a disposition review in those locations is permanently deleted only after a reviewer for the final stage of disposition chooses to permanently delete the content.\nNote\nA mailbox must have at least 10 MB data to support disposition reviews.\nAdministrators can see an overview of all pending dispositions in the\nOverview\ntab. Reviewers see only their items pending disposition.\nSelect the\nView all pending dispositions\n, to view them the\nDisposition\npage.\nWorkflow summary for a disposition review\nBasic workflow for a disposition review, single stage:\nThe admin configures a retention label to start a disposition review at the end of the retention period.\nThe admin publishes the label and a user applies the label to one or more items, or the admin automatically applies the retention label to items.\nAt the end of the retention period for each item, the designated disposition reviewers receive an email to review the item for disposition.\nOne of the reviewers selects the link to review the item in the disposition page from the Microsoft Purview portal, and confirms that the item should be permanently deleted.\nAuto-approval for disposition\nYou can optionally specify a time period (7-365 days) for auto-approval. The default period if you select this option is 14 days.\nIf designated reviewers don't take manual action during this time period by using the\nstandard disposition review process\n, the item automatically passes to the next review stage. If the item is in the final review stage, the item is automatically disposed with permanent deletion.\nImportant\nIf you configure this option and items are already pending disposition review, they automatically become auto-approved if they have already exceeded the number of days that you specified for auto-approval. The time period always starts from when the item is ready for disposition review and not from when you configure the option.\nAs with all retention label changes, allow up to 7 days if you turn on, turn off, or change the number of days for this option.\nThere's no new auditing event for auto-approval. Instead, use the details in the existing\nApproved disposal\nauditing event to identify whether the item was manually approved or automatically approved by using this option.\nHow to configure a retention label for disposition review\nTriggering a disposition review at the end of the retention period is a configuration option that's available only with a retention label. Disposition review isn't available for a retention policy. For more information about these two retention solutions, see\nLearn about retention policies and retention labels\n.\nFrom the\nChoose what happens after the retention period\npage for a retention label:\nAfter you select the\nStart a disposition review\noption, select\n+ Create stages and assign reviewers\n. On the next page of the configuration, you'll specify how many consecutive stages of disposition you want and the disposition reviewers for each stage:\nOptionally, select whether you want to use\nautomatic-approval\n. If you use this option, specify the number of days reviewers have to take manual action before the item is automatically moved to the next disposition stage or automatically disposed.\nSelect\n+ Add a stage\n, and name your stage for identification purposes. Then specify the reviewers for that stage.\nFor the reviewers, specify up to 10 individual users or mail-enabled security groups. Microsoft 365 groups aren't supported for this option.\nIf you need more than one person to review an item at the end of its retention period, select\nAdd another stage\nand repeat the configuration process for the number of stages that you need, with a maximum of five stages.\nWithin each individual stage of disposition, any of the users you specify for that stage are authorized to take the next action for the item at the end of its retention period. These users can also add other users to their disposition review stage.\nNote\nIf you configured retention labels before multi-staged disposition review was available, you can upgrade your labels to support this feature: Edit the label and select\nEdit stages and reviewers\non the\nChoose what happens after the retention period\npage.\nDuring the configuration phase, for each stage specified, you can rename it, reorder it, or remove it by selecting\nEdit stages and reviewers\nthat now displays for the\nStart a disposition review\noption. Then for each stage, you can select the Stage actions option (\n...\n):\nHowever, you can't reorder or remove a stage after you've created the retention label. You'll see only the\nAdd a stage\nand\nRename a stage\noptions available. You can still edit the reviewers.\nAfter you've specified your reviewers, remember to grant them the\nDisposition Management\nrole permission. For more information, see the\nPermissions for disposition\nsection on this page.\nHow to customize email messages for disposition review\nExample default email notification sent to a reviewer:\nYou can customize the email messages that are sent to disposition reviewers for the initial notification and then reminders.\nSign in to the Microsoft Purview portal\n>\nSettings\n>\nSolutions settings\n>\nRecords Management\n>\nDisposition\n.\nFrom the\nEmail notifications for disposition reviews\nsection, select and specify whether you want to use just the default email message, or add your own text to the default message. Your custom text is added to the email instructions after the information about the retention label and before the next steps instructions.\nText for all languages can be added, but formatting and images are unsupported. URLs and email addresses can be entered as text and depending on the email client, display as hyperlinks or unformatted text in the customized email.\nExample text to add:\nIf you need additional information, visit the helpdesk website (https://support.contoso.com) or send them an email (helpdesk@contoso.com).\nSelect\nSave\nto save any changes.\nViewing and disposing of content\nWhen a reviewer is notified by email that content is ready to review, they can click a link in the email that takes them directly to the\nDisposition\npage from\nRecords management\nin the Microsoft Purview portal. There, the reviewers can see how many items for each retention label are waiting disposition with the\nType\ndisplaying\nPending disposition\n. They then select a retention label, and\nOpen in new window\nto see all content with that label:\nFrom the\nPending dispositions\npage, they see all pending dispositions for that label. When one or more items are selected, they can use the mini-preview pane and the\nSource\n,\nDetails\n, and\nHistory\ntab to inspect the content before taking action on it:\nIf you use the horizontal scroll bar, or close the min-review pane, you see more columns that include the expiry date and the name of the disposition review stage.\nAs you can see from the example shown, the actions supported are:\nApprove disposal\n:\nWhen this action is selected for an interim stage of disposition review (you've configured multiple stages): The item moves to the next disposition stage.\nWhen this action is selected for the final stage of disposition review, or there's only one stage of disposition: The item is marked as eligible for permanent deletion, which happens within 15 days.\nRelabel\n:\nWhen this action is selected, the item exits the disposition review process for the original label. The item is then subject to the retention settings of the newly selected retention label.\nExtend\n:\nWhen this action is selected, disposition review is effectively suspended until the end of the extended period and then disposition review is triggered again from the first stage.\nAdd reviewers\n:\nWhen this action is selected, the user is prompted to specify and add other users for review.\nNote\nThis action doesn't automatically grant the\nrequired permissions\nto the users who are added. If they don't have these permissions, they can't participate in the disposition review.\nEach action taken has a corresponding audit event in the\nDisposition review activities\nauditing activities group.\nDuring the disposition review process, unless you're using the optional setting of an\nauto-approval timeout period\n, the content never moves from its original location, and it's not marked for permanent deletion until this action is selected by a reviewer for the final or only disposition stage.\nDisposition of records\nFrom the\nRecords management\nmain page >\nDisposition\ntab, you can identify:\nItems deleted as a result of a disposition review.\nItems marked as a record or regulatory record but not marked for disposition review and automatically deleted at the end of their retention period.\nThese items indicate\nRecords Disposed\nin the\nType\ncolumn. For example:\nNote\nThis functionality uses information from the\nunified audit log\nand therefore requires auditing to be\nenabled and searchable\nso the corresponding events are captured.\nFor auditing of deleted items that were marked as records or regulatory records, search for\nDeleted file marked as a record\nin the\nFile and page activities\ncategory. This audit event is applicable to documents and emails.\nFilter and export the views\nWhen you select a retention label from the\nDisposition\npage, the\nPending disposition\ntab (if applicable) and the\nDisposed items\ntab let you filter the views to help you more easily find items.\nFor pending dispositions, the time range is based on the expiration date. For disposed items, the time range is based on the deletion date.\nYou can export information about the items in either view as a .csv file that you can then sort and manage using Excel.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Disposition",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/retention-regulatory-requirements": {
      "content_hash": "sha256:3d0db92b9a3e20776a95f9fff5c7a82bd2d1d7c4d0aefde530918867fdde3571",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRegulatory requirements for data lifecycle management and records management\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nUse the resources on this page to help you meet specific regulatory requirements for data lifecycle management and records management in Microsoft 365. Each section of this document focuses on one or more related regulations and includes any existing guidance or third-party assessment of how to configure Microsoft 365 to help with the requirements outlined.\nThese resources are available to download from the\nData Protection Resources, FAQ, and White Papers\npage of the Service Trust Portal.\nNew Zealand Public Records Act\nSupporting New Zealand's Public Records Act compliance obligations with Microsoft 365\n-\nDownload assessment\nApplicable workloads: SharePoint, OneDrive, Teams, and Exchange\nReleased January 2021, this report has been produced in partnership with Microsoft New Zealand to assess the capabilities of Microsoft 365 services for recording, storing, and managing requirements for electronic records, as specified by:\nNew Zealand Public Records Act 2005, which sets guidelines for preservation of public archives and local authority archives in New Zealand.\nThis report helps you understand how the system aspects of the New Zealand Public Records Act 2005 (PRA) are achievable when using Microsoft 365.\nSEC 17a-4(f), FINRA 4511(c), and CFTC 1.31(c)-(d)\nCohasset Assessment - Microsoft 365 - SEC Rule 17a-4(f) - Immutable Storage for SharePoint, OneDrive, Exchange, Teams, and Viva Engage\n-\nDownload assessment\nApplicable workloads: SharePoint, OneDrive, Teams, Exchange, and Viva Engage\nLatest version released July 2022, this report has been produced in partnership with Cohasset Associates, Inc. (Cohasset) to assess the capabilities of Microsoft 365 services for recording, storing, and managing requirements for electronic records, as specified by:\nSecurities and Exchange Commission (SEC) in 17 CFR Â§ 240.17a-4(f), which regulates exchange members, brokers or dealers.\nFinancial Industry Regulatory Authority (FINRA) Rule 4511(c), which defers to the format and media requirements of SEC Rule 17a-4(f).\nThe principles-based electronic records requirements of the Commodity Futures Trading Commission (CFTC) in 17 CFR Â§ 1.31(c)-(d).\nThe opinion from Cohasset is that when compliance features are properly configured and carefully applied and managed as described in their report, the assessed Microsoft 365 services meet the five requirements related to the recording and non-rewriteable, non-erasable storage of electronic records.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "SEC 17a-4 / Preservation Lock",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/records-management": {
      "content_hash": "sha256:e7a4b7b8541504e8d8f2e7b8e0b8f6d1a5785bbcbe2e003ed14aafb47560adbc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about records management\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\nA records management system, also known as records and information management, is a solution for organizations to manage regulatory, legal, and business-critical records. Records management for Microsoft Purview helps you achieve your organization's legal obligations, provides the ability to demonstrate compliance with regulations, and increases efficiency with regular disposition of items that are no longer required to be retained, no longer of value, or no longer required for business purposes.\nUse the following capabilities to support your records management solution for Microsoft 365 data:\nLabel items as a record\n. Create and configure retention labels to mark items as a\nrecord\nthat can then be applied by users or automatically applied by identifying sensitive information, keywords, or content types.\nMigrate and manage your retention requirements with file plan\n. By using a\nfile plan\n, you can bring in an existing retention plan to Microsoft 365, or build a new one for enhanced management capabilities.\nConfigure retention and deletion settings with retention labels\n. Configure\nretention labels\nwith the retention periods and actions based on various factors that include the date last modified or created.\nStart different retention periods when an event occurs\nwith\nevent-based retention\n.\nReview and validate disposition\nwith\ndisposition reviews\nand proof of\nrecords deletion\n.\nExport information about all disposed items\nwith the\nexport option\n.\nSet specific permissions\nfor records manager functions in your organization to\nhave the right access\n.\nUsing these capabilities, you can incorporate your organization's retention schedules and requirements into a records management solution that manages retention, records declaration, and disposition, to support the full lifecycle of your content.\nIn addition to the online documentation, you might find it useful to download a\ndeck with FAQs\nfrom a records management webinar. The recording of the actual webinar is no longer available.\nRecords\nWhen an item is declared a record by using a retention label:\nRestrictions are placed on the item in terms of what\nactions are allowed or blocked\n.\nAdditional activities about the item are logged.\nYou have proof of disposition when the item is deleted at the end of their retention period.\nYou use\nretention labels\nto mark items as a\nrecord\n, or a\nregulatory record\n. The difference between these two are explained in the next section. You can either publish those labels so that users and administrators can manually apply them to items, or for labels that mark items as a record, you can auto-apply those labels.\nBy using retention labels to declare records, you can implement a single and consistent strategy for managing records across your Microsoft 365 environment.\nCompare restrictions for what actions are allowed or blocked\nUse the following table to identify what restrictions are placed on items as a result of applying a standard retention label, and retention labels that mark items as a record or regulatory record.\nA standard retention label has retention settings and actions but doesn't mark items as a record or a regulatory record.\nNote\nFor completeness, the table includes columns for a locked and unlocked record, which is applicable to SharePoint and OneDrive, but not Exchange. The ability to lock and unlock a record uses\nrecord versioning\nthat isn't supported for Exchange items. So for all Exchange items that are marked as a record, the behavior maps to the\nRecord - locked\ncolumn, and the\nRecord - unlocked column\nis not relevant.\nAction\nRetention label\nRecord - locked\nRecord - unlocked\nRegulatory record\nEdit contents\nAllowed\nBlocked\nAllowed\nBlocked\nEdit properties, including rename\nAllowed\nAllowed\n1\nAllowed\nBlocked\nDelete\nAllowed\n2\nBlocked\nBlocked\nBlocked\nCopy\nAllowed\nAllowed\nAllowed\nAllowed\nMove within container\n3\nAllowed\nAllowed\nAllowed\nAllowed\nMove across containers\n3\nAllowed\nAllowed if never unlocked\nBlocked\nBlocked\nOpen/Read\nAllowed\nAllowed\nAllowed\nAllowed\nChange label\nAllowed\nAllowed - container admin only\nBlocked\nBlocked\nRemove label\n4\nAllowed\nAllowed - container admin only\nBlocked\nBlocked\nOverride with\npriority cleanup\nAllowed\nBlocked\nBlocked\nBlocked\nFootnotes:\n1\nEditing properties for a locked record is allowed by default but can be blocked by a tenant setting in the\nMicrosoft Purview portal\n:\nSign in to the Microsoft Purview portal\n>\nSettings\n>\nSolutions settings\n>\nRecords Management\n>\nRetention Labels\n>\nAllow editing of record properties\n2\nDeleting labeled items in SharePoint and OneDrive can be blocked as a tenant setting in the\nMicrosoft Purview portal\n:\nSign in to the Microsoft Purview portal\n>\nSettings\n>\nSolutions settings\n>\nRecords Management\n>\nRetention Labels\n>\nDeletion of items\n.\nWhen you apply a standard retention label to a list item that has a document attachment, that document doesn't inherit the retention settings and can be deleted from the list item. In comparison, if that retention label marked items as a record or regulatory record, the document attachment would inherit the retention settings and couldn't be deleted.\n3\nContainers include SharePoint sites, OneDrive accounts, and Exchange mailboxes.\n4\nLabels can be removed from items even if the labels are no longer published.\nImportant\nThe most important difference for a regulatory record is that after it is applied to content, nobody, not even a global administrator, can remove the label.\nRetention labels configured for regulatory records also have the following admin restrictions:\nThe retention period can't be made shorter after the label is saved, only extended.\nThese labels aren't supported by auto-labeling policies, and must be applied by using\nretention label policies\n.\nIn addition, a regulatory label can't be applied to a document that's checked out in SharePoint.\nBecause of the restrictions and irreversible actions, make sure you really do need to use regulatory records before you select this option for your retention labels. To help prevent accidental configuration, this option is not available by default but must first be enabled by using PowerShell. Instructions are included in\nDeclare records by using retention labels\n.\nValidating migrated records\nIf you're migrating files to SharePoint or OneDrive and your organization needs to manage these items as records, you might need to validate that the files haven't been altered and retain their immutability status. For example, you're using a migration solution and need to meet the chain of custody requirements. Typical file properties and methods often used for this type of validation, such as file size or file hash, might not be sufficient because SharePoint automatically updates the metadata for a file when it's uploaded.\nInstead, to validate your migrated files, you can use the value of the\nvti_writevalidationtoken\nproperty, which is a base64-encoded XOR hash of the file before it is modified by SharePoint. Use the following steps:\nGenerate the XOR hash of the original file by using the QuickXorHash algorithm. For more information, see the\nQuickXorHash Algorithm code snippet\n.\nBase64-encode the XOR hash. For more information, see the\nBase64Encode method documentation\n.\nAfter the file is migrated, retrieve the value of the\nvti_writevalidationtoken\nproperty from the uploaded file.\nCompare the value generated in step 2 with the value retrieved in step 3. These two values should match. If they do, you've validated that the file hasn't changed.\nConfiguration guidance\nSee\nGet started with records management\n. This article has information about subscriptions, permissions, and links to end-to-end configuration guidance for records management scenarios.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Records Management",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/data-lifecycle-management": {
      "content_hash": "sha256:09074ec74f523b02e829a6fd947b48f68e6d2d7821f6fbef3f7b3edc40a1e6ed",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about data lifecycle management\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nMicrosoft Purview Data Lifecycle Management (formerly Microsoft Information Governance) provides you with tools and capabilities to retain the content that you need to keep, and delete the content that you don't.\nRetaining and deleting content is often needed for compliance and regulatory requirement, but deleting content that no longer has business value also helps you manage risk and liability. For example, it reduces your attack surface.\nMicrosoft 365 features\nRetention policies\nare the cornerstone for data lifecycle management. Use these policies for Microsoft 365 workloads that include Exchange, SharePoint, OneDrive, Teams, and Viva Engage. Configure whether content for these services needs to be retained indefinitely, or for a specific period if users edit or delete it. Or you can configure the policy to automatically permanently delete the content after a specified period if it's not already deleted. You can also combine these two actions for retain and then delete, which is a very typical configuration. For example, retain email for three years and then delete it.\nWhen you configure a retention policy, you can target all instances in your organization (such as all mailboxes and all SharePoint sites), or individual instances (such as only the mailboxes for specific departments or regions, or just selected SharePoint sites).\nIf you need exceptions for individual emails or documents, such as a longer retention period for legal documents, you do this with\nretention labels\nthat you publish to apps so that users can apply them, or automatically apply them by inspecting the content.\nRetention labels are also used with\nAdaptive Protection\n, if you're using\nthis solution with insider risk management\n. In this case, the retention label and auto-apply policy is automatically created for you. For details, see\nDynamically mitigate the risk of accidental or malicious deletes\n.\nUnder the covers, retention labels are also used with\npriority cleanup\nfor scenarios where you need to expedite the permanent deletion of sensitive information from mailboxes, even if they have existing holds for retention or eDiscovery.\nFor more information about retention policies and retention labels, and how retention works in Microsoft 365, see\nLearn about retention policies and retention labels\n.\nNote\nIf you need to manage high-value items for business, legal, or regulatory record-keeping requirements, use retention labels with\nrecords management\nrather than retention labels with data lifecycle management.\nOther data lifecycle management capabilities to help you keep what you need and delete what you don't:\nMailbox archiving\nto provide users with additional mailbox storage space, and auto-expanding archiving for mailboxes that need more than 100 GB storage. A default archiving policy automatically moves email to the archive mailbox, and if required, you can customize this policy. For more information about mailbox archiving, see\nLearn about archive mailboxes\n.\nInactive mailboxes\nthat retain mailbox content after employees leave the organization. For more information about inactive mailboxes, see\nLearn about inactive mailboxes\n.\nImport service for PST files\nby using network upload or drive shipping. For more information, see\nLearn about importing your organization's PST files\n.\nExchange (legacy) features\nRetention policies and retention tags\nfrom messaging records management (MRM), and\njournaling rules\nare older compliance features from Exchange that were originally configurable from the Classic Exchange admin center. They haven't been brought forward to the\nnew Exchange admin center\n.\nIf you're not already using these features, or have a specific business requirement to use them instead of the Microsoft 365 features for data lifecycle management, we don't recommend you use these older compliance features. Instead, use the newer Microsoft 365 features that retain data in place and support policies across other Microsoft 365 services.\nFor more information, see\nUse retention policies and retention labels instead of older features\n.\nDeployment guidance\nFor deployment guidance for data lifecycle management that includes a recommended deployment roadmap, licensing information, permissions, a list of supported scenarios, and end-user documentation, see\nGet started with data lifecycle management\n.\nLooking for deployment guidance to protect your data? See\nDeploy an information protection solution with Microsoft Purview\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data Lifecycle Management",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ediscovery": {
      "content_hash": "sha256:eb9688a892d91d909a9494f8c416b260ba91ef5dcf7345c220318fa21b959dfb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Purview eDiscovery legacy solutions\nFeedback\nSummarize this article for me\nImportant\nThe classic eDiscovery experiences were\nretired on August 31, 2025\n. This retirement includes classic\nContent Search\n, classic\neDiscovery (Standard)\n, and classic\neDiscovery (Premium)\n. These options aren't available as an experience option in the Microsoft Purview portal.\nUnless you're working directly with Microsoft when using these legacy features for specific short-term transition scenarios, use the guidance for the\nnew eDiscovery experience\nin the\nMicrosoft Purview portal\n.\nElectronic discovery, or eDiscovery, is the process of identifying and delivering electronic information that can be used as evidence in legal cases. You can use eDiscovery tools in Microsoft Purview to search for content in Exchange Online, OneDrive for Business, SharePoint Online, Microsoft Teams, Microsoft 365 Groups, and Viva Engage teams. You can search mailboxes and sites in the same eDiscovery search, and then export the search results. You can use Microsoft Purview eDiscovery (Standard) cases to identify, hold, and export content found in mailboxes and sites. If your organization has an Office 365 E5 or Microsoft 365 E5 subscription (or related E5 add-on subscriptions), you can further manage custodians and analyze content by using the feature-rich Microsoft Purview eDiscovery (Premium) solution in Microsoft 365.\neDiscovery solutions\nMicrosoft Purview provides three eDiscovery solutions: Content search, eDiscovery (Standard), and eDiscovery (Premium).\nContent Search\neDiscovery (Standard)\neDiscovery (Premium)\n- Search for content\n- Keyword queries and search conditions\n- Export search results\n- Role-based permissions\n- Search and export\n- Case management\n- Legal hold\n- Custodian management\n- Legal hold notifications\n- Advanced indexing\n- Review set filtering\n- Tagging\n- Analytics\n- Predictive coding models\nAnd more...\nContent search\n. Use the Content search tool to search for content across Microsoft 365 data sources and then export the search results to a local computer.\neDiscovery (Standard)\n. eDiscovery (Standard) builds on the basic search and export functionality of Content search by enabling you to create eDiscovery cases and assign eDiscovery managers to specific cases. eDiscovery managers can only access the cases of which they're members. eDiscovery (Standard) also lets you associate searches and exports with a case and lets you place an eDiscovery hold on content locations relevant to the case.\neDiscovery (Premium)\n. The eDiscovery (Premium) tool builds on the existing case management, preservation, search, and export capabilities in eDiscovery (Standard). eDiscovery (Premium) provides an end-to-end workflow to identify, preserve, collect, review, analyze, and export content that's responsive to your organization's internal and external investigations. It lets legal teams manage custodians and the legal hold notification workflow to communicate with custodians involved in a case. It allows you to collect and copy data from the live service into review sets, when you can filter, search, and tag content to cull non-relevant content from further review so your workflow can identify and focus on content that's most relevant. eDiscovery (Premium) provides analytics and machine learning-based predictive coding models to further narrow to scope of your investigation to the most relevant content.\nComparison of key capabilities\nThe following table compares the key capabilities available in Content search, eDiscovery (Standard), and eDiscovery (Premium).\nCapability\nContent search\neDiscovery (Standard)\neDiscovery (Premium)\nSearch for content\nKeyword queries and search conditions\nSearch statistics\nExport search results\nRole-based permissions\nCase management\nPlace content locations on legal hold\nCustodian management\nLegal hold notifications\nAdvanced indexing\nError remediation\nReview sets\nSupport for cloud attachments and SharePoint versions\nOptical character recognition\nConversation threading\nCollection statistics and reports\nReview set filtering\nTagging\nAnalytics\nPredictive coding models\nComputed document metadata\nTransparency of long-running jobs\nExport to customer-owned Azure Storage location\nHere's a description of each eDiscovery capability.\nSearch for content\n. Search for content that's stored in Exchange mailboxes, OneDrive for Business accounts, SharePoint sites, Microsoft Teams, Microsoft 365 Groups, and Viva Engage Teams. This includes content generated by other Microsoft 365 apps that store data in mailboxes and sites.\nKeyword queries and search conditions\n. Create Keyword Query Language (KeyQL) search queries to search for content keywords that match query criteria. You can also include conditions to narrow the scope of your search.\nSearch statistics\n. After you run a search, you can view statistics of the estimated search results, such as the number and total size of items matching your search criteria. Other statistics include the top content locations that contain search results and the number of items that match different parts of the search query.\nExport search results\n. Export search results to a local computer in your organization in a two-step process. When you export search results, items are copied from their original content location in Microsoft 365 to a Microsoft-provided Azure Storage location. Then you can download those items to a local computer.\nRole-based permissions\n. Use role-based access control (RBAC) permissions to control what eDiscovery-related tasks that different users can perform. You can use a built-in eDiscovery-related role group or create custom role groups that assign specific eDiscovery permissions.\nCase management\n. eDiscovery cases in eDiscovery (Standard) and eDiscovery (Premium) let you associate specific searches and exports with a specific investigation. You can also assign members to a case to control who can access the case and view the contents of the case. eDiscovery (Premium) also supports new case creation integration with\nMicrosoft Purview Insider Risk Management\ncases.\nPlace content locations on legal hold\n. Preserve content relevant to your investigation by placing a legal hold on the content locations in a case. This lets you secure electronically stored information from inadvertent (or intentional) deletion during your investigation.\nCustodian management\n. Manage the people that you've identified as people of interest in the case (called\ncustodians\n) and other data sources that may not be associated with a custodian. When you add custodians and non-custodial data sources to a case, you can place a legal hold on these data sources, communicate with custodians by using the legal hold notification process, and search custodian and non-custodial data sources to collect content relevant to the case.\nLegal hold notifications\n. Manage the process of communicating with case custodians. A legal hold notification instructs custodians to preserve content that's relevant to the case. You can track the notices that were received, read, and acknowledged by custodians. The communications workflow in eDiscovery (Premium) allows you to create and send initial notifications, reminders, and escalations if custodians fail to acknowledge a hold notification.\nAdvanced indexing\n. When you add custodial and non-custodian data sources to a case, the associated content locations are reindexed in a process called\nAdvanced indexing\n. Advanced indexing ensures any content deemed as partially indexed is reprocessed to make it fully searchable when you collect data for an investigation.\nError remediation\n. Fix processing errors using a process called\nerror remediation\n. Error remediation allows you to rectify data issues that prevent eDiscovery (Premium) from properly processing the content during Advanced indexing. For example, files that are password protected can't be processed since the files are locked or encrypted. Using error remediation, you can download files with errors, remove the password protection, and then upload the remediated files.\nReview sets\n. Add relevant data to a review set. A review set is a secure, Microsoft-provided Azure Storage location in the Microsoft cloud. When you add data to a review set, the collected items are copied from their original content location to the review set. Review sets provide a static, known set of content that you can search, filter, tag, analyze, and predict relevancy using predictive coding models. You can also track and report on what content gets added to the review set.\nSupport for cloud attachments and SharePoint versions\n. When you add content to a review set, you have the option to include cloud attachments or linked files. This means that the target file of a cloud attachment or linked file is added to the review set. You also have the option to add all versions of a SharePoint document to a review set.\nOptical character recognition (OCR)\n. When content is added to a review set, OCR functionality extracts text from images, and includes the image text with the content that's added to a review set. This lets you search for image text when you query the content in the review set.\nConversation threading\n. When chat messages from Teams and Viva Engage conversations are added to a review set, you can collect the entire conversation thread. This means that the entire chat conversation that contains items that match the collection criteria is added to the review set. This lets you review chat items in the context of the back-and-forth conversation.\nCollection statistics and reports\n. After you create a collection estimate or commit a collection to a review set, you can view a rich set of statistics on the retrieved items, such as the content locations that contain the most items that matched the search criteria and the number of items returned by the search query. You can also preview a subset of the results.\nReview set filtering\n. After content is added to a review set, you can apply filters to display only the set of items that match your filtering criteria. Then you can save the filter sets as a query, which lets you quickly reapply the saved filters. Review set filtering and saved queries help you quickly select content items that are most relevant to your investigation.\nTagging\n. Tags also help you omit non-relevant content and identify the most relevant content. When experts, attorneys, or other users review content in a review set, their opinions related to the content can be captured by using tags. For example, if the intent is to exclude unnecessary content, a user can tag documents with a tag such as \"non-responsive\". After content has been reviewed and tagged, a review set query can be created to exclude any content tagged as \"non-responsive\". This process eliminates the non-responsive content from subsequent steps in the eDiscovery workflow.\nAnalytics\n. eDiscovery (Premium) provides tools to analyze review set documents to help you organize the documents in a coherent manner and reduce the volume of documents to be reviewed.\nNear duplicate detection\ngroups textually similar documents together to help you make your review process more efficient.\nEmail threading\nidentifies specific email messages that give a complete context of the conversation in an email thread.\nThemes\nfunctionality attempts to analyze themes in review set documents and assign a theme to documents so that you can review documents with related theme. These analytics capabilities help make your review process more efficient so that reviewers can review a fraction of collected documents.\nPredictive coding models\n. Use predictive coding models to reduce large volumes of case content to a relevant set of items that you can prioritize for review. This is accomplished by creating and training your own predictive coding models that help you prioritize the review of the most relevant items in a review set. The system uses the training to apply prediction scores to every item in the review set. This lets you filter items based on the prediction score, which allows you to review the most relevant (or non-relevant) items first.\nComputed document metadata\n. Many of the eDiscovery (Premium) features, such as Advanced indexing, conversation threading, analytics, and predictive coding add metadata properties to review set documents. This metadata contains information related to the function performed by a specific feature. When reviewing documents, you can filter on metadata properties to display documents that match your filter criteria. This metadata can be imported into third-party review applications after review set documents are exported.\nTransparency of long-running jobs\n. Jobs in eDiscovery (Premium) are typically long-running processes that are triggered by user actions, such as the adding custodians to a case, adding content to a review set, running analytics, and training predictive coding models. You can track the status of these jobs and get support information if you need to escalate issues to Microsoft Support.\nExport to customer-owned Azure Storage location\n. When you export documents from a review set, you have the option to export them to an Azure Storage account managed by your organization. Additionally, eDiscovery (Premium) lets you customize what data is exported. This includes exporting file metadata, native files, text files, tags, and redacted documents saved to a PDF file.\neDiscovery subscription comparison\nBefore you get started, review the\nsubscription requirements\nfor Content search, eDiscovery (Standard), and eDiscovery (Premium). Generally, subscriptions that support eDiscovery (Standard) also support Content search and subscriptions that support eDiscovery (Premium) also support Content search and eDiscovery (Standard).\nGet started with eDiscovery\nSee the following articles to help you learn more and get started using Microsoft Purview eDiscovery solutions.\nGet started with eDiscovery (Premium)\nOverview of eDiscovery (Premium)\nGet started with eDiscovery (Premium)\nCreate and manage an eDiscovery (Premium) case\nIntegration with Insider Risk Management\nCases in\nMicrosoft Purview Insider Risk Management\ncan be quickly escalated to new cases in Microsoft Purview eDiscovery (Premium) when additional legal review is needed for potentially risky user activity. The tight integration between these solutions can help your risk and legal teams work more efficiently and can help provide a complete end-to-end view of user activities under review. Check out how to\nget started with Insider Risk Management\nand how to easily\nescalate an Insider Risk Management case\nto an eDiscovery (Premium) case.\neDiscovery roadmap\nTo see what eDiscovery features have been launched, are rolling out, or in development, see the\nMicrosoft 365 Roadmap\n.\nTraining\nTraining your IT administrators, eDiscovery managers, and compliance investigation teams in the basics for Content search, eDiscovery (Standard), and eDiscovery (Premium) can help your organization get started more quickly using Microsoft Purview eDiscovery tools. To help these users in your organization getting started with eDiscovery, see\nDescribe the eDiscovery and audit capabilities of Microsoft Purview\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "eDiscovery",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ediscovery-create-and-manage-cases": {
      "content_hash": "sha256:a9c6d3c6a4788bed1bb8cdbc5b2d63c71f9873232ffe5441415c334530869354",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and manage an eDiscovery (Premium) case\nFeedback\nSummarize this article for me\nImportant\nThe classic eDiscovery experiences were\nretired on August 31, 2025\n. This retirement includes classic\nContent Search\n, classic\neDiscovery (Standard)\n, and classic\neDiscovery (Premium)\n. These options aren't available as an experience option in the Microsoft Purview portal.\nUnless you're working directly with Microsoft when using these legacy features for specific short-term transition scenarios, use the guidance for the\nnew eDiscovery experience\nin the\nMicrosoft Purview portal\n.\nAfter setting up Microsoft Purview eDiscovery (Premium) and\nassigning permissions to eDiscovery managers\nin your organization that will manage cases, the next step is to create and manage a case.\nThis article also provides a high-level overview of using cases to manage the eDiscovery (Premium) workflow for a legal case or other types of investigations.\nCreate a case\nComplete the following steps to create a case and configure case settings. The user who creates the case is automatically added as a member. Members of the case can access the case in the Microsoft Purview portal and perform eDiscovery (Premium) tasks.\nGo to the\nMicrosoft Purview portal\nand sign in using the credentials for user account that has been assigned eDiscovery permissions. Members of the\nOrganization Management\nrole group can also create eDiscovery (Premium) cases.\nIn the left navigation pane of the Microsoft Purview portal, select\nShow all\n, and then select\neDiscovery\n>\nPremium\n, and then select the\nCases\ntab.\nSelect\nCreate a case\n.\nOn the\nName and description\npage, complete the following fields:\nName\n: give the case a name (required). The case name must be unique in your organization\nDescription\n: Add an optional description to help others understand this case.\nNumber\n: Enter an optional docket number or other numeric identifier.\nCase format\n: The\nNew (recommended)\noption is automatically selected.\nNote\nThe legacy\nClassic\nformat is no longer available when creating new cases. This format is now retired for all new cases.\nSelect\nNext\n.\nOn the\nMembers and settings\npage, complete the following fields as applicable:\nTeam members\n: Select users and groups that should be assigned to the case. Make sure that users and groups assigned here have been\nassigned the appropriate eDiscovery permissions\n.\nSearch and analytics\n: Select the options to configure the case. You can skip this section and configure these settings after the case is created if needed.\nText to ignore\n: Add text or regex expressions to define text to ignore in the case. You can apply this to\nNear-duplicates\n,\nEmail threads\n, or\nThemes\nmodules.\nOptical character recognition (OCR)\n: Configure the option and settings for finding text contained in images during advanced indexing.\nSelect\nNext\n.\nOn the\nSummary\npage, review the settings for the case and edit the settings if needed. Select\nSubmit\nto create the new case and start your investigation.\nMark a case as a favorite\nYou can mark an eDiscovery (Premium) case as a favorite for quicker access to cases you want to prioritize. Cases marked as favorites can be accessed quickly via the eDiscovery (Premium)\nOverview\npage or can be sorted to be shown at the top of the\nCases\ntab for ease of access. You can mark a case as a favorite in the case list on the\nCases\ntab or on the top right of the case\nOverview\ntab for each case. The\nRecent favorite cases\ncard on the\nOverview\ntab displays all the cases marked as favorites in your organization.\nManage the workflow\nTo get you started using eDiscovery (Premium), here's a basic workflow that aligns with\ncommon eDiscovery practices\n. In each of these steps, we'll also highlight some extended eDiscovery (Premium) functionality that you can explore. ediscovery-overview\nAdd custodians\nand\nnon-custodial data sources\nto the case\n. The first step after creating a case is to add custodians. A\ncustodian\nis a person having administrative control of a document or electronic file that may be relevant to the case. Additionally, you can add data sources that aren't associated with a specific user but may be relevant to the case. These are\nnon-custodial data sources\n.\nHere are some things that happen (or that you can do) when you add custodians to a case:\nData in the custodian's Exchange mailbox, OneDrive account, and any Microsoft Teams or Viva Engage groups that the custodian is a member of can be \"marked\" as custodial data in the case.\nCustodian (and non-custodial) data is reindexed (by a process called\nAdvanced indexing\n). This helps optimize searching for it in the next step.\nYou can place a hold on custodian and non-custodial data. This hold preserves data that may be relevant to the case during the investigation. To learn more about managing holds, see\nManage holds in eDiscovery (Premium)\n.\nYou can associate other data sources with a custodian (for example, you can associate a SharePoint site or Microsoft 365 Group with a custodian) so this data can be reindexed, placed on hold, and searched, just like the data in the custodian's mailbox or OneDrive account.\nYou can use the\ncommunications workflow\nin eDiscovery (Premium) to send a legal hold notification to custodians.\nCollect relevant content from data sources\n. After you add custodians and non-custodial data sources to a case, use the built-in collections tool to search these data sources for content that may be relevant to the case. You use keywords, properties, and conditions to\nbuild search queries\nthat return search results with the data that's most likely relevant to the case. You can also:\nView\ncollection statistics\nthat may help you refine a collection to narrow the results.\nPreview a sample of the collection to quickly verify whether the relevant data is being found.\nRevise a query and rerun the collection.\nCommit collection to a review set\n. Once you've configured and verified that a search returns the desired data, the next step is to add the search results to a review set. When you add data to a review set, items are copied from their original location to a secure Azure Storage location. The data is reindexed again to optimize it for thorough and fast searches when reviewing and analyzing items in the review set. Additionally, you can also\nadd non-Office 365 data into a review set\n.\nThere's also a special kind of review set that you can add data to, called a\nconversation review set\n. These types of reviews sets provide conversation reconstruction capabilities to reconstruct, review, and export threaded conversations like those in Microsoft Teams. For more information, see\nReview conversations in eDiscovery (Premium)\n.\nReview and analyze data in a review set\n. Now that data is in a review set, you can use a wide-variety of tools and capabilities to view and analyze the case data with the goal of reducing the data set to what is most relevant to the case you're investigating. Here's a list of some tools and capabilities that you can use during this process.\nGroup and view documents\n. This includes selecting the group options for review sets in your cases, viewing the metadata for each document in a review set, and viewing the document in its native version or text version.\nCreate queries and filters\n. You create search queries using various search criteria (including the ability to search all\nfile metadata properties\nto further refine and cull the case data to what is most relevant to the case. You can also use review set filters to quickly apply other conditions to the results of a search query to further refine those results.\nCreate and use tags\n. You can apply tags to documents in a review set to identify which are responsive (or non-responsive to the case) and then use those tags when creating search queries to include or exclude the tagged documents. You can also tagging to determine which documents to export.\nAnnotate and redact documents\n. You can use the annotation tool in a review to annotate documents and redact content in documents as work product. We generate a PDF version of an annotated or redacted document during review to reduce the risk of exporting the unredacted native version of the document.\nAnalyze case data\n. The analytics functionality in eDiscovery (Premium) is powerful. After you run analytics on the data in review set, we perform analysis such as near duplicate detection, email threading, and themes that can help reduce the volume of documents that you have to review. We also generate an Analytics reports that summarize the result of running analytics. As previously explained, running analytics also runs\nthe attorney-client privilege detection model\n.\nExport and download case data\n. A final step after collecting, reviewing, and analyzing case data is to export it out of eDiscovery (Premium) for external review or for review by people outside of the investigation team. Exporting data is a two-step process. The first step is to\nexport\ndata out of the review set and copy it to a different Azure Storage location (one provided by Microsoft or one managed by your organization). Then you use Azure Storage Explorer to\ndownload\nthe data to a local computer. In addition to the exported data files, the contains of the export package also contains an export report, a summary report, and an error report.\neDiscovery (Premium) architecture\nHere's an architecture diagram that shows the eDiscovery (Premium) end-to-end workflow in a single-geo environment and in a multi-geo environment, and the end-to-end data flow that's aligned with the\nElectronic Discovery Reference Model\n.\nView as an image\nDownload as a PDF file\nDownload as a Visio file\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create Cases",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ediscovery-keyword-queries-and-search-conditions": {
      "content_hash": "sha256:1cd707bbbfee60b6223a9264261b5c6a26dccad918d9a6a9cca28c69e1991284",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nKeyword queries and search conditions for eDiscovery\nFeedback\nSummarize this article for me\nImportant\nThe classic eDiscovery experiences were\nretired on August 31, 2025\n. This retirement includes classic\nContent Search\n, classic\neDiscovery (Standard)\n, and classic\neDiscovery (Premium)\n. These options aren't available as an experience option in the Microsoft Purview portal.\nUnless you're working directly with Microsoft when using these legacy features for specific short-term transition scenarios, use the guidance for the\nnew eDiscovery experience\nin the\nMicrosoft Purview portal\n.\nThis article describes the properties available to help find content across email and chat in Exchange Online and documents and files stored on SharePoint and OneDrive using the eDiscovery search tools in the Microsoft Purview portal.\nThis includes Content search, Microsoft Purview eDiscovery (Standard), and Microsoft Purview eDiscovery (Premium) (eDiscovery searches in eDiscovery (Premium) are called\ncollections\n). You can also use the\n*-ComplianceSearch\ncmdlets in\nSecurity & Compliance PowerShell\nto search for these properties.\nThis article also describes:\nUsing Boolean search operators, search conditions, and other search query techniques to refine your search results.\nSearching for communications of various types related to specific users and projects during a specific time frame.\nSearching for site content that is related to a specific project, users and/or subjects during a specific time period.\nFor step-by-step instructions on how to create different eDiscovery searches, see:\nContent search\nSearch for content in eDiscovery (Standard)\nCreate a collection estimate in eDiscovery (Premium)\nNote\neDiscovery searches in the Microsoft Purview portal and the corresponding\n*-ComplianceSearch\ncmdlets in Security & Compliance PowerShell use the Keyword Query Language (KeyQL). For more detailed information, see\nKeyword Query Language syntax reference\n.\nSearch tips and tricks\nThe time zone for all searches is Coordinated Universal Time (UTC). Changing time zones for your organization isn't currently supported. Time zone display settings in the search view are only for applicable for values in\nData\ncolumn and don't affect time stamps on collected items.\nKeyword searches aren't case-sensitive. For example,\ncat\nand\nCAT\nreturn the same results.\nThe Boolean operators\nAND\n,\nOR\n,\nNOT\n, and\nNEAR\nmust be uppercase.\nUsing quotes stops wild cards and any operations inside the quotes.\nA space between two keywords or two\nproperty:value\nexpressions is the same as using\nOR\n. For example,\nfrom:\"Sara Davis\" subject:reorganization\nreturns all messages sent by Sara Davis or messages that contain the word reorganization in the subject line. However, using a mix of spaces and\nOR\nconditionals in a single query might lead to unexpected results. We recommend using either spaces or\nOR\nin a single query.\nUse syntax that matches the\nproperty:value\nformat. Values aren't case-sensitive, and they can't have a space after the operator. If there's a space, your intended value is a full-text search. For example\nto: pilarp\nsearches for \"pilarp\" as a keyword, rather than for messages sent to pilarp.\nWhen searching a recipient property, such as To, From, Cc, or Recipients, you can use an SMTP address, alias, or display name to denote a recipient. For example, you can use pilarp@contoso.com, pilarp, or \"Pilar Pinilla.\"\nYou can use only prefix searches; for example,\ncat*\nor\nset*\n. Suffix searches (\n*cat\n), infix searches (\nc*t\n), and substring searches (\n*cat*\n) aren't supported.\nWhen searching a property, use double quotation marks (\" \") if the search value consists of multiple words or special characters. For example,\nsubject:budget Q1\nreturns messages that contain\nbudget\nin the subject line and that contain\nQ1\nanywhere in the message or in any of the message properties. Using\nsubject:\"budget Q1\"\nreturns all messages that contain\nbudget Q1\nanywhere in the subject line.\nTo exclude content marked with a certain property value from your search results, place a minus sign (-) before the name of the property. For example,\n-from:\"Sara Davis\"\nexcludes any messages sent by Sara Davis.\nYou can export items based on message type. For example, to export Skype conversations and chats in Microsoft Teams, use the syntax\nkind:im\n. To return only email messages, you would use\nkind:email\n. To return chats, meetings, and calls in Microsoft Teams, use\nkind:microsoftteams\n.\nWhen searching sites, you have to add the trailing\n/\nto the end of the URL when using the\npath\nproperty to return only items in a specified site. If you don't include the trailing\n/\n, items from a site with a similar path name are also returned. For example, if you use\npath:sites/HelloWorld\nthen items from sites named\nsites/HelloWorld_East\nor\nsites/HelloWorld_West\nwould also be returned. To return items only from the HelloWorld site, you have to use\npath:sites/HelloWorld/\n.\nThe\nQuery language-country/region\nmust be defined in your search query prior to collecting content.\nWhen searching the\nSent\nfolders for emails, using the SMTP address for the sender isn't supported. Items in the\nSent\nfolder contain only display names.\nFinding content in Exchange Online\nAdmins are often charged with finding out who knew what when in the most efficient and effective way possible to respond to requests concerning ongoing or potential litigation, internal investigations, and other scenarios. These requests are often urgent, involve multiple stakeholder teams, and have significant impact if not completed in a timely manner. Knowing how to find the right information is critical for admins to complete searches successfully and help their organizations to manage the risk and cost associated with eDiscovery requirements.\nWhen an eDiscovery request is submitted, often there's only partial information available for the admin to start to collect content that might be related to a particular investigation. The request might include employee names, project titles, rough date ranges when the project was active, and not much more. From this information, the admin needs to create queries to find relevant content across Microsoft 365 services to determine the information needed for a particular project or subject. Understanding how information is stored and managed for these services help admins more efficiently find what they need quickly and in an effective manner.\nEmail, chat, meeting, and Microsoft 365 Copilot and Microsoft 365 Copilot Chat activity data (user prompts and Copilot responses) are all stored in Exchange Online. Many communication properties are available for searching items included in Exchange Online. Some properties such as\nFrom\n,\nSent\n,\nSubject\n, and\nTo\nare unique to certain items and aren't relevant when searching for files or documents in SharePoint and OneDrive for Business. Including these types of properties when searching across workloads can sometimes lead to unexpected results.\nFor example, to find content related to specific employees (\nUser 1\nand\nUser 2\n), associated with a project called\nTradewinds\n, and during January 2020 through January 2022, you might use a query with the following properties:\nAdd User 1 and User 2's Exchange Online locations as data sources to the case\nSelect User 1 and User 2's Exchange Online locations as collection locations\nFor\nKeyword\n, use\nTradewinds\nFor\nDate Range\n, use the\nJanuary 1, 2020\nto\nJanuary 31, 2022\nrange\nImportant\nFor emails, when a keyword is used, we search subject, body, and many properties related to the participants. However, due to recipient expansion, search might not return expected results when using the alias or part of the alias. Therefore we recommend using the full UPN.\nSearchable email properties\nThe following table lists the email message properties that can be searched by using the eDiscovery search tools in the Microsoft Purview portal or by using the\nNew-ComplianceSearch\nor the\nSet-ComplianceSearch\ncmdlet.\nImportant\nWhile email messages might have other properties supported in other Microsoft 365 services, only the email properties listed in this table are supported in eDiscovery search tools. Attempting to include other email messages properties in searches isn't supported.\nThe table includes an example of the\nproperty:value\nsyntax for each property and a description of the search results returned by the examples. You can enter these\nproperty:value\npairs in the keywords box for an eDiscovery search.\nNote\nWhen searching email properties, it's not possible to search for message headers. Header information isn't indexed for collections. Additionally, items in which the specified property is empty or blank aren't searchable. For example, using the\nproperty:value\npair of\nsubject:\"\"\nto search for email messages with an empty subject line return zero results. This also applies when searching site and contact properties.\nProperty\nProperty description\nExamples\nSearch results returned by the examples\nAttachmentNames\nThe names of files attached to an email message.\nattachmentnames:annualreport.ppt\nattachmentnames:annual*\nMessages that have an attached file named\nannualreport.ppt\n. In the second example, using the wildcard character ( * ) returns messages with the word\nannual\nin the file name of an attachment.\n1\nBcc\nThe Bcc field of an email message.\n1\nbcc:pilarp@contoso.com\nbcc:pilarp\nbcc:\"Pilar Pinilla\"\nAll examples return messages with\nPilar Pinilla\nincluded in the Bcc field.\n(\nSee Recipient Expansion\n)\nCategory\nThe categories to search. Categories can be defined by users by using Outlook or Outlook on the web (formerly known as Outlook Web App). The possible values are:\nblue\ngreen\norange\npurple\nred\nyellow\ncategory:\"Red Category\"\nMessages that have been assigned the\nred\ncategory in the source mailboxes.\nCc\nThe Cc field of an email message.\n1\ncc:pilarp@contoso.com\ncc:\"Pilar Pinilla\"\nIn both examples, messages with\nPilar Pinilla\nspecified in the Cc field.\n(\nSee Recipient Expansion\n)\nFolderid\nThe folder ID (GUID) of a specific mailbox folder in 48-character format. If you use this property, be sure to search the mailbox that the specified folder is located in. Only the specified folder is searched. Any subfolders in the folder won't be searched. To search subfolders, you need to use the\nFolderid\nproperty for the subfolder you want to search.\nfolderid:4D6DD7F943C29041A65787E30F02AD1F00000000013A0000\nfolderid:2370FB455F82FC44BE31397F47B632A70000000001160000 AND participants:garthf@contoso.com\nThe first example returns all items in the specified mailbox folder. The second example returns all items in the specified mailbox folder that were sent or received by\ngarthf@contoso.com\n.\nFrom\nThe sender of an email message.\n1\nfrom:pilarp@contoso.com\nMessages sent by the specified user.\n(\nSee Recipient Expansion\n)\nHasAttachment\nIndicates whether a message has an attachment. Use the values\ntrue\nor\nfalse\n.\nfrom:pilar@contoso.com AND hasattachment:true\nMessages sent by the specified user that have attachments.\nImportance\nThe importance of an email message, which a sender can specify when sending a message. By default, messages are sent with normal importance, unless the sender sets the importance as\nhigh\nor\nlow\n.\nimportance:high\nimportance:medium\nimportance:low\nMessages that are marked as high importance, medium importance, or low importance.\nIsRead\nIndicates whether messages have been read. Use the values\ntrue\nor\nfalse\n.\nisread:true\nisread:false\nThe first example returns messages with the IsRead property set to\nTrue\n. The second example returns messages with the IsRead property set to\nFalse\n.\nItemClass\nUse this property to search specific third-party data types that your organization imported to Office 365. Use the following syntax for this property:\nitemclass:ipm.externaldata.<third-party data type>*\nitemclass:ipm.externaldata.Facebook* AND subject:contoso\nitemclass:ipm.externaldata.Twitter* AND from:\"Ann Beebe\" AND \"Northwind Traders\"\nThe first example returns Facebook items that contain the word \"contoso\" in the Subject property. The second example returns Twitter items that were posted by Ann Beebe and that contain the keyword phrase \"Northwind Traders\".\nFor a complete list of values to use for third-party data types for the ItemClass property, see\nUse Content search to search third-party data that was imported to Office 365\n.\nKind\nThe type of email message to search for. Possible values:\ncontacts\ndocs\nemail\nexternaldata\nfaxes\nim\njournals\nmeetings\nmicrosoftteams (returns items from chats, meetings, and calls in Microsoft Teams)\nnotes\nposts\nrssfeeds\ntasks\nvoicemail\nkind:email\nkind:email OR kind:im OR kind:voicemail\nkind:externaldata\nThe first example returns email messages that meet the search criteria. The second example returns email messages, instant messaging conversations (including Skype for Business conversations and chats in Microsoft Teams), and voice messages that meet the search criteria. The third example returns items that were imported to mailboxes in Microsoft 365 from third-party data sources, such as Twitter, Facebook, and Cisco Jabber that meet the search criteria. For more information, see\nArchiving third-party data in Office 365\n.\nParticipants\nAll the people fields in an email message. These fields are From, To, Cc, and Bcc.\n1\nparticipants:garthf@contoso.com\nparticipants:contoso.com\nMessages sent by or sent to garthf@contoso.com. The second example returns all messages sent by or sent to a user in the contoso.com domain.\n(\nSee Recipient Expansion\n)\nReceived\nThe date that an email message was received by a recipient.\nreceived:2021-04-15\nreceived>=2021-01-01 AND received<=2021-03-31\nMessages that were received on April 15, 2021. The second example returns all messages received between January 1, 2021 and March 31, 2021.\nRecipients\nAll recipient fields in an email message. These fields are To, Cc, and Bcc.\n1\nrecipients:garthf@contoso.com\nrecipients:contoso.com\nMessages sent to garthf@contoso.com. The second example returns messages sent to any recipient in the contoso.com domain.\n(\nSee Recipient Expansion\n)\nSent\nThe date that an email message was sent by the sender.\nsent:2021-07-01\nsent>=2021-06-01 AND sent<=2021-07-01\nMessages that were sent on the specified date or sent within the specified date range.\nSize\nThe size of an item, in bytes.\nsize>26214400\nsize:1..1048567\nMessages larger than 25 MB. The second example returns messages from 1 through 1,048,567 bytes (1 MB) in size.\nSubject\nThe text in the subject line of an email message.\nNote:\nWhen you use the Subject property in a query, the search returns all messages in which the subject line contains the text you're searching for. In other words, the query doesn't return only those messages that have an exact match. For example, if you search for\nsubject:\"Quarterly Financials\"\n, your results include messages with the subject \"Quarterly Financials 2018\".\nsubject:\"Quarterly Financials\"\nsubject:northwind\nMessages that contain the phrase \"Quarterly Financials\" anywhere in the text of the subject line. The second example returns all messages that contain the word northwind in the subject line.\nTo\nThe To field of an email message.\n1\nto:annb@contoso.com\nto:annb\nto:\"Ann Beebe\"\nAll examples return messages where Ann Beebe is specified in the To: line.\nNote\n1\nFor the value of a recipient property, you can use email address (also called\nuser principal name\nor UPN), display name, or alias to specify a user. For example, you can use annb@contoso.com, annb, or \"Ann Beebe\" to specify the user Ann Beebe.\nRecipient expansion\nTip\nUse the new\neDiscovery\nexperience and condition builder to use common mailbox and site\nproperties\nlike\nMessageIDs\nand\nChatThreadIds\nwhen searching for specific recipients or messages.\nWhen searching any of the recipient properties (From, To, Cc, Bcc, Participants, and Recipients), Microsoft 365 attempts to expand the identity of each user by looking them up in Microsoft Entra ID. If the user is found in Microsoft Entra ID, the query is expanded to include the user's email address (or UPN), alias, display name, and LegacyExchangeDN. For example, a query such as\nparticipants:ronnie@contoso.com\nexpands to\nparticipants:ronnie@contoso.com OR participants:ronnie OR participants:\"Ronald Nelson\" OR participants:\"<LegacyExchangeDN>\"\n.\nTo prevent recipient expansion, add a wild card character (asterisk) to the end of the email address and use a reduced domain name; for example,\nparticipants:\"ronnie@contoso*\"\nBe sure to surround the email address with double quotation marks.\nHowever, be aware that preventing recipient expansion in the search query might result in relevant items not being returned in the search results. Email messages in Exchange can be saved with different text formats in the recipient fields. Recipient expansion is intended to help mitigate this fact by returning messages that might contain different text formats. So preventing recipient expansion might result in the search query not returning all items that might be relevant to your investigation.\nNote\nIf you need to review or reduce the items returned by a search query due to recipient expansion, consider using eDiscovery (Premium). You can search for messages (taking advantage of recipient expansion), add them to a review set, and then use review set queries or filters to review or narrow the results. For more information, see\nCollect data for a case\nand\nQuery the data in a review set\n.\nFinding content in SharePoint and OneDrive\nTip\nUse the new\neDiscovery\nexperience and search\nexport options\nto download all list attachments for SharePoint sites.\nWhen searching for documents and files located in SharePoint or OneDrive for Business, it might make sense to adjust the query approach based on the metadata for the documents and files of interest. Files and documents have relevant properties like\nAuthor\n,\nCreated\n,\nCreatedBy\n,\nFileName\n,\nLastModifiedTime\n, and\nTitle\n. Most of these proprieties aren't relevant when searching for communications content in Exchange Online, and using these properties might lead to unexpected results if used across both documents and communications. Additionally,\nFileName\nand\nTitle\nof a document might not be the same and using one or the other to try to find a file with specific content might lead to different or inaccurate results. Keep these properties in mind when searching for specific document and file content in SharePoint and OneDrive for Business.\nFor example, to find content related to documents created by User 1, for a project called\nTradewinds\n, for specific files named\nFinancials\n, and from January 2020 to January 2022, you might use a query with the following properties:\nAdd User 1's OneDrive for Business site as a data sources to the case\nSelect User 1's OneDrive for Business site as a collection location\nAdd additional SharePoint site locations related to the project as collection locations\nFor\nFileName\n, use\nFinancials\nFor\nKeyword\n, use\nTradewinds\nFor\nDate Range\n, use the\nJanuary 1, 2020\nto\nJanuary 31, 2022\nrange\nSearchable site properties\nThe following table lists the SharePoint and OneDrive for Business properties that can be searched by using the eDiscovery search tools in the Microsoft Purview portal or by using the\nNew-ComplianceSearch\nor the\nSet-ComplianceSearch\ncmdlet.\nImportant\nWhile documents and files stored on SharePoint and OneDrive for Business might have other properties supported in other Microsoft 365 services, only the document and file properties listed in this table are supported in eDiscovery search tools. Attempting to include other document or file properties in searches isn't supported.\nThe table includes an example of the\nproperty:value\nsyntax for each property and a description of the search results returned by the examples.\nProperty\nProperty description\nExample\nSearch results returned by the examples\nAuthor\nThe author field from Office documents, which persists if a document is copied. For example, if a user creates a document and the emails it to someone else who then uploads it to SharePoint, the document will still retain the original author. Be sure to use the user's display name for this property.\nauthor:\"Garth Fort\"\nAll documents that are authored by Garth Fort.\nContentType\nThe SharePoint content type of an item, such as Item, Document, or Video.\ncontenttype:document\nAll documents would be returned.\nCreated\nThe date that an item is created.\ncreated>=2021-06-01\nAll items created on or after June 1, 2021.\nCreatedBy\nThe person that created or uploaded an item. Be sure to use the user's display name for this property.\ncreatedby:\"Garth Fort\"\nAll items created or uploaded by Garth Fort.\nDetectedLanguage\nThe language of an item.\ndetectedlanguage:english\nAll items in English.\nDocumentLink\nThe path (URL) of a specific folder on a SharePoint or OneDrive for Business site. If you use this property, be sure to search the site that the specified folder is located in. We recommend using this property instead of the\nSite\nand\nPath\nproperties.\nTo return items located in subfolders of the folder that you specify for the documentlink property, you have to add /* to the URL of the specified folder; for example,\ndocumentlink: \"https://contoso.sharepoint.com/Shared Documents/*\"\ndocumentlink:\"https://contoso-my.sharepoint.com/personal/garthf_contoso_com/Documents/Private\"\ndocumentlink:\"https://contoso-my.sharepoint.com/personal/garthf_contoso_com/Documents/Shared with Everyone/*\" AND filename:confidential\nThe first example returns all items in the specified OneDrive for Business folder. The second example returns documents in the specified site folder (and all subfolders) that contain the word \"confidential\" in the file name.\nFileExtension\nThe extension of a file; for example, docx, one, pptx, or xlsx.\nfileextension:xlsx\nAll Excel files (Excel 2007 and later)\nFileName\nThe name of a file.\nfilename:\"marketing plan\"\nfilename:estimate\nThe first example returns files with the exact phrase \"marketing plan\" in the title. The second example returns files with the word \"estimate\" in the file name.\nLastModifiedTime\nThe date that an item was last changed.\nlastmodifiedtime>=2021-05-01\nlastmodifiedtime>=2021-05-01 AND lastmodifiedtime<=2021-06-01\nThe first example returns items that were changed on or after May 1, 2021. The second example returns items changed between May 1, 2021 and June 1, 2021.\nModifiedBy\nThe person who last changed an item. Be sure to use the user's display name for this property.\nmodifiedby:\"Garth Fort\"\nAll items that were last changed by Garth Fort.\nSharedWithUsersOWSUser\nDocuments that have been shared with the specified user and displayed on the\nShared with me\npage in the user's OneDrive for Business site. These are documents that have been explicitly shared with the specified user by other people in your organization. When you export documents that match a search query that uses the SharedWithUsersOWSUser property, the documents are exported from the original content location of the person who shared the document with the specified user. For more information, see\nSearching for site content shared within your organization\n.\nsharedwithusersowsuser:garthf\nsharedwithusersowsuser:\"garthf@contoso.com\"\nBoth examples return all internal documents that have been explicitly shared with Garth Fort and that appear on the\nShared with me\npage in Garth Fort's OneDrive for Business account.\nSize\nThe size of an item, in bytes.\nsize>=1\nsize:1..10000\nThe first example returns items larger than 1 byte. The second example returns items from 1 through 10,000 bytes in size.\nTitle\nThe title of the document. The Title property is metadata that's specified in Microsoft Office documents. It's different from the file name of the document.\ntitle:\"communication plan\"\nAny document that contains the phrase \"communication plan\" in the Title metadata property of an Office document.\nSearchable contact properties\nThe following table lists the contact properties that are indexed and that you can search for using eDiscovery search tools. These are the properties that are available for users to configure for the contacts (also called personal contacts) that are located in the personal address book of a user's mailbox. To search for contacts, you can select the mailboxes to search and then use one or more contact properties in the keyword query.\nTip\nTo search for values that contain spaces or special characters, use double quotation marks (\" \") to contain the phrase; for example,\nbusinessaddress:\"123 Main Street\"\n.\nProperty\nProperty description\nBusinessAddress\nThe address in the\nBusiness Address\nproperty. The property is also called the\nWork\naddress on the contact properties page.\nBusinessPhone\nThe phone number in any of the\nBusiness Phone\nnumber properties.\nCompanyName\nThe name in the\nCompany\nproperty.\nDepartment\nThe name in the\nDepartment\nproperty.\nDisplayName\nThe display name of the contact. This is the name in the\nFull Name\nproperty of the contact.\nEmailAddress\nThe address for any email address property for the contact. Users can add multiple email addresses for a contact. Using this property would return contacts that match any of the contact's email addresses.\nFileAs\nThe\nFile as\nproperty. This property is used to specify how the contact is listed in the user's contact list. For example, a contact could be listed as\nFirstName,LastName\nor\nLastName,FirstName\n.\nGivenName\nThe name in the\nFirst Name\nproperty.\nHomeAddress\nThe address in any of the\nHome\naddress properties.\nHomePhone\nThe phone number in any of the\nHome\nphone number properties.\nIMAddress\nThe IM address property, which is typically an email address used for instant messaging.\nMiddleName\nThe name in the\nMiddle\nname property.\nMobilePhone\nThe phone number in the\nMobile\nphone number property.\nNickname\nThe name in the\nNickname\nproperty.\nOfficeLocation\nThe value in\nOffice\nor\nOffice location\nproperty.\nOtherAddress\nThe value for the\nOther\naddress property.\nSurname\nThe name in the\nLast\nname property.\nTitle\nThe title in the\nJob title\nproperty.\nSearch operators\nBoolean search operators, such as\nAND\n,\nOR\n, and\nNOT\n, help you define more-precise searches by including or excluding specific words in the search query. Other techniques, such as using property operators (such as\n>=\nor\n..\n), quotation marks, parentheses, and wildcards, help you refine a search query. The following table lists the operators that you can use to narrow or broaden search results.\nOperator\nUsage\nDescription\nAND\nkeyword1 AND keyword2\nReturns items that include all of the specified keywords or\nproperty:value\nexpressions. For example,\nfrom:\"Ann Beebe\" AND subject:northwind\nwould return all messages sent by Ann Beebe that contained the word northwind in the subject line.\n2\n+\nkeyword1 + keyword2 + keyword3\nReturns items that contain\neither\nkeyword2\nor\nkeyword3\nand\nthat also contain\nkeyword1\n. Therefore, this example is equivalent to the query\n(keyword2 OR keyword3) AND keyword1\n.\nThe query\nkeyword1 + keyword2\n(with a space after the\n+\nsymbol) isn't the same as using the\nAND\noperator. This query would be equivalent to\n\"keyword1 + keyword2\"\nand return items with the exact phase\n\"keyword1 + keyword2\"\n.\nOR\nkeyword1 OR keyword2\nReturns items that include one or more of the specified keywords or\nproperty:value\nexpressions.\n2\nNOT\nkeyword1 NOT keyword2\nNOT from:\"Ann Beebe\"\nNOT kind:im\nExcludes items specified by a keyword or a\nproperty:value\nexpression. In the second example excludes messages sent by Ann Beebe. The third example excludes any instant messaging conversations, such as Skype for Business conversations that are saved to the Conversation History mailbox folder.\n2\nNEAR\nkeyword1 NEAR(n) keyword2\nReturns items with words that are near each other. In the\nkeyword1 NEAR(n) keyword2\nsyntax,\nn\nequals the number of words exclusive of\nkeyword1\nand\nkeyword2\n. For example, to identify instances where the term\nbest\nis within 3 words of\nworst\n(example sentence, 'Best is opposite of worst.'), you would use\nbest NEAR(3) worst\n. This returns any items where there are 3 or fewer words between\nbest\n(keyword1) and\nworst\n(keyword2). If no number is specified, the default\nn\nvalue is 8.\n2\n:\nproperty:value\nThe colon (:) in the\nproperty:value\nsyntax specifies that the value of the property being searched for contains the specified value. For example,\nrecipients:garthf@contoso.com\nreturns any message sent to garthf@contoso.com.\n=\nproperty=value\nThe same as the\n:\noperator.\n<\nproperty<value\nDenotes that the property being searched is less than the specified value.\n1\n>\nproperty>value\nDenotes that the property being searched is greater than the specified value.\n1\n<=\nproperty<=value\nDenotes that the property being searched is less than or equal to a specific value.\n1\n>=\nproperty>=value\nDenotes that the property being searched is greater than or equal to a specific value.\n1\n..\nproperty:value1..value2\nDenotes that the property being searched is greater than or equal to value1 and less than or equal to value2.\n1\n\" \"\n\"fair value\"\nsubject:\"Quarterly Financials\"\nIn a keyword query (where you type the\nproperty:value\npair in the\nKeyword\nbox), use double quotation marks (\" \") to search for an exact phrase or term. However, if you use the\nSubject\nor\nSubject/Title\nsearch condition\ncondition, don't add double quotation marks to the value because quotation marks are automatically added when using these search conditions. If you do add quotation marks to the value, two pairs of double quotations are added to the condition value, and the search query will return an error.\n*\ncat*\nsubject:set*\nPrefix searches (also called\nprefix matching\n) where a wildcard character ( * ) is placed at the end of a word in keywords or\nproperty:value\nqueries. In prefix searches, the search returns results with terms that contain the word followed by zero or more characters. For example,\ntitle:set*\nreturns documents that contain the word \"set\", \"setup\", and \"setting\" (and other words that start with \"set\") in the document title.\nNote:\nYou can use only prefix searches; for example,\ncat*\nor\nset*\n. Suffix searches (\n*cat\n), infix searches (\nc*t\n), and substring searches (\n*cat*\n) aren't supported.\nAlso, adding a period ( . ) to a prefix search changes the results that are returned. That's because a period is treated as a stop word. For example, searching for\ncat*\nand searching for\ncat.*\nwill return different results. We recommend not using a period in a prefix search.\n( )\n(fair OR free) AND (from:contoso.com)\n(IPO OR initial) AND (stock OR shares)\n(quarterly financials)\nParentheses group together Boolean phrases,\nproperty:value\nitems, and keywords. For example,\n(quarterly financials)\nreturns items that contain the words quarterly and financials.\nNote\n1\nUse this operator for properties that have date or numeric values.\n2\nBoolean search operators must be uppercase; for example,\nAND\n. If you use a lowercase operator, such as\nand\n, it is treated as a keyword in the search query.\nSearch conditions\nYou can add conditions to a search query to narrow a search and return a more refined set of results. Each condition adds a clause to the KeyQL search query that is created and run when you start the search.\nConditions for common properties\nConditions for mail properties\nConditions for document properties\nOperators used with conditions\nGuidelines for using conditions\nExamples of using conditions in search queries\nConditions for common properties\nCreate a condition using common properties when searching mailboxes and sites in the same search. The following table lists the available properties to use when adding a condition.\nCondition\nDescription\nDate\nFor email, the date a message was created or imported from a PST file. For documents, the date a document was last modified.\nIf you're searching for email messages for a specific time period, you should use the message\nReceived\nand\nSent\nconditions if you're unsure if the email messages might have been imported instead of natively created in Exchange.\nSender/Author\nFor email, the person who sent a message. For documents, the person cited in the author field from Office documents. You can type more than one name, separated by commas. Two or more values are logically connected by the\nOR\noperator.\n(\nSee Recipient Expansion\n)\nSize (in bytes)\nFor both email and documents, the size of the item (in bytes).\nSubject/Title\nFor email, the text in the subject line of a message. For documents, the title of the document. As previously explained, the Title property is metadata specified in Microsoft Office documents. You can type the name of more than one subject/title values, separated by commas. Two or more values are logically connected by the\nOR\noperator.\nNote\n: Don't include double quotation marks to the values for this condition because quotation marks are automatically added when using this search condition. If you add quotation marks to the value, two pairs of double quotations are added to the condition value, and the search query will return an error.\nRetention label\nFor both email and documents, retention labels that can be automatically or manually applied to messages and documents. Retention labels can be used to declare records and help you manage the data lifecycle of content by enforcing retention and deletion rules specified by the label. You can type part of the retention label name and use a wildcard or type the complete label name. For more information about retention labels, see\nLearn about retention policies and retention labels\n.\nConditions for mail properties\nCreate a condition using mail properties when searching mailboxes or public folders in Exchange Online. The following table lists the email properties that you can use for a condition. These properties are a subset of the email properties that were previously described. These descriptions are repeated for your convenience.\nCondition\nDescription\nMessage kind\nThe message type to search. This is the same property as the Kind email property. Possible values:\ncontacts\ndocs\nemail\nexternaldata\nfax\nim\njournals\nmeetings\nmicrosoftteams\nnotes\nposts\nrssfeeds\ntasks\nvoicemail\nParticipants\nAll the people fields in an email message. These fields are From, To, Cc, and Bcc. (\nSee Recipient Expansion\n)\nType\nThe message class property for an email item. This is the same property as the ItemClass email property. It's also a multi-value condition. So to select multiple message classes, hold the\nCTRL\nkey and then select two or more message classes in the drop-down list that you want to add to the condition. Each message class that you select in the list is logically connected by the\nOR\noperator in the corresponding search query.\nFor a list of the message classes (and their corresponding message class ID) that are used by Exchange and that you can select in the\nMessage class\nlist, see\nItem Types and Message Classes\n.\nReceived\nThe date that an email message was received by a recipient. This is the same property as the Received email property.\nRecipients\nAll recipient fields in an email message. These fields are To, Cc, and Bcc. (\nSee Recipient Expansion\n)\nSent\nThe date that an email message was sent by the sender. This is the same property as the Sent email property.\nSubject\nThe text in the subject line of an email message.\nNote\n: Don't include double quotation marks to the values for this condition because quotation marks are automatically added when using this search condition. If you add quotation marks to the value, two pairs of double quotations are added to the condition value, and the search query will return an error.\nTo\nThe recipient of an email message in the To field.\nConditions for document properties\nCreate a condition using document properties when searching for documents on SharePoint and OneDrive for Business sites. The following table lists the document properties that you can use for a condition. These properties are a subset of the site properties that were previously described. These descriptions are repeated for your convenience.\nCondition\nDescription\nAuthor\nThe author field from Office documents, which persists if a document is copied. For example, if a user creates a document and the emails it to someone else who then uploads it to SharePoint, the document will still retain the original author.\nTitle\nThe title of the document. The Title property is metadata that's specified in Office documents. It's different than the file name of the document.\nCreated\nThe date that a document is created.\nLast modified\nThe date that a document was last changed.\nFile type\nThe extension of a file; for example, docx, one, pptx, or xlsx. This is the same property as the FileExtension site property.\nNote:\nIf you include a File type condition using the\nEquals\nor\nEquals any of\noperator in a search query, you can't use a prefix search (by including the wildcard character ( * ) at the end of the file type) to return all versions of a file type. If you do, the wildcard is ignored. For example if you include the condition\nEquals any of doc*\n, only files with an extension of\n.doc\nare returned. Files with an extension of\n.docx\nwonât be returned. To return all versions of a file type, used the\nproperty:value\npair in a keyword query; for example,\nfiletype:doc*\n.\nOperators used with conditions\nWhen you add a condition, you can select an operator that is relevant to type of property for the condition. The following table describes the operators that are used with conditions and lists the equivalent that is used in the search query.\nOperator\nQuery equivalent\nDescription\nAfter\nproperty>date\nUsed with date conditions. Returns items that were sent, received, or modified after the specified date.\nBefore\nproperty<date\nUsed with date conditions. Returns items that were sent, received, or modified before the specified date.\nBetween\ndate..date\nUse with date and size conditions. When used with a date condition, returns items there were sent, received, or modified within the specified date range. When used with a size condition, returns items whose size is within the specified range.\nContains any of\n(property:value) OR (property:value)\nUsed with conditions for properties that specify a string value. Returns items that contain any part of one or more specified string values.\nDoesn't contain any of\n-property:value\nNOT property:value\nUsed with conditions for properties that specify a string value. Returns items that don't contain any part of the specified string value.\nDoesn't equal any of\n-property=value\nNOT property=value\nUsed with conditions for properties that specify a string value. Returns items that don't contain the specific string.\nEquals\nsize=value\nReturns items that are equal to the specified size.\n1\nEquals any of\n(property=value) OR (property=value)\nUsed with conditions for properties that specify a string value. Returns items that are a match of one or more specified string values.\nGreater\nsize>value\nReturns items where the specified property is greater than the specified value.\n1\nGreater or equal\nsize>=value\nReturns items where the specified property is greater than or equal to the specified value.\n1\nLess\nsize<value\nReturns items that are greater than or equal to the specific value.\n1\nLess or equal\nsize<=value\nReturns items that are greater than or equal to the specific value.\n1\nNot equal\nsize<>value\nReturns items that don't equal the specified size.\n1\nNote\n1\nThis operator is available only for conditions that use the Size property.\nGuidelines for using conditions\nKeep the following in mind when using search conditions.\nA condition is logically connected to the keyword query (specified in the keyword box) by the\nAND\noperator. That means that items have to satisfy both the keyword query and the condition to be included in the results. This is how conditions help to narrow your results.\nIf you add two or more unique conditions to a search query (conditions that specify different properties), those conditions are logically connected by the\nAND\noperator. That means only items that satisfy all the conditions (in addition to any keyword query) are returned.\nIf you add more than one condition for the same property, those conditions are logically connected by the\nOR\noperator. That means items that satisfy the keyword query and any one of the conditions are returned. So, groups of the same conditions are connected to each other by the\nOR\noperator and then sets of unique conditions are connected by the\nAND\noperator.\nIf you add multiple values (separated by commas or semi-colons) to a single condition, those values are connected by the\nOR\noperator. That means items are returned if they contain any of the specified values for the property in the condition.\nAny condition that uses an operator with\nContains\nand\nEquals\nlogic will return similar search results for simple string searches. A simple string search is a string in the condition that doesn't include a wildcard). For example, a condition that uses\nEquals any of\nwill return the same items as a condition that uses\nContains any of\n.\nThe search query that is created by using the keywords box and conditions is displayed on the\nSearch\npage, in the details pane for the selected search. In a query, everything to the right of the notation\n(c:c)\nindicates conditions that are added to the query.\n(c:c)\nshouldn't be used in manually entered queries and isn't equal to\nAND\nor\nOR\n.\nConditions only add properties to the search query; they don't add operators. This is why the query displayed in the detail pane doesn't show operators to the right of the\n(c:c)\nnotation. KeyQL adds the logical operators (according to the previously explained rules) when the executing the query.\nYou can use the drag and drop control to resequence the order of conditions. Select the control for a condition and move it up or down.\nAs previously explained, some condition properties allow you to type multiple values (separated by semi-colons). Each value is logically connected by the\nOR\noperator, and results in the query\n(filetype=docx) OR (filetype=pptx) OR (filetype=xlsx)\n. The following illustration shows an example of a condition with multiple values.\nNote\nYou can't add multiple conditions (by selecting\nAdd condition\nfor the same property). Instead, you have to provide multiple values for the condition (separated by semi-colons), as shown in the previous example.\nExamples of using conditions in search queries\nThe following examples show the GUI-based version of a search query with conditions, the search query syntax that is displayed in the details pane of the selected search (which is also returned by the\nGet-ComplianceSearch\ncmdlet), and the logic of the corresponding KeyQL query.\nExample 1\nThis example returns email items or documents that contain the keyword \"report\", that were sent or created before April 1, 2021, and that contain the word \"northwind\" in the subject field of email messages or in the title property of documents. The query excludes Web pages that meet the other search criteria.\nGUI\n:\nSearch query syntax\n:\nreport(c:c)(date<2021-04-01)(subjecttitle:\"northwind\")(-filetype:aspx)\nSearch query logic\n:\nreport AND (date<2021-04-01) AND (subjecttitle:\"northwind\") NOT (filetype:aspx)\nExample 2\nThis example returns email messages or calendar meetings that were sent between December 1, 2019 and November 30, 2020 and that contain words that start with \"phone\" or \"smartphone\".\nGUI\n:\nSearch query syntax\n:\nphone* OR smartphone*(c:c)(sent=2019-12-01..2020-11-30)(kind=\"email\")(kind=\"meetings\")\nSearch query logic\n:\nphone* OR smartphone* AND (sent=2019-12-01..2020-11-30) AND ((kind=\"email\") OR (kind=\"meetings\"))\nSpecial characters\nSome special characters aren't included in the search index and therefore aren't searchable. This also includes the special characters that represent search operators in the search query. Here's a list of special characters that are either replaced by a blank space in the actual search query or cause a search error.\n+ - = : ! @ # % ^ & ; _ / ? ( ) [ ] { }\nSearchable sensitive data types\nYou can use eDiscovery search tools in the Microsoft Purview portal to search for sensitive data, such as credit card numbers or social security numbers, that is stored in documents on SharePoint and OneDrive for Business sites. You can do this by using the\nSensitiveType\nproperty and the name (or ID) of a sensitive information type in a keyword query. For example, the query\nSensitiveType:\"Credit Card Number\"\nreturns documents that contain a credit card number. The query\nSensitiveType:\"U.S. Social Security Number (SSN)\"\nreturns documents that contain a U.S. social security number.\nTo see a list of the sensitive information types that you can search for, go to\nData classifications\n>\nSensitive info types\nin the Microsoft Purview portal. Or you can use the\nGet-DlpSensitiveInformationType\ncmdlet in Security & Compliance PowerShell to display a list of sensitive information types.\nLimitations for searching sensitive data types\nTo search for custom sensitive information types, you have to specify the ID of the sensitive information type in the\nSensitiveType\nproperty. Using the name of a custom sensitive information type (as shown in the example for built-in sensitive information types in the previous section) will return no results. Use the\nPublisher\ncolumn on the\nSensitive info types\npage in the Microsoft Purview portal (or the\nPublisher\nproperty in PowerShell) to differentiate between built-in and custom sensitive information types. Built-in sensitive data types have a value of\nMicrosoft Corporation\nfor the\nPublisher\nproperty.\nTo display the name and ID for the custom sensitive data types in your organization, run the following command in Security & Compliance PowerShell:\nGet-DlpSensitiveInformationType | Where-Object {$_.Publisher -ne \"Microsoft Corporation\"} | FT Name,Id\nThen you can use the ID in the\nSensitiveType\nsearch property to return documents that contain the custom sensitive data type; for example,\nSensitiveType:7e13277e-6b04-3b68-94ed-1aeb9d47de37\nYou can't use sensitive information types and the\nSensitiveType\nsearch property to search for sensitive data at-rest in Exchange Online mailboxes. This includes 1:1 chat messages, 1:N group chat messages, and team channel conversations in Microsoft Teams because all of this content is stored in mailboxes. However, you can use data loss prevention (DLP) policies to protect sensitive email data in transit. For more information, see\nLearn about data loss prevention\nand\nSearch for and find personal data\n.\nSearching for site content shared with external users\nYou can also use eDiscovery search tools in the Microsoft Purview portal to search for documents stored on SharePoint and OneDrive for Business sites that have been shared with people outside of your organization. This can help you identify sensitive or proprietary information that's being shared outside your organization. You can do this by using the\nViewableByExternalUsers\nproperty in a keyword query. This property returns documents or sites that have been shared with external users by using one of the following sharing methods:\nA sharing invitation that requires users to sign in to your organization as an authenticated user.\nAn anonymous guest link, which allows anyone with this link to access the resource without having to be authenticated.\nHere are some examples:\nThe query\nViewableByExternalUsers:true AND SensitiveType:\"Credit Card Number\"\nreturns all items that have been shared with people outside your organization and contain a credit card number.\nThe query\nViewableByExternalUsers:true AND ContentType:document AND site:\"https://contoso.sharepoint.com/Sites/Teams\"\nreturns a list of documents on all team sites in the organization that have been shared with external users.\nTip\nA search query such as\nViewableByExternalUsers:true AND ContentType:document\nmight return numerous .aspx files in the search results. To eliminate these (or other types of files), you can use the\nFileExtension\nproperty to exclude specific file types; for example\nViewableByExternalUsers:true AND ContentType:document NOT FileExtension:aspx\n.\nWhat is considered content that is shared with people outside your organization? Documents in your organization's SharePoint and OneDrive for Business sites that are shared by sending a sharing invitation or that are shared in public locations. For example, the following user activities result in content that is viewable by external users:\nA user shares a file or folder with a person outside your organization.\nA user creates and sends a link to a shared file to a person outside your organization. This link allows the external user to view (or edit) the file.\nA user sends a sharing invitation or a guest link to a person outside your organization to view (or edit) a shared file.\nIssues using the ViewableByExternalUsers property\nWhile the\nViewableByExternalUsers\nproperty represents the status of whether a document or site is shared with external users, there are some caveats to what this property does and doesn't reflect. In the following scenarios, the value of the\nViewableByExternalUsers\nproperty won't be updated, and the results of a search query that uses this property might be inaccurate.\nChanges to sharing policy, such as turning off external sharing for a site or for the organization. The property will still show previously shared documents as being externally accessible even though external access might have been revoked.\nChanges to group membership, such as adding or removing external users to Microsoft 365 Groups or Microsoft 365 security groups. The property won't automatically be updated for items the group has access to.\nSending sharing invitations to external users where the recipient hasn't accepted the invitation, and therefore doesn't yet have access to the content.\nIn these scenarios, the\nViewableByExternalUsers\nproperty won't reflect the current sharing status until the site or document library is recrawled and reindexed.\nSearching for site content shared within your organization\nAs previously explained, you can use the\nSharedWithUsersOWSUser\nproperty so search for documents that have been shared between people in your organization. When a person shares a file (or folder) with another user inside your organization, a link to the shared file appears on the\nShared with me\npage in the OneDrive for Business account of the person who the file was shared with. For example, to search for the documents that have been shared with Sara Davis, you can use the query\nSharedWithUsersOWSUser:\"sarad@contoso.com\"\n. If you export the results of this search, the original documents (located in the content location of the person who shared the documents with Sara) are downloaded.\nDocuments must be explicitly shared with a specific user to be returned in search results when using the\nSharedWithUsersOWSUser\nproperty. For example, when a person shares a document in their OneDrive account, they have the option to share it with anyone (inside or outside the organization), share it only with people inside the organization, or share it with a specific person. Here's a screenshot of the\nShare\nwindow in OneDrive that shows the three sharing options.\nOnly documents that are shared by using the third option (shared with\nSpecific people\n) are returned by a search query that uses the\nSharedWithUsersOWSUser\nproperty.\nSearching for Skype for Business conversations\nYou can use the following keyword query to specifically search for content in Skype for Business conversations:\nkind:im\nThe previous search query also returns chats from Microsoft Teams. To prevent this, you can narrow the search results to include only Skype for Business conversations by using the following keyword query:\nkind:im AND subject:conversation\nThe previous keyword query excludes chats in Microsoft Teams because Skype for Business conversations are saved as email messages with a Subject line that starts with the word \"Conversation\".\nTo search for Skype for Business conversations that occurred within a specific date range, use the following keyword query:\nkind:im AND subject:conversation AND (received=startdate..enddate)\nCharacter limits for searches\nThere's a 4,000 character limit for search queries when searching for content in SharePoint sites and OneDrive accounts.\nHere's how the total number of characters in the search query are calculated:\nThe characters in keyword search query (including both user and filter fields) count against this limit.\nThe characters in any location property (such as the URLs for all the SharePoint sites or OneDrive locations being searched) count against this limit.\nThe characters in all the search permissions filters that are applied to the user running the search count against the limit.\nNote\nThe 4,000 character limit applies to Content search, eDiscovery (Standard), and eDiscovery (Premium).\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "KeyQL Reference",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/ediscovery-create-holds": {
      "content_hash": "sha256:47dba85ebfc2815482f730a44a466af5c883bffbebaad2c9f232ed9b239b744d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate eDiscovery holds in an eDiscovery case\nFeedback\nSummarize this article for me\nImportant\nThe classic eDiscovery experiences were\nretired on August 31, 2025\n. This retirement includes classic\nContent Search\n, classic\neDiscovery (Standard)\n, and classic\neDiscovery (Premium)\n. These options aren't available as an experience option in the Microsoft Purview portal.\nUnless you're working directly with Microsoft when using these legacy features for specific short-term transition scenarios, use the guidance for the\nnew eDiscovery experience\nin the\nMicrosoft Purview portal\n.\nYou can use a Microsoft Purview eDiscovery (Premium) or (Standard) case to create holds to preserve content that might be relevant to the case. You can place a hold on the Exchange mailboxes and OneDrive for Business accounts of people you're investigating in the case. You can also place a hold on the mailboxes and sites that are associated with Microsoft Teams, Microsoft 365 groups, and Viva Engage Groups. When you place content locations on hold, content is preserved until you remove the content location from the hold or until you delete the hold.\nImportant\nFor long term data retention not related to eDiscovery investigations, it is strongly advised to use retention policies and retention labels. For more information, see\nLearn about retention policies and retention labels\n.\nAfter you create an eDiscovery hold, it may take up to 24 hours for the hold to take effect.\nWhen you create a hold, you have the following options to scope the content that's preserved in the specified content locations:\nCreate an infinite hold where all content in the specified locations is placed on hold. Alternatively, you can create a query-based hold where only the content in the specified locations that matches a search query is placed on hold.\nSpecify a date range to preserve only the content that was sent, received, or created within that date range. Alternatively, you can hold all content in specified locations regardless of when sent, received, or created.\nHow to create an eDiscovery hold\nTo create an eDiscovery hold that's associated with a eDiscovery (Premium) or (Standard) case:\nGo to\nMicrosoft Purview portal\nand sign in using the credentials for user account with the appropriate eDiscovery permissions.\nIn the left navigation pane, select\nShow all\n, and then select\neDiscovery > Premium\nor\neDiscovery > Standard\n.\nOn the\neDiscovery > Premium\nor\neDiscovery (Standard)\npage, select the name of the case that you want to create the hold in.\nOn the\nHome\npage for the case, select the\nHold\ntab.\nOn the\nHold\npage, select\nCreate\n.\nOn the\nName your hold\nworkflow page, give the hold a name and add an optional description, and then select\nNext\n. The name of the hold must be unique in your organization.\nOn the\nChoose locations\nworkflow page, choose the content locations that you want to place on hold. You can place mailboxes, sites, and public folders on hold.\nExchange mailboxes\n: Set the toggle to\nOn\nand then select\nChoose users, groups, or teams\nto specify the mailboxes to place on hold. Use the search box to find user mailboxes and distribution groups (to place a hold on the mailboxes of group members) to place on hold. You can also place a hold on the associated mailbox for a Microsoft Team, Microsoft 365 group, and Viva Engage Group. For more information about the application data that is preserved when a mailbox is placed on hold, see\nContent stored in mailboxes for eDiscovery\n.\nImportant\nWhen you select a distribution list to be placed on hold, the hold is placed on each of the member mailboxes in the distribution list when the policy is created. Subsequent changes in the distribution list do not change or update the holds or the policy.\nSharePoint sites\n: Set the toggle to\nOn\nand then select\nChoose sites\nto specify SharePoint sites and OneDrive accounts to place on hold. Type the URL for each site that you want to place on hold. You can also add the URL for the SharePoint site for a Microsoft Team, Microsoft 365 group or a Yammer Group.\nImportant\nTo create a hold for a subsite related to a SharePoint Online site, you must use the\nPath\nproperty in a query filter to select a specific subsite.\nExchange public folders\n: Set the toggle to\nOn\nto put all public folders in your Exchange Online organization on hold. You can't choose specific public folders to put on hold. Leave the toggle switch off if you don't want to put a hold on public folders.\nImportant\nWhen adding Exchange mailboxes or SharePoint sites to a hold, you must explicitly add at least one content location to the hold. In other words, if you set the toggle to\nOn\nfor mailboxes or sites, you must select specific mailboxes or sites to add to the hold. Otherwise, the eDiscovery hold will be created but no mailboxes or sites will be added to the hold.\nWhen finished adding locations to the hold, select\nNext\n.\nTo create a query-based hold using keywords or conditions, complete the following steps. To preserve all content in the specified content locations, select\nNext\n.\nIn the box under\nKeywords\n, type a query to preserve only the content that matches the query criteria. You can specify keywords, email message properties, or site properties, such as file names. You can also use more complex queries that use a Boolean operator, such as\nAND\n,\nOR\n, or\nNOT\n.\nSelect\nAdd condition\nto add one or more conditions to narrow the query for the hold. Each condition adds a clause to the KeyQL search query that is created and run when you create the hold. For example, you can specify a date range so that email or site documents that were created within the date ranged are preserved. A condition is logically connected to the keyword query (specified in the\nKeywords\nbox) and other conditions by the\nAND\noperator. That means items have to satisfy both the keyword query and the condition to be preserved.\nFor more information about creating a search query and using conditions, see\nKeyword queries and search conditions for eDiscovery\n.\nAfter configuring a query-based hold, select\nNext\n.\nReview your settings (and edit them if necessary), and then select\nSubmit\n.\nAfter creating a hold, check that the hold is applied successfully by navigating to the\nHold\ntab in the case and selecting the hold policy. For more information about troubleshooting holds with errors, see\nResolve eDiscovery hold errors\n.\nNote\nWhen you create a query-based hold, all content from selected locations is initially placed on hold. Subsequently, any content that doesn't match the specified query is cleared from the hold every seven to 14 days. However, a query-based hold won't clear content if more than five holds of any type are applied to a content location, or if any item has indexing issues.\nQuery-based holds placed on sites\nKeep the following things in mind when you place a query-based eDiscovery hold on documents located in SharePoint sites:\nA query-based hold initially preserves all documents in a site for a short period of time after they're deleted. That means when a document is deleted, it is moved to the Preservation Hold library even if it doesn't match the criteria of the query-based hold. However, deleted documents that don't match a query-based hold will be removed by a timer job that processes the Preservation Hold library. The timer job runs periodically and compares all documents in the Preservation Hold library to your query-based eDiscovery holds (and other types of holds and retention policies). The timer job deletes the documents that don't match a query-based hold and preserves the documents that do.\nQuery-based holds shouldn't be used to perform targeted preservation, like preserving documents in a specific folder or site or by using other location-based hold criteria. Doing so may have unintended results. We recommend using non-location based hold criteria such as keywords, date ranges, or other document properties to preserve site documents.\nSearch locations on eDiscovery hold\nWhen you\nsearch for content\nin a eDiscovery (Standard) case, you can quickly configure the search to only search the content locations that have been placed on a hold associated with the case.\nSelect the\nLocations on hold\noption to search all the content locations that have been placed on hold. If the case contains multiple eDiscovery holds, the content locations from all holds are searched when you select this option. Additionally, if a content location was placed on a query-based hold, only the items that match the hold query are searched when you run the search. In other words, only the content that matches both the hold criteria and the search criteria is returned with the search results. For example, if a user was placed on query-based case hold that preserves items that were sent or created before a specific date, only those items would be searched. This is accomplished by connecting the case hold query and the search query by an\nAND\noperator.\nHere are some other things to keep in mind when searching locations on eDiscovery hold:\nIf a content location is part of multiple holds within the same case, the hold queries are combined by\nOR\noperators when you search that content location using the all case content option. Similarly, if a content location is part of two different holds, where one is query-based and the other is an infinite hold (where all content is placed on hold), then all content is search because of the infinite hold.\nIf a search is configured it to search locations on hold and then you change an eDiscovery hold in the case (by adding or removing a location or changing a hold query), the search configuration is updated with those changes. However, you have to rerun the search after the hold is changed to update the search results.\nIf multiple eDiscovery holds are placed on a single location in an eDiscovery case and you select to search locations on hold, the maximum number of keywords for that search query is 500. That's because the search combines all the query-based holds by using the\nOR\noperator. If there are more than 500 keywords in the combined hold queries and the search query, then all content in the mailbox is searched, not just that content that matches the query-based case holds.\nIf an eDiscovery hold has a status of\nOn (Pending)\n, you can still search the locations on hold while the hold is being turned on.\nPreserve content in Microsoft Teams\nConversations that are part of a Microsoft Teams channel are stored in the mailbox that's associated with the Microsoft Team. Similarly, files that team members share in a channel are stored on the team's SharePoint site. Therefore, you have to place the Team mailbox and SharePoint site on eDiscovery hold to preserve conversations and files in a channel.\nAlternatively, conversations that are part of the Chat list in Teams (called\n1:1 chats\nor\n1:N group chats\n) are stored in the mailboxes of the users who participate in the chat. And files that users share in chat conversations are stored in the OneDrive account of the user who shares the file. Therefore, you have to add the individual user mailboxes and OneDrive accounts to an eDiscovery hold to preserve conversations and files in the chat list. It's a good idea to place a hold on the mailboxes of members of a Microsoft Team in addition to placing the team mailbox and site on hold.\nNote\nIf your organization has an Exchange hybrid deployment (or your organization synchronizes an on-premises Exchange organization with Office 365) and has enabled Microsoft Teams, on-premises users can use the Teams chat application and participate in 1:1 chats and 1:N group chats. These conversations are stored in cloud-based storage that's associated with an on-premises user. If an on-premises user is placed on an eDiscovery hold, the Teams chat content in the cloud-based storage will be preserved. For more information, see\nSearch for Teams chat data for on-premises users\n.\nFor more information about preserving Teams content, see\nPlace a Microsoft Teams user or team on legal hold\n.\nPreserve card content\nSimilarly, card content generated by apps in Teams channels, 1:1 chats, and 1:N group chats are stored in mailboxes and is preserved when a mailbox is placed on an eDiscovery hold. A\ncard\nis a UI container for short pieces of content. Cards can have multiple properties and attachments, and can include items that trigger card actions. For more information, see\nCards\n. Like other Teams content, where card content is stored is based on where the card was used. Content for cards used in a Teams channel is stored in the Teams group mailbox. Card content for 1:1 and 1xN chats are stored in the mailboxes of the chat participants.\nPreserve meeting and call information\nSummary information for meetings and calls in a Teams channel is also stored in the mailboxes of users who dialed into the meeting or call. This content is also preserved when an eDiscovery hold is placed on user mailboxes.\nPreserve content in private channels\nStarting in February 2020, we also turned on the ability to preserve content in private channels. Because private channel chats are stored in the mailboxes of the chat participants, placing a user mailbox on eDiscovery hold preserves private channel chats. Also, if a user mailbox was placed on an eDiscovery hold prior to February 2020, the hold will now automatically apply to private channel messages stored in that mailbox. Preserving files shared in private channels is also supported.\nPreserve wiki content\nEvery Team or team channel also contains a Wiki for note taking and collaboration. The Wiki content is automatically saved to a file with a .mht format. This file is stored in the Teams Wiki Data document library on the team's SharePoint site. You can preserve the wiki content by adding the team's SharePoint site to an eDiscovery hold.\nNote\nThe capability to preserve Wiki content for a Team or team channel (when you place the team's SharePoint site on hold) was released on June 22, 2017. If a team site is on hold, the Wiki content will be retained starting on that date. However, if a team site is on hold and the Wiki content was deleted before June 22, 2017, the Wiki content was not preserved.\nMicrosoft 365 groups\nTeams is built on Microsoft 365 groups. Therefore, placing Microsoft 365 groups on eDiscovery hold is similar placing Teams content on hold.\nKeep the following things in mind when placing both Teams and Microsoft 365 groups on an eDiscovery hold:\nAs previously explained, to place content located in Teams and Microsoft 365 groups on hold, you have to specify the mailbox and SharePoint site that associated with a group or team.\nRun the\nGet-UnifiedGroup\ncmdlet in\nExchange Online PowerShell\nto view properties for Teams and Microsoft 365 groups. This is a good way to get the URL for the site that's associated with a Team or Microsoft 365 group. For example, the following command displays selected properties for a Microsoft 365 group named Senior Leadership Team:\nGet-UnifiedGroup \"Senior Leadership Team\" | FL DisplayName,Alias,PrimarySmtpAddress,SharePointSiteUrl\n\nDisplayName : Senior Leadership Team\nAlias : seniorleadershipteam\nPrimarySmtpAddress : seniorleadershipteam@contoso.onmicrosoft.com\nSharePointSiteUrl : https://contoso.sharepoint.com/sites/seniorleadershipteam\nNote\nTo run the\nGet-UnifiedGroup\ncmdlet, you have to be assigned the View-Only Recipients role in Exchange Online or be a member of a role group that's assigned the View-Only Recipients role.\nWhen a user's mailbox is searched, any Team or Microsoft 365 group that the user is a member of won't be searched. Similarly, when you place a Team or Microsoft 365 group on eDiscovery hold, only the group mailbox and group site are placed on hold. The mailboxes and OneDrive for Business sites of group members aren't placed on hold unless you explicitly add them to the eDiscovery hold. So if you have to place a Team or Microsoft 365 group on hold for a legal reason, consider adding the mailboxes and OneDrive accounts of team or group members on the same hold.\nTo get a list of the members of a Team or Microsoft 365 group, you can view the properties on the\nGroups\npage in the Microsoft 365 admin center. Alternatively, you can run the following command in Exchange Online PowerShell:\nGet-UnifiedGroupLinks <group or team name> -LinkType Members | FL DisplayName,PrimarySmtpAddress\nNote\nTo run the\nGet-UnifiedGroupLinks\ncmdlet, you have to be assigned the View-Only Recipients role in Exchange Online or be a member of a role group that's assigned the View-Only Recipients role.\nPreserve content in OneDrive accounts\nImportant\nThe retention period for deleted OneDrive accounts is different from the retention period for mailboxes. For more information about the retention period for deleted OneDrive accounts, see\nOneDrive retention and deletion\n.\nTo collect a list of the URLs for the OneDrive for Business sites in your organization so you can add them to a hold or search associated with an eDiscovery case, see\nCreate a list of all OneDrive locations in your organization\n. The script in this article creates a text file that contains a list of all OneDrive sites in your organization. To run this script, you have to install and use the SharePoint Online Management Shell. Be sure to append the URL for your organization's MySite domain to each OneDrive site that you want to search. This is the domain that contains all your OneDrive; for example,\nhttps://contoso-my.sharepoint.com\n. Here's an example of a URL for a user's OneDrive site:\nhttps://contoso-my.sharepoint.com/personal/sarad_contoso_onmicrosoft.com\n.\nImportant\nThe URL for a user's OneDrive account includes their user principal name (UPN) (for example,\nhttps://alpinehouse-my.sharepoint.com/personal/sarad_alpinehouse_onmicrosoft_com\n). In the rare case that a person's UPN is changed, their OneDrive URL will also change to incorporate the new UPN. If a user's OneDrive account is part of an eDiscovery hold, and their UPN is changed, you need to update the hold by adding the user's new OneDrive URL and removing the old one. If the URL for the OneDrive site changes, previously placed holds on the site remain effective and content is preserved. For more information, see\nHow UPN changes affect the OneDrive URL\n.\nRemoving content locations from an eDiscovery hold\nAfter a mailbox, SharePoint site, or OneDrive account is removed from an eDiscovery hold, a\ndelay hold\nis applied. This means that the actual removal of the hold is delayed for 30 days to prevent data from being permanently deleted (purged) from a content location. This gives admins an opportunity to search for or recover content that will be purged after an eDiscovery hold is removed. The details of how the delay hold works for mailboxes and sites are different.\nMailboxes:\nA delay hold is placed on a mailbox the next time the Managed Folder Assistant processes the mailbox and detects that an eDiscovery hold was removed. Specifically, a delay hold is applied to a mailbox when the Managed Folder Assistant sets one of the following mailbox properties to\nTrue\n:\nDelayHoldApplied:\nThis property applies to email-related content (generated by people using Outlook and Outlook on the web) that's stored in a user's mailbox.\nDelayReleaseHoldApplied:\nThis property applies to cloud-based content (generated by non-Outlook apps such as Microsoft Teams, Microsoft Forms, and Microsoft Yammer) that's stored in a user's mailbox. Cloud data generated by a Microsoft app is typically stored in a hidden folder in a user's mailbox.\nWhen a delay hold is placed on the mailbox (when either of the previous properties is set to\nTrue\n), the mailbox is still considered to be on hold for an unlimited hold duration, as if the mailbox was on Litigation Hold. After 30 days, the delay hold expires, and Microsoft 365 will automatically attempt to remove the delay hold (by setting the DelayHoldApplied or DelayReleaseHoldApplied property to\nFalse\n) so that the hold is removed. After either of these properties are set to\nFalse\n, the corresponding items that are marked for removal are purged the next time the mailbox is processed by the Managed Folder Assistant.\nFor more information, see\nManaging mailboxes on delay hold\n.\nSharePoint and OneDrive sites:\nAny SharePoint or OneDrive content that's being retained in the Preservation Hold library isn't deleted during the 30-day delay hold period after a site is removed from an eDiscovery hold. This is similar to what happens when a site is released from a retention policy. Additionally, you can't manually delete this content in the Preservation Hold library during the 30-day delay hold period. To release a site from the 30-day delay hold/grace period hold, see the\nCan't delete a site because of an invalid retention policy or eDiscovery hold\ntroubleshooting article.\nFor more information, see\nReleasing a policy for retention\n.\nA delay hold is also applied to content locations on hold when you close a eDiscovery (Standard) case because holds are turned off when a case is closed. For more information about closing a case, see\nClose, reopen, and delete a eDiscovery (Standard) case\n.\neDiscovery hold limits\nThe following table lists the limits for eDiscovery cases and case holds.\nDescription of limit\nLimit\nMaximum number of cases for an organization.\nNo limit\nMaximum number of eDiscovery hold policies for an organization. This limit includes the combined total of hold policies in eDiscovery (Standard) and eDiscovery (Premium) cases.\n10,000\n1\nMaximum number of mailboxes in a single eDiscovery hold. This limit includes the combined total of user mailboxes, and the mailboxes associated with Microsoft 365 groups, Microsoft Teams, and Viva Engage Groups.\n1,000\nMaximum number of sites in a single eDiscovery hold. This limit includes the combined total of OneDrive for Business sites, SharePoint sites, and the sites associated with Microsoft 365 groups, Microsoft Teams, and Viva Engage Groups. <br/\n100\nMaximum number of cases displayed on the eDiscovery home page, and the maximum number of items displayed on the Holds, Searches, and Export tabs within a case.\n1,000\n1\nHold limits for SharePoint sites and OneDrive\nFor details, see\nSharePoint limits\n.\nNote\n1\nTo view a list of more than 1,000 cases, holds, searches, or exports, you can use the corresponding Security & Compliance PowerShell cmdlet:\nGet-ComplianceCase\nGet-CaseHoldPolicy\nGet-ComplianceSearch\nGet-ComplianceSearchAction\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "eDiscovery Holds",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/endpoint-dlp-learn-about": {
      "content_hash": "sha256:8f1c9dc972d15a7ae87ab587a4ef0e95e5ee73667c41d65f5290adaa025353e1",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about Endpoint data loss prevention\nFeedback\nSummarize this article for me\nYou can use Microsoft Purview Data Loss Prevention (DLP) to monitor the actions that are being taken on items you've determined to be sensitive and to help prevent the unintentional sharing of those items.\nEndpoint data loss prevention\n(Endpoint DLP) extends the activity monitoring and protection capabilities of DLP to Windows 10/11, macOS (the three latest released major versions) devices, and Windows certain server versions. Once devices are onboarded into the Microsoft Purview solutions, the information about what users are doing with sensitive items is made visible in\nactivity explorer\n. You can then enforce protective actions on those items via\nDLP policies\n.\nWhen are files classified by Endpoint DLP?\nEndpoint DLP classifies files under the following conditions:\nCreation or Modification:\nEvery time a file is created or modified, it is fully scanned for sensitive information types (SITs) and labels. The file is then evaluated for matches against DLP policies and rules.\nReading an Already Classified File:\nWhen an already classified file is read, Endpoint DLP checks for any changes to the policies, rules, or SITs. If there is a change in the DLP configuration, it re-evaluates the policies and rules, but it will not re-extract the text.\nTip\nIf you're looking for device control for removable storage, see\nMicrosoft Defender for Endpoint Device Control Removable Storage Access Control\n.\nNote\nEndpoint DLP cannot detect the sensitivity label from another tenant on a document.\nEndpoint DLP Windows 10/11 and macOS support\nEndpoint DLP allows you to onboard devices running the following versions of Windows Server:\nWindows Server 2019 (\nNovember 14, 2023âKB5032196 (OS Build 17763.5122) - Microsoft Support\n)\nWindows Server 2022 (\nNovember 14, 2023 Security update (KB5032198) - Microsoft Support\n)\nNote\nInstalling the supported Windows Server KBs disables the\nClassification\nfeature on the server. This means that Endpoint DLP won't classify files on the server. However, Endpoint DLP will still protect those files on the server that were classified before those KBs were installed on server. To ensure this protection, install Microsoft Defender version 4.18.23100 (October 2023) or later.\nBy default, Endpoint DLP isn't enabled for Windows servers when they're initially onboarded. Before you can see Endpoint DLP events for your servers in Activity Explorer, you must first\nEnable Endpoint DLP for Windows Servers\n.\nOnce properly configured, the same data loss protection policies can be automatically applied to both Windows PCs and Windows servers.\nSetting\nSubsetting\nWindows 10, 1809 and later, Windows 11, Windows Server 2019, Windows Server 2022 (21H2 onwards) for Endpoints (X64)\nmacOS (three latest released versions)\nNotes\nAdvanced classification scanning and protection\nAllocated bandwidth limits\nSupported\nSupported\nAdvanced classification enables these features for macOS: -\nDocument Fingerprinting\n-\nExact data match based sensitive information types\n-\nTrainable classifiers\n-\nLearn about named entities\nFile path exclusions for Windows\nn/a\nSupported\nn/a\nFile path exclusions for Mac\nn/a\nn/a\nSupported\nmacOS includes a recommended list of exclusions that is on by default\nSetup evidence collection for file activities on devices\nSet evidence cache on device\nSupported\nPreview\nNetwork share coverage and exclusions\nn/a\nSupported\nSupported\nRestricted apps and app groups\nRestricted app groups\nSupported\nSupported\nRestricted apps and app groups\nRestricted apps\nSupported\nSupported\nRestricted apps and app groups\nAuto-quarantine settings\nSupported\nSupported\nUnallowed Bluetooth apps\nn/a\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nUnallowed browsers\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nService domains\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nSensitive service domain groups\nSupported\nSupported\nAdditional settings for Endpoint DLP\nBusiness justification in policy tips\nSupported\nSupported\nAlways audit file activity for devices\nn/a\nSupported\nSupported\nPrinter groups\nn/a\nSupported\nSupported\nRemovable USB device groups\nn/a\nSupported\nSupported\nNetwork share groups\nn/a\nSupported\nSupported\nVPN settings\nn/a\nSupported\nNot supported\nScoping DLP policies (preview)\nIn preview, DLP policies for endpoints are scoped by users, and devices. For an endpoint policy to be applied, both the user and the device must be in the policy scope. This means that if a user is in the policy scope, but the device isn't, the policy won't be applied. Similarly, if a device is in the policy scope, but the user isn't, the policy won't be applied.\nFor more information on scoping endpoint DLP policies, see\nDevice scoping\n.\nOther settings\nSetting\nWindows 10/11, Windows 10, 1809 and later, Windows 11\nWindows Server 2019, Windows Server 2022 (21H2 onwards) for Endpoints (X64)\nmacOS (three latest released versions)\nArchive file\nSupported\nSupported\nSupported\nFile type and File extension\nSupported\nSupported\nSupported\nEnable Endpoint DLP for Windows Servers\nNot supported\nSupported\nNot supported\nNote\nEndpoint DLP is not supported on Windows Servers configured as Domain Controllers or Windows Servers with the Core Server option selected during installation.\nEndpoint activities you can monitor and take action on\nEndpoint DLP enables you to audit and manage the following types of activities users take on sensitive items that are physically stored Windows 10, Windows 11, or macOS devices.\nActivity\nDescription\nWindows 10 (21H2, 22H2), Windows 11 (21H2, 22H2), Windows Server 2019, Server 2022 (21H2 onwards) for Endpoints (X64)\nWindows 11 (21H2, 22H2) for Endpoints (ARM64)\nmacOS three latest released versions\nAuditable/\nRestrictable\nUpload to a restricted cloud service domain or access from an unallowed browser\nDetects when a user attempts to upload an item to a restricted service domain or access an item through a browser. If they're using an unallowed browser, the upload activity is blocked and the user is redirected to use Microsoft Edge. Microsoft Edge then either allows or blocks the upload or access based on the DLP policy configuration. You can block, warn, or audit when protected files can be uploaded or prevented from being uploaded to cloud services based on the allow/unallowed domains list in\nData loss prevention settings\n. When the configured action is set to warn or block, other browsers (defined on the unallowed browsers list under\nData loss prevention settings\n) are blocked from accessing the file.\nSupported\nSupported\nSupported\nAuditable and restrictable\nPaste to supported browsers\nDetects when a user attempts to paste content to a restricted service domain. Evaluation is performed on the content that is being pasted. This evaluation is independent of how the source item that the content came from is classified.\nSupported\nSupported\nPreview\nAuditable and restrictable\nCopy to clipboard\nWhen a user attempts to copy content from a protected file, you can block, block with override, or audit the copying of protected files to a clipboard on an endpoint device. If the rule is configured to\nBlock\nor\nBlock with override\ncopying is blocked when the source content is sensitive except when the destination is within the same Microsoft 365 Office app. This activity also applies to redirected clipboards when using Azure Virtual Desktop with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy to USB removable device\nWhen this activity is detected, you can block, warn, or audit the copying or moving of protected files from an endpoint device to USB removable media.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy to a network share\nWhen this activity is detected, you can block, warn, or audit the copying or moving of protected files from an endpoint device to any network share, including redirected USB devices that are displayed as network shares on an Azure Virtual Desktop with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nPrint\nWhen this activity is detected, you can block, warn, or audit the printing of protected files from an endpoint device. This activity also applies to redirected printers when using Azure Virtual Desktop together with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy or move using unallowed Bluetooth app\nDetects when a user attempts to copy an item to an unallowed Bluetooth app (as defined in the list of unallowed Bluetooth apps in\nData loss prevention settings\n>\nEndpoint settings\n).\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy or move using RDP\nDetects when a user attempts to copy an item to a remote desktop session.\nSupported\nSupported\nNot supported\nAuditable and restrictable\nCreate an item\nDetects the creation of an item.\nSupported\nSupported\nSupported\nAuditable\nRename an item\nDetects the renaming of an item.\nSupported\nSupported\nSupported\nAuditable\nAccess by restricted apps\nDetects when an application that is on the restricted apps list (as defined in\nrestricted apps and app groups\n) attempts to access protected files on an endpoint device.\nSupported\nSupported\nSupported\nCreate Windows Recall snapshots (in preview)\nDetects when there is an item or Teams message that contains a sensitive information type or has a senstivity label applied that would be included in a\nWindows Recall\nsnapshot.\nSupported\nNot supported\nNot supported\nAuditable and restrictable\nCopy to clipboard behavior\nWhen you configure a rule to\nBlock\nor\nBlock with override\nwhen a user attempts the Copy to clipboard activity on content from a file that matches the policy, end users see this behavior with these configurations:\nWord file 123 contains sensitive information that matches the copy to clipboard Block rule.\nExcel file 123 contains sensitive information that matches the copy to clipboard Block rule.\nPowerPoint file 123 contains sensitive information that matches the copy to clipboard Block rule.\nWord file 789 doesn't contain sensitive information.\nExcel file 789 doesn't contain sensitive information.\nPowerPoint file 789 doesn't contain sensitive information.\nNotepad (or any non Microsoft Office based app or process) file XYZ contains sensitive information that matches the copy to clipboard Block rule.\nNotepad (or any non Microsoft Office based app or process) file ABC doesn't contain sensitive information.\nSource\nDestination\nBehavior\nWord file 123/Excel file 123/PowerPoint file 123\nWord file 123/Excel file 123/PowerPoint file 123\ncopy and paste are allowed, in other words intra file copy and paste is allowed.\nWord file 123/Excel File 123/PowerPoint file 123\nWord file 789/Excel file 789/PowerPoint file 789\ncopy and paste are blocked, in other words inter file copy and paste is blocked.\nWord file 789/Excel file 789/PowerPoint file 789\nWord file 123/Excel File 123/PowerPoint file 123\ncopy and paste are allowed\nWord file 123/Excel file 123/PowerPoint file 123\nNotepad file ABC\ncopy and paste are blocked\nNotepad file XYZ\nany\ncopy is blocked\nNotepad file ABC\nany\ncopy and paste are allowed\nNote\nWhen a DLP rule that blocks copying is applied to an open file, copying from any other file within the same application (even files with no DLP rules applied) is restricted while the DLP blocked file is open.\nBest practice for endpoint DLP policies\nSay you want to block all items that contain credit card numbers from leaving endpoints of Finance department users. We recommend:\nCreate a policy and scope it to endpoints and to that group of users.\nCreate a rule in the policy that detects the type of information that you want to protect. In this case, set\ncontent contains\nto\nSensitive information type\n*, and select\nCredit Card\n.\nSet the actions for each activity to\nBlock\n.\nFor more information on designing your DLP policies, see\nDesign a data loss prevention policy\n.\nNote\nIn Microsoft Purview, DLP policy evaluation of sensitive items occurs centrally, so there's no time lag for policies and policy updates to be distributed to individual devices. When a policy is updated in Microsoft Purview portal, it generally takes about an hour for those updates to be synchronized across the service. Once policy updates are synchronized, items on targeted devices are automatically reevaluated the next time they're accessed or modified. In preview, you can also use\non-demand classification\nto identify and classifies sensitive content in historical data stored in SharePoint and OneDrive. For Authorized Groups changes, the policy needs 24 hours to sync.\nMonitored files\nFiles monitored via policy\nEndpoint DLP monitors these file types policy in Windows 10, 11:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .obd, obt\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .xlb, .xlc, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pptm, .pps, .ppsx, .ppsm, .pot, .potx, .potm, .ppam, .pos\nArchive\nZip, RAR, 7z, TAR\n.zip, .rar, .7z, .tar, .gz, .arj, .bz2, .cab, .chm, .lha, .lzh, .lzma, .mhtml, .xar, .xz\nAdobe PDF\nPDF\n.pdf\nText\nText\n.asm, .bat, .c, .cmd, .cpp, .cs, .csv, .cxx, .def, .dic, .h, .hpp, .hxx, .idl, .inc, .inx, .java, .m3u, .mpx, .php, .pl, .pos, .txt, .vcf, .vcs\nHTML\nHTML\n.ascx, .asp, .aspx, .hta, .htm, .htw, .htx, .jhtml, .html\nJSON\nJSON\n.json\nMail\nMail\n.eml, .msg, .nws\nXML\nXML\n.jsp, .mspx\nMicrosoft Office xml\nMicrosoft Office xml\n.powerpointml\nProtected Files\nPFile\n.pbmp, .pgif, .pjfif, .pjpe, .pjpeg, .pjpg, .ppng, .ptif, .ptiff, .ptxt, .pxla, .pxlam, .pxml\nOther\nOther\n.dfx, .dxf, .fluid, .mime, .pointpub, .rtf, .vtt\nEndpoint DLP monitors these file types policy in the latest three major releases of macOS:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .xlb, .xlc, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pptm, .pps, .ppsx, .ppsm, .pot, .potx, .potm, .ppam\nArchive\nZip, RAR, 7z, TAR\n.zip, .rar, .7z, .tar\nAdobe PDF\nPDF\n.pdf\nText\nText\n.asm, .bat, .c, .cmd, .cpp, .cs, .csv, .cxx, .def, .dic, .h, .hpp, .hxx, .idl, .inc, .inx, .java, .m3u, .mpx, .php, .pl, .pos, .txt, .vcf, .vcs\nHTML\nHTML\n.ascx, .asp, .aspx, .hta, .htm, .htw, .htx, .jhtml, .html, .mht\nJSON\nJSON\n.json\nMail\nMail\n.eml, .msg, .nws\nXML\nXML\n.jsp, .mspx\nMicrosoft Office xml\nMicrosoft Office xml\n.powerpointml\nOther\nOther\n.pointpub, .rtf, .vtt\nThese file types can be monitored through policy settings in Windows 10, 11 and macOS devices, if\nOCR\nis enabled:\n.jpg, .png, .tif, .tiff, .bmp, .jpeg\nEndpoint DLP scans files with the specified extensions listed above. If you need to protect or monitor files not listed, use the 'Apply restrictions to only unsupported file extensions' feature. The key differences between this feature and the\nFile extension is\ncondition are:\nEndpoint DLP scans content for the\nFile extension is\ncondition, allowing you to see Sensitive info type values in events or alerts. In contrast, the\nApply restrictions to only unsupported file extensions\nfeature does not scan file content.\nThe\nFile extension is\ncondition triggers content scanning, which may consume higher machine resources like CPU and memory, potentially causing performance issues for some file types.\nFor more details on the\nApply restrictions to only unsupported file extensions\nfeature, refer to the following resources:\nHelp protect files that Endpoint Data Loss Prevention doesn't scan\nHelp protect against sharing of a defined set of unsupported files\nFiles audited regardless of policy match\nActivities can be audited on these file types in Windows 10, 11, and in the latest three major releases of macOS, even if no policy match exists:\nWindows 10, 11\nmacOS\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx, .pbix, .pdf, .csv, .tsv, .zip, .rar, .7z, .tar, .war, .gz, .dlp\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx, .pbix, .pdf, .csv, .tsv\nNote\nThese file types can be audited, regardless of a policy match, in Windows 10, 11 and macOS devices, so long as\nOCR\nis enabled:\n.jpg, .png, .tif, .tiff, .bmp, .jpeg\nImportant\nFor information about the Adobe requirements for using Microsoft Purview Data Loss Prevention (DLP) features with PDF files, see this article from Adobe:\nMicrosoft Purview Information Protection Support in Acrobat\n.\nIf you only want to monitor data from policy matches, you can turn off the\nAlways audit file activity for devices\nin the\nData loss prevention settings\n>\nEndpoint settings\n.\nIf the\nAlways audit file activity for devices\nsetting is on, activities on any Word, PowerPoint, Excel, PDF, and .csv files are always audited, even if the device isn't targeted by any policy.\nTo ensure activities are audited for all supported file types, create a\ncustom DLP policy\n.\nEndpoint DLP monitors activity-based on MIME type, so activities are captured, even if the file extension is changed, for these files types:\nAfter the extension is changed to any other file extension:\n.doc\n.docx\n.xls\n.xlsx\n.ppt\n.pptx\n.pdf\nIf the extension is changed only to supported file extensions:\n.txt\n.msg\n.rtf\n.c\n.cpp\n.h\n.cs\n.java\n.tsv\nUnsupported File types\nEndpoint DLP does not support monitoring for the following file types:\n.exe\n.dll\n.sys\n.lib\n.obj\n.mui\n.spl\n.drv\n.pf\n.crdownload\n.ini\nWhat's different in Endpoint DLP\nThere are a few extra concepts that you need to be aware of before you dig into Endpoint DLP.\nEnabling Device management\nDevice management is the functionality that enables the collection of telemetry from devices and brings it into Microsoft Purview solutions like Endpoint DLP and\ninsider risk management\n. You need to onboard all the devices you want to use as locations in your DLP policies.\nOnboarding and offboarding are handled via scripts that you download from the device management center. The device management center has custom scripts for each of the following deployment methods:\nLocal script (up to 10 machines)\nGroup policy\nSystem Center Configuration Manager (version 1610 or later)\nMobile Device Management/Microsoft Intune\nVDI onboarding scripts for non-persistent machines\nUse the procedures in\nGetting started with Microsoft 365 Endpoint DLP\nto onboard devices.\nOnboarding devices to Defender also onboards them to DLP. So, if you have onboarded devices through\nMicrosoft Defender for Endpoint\n, those devices show up automatically in the list of devices. You need only\nTurn on device monitoring\nto use endpoint DLP.\nViewing Endpoint DLP data\nYou can view alerts related to DLP policies enforced on endpoint devices by going to the\nDLP Alerts Management Dashboard\nand\nInvestigate data loss incidents with Microsoft Defender XDR\n.\nYou can also view details of the associated event, with rich metadata, in the same dashboard\nOnce a device is onboarded, information about audited activities flows into Activity explorer even before you configure and deploy any DLP policies that have devices as a location.\nEndpoint DLP collects extensive information on audited activity.\nFor example, if a file is copied to removable USB media, you'd see these attributes in the activity details:\nactivity type\nclient IP\ntarget file path\nhappened timestamp\nfile name\nuser\nfile extension\nfile size\nsensitive information type (if applicable)\nsha1 value\nsha256 value\nprevious file name\nlocation\nparent\nfilepath\nsource location type\nplatform\ndevice name\ndestination location type\napplication that performed the copy\nMicrosoft Defender for Endpoint device ID (if applicable)\nremovable media device manufacturer\nremovable media device model\nremovable media device serial number\nWhy are all endpoint policies on all onboarded devices?\nA device can support multiple user accounts. Because endpoint policies are scoped to users, different users of the device may have different policies scoped to them. Therefore, the device must have access to all endpoint DLP policies in order to evaluate items. All devices that are onboarded into Purview are scanned regardless if the user is in scope.\nEndpoint DLP and offline devices\nWhen a Windows endpoint device is offline, existing policies continue to be enforced on existing files. Additionally, with just-in-time protection enabled and in \"block\" mode, when a new\nfile\nis created on an offline device, the file is still prevented from being shared until the device connects to the data classification service and evaluation completes. If a new\npolicy\nis created on the server, or an existing policy is modified, those changes are updated on the device once it reconnects to the internet.\nImportant\nThis functionality isn't supported on macOS endpoint devices.\nConsider the following use cases.\nPolicies that have been pushed to a device will continue to be applied to files already classified as sensitive even after the device goes offline.\nPolicies that are updated while a device is offline won't be pushed to that device. Similarly, such policies won't be enforced on that device, until the device is back online. However, the outdated policy that exists on the offline device will still be enforced.\nJust-in-time protection\nIf notifications are configured to display, they'll always display when DLP policies are triggered, regardless of whether or not the device is online.\nNote\nWhile policies that have already been pushed to an offline device are enforced, the enforcement events don't appear in activity explorer until the device is back online.\nDLP policies regularly sync to endpoint devices. If a device is offline, the policies can't be synchronized. In this case, the\nDevices list\nreflects that the device is out of sync with the policies in on the server.\nJust-in-time protection\nJust-in-time protection blocks egress activities on these monitored files until policy evaluation completes successfully:\nItems that have never been evaluated.\nItems on which the evaluation has gone stale. These are previously evaluated items that haven't been reevaluated by the current, updated cloud versions of the policies.\nBefore you can deploy just-in-time protection, you must first deploy Antimalware Client version 4.18.23080 or later.\nNote\nFor machines with an outdated version of the Antimalware Client, we recommend disabling just-in-time protection by installing one of the following KBs:\nWindows 10 -\nKB5032278\nWindows 11 -\nKB5032288\nTo enable Just-in-time protection in the Microsoft Purview Portal, select\nSettings\nin the left navigation pane, choose\nJust-in-time protection\n, and configure your desired settings.\nChoose which locations to monitor:\nSelect\nDevices\n.\nChoose\nEdit\n.\nIn the flyout pane, select the scope of accounts and distribution groups you want to apply just-in-time protection to. Keep in mind that, while policy evaluation is processing, Endpoint DLP blocks all egress activities for each user whose account is in the selected scope. Endpoint DLP audits the egress activities for all user accounts that are excluded (via the Exclude setting) or are otherwise not in scope.\nJust-in-time protection is supported on macOS devices running the three latest major versions.\nFallback action in case of failure\n: This configuration specifies the enforcement mode that DLP should apply when the policy evaluation doesn't complete. No matter which value you select, the relevant telemetry shows in activity explorer.\nTip\nTips for maximizing user productivity:\nConfigure and deploy your Endpoint DLP policies to your devices before enabling just-in-time protection to prevent unnecessarily blocking user activity during policy evaluation.\nMake sure to carefully configure your settings for egress activities. Just-in-time protection blocks an egress activity only when that activity has one or more\nBlock\nor\nBlock with override\npolicies. This means that egress activities that aren't blocked will only be audited, even for users included in the scope of the applicable policies.\nFor more information, see\nGet started with Just-In-Time protection.\n.\nNext steps\nNow that you've learned about Endpoint DLP, your next steps are:\nOnboard Windows 10 or Windows 11 devices into Microsoft Purview overview\nOnboard macOS devices into Microsoft Purview overview\nConfigure endpoint data loss prevention settings\nUsing Endpoint data loss prevention\nSee also\nGetting started with Microsoft Endpoint data loss prevention\nUsing Microsoft Endpoint data loss prevention\nLearn about data loss prevention\nCreate and Deploy data loss prevention policies\nGet started with Activity explorer\nMicrosoft Defender for Endpoint\nInsider risk management\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Endpoint DLP",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/endpoint-dlp-learn-about": {
      "content_hash": "sha256:8f1c9dc972d15a7ae87ab587a4ef0e95e5ee73667c41d65f5290adaa025353e1",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about Endpoint data loss prevention\nFeedback\nSummarize this article for me\nYou can use Microsoft Purview Data Loss Prevention (DLP) to monitor the actions that are being taken on items you've determined to be sensitive and to help prevent the unintentional sharing of those items.\nEndpoint data loss prevention\n(Endpoint DLP) extends the activity monitoring and protection capabilities of DLP to Windows 10/11, macOS (the three latest released major versions) devices, and Windows certain server versions. Once devices are onboarded into the Microsoft Purview solutions, the information about what users are doing with sensitive items is made visible in\nactivity explorer\n. You can then enforce protective actions on those items via\nDLP policies\n.\nWhen are files classified by Endpoint DLP?\nEndpoint DLP classifies files under the following conditions:\nCreation or Modification:\nEvery time a file is created or modified, it is fully scanned for sensitive information types (SITs) and labels. The file is then evaluated for matches against DLP policies and rules.\nReading an Already Classified File:\nWhen an already classified file is read, Endpoint DLP checks for any changes to the policies, rules, or SITs. If there is a change in the DLP configuration, it re-evaluates the policies and rules, but it will not re-extract the text.\nTip\nIf you're looking for device control for removable storage, see\nMicrosoft Defender for Endpoint Device Control Removable Storage Access Control\n.\nNote\nEndpoint DLP cannot detect the sensitivity label from another tenant on a document.\nEndpoint DLP Windows 10/11 and macOS support\nEndpoint DLP allows you to onboard devices running the following versions of Windows Server:\nWindows Server 2019 (\nNovember 14, 2023âKB5032196 (OS Build 17763.5122) - Microsoft Support\n)\nWindows Server 2022 (\nNovember 14, 2023 Security update (KB5032198) - Microsoft Support\n)\nNote\nInstalling the supported Windows Server KBs disables the\nClassification\nfeature on the server. This means that Endpoint DLP won't classify files on the server. However, Endpoint DLP will still protect those files on the server that were classified before those KBs were installed on server. To ensure this protection, install Microsoft Defender version 4.18.23100 (October 2023) or later.\nBy default, Endpoint DLP isn't enabled for Windows servers when they're initially onboarded. Before you can see Endpoint DLP events for your servers in Activity Explorer, you must first\nEnable Endpoint DLP for Windows Servers\n.\nOnce properly configured, the same data loss protection policies can be automatically applied to both Windows PCs and Windows servers.\nSetting\nSubsetting\nWindows 10, 1809 and later, Windows 11, Windows Server 2019, Windows Server 2022 (21H2 onwards) for Endpoints (X64)\nmacOS (three latest released versions)\nNotes\nAdvanced classification scanning and protection\nAllocated bandwidth limits\nSupported\nSupported\nAdvanced classification enables these features for macOS: -\nDocument Fingerprinting\n-\nExact data match based sensitive information types\n-\nTrainable classifiers\n-\nLearn about named entities\nFile path exclusions for Windows\nn/a\nSupported\nn/a\nFile path exclusions for Mac\nn/a\nn/a\nSupported\nmacOS includes a recommended list of exclusions that is on by default\nSetup evidence collection for file activities on devices\nSet evidence cache on device\nSupported\nPreview\nNetwork share coverage and exclusions\nn/a\nSupported\nSupported\nRestricted apps and app groups\nRestricted app groups\nSupported\nSupported\nRestricted apps and app groups\nRestricted apps\nSupported\nSupported\nRestricted apps and app groups\nAuto-quarantine settings\nSupported\nSupported\nUnallowed Bluetooth apps\nn/a\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nUnallowed browsers\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nService domains\nSupported\nSupported\nBrowser and domain restrictions to sensitive data\nSensitive service domain groups\nSupported\nSupported\nAdditional settings for Endpoint DLP\nBusiness justification in policy tips\nSupported\nSupported\nAlways audit file activity for devices\nn/a\nSupported\nSupported\nPrinter groups\nn/a\nSupported\nSupported\nRemovable USB device groups\nn/a\nSupported\nSupported\nNetwork share groups\nn/a\nSupported\nSupported\nVPN settings\nn/a\nSupported\nNot supported\nScoping DLP policies (preview)\nIn preview, DLP policies for endpoints are scoped by users, and devices. For an endpoint policy to be applied, both the user and the device must be in the policy scope. This means that if a user is in the policy scope, but the device isn't, the policy won't be applied. Similarly, if a device is in the policy scope, but the user isn't, the policy won't be applied.\nFor more information on scoping endpoint DLP policies, see\nDevice scoping\n.\nOther settings\nSetting\nWindows 10/11, Windows 10, 1809 and later, Windows 11\nWindows Server 2019, Windows Server 2022 (21H2 onwards) for Endpoints (X64)\nmacOS (three latest released versions)\nArchive file\nSupported\nSupported\nSupported\nFile type and File extension\nSupported\nSupported\nSupported\nEnable Endpoint DLP for Windows Servers\nNot supported\nSupported\nNot supported\nNote\nEndpoint DLP is not supported on Windows Servers configured as Domain Controllers or Windows Servers with the Core Server option selected during installation.\nEndpoint activities you can monitor and take action on\nEndpoint DLP enables you to audit and manage the following types of activities users take on sensitive items that are physically stored Windows 10, Windows 11, or macOS devices.\nActivity\nDescription\nWindows 10 (21H2, 22H2), Windows 11 (21H2, 22H2), Windows Server 2019, Server 2022 (21H2 onwards) for Endpoints (X64)\nWindows 11 (21H2, 22H2) for Endpoints (ARM64)\nmacOS three latest released versions\nAuditable/\nRestrictable\nUpload to a restricted cloud service domain or access from an unallowed browser\nDetects when a user attempts to upload an item to a restricted service domain or access an item through a browser. If they're using an unallowed browser, the upload activity is blocked and the user is redirected to use Microsoft Edge. Microsoft Edge then either allows or blocks the upload or access based on the DLP policy configuration. You can block, warn, or audit when protected files can be uploaded or prevented from being uploaded to cloud services based on the allow/unallowed domains list in\nData loss prevention settings\n. When the configured action is set to warn or block, other browsers (defined on the unallowed browsers list under\nData loss prevention settings\n) are blocked from accessing the file.\nSupported\nSupported\nSupported\nAuditable and restrictable\nPaste to supported browsers\nDetects when a user attempts to paste content to a restricted service domain. Evaluation is performed on the content that is being pasted. This evaluation is independent of how the source item that the content came from is classified.\nSupported\nSupported\nPreview\nAuditable and restrictable\nCopy to clipboard\nWhen a user attempts to copy content from a protected file, you can block, block with override, or audit the copying of protected files to a clipboard on an endpoint device. If the rule is configured to\nBlock\nor\nBlock with override\ncopying is blocked when the source content is sensitive except when the destination is within the same Microsoft 365 Office app. This activity also applies to redirected clipboards when using Azure Virtual Desktop with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy to USB removable device\nWhen this activity is detected, you can block, warn, or audit the copying or moving of protected files from an endpoint device to USB removable media.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy to a network share\nWhen this activity is detected, you can block, warn, or audit the copying or moving of protected files from an endpoint device to any network share, including redirected USB devices that are displayed as network shares on an Azure Virtual Desktop with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nPrint\nWhen this activity is detected, you can block, warn, or audit the printing of protected files from an endpoint device. This activity also applies to redirected printers when using Azure Virtual Desktop together with Windows 365.\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy or move using unallowed Bluetooth app\nDetects when a user attempts to copy an item to an unallowed Bluetooth app (as defined in the list of unallowed Bluetooth apps in\nData loss prevention settings\n>\nEndpoint settings\n).\nSupported\nSupported\nSupported\nAuditable and restrictable\nCopy or move using RDP\nDetects when a user attempts to copy an item to a remote desktop session.\nSupported\nSupported\nNot supported\nAuditable and restrictable\nCreate an item\nDetects the creation of an item.\nSupported\nSupported\nSupported\nAuditable\nRename an item\nDetects the renaming of an item.\nSupported\nSupported\nSupported\nAuditable\nAccess by restricted apps\nDetects when an application that is on the restricted apps list (as defined in\nrestricted apps and app groups\n) attempts to access protected files on an endpoint device.\nSupported\nSupported\nSupported\nCreate Windows Recall snapshots (in preview)\nDetects when there is an item or Teams message that contains a sensitive information type or has a senstivity label applied that would be included in a\nWindows Recall\nsnapshot.\nSupported\nNot supported\nNot supported\nAuditable and restrictable\nCopy to clipboard behavior\nWhen you configure a rule to\nBlock\nor\nBlock with override\nwhen a user attempts the Copy to clipboard activity on content from a file that matches the policy, end users see this behavior with these configurations:\nWord file 123 contains sensitive information that matches the copy to clipboard Block rule.\nExcel file 123 contains sensitive information that matches the copy to clipboard Block rule.\nPowerPoint file 123 contains sensitive information that matches the copy to clipboard Block rule.\nWord file 789 doesn't contain sensitive information.\nExcel file 789 doesn't contain sensitive information.\nPowerPoint file 789 doesn't contain sensitive information.\nNotepad (or any non Microsoft Office based app or process) file XYZ contains sensitive information that matches the copy to clipboard Block rule.\nNotepad (or any non Microsoft Office based app or process) file ABC doesn't contain sensitive information.\nSource\nDestination\nBehavior\nWord file 123/Excel file 123/PowerPoint file 123\nWord file 123/Excel file 123/PowerPoint file 123\ncopy and paste are allowed, in other words intra file copy and paste is allowed.\nWord file 123/Excel File 123/PowerPoint file 123\nWord file 789/Excel file 789/PowerPoint file 789\ncopy and paste are blocked, in other words inter file copy and paste is blocked.\nWord file 789/Excel file 789/PowerPoint file 789\nWord file 123/Excel File 123/PowerPoint file 123\ncopy and paste are allowed\nWord file 123/Excel file 123/PowerPoint file 123\nNotepad file ABC\ncopy and paste are blocked\nNotepad file XYZ\nany\ncopy is blocked\nNotepad file ABC\nany\ncopy and paste are allowed\nNote\nWhen a DLP rule that blocks copying is applied to an open file, copying from any other file within the same application (even files with no DLP rules applied) is restricted while the DLP blocked file is open.\nBest practice for endpoint DLP policies\nSay you want to block all items that contain credit card numbers from leaving endpoints of Finance department users. We recommend:\nCreate a policy and scope it to endpoints and to that group of users.\nCreate a rule in the policy that detects the type of information that you want to protect. In this case, set\ncontent contains\nto\nSensitive information type\n*, and select\nCredit Card\n.\nSet the actions for each activity to\nBlock\n.\nFor more information on designing your DLP policies, see\nDesign a data loss prevention policy\n.\nNote\nIn Microsoft Purview, DLP policy evaluation of sensitive items occurs centrally, so there's no time lag for policies and policy updates to be distributed to individual devices. When a policy is updated in Microsoft Purview portal, it generally takes about an hour for those updates to be synchronized across the service. Once policy updates are synchronized, items on targeted devices are automatically reevaluated the next time they're accessed or modified. In preview, you can also use\non-demand classification\nto identify and classifies sensitive content in historical data stored in SharePoint and OneDrive. For Authorized Groups changes, the policy needs 24 hours to sync.\nMonitored files\nFiles monitored via policy\nEndpoint DLP monitors these file types policy in Windows 10, 11:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .obd, obt\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .xlb, .xlc, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pptm, .pps, .ppsx, .ppsm, .pot, .potx, .potm, .ppam, .pos\nArchive\nZip, RAR, 7z, TAR\n.zip, .rar, .7z, .tar, .gz, .arj, .bz2, .cab, .chm, .lha, .lzh, .lzma, .mhtml, .xar, .xz\nAdobe PDF\nPDF\n.pdf\nText\nText\n.asm, .bat, .c, .cmd, .cpp, .cs, .csv, .cxx, .def, .dic, .h, .hpp, .hxx, .idl, .inc, .inx, .java, .m3u, .mpx, .php, .pl, .pos, .txt, .vcf, .vcs\nHTML\nHTML\n.ascx, .asp, .aspx, .hta, .htm, .htw, .htx, .jhtml, .html\nJSON\nJSON\n.json\nMail\nMail\n.eml, .msg, .nws\nXML\nXML\n.jsp, .mspx\nMicrosoft Office xml\nMicrosoft Office xml\n.powerpointml\nProtected Files\nPFile\n.pbmp, .pgif, .pjfif, .pjpe, .pjpeg, .pjpg, .ppng, .ptif, .ptiff, .ptxt, .pxla, .pxlam, .pxml\nOther\nOther\n.dfx, .dxf, .fluid, .mime, .pointpub, .rtf, .vtt\nEndpoint DLP monitors these file types policy in the latest three major releases of macOS:\nFile Type\nFormat\nMonitored file extensions\nWord processing\nWord\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb\nSpreadsheet\nExcel, CSV, TSV\n.xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .xlb, .xlc, .csv, .tsv\nPresentation\nPowerPoint\n.ppt, .pptx, .pptm, .pps, .ppsx, .ppsm, .pot, .potx, .potm, .ppam\nArchive\nZip, RAR, 7z, TAR\n.zip, .rar, .7z, .tar\nAdobe PDF\nPDF\n.pdf\nText\nText\n.asm, .bat, .c, .cmd, .cpp, .cs, .csv, .cxx, .def, .dic, .h, .hpp, .hxx, .idl, .inc, .inx, .java, .m3u, .mpx, .php, .pl, .pos, .txt, .vcf, .vcs\nHTML\nHTML\n.ascx, .asp, .aspx, .hta, .htm, .htw, .htx, .jhtml, .html, .mht\nJSON\nJSON\n.json\nMail\nMail\n.eml, .msg, .nws\nXML\nXML\n.jsp, .mspx\nMicrosoft Office xml\nMicrosoft Office xml\n.powerpointml\nOther\nOther\n.pointpub, .rtf, .vtt\nThese file types can be monitored through policy settings in Windows 10, 11 and macOS devices, if\nOCR\nis enabled:\n.jpg, .png, .tif, .tiff, .bmp, .jpeg\nEndpoint DLP scans files with the specified extensions listed above. If you need to protect or monitor files not listed, use the 'Apply restrictions to only unsupported file extensions' feature. The key differences between this feature and the\nFile extension is\ncondition are:\nEndpoint DLP scans content for the\nFile extension is\ncondition, allowing you to see Sensitive info type values in events or alerts. In contrast, the\nApply restrictions to only unsupported file extensions\nfeature does not scan file content.\nThe\nFile extension is\ncondition triggers content scanning, which may consume higher machine resources like CPU and memory, potentially causing performance issues for some file types.\nFor more details on the\nApply restrictions to only unsupported file extensions\nfeature, refer to the following resources:\nHelp protect files that Endpoint Data Loss Prevention doesn't scan\nHelp protect against sharing of a defined set of unsupported files\nFiles audited regardless of policy match\nActivities can be audited on these file types in Windows 10, 11, and in the latest three major releases of macOS, even if no policy match exists:\nWindows 10, 11\nmacOS\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx, .pbix, .pdf, .csv, .tsv, .zip, .rar, .7z, .tar, .war, .gz, .dlp\n.doc, .docx, .docm, .dot, .dotx, .dotm, .docb, .xls, .xlsx, .xlt, .xlm, .xlsm, .xltx, .xltm, .xlsb, .xlw, .ppt, .pptx, .pos, .pps, .pptm, .potx, .potm, .ppam, .ppsx, .pbix, .pdf, .csv, .tsv\nNote\nThese file types can be audited, regardless of a policy match, in Windows 10, 11 and macOS devices, so long as\nOCR\nis enabled:\n.jpg, .png, .tif, .tiff, .bmp, .jpeg\nImportant\nFor information about the Adobe requirements for using Microsoft Purview Data Loss Prevention (DLP) features with PDF files, see this article from Adobe:\nMicrosoft Purview Information Protection Support in Acrobat\n.\nIf you only want to monitor data from policy matches, you can turn off the\nAlways audit file activity for devices\nin the\nData loss prevention settings\n>\nEndpoint settings\n.\nIf the\nAlways audit file activity for devices\nsetting is on, activities on any Word, PowerPoint, Excel, PDF, and .csv files are always audited, even if the device isn't targeted by any policy.\nTo ensure activities are audited for all supported file types, create a\ncustom DLP policy\n.\nEndpoint DLP monitors activity-based on MIME type, so activities are captured, even if the file extension is changed, for these files types:\nAfter the extension is changed to any other file extension:\n.doc\n.docx\n.xls\n.xlsx\n.ppt\n.pptx\n.pdf\nIf the extension is changed only to supported file extensions:\n.txt\n.msg\n.rtf\n.c\n.cpp\n.h\n.cs\n.java\n.tsv\nUnsupported File types\nEndpoint DLP does not support monitoring for the following file types:\n.exe\n.dll\n.sys\n.lib\n.obj\n.mui\n.spl\n.drv\n.pf\n.crdownload\n.ini\nWhat's different in Endpoint DLP\nThere are a few extra concepts that you need to be aware of before you dig into Endpoint DLP.\nEnabling Device management\nDevice management is the functionality that enables the collection of telemetry from devices and brings it into Microsoft Purview solutions like Endpoint DLP and\ninsider risk management\n. You need to onboard all the devices you want to use as locations in your DLP policies.\nOnboarding and offboarding are handled via scripts that you download from the device management center. The device management center has custom scripts for each of the following deployment methods:\nLocal script (up to 10 machines)\nGroup policy\nSystem Center Configuration Manager (version 1610 or later)\nMobile Device Management/Microsoft Intune\nVDI onboarding scripts for non-persistent machines\nUse the procedures in\nGetting started with Microsoft 365 Endpoint DLP\nto onboard devices.\nOnboarding devices to Defender also onboards them to DLP. So, if you have onboarded devices through\nMicrosoft Defender for Endpoint\n, those devices show up automatically in the list of devices. You need only\nTurn on device monitoring\nto use endpoint DLP.\nViewing Endpoint DLP data\nYou can view alerts related to DLP policies enforced on endpoint devices by going to the\nDLP Alerts Management Dashboard\nand\nInvestigate data loss incidents with Microsoft Defender XDR\n.\nYou can also view details of the associated event, with rich metadata, in the same dashboard\nOnce a device is onboarded, information about audited activities flows into Activity explorer even before you configure and deploy any DLP policies that have devices as a location.\nEndpoint DLP collects extensive information on audited activity.\nFor example, if a file is copied to removable USB media, you'd see these attributes in the activity details:\nactivity type\nclient IP\ntarget file path\nhappened timestamp\nfile name\nuser\nfile extension\nfile size\nsensitive information type (if applicable)\nsha1 value\nsha256 value\nprevious file name\nlocation\nparent\nfilepath\nsource location type\nplatform\ndevice name\ndestination location type\napplication that performed the copy\nMicrosoft Defender for Endpoint device ID (if applicable)\nremovable media device manufacturer\nremovable media device model\nremovable media device serial number\nWhy are all endpoint policies on all onboarded devices?\nA device can support multiple user accounts. Because endpoint policies are scoped to users, different users of the device may have different policies scoped to them. Therefore, the device must have access to all endpoint DLP policies in order to evaluate items. All devices that are onboarded into Purview are scanned regardless if the user is in scope.\nEndpoint DLP and offline devices\nWhen a Windows endpoint device is offline, existing policies continue to be enforced on existing files. Additionally, with just-in-time protection enabled and in \"block\" mode, when a new\nfile\nis created on an offline device, the file is still prevented from being shared until the device connects to the data classification service and evaluation completes. If a new\npolicy\nis created on the server, or an existing policy is modified, those changes are updated on the device once it reconnects to the internet.\nImportant\nThis functionality isn't supported on macOS endpoint devices.\nConsider the following use cases.\nPolicies that have been pushed to a device will continue to be applied to files already classified as sensitive even after the device goes offline.\nPolicies that are updated while a device is offline won't be pushed to that device. Similarly, such policies won't be enforced on that device, until the device is back online. However, the outdated policy that exists on the offline device will still be enforced.\nJust-in-time protection\nIf notifications are configured to display, they'll always display when DLP policies are triggered, regardless of whether or not the device is online.\nNote\nWhile policies that have already been pushed to an offline device are enforced, the enforcement events don't appear in activity explorer until the device is back online.\nDLP policies regularly sync to endpoint devices. If a device is offline, the policies can't be synchronized. In this case, the\nDevices list\nreflects that the device is out of sync with the policies in on the server.\nJust-in-time protection\nJust-in-time protection blocks egress activities on these monitored files until policy evaluation completes successfully:\nItems that have never been evaluated.\nItems on which the evaluation has gone stale. These are previously evaluated items that haven't been reevaluated by the current, updated cloud versions of the policies.\nBefore you can deploy just-in-time protection, you must first deploy Antimalware Client version 4.18.23080 or later.\nNote\nFor machines with an outdated version of the Antimalware Client, we recommend disabling just-in-time protection by installing one of the following KBs:\nWindows 10 -\nKB5032278\nWindows 11 -\nKB5032288\nTo enable Just-in-time protection in the Microsoft Purview Portal, select\nSettings\nin the left navigation pane, choose\nJust-in-time protection\n, and configure your desired settings.\nChoose which locations to monitor:\nSelect\nDevices\n.\nChoose\nEdit\n.\nIn the flyout pane, select the scope of accounts and distribution groups you want to apply just-in-time protection to. Keep in mind that, while policy evaluation is processing, Endpoint DLP blocks all egress activities for each user whose account is in the selected scope. Endpoint DLP audits the egress activities for all user accounts that are excluded (via the Exclude setting) or are otherwise not in scope.\nJust-in-time protection is supported on macOS devices running the three latest major versions.\nFallback action in case of failure\n: This configuration specifies the enforcement mode that DLP should apply when the policy evaluation doesn't complete. No matter which value you select, the relevant telemetry shows in activity explorer.\nTip\nTips for maximizing user productivity:\nConfigure and deploy your Endpoint DLP policies to your devices before enabling just-in-time protection to prevent unnecessarily blocking user activity during policy evaluation.\nMake sure to carefully configure your settings for egress activities. Just-in-time protection blocks an egress activity only when that activity has one or more\nBlock\nor\nBlock with override\npolicies. This means that egress activities that aren't blocked will only be audited, even for users included in the scope of the applicable policies.\nFor more information, see\nGet started with Just-In-Time protection.\n.\nNext steps\nNow that you've learned about Endpoint DLP, your next steps are:\nOnboard Windows 10 or Windows 11 devices into Microsoft Purview overview\nOnboard macOS devices into Microsoft Purview overview\nConfigure endpoint data loss prevention settings\nUsing Endpoint data loss prevention\nSee also\nGetting started with Microsoft Endpoint data loss prevention\nUsing Microsoft Endpoint data loss prevention\nLearn about data loss prevention\nCreate and Deploy data loss prevention policies\nGet started with Activity explorer\nMicrosoft Defender for Endpoint\nInsider risk management\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Endpoint DLP Overview",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/endpoint-dlp-getting-started": {
      "content_hash": "sha256:e776d53f309530465a97fe6b669ad94fc5164ba7c1051c15ac06549d54b10ccd",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGet started with endpoint data loss prevention\nFeedback\nSummarize this article for me\nEndpoint data loss prevention (Endpoint DLP) is part of the Microsoft Purview Data Loss Prevention (DLP) suite of features you can use to discover and protect sensitive items across Microsoft 365 services. For more information about all of Microsoft's DLP offerings, see\nLearn about data loss prevention\n. To learn more about Endpoint DLP, see\nLearn about Endpoint data loss prevention\nMicrosoft Endpoint DLP allows you to monitor\nonboarded Windows 10, and Windows 11\nand\nonboarded macOS devices\nrunning any of the three latest released versions. Once a device is onboarded, DLP detects when sensitive items are used and shared. This gives you the visibility and control you need to ensure that they're used and protected properly, and to help prevent risky behavior that might compromise them.\nTip\nGet started with Microsoft Security Copilot to explore new ways to work smarter and faster using the power of AI. Learn more about\nMicrosoft Security Copilot in Microsoft Purview\n.\nBefore you begin\nSKU/subscriptions licensing\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nConfigure proxy on the Windows 10 or Windows 11 device\nIf you're onboarding Windows 10 or Windows 11 devices, check to make sure that the device can communicate with the cloud DLP service. For more information, see,\nConfigure device proxy and internet connection settings for Information Protection\n.\nWindows 10 and Windows 11 Onboarding procedures\nFor a general introduction to onboarding Windows devices, see:\nOnboard Windows devices into Microsoft 365 overview\nFor specific guidance to onboarding Windows devices, see:\nArticle\nDescription\nOnboard Windows 10 or 11 devices using Group Policy\nUse Group Policy to deploy the configuration package on devices.\nOnboard Windows 10 or 11 devices using Microsoft Endpoint Configuration Manager\nYou can use either use Microsoft Endpoint Configuration Manager (current branch) version 1606 or Microsoft Endpoint Configuration Manager (current branch) version 1602 or earlier to deploy the configuration package on devices.\nOnboard Windows 10 or 11 devices using Microsoft Intune\nUse Microsoft Intune to deploy the configuration package on device.\nOnboard Windows 10 or 11 devices using a local script\nLearn how to use the local script to deploy the configuration package on endpoints.\nOnboard non-persistent virtual desktop infrastructure (VDI) devices\nLearn how to use the configuration package to configure VDI devices.\nEndpoint DLP support for virtualized environments\nYou can onboard virtual machines as monitored devices in Microsoft Purview portal. There's no change to the onboarding procedures listed above.\nThe table that follows lists the virtual operating systems that are supported by virtualization environments.\nVirtualization\nplatform\nWindows 10\nWindows 11\nWindows Server 2019\nWindows Server 2022\n21H2, 22H2, Data Center\nAzure virtual desktop (AVD)\nSingle session supported for 21H2, 22H2\nMulti session supported for 21H2, 22H2\nSingle session supported for 21H2, 22H2\nMulti session supported for 21H2, 22H2\nSingle session and Multi session supported.\nSupported\nWindows 365\nSupported for 21H2, 22H2\nSupported for 21H2, 22H2\nNot applicable\nNot applicable\nCitrix Virtual Apps and Desktops 7 (2209 and higher)\nSingle session supported for 21H2, 22H2\nMulti session supported for 21H2, 22H2\nSingle session supported for 21H2, 22H2\nMulti session supported for 21H2, 22H2\nSupported\nSupported\nAmazon workspaces\nSingle session supported for 21H2, 22H2\nNot applicable\nWindows 10 powered by Windows Server 2019\nNot applicable\nHyper-V\nSingle session supported for 21H2, 22H2\nMulti session with Hybrid AD join supported for 21H2, 22H2\nSingle session supported for 21H2, 22H2\nMulti session with Hybrid AD join supported for 21H2, 22H2\nSupported with Hybrid AD join\nSupported with Hybrid AD join\nKnown issues\nYou can't monitor\nCopy to Clipboard\nand\nEnforcing Endpoint DLP\non Azure Virtual Desktop environments via browsers. However, the same egress operation will be monitored by\nEndpoint DLP for actions via Remote Desktop Session (RDP)\n.\nCitrix XenApp doesn't support access by restricted app monitoring.\nLimitations\nHandling of USBs in virtualized environments: USB storage devices are treated as network shares. You need to include the\nCopy to network share\nactivity to monitor\nCopy to a USB device\n. All activity explorer events for virtual devices and incident alerts show the\nCopy to a network share\nactivity for all copy to USB events.\nmacOS onboarding procedures\nFor a general introduction to onboarding macOS devices, see:\nOnboard macOS devices into Microsoft Purview\nFor specific guidance to onboarding macOS devices, see:\nArticle\nDescription\nIntune\nFor macOS devices that are managed through Intune\nIntune for Microsoft Defender for Endpoint customers\nFor macOS devices that are managed through Intune and that have Microsoft Defender for Endpoint (MDE) deployed to them\nJAMF Pro)\nFor macOS devices that are managed through JAMF Pro\nJAMF Pro for Microsoft Defender for Endpoint customers)\nFor macOS devices that are managed through JAMF Pro and that have Microsoft Defender for Endpoint (MDE) deployed to them\nOnce a device is onboarded, it should be visible in the devices list, and should start reporting audit activity to Activity explorer.\nSee also\nLearn about Endpoint data loss prevention\nUsing Endpoint data loss prevention\nLearn about data loss prevention\nCreate and Deploy data loss prevention policies\nGet started with Activity explorer\nMicrosoft Defender for Endpoint\nOnboarding tools and methods for Windows machines\nMicrosoft 365 subscription\nMicrosoft Entra joined devices\nDownload the new Microsoft Edge based on Chromium\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Onboard Devices",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/dlp-configure-endpoint-settings": {
      "content_hash": "sha256:49e31b82fa0f5236dad23fb5caa893cae7041e9861d9e28b6c262ca7c8057169",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConfigure endpoint data loss prevention settings\nFeedback\nSummarize this article for me\nMany aspects of endpoint data loss prevention (DLP) behavior are controlled by centrally configured settings that are applied to all DLP policies for devices. Use these settings to control the following behaviors:\nCloud egress restrictions\nVarious types of restrictive actions on user activities per application\nFile path exclusions for Windows and macOS devices\nBrowser and domain restrictions\nAppearance of business justifications for overriding policies in policy tips\nWhether actions performed on Office, PDF, and CSV files are automatically audited\nTo access these settings, from the Microsoft Purview portal, navigate to\nData loss prevention\n>\nOverview\n>\nData loss prevention settings\n>\nEndpoint settings\n.\nTip\nGet started with Microsoft Security Copilot to explore new ways to work smarter and faster using the power of AI. Learn more about\nMicrosoft Security Copilot in Microsoft Purview\n.\nImportant\nFor information about the Adobe requirements for using Microsoft Purview Data Loss Prevention (DLP) features with PDF files, see this article from Adobe:\nMicrosoft Purview Information Protection Support in Acrobat\n.\nAdvanced classification scanning and protection\nAdvanced classification scanning and protection allow the Microsoft Purview cloud-based data classification service to scan items, classify them, and return the results to the local machine. Therefore, you can take advantage of classification techniques such as\nexact data match\nclassification,\ntrainable classifiers\n,\ncredential classifiers\n, and\nnamed entities\nin your DLP policies.\nNote\nThe\nPaste to browser\naction doesn't support advanced classification.\nWhen advanced classification is turned on, content is sent from the local device to the cloud services for scanning and classification. If bandwidth usage is a concern, you can set a limit on how much bandwidth can be used in a rolling 24-hour period. The limit is configured in\nEndpoint DLP settings\nand is applied per device. If you set a bandwidth usage limit and that usage limit is exceeded, DLP stops sending the user content to the cloud. At that point, data classification continues locally on the device but classification using exact data match, named entities, trainable classifiers, and credential classifiers aren't available. When the cumulative bandwidth usage drops below the rolling 24-hour limit, communication with the cloud services resumes.\nIf bandwidth usage isn't a concern, select\nDo not limit bandwidth. Unlimited\nto allow unlimited bandwidth use.\nAdvanced classification file scanning size limits\nEven with\nDo not limit bandwidth. Unlimited\nenabled for advanced classification, there are still limits on the size of individual files that can be scanned.\nThere is a 64 MB limit on text files.\nThere is a 50 MB limit on image files when Optical Character Recognition (OCR) is enabled.\nAdvanced classification will not work for text files larger than 64 MB, even if the bandwidth limit is set to\nDo not limit bandwidth. Unlimited\n.\nThe following Windows versions (and later) support advanced classification scanning and protection.\nall Windows 11 versions\nWindows 10 versions 20H1/21H1 or higher (KB 5006738)\nWindows 10 RS5 (KB 5006744)\nNote\nSupport for advanced classification is available for Office (Word, Excel, PowerPoint) and PDF file types.\nDLP policy evaluation always occurs in the cloud, even if user content is not being sent.\nTip\nTo use advanced classification for Windows 10 devices, you must install KB5016688. To use advanced classification for Windows 11 devices, KB5016691 must be installed on those Windows 11 devices. Additionally, you must enable advanced classification before\nActivity explorer\nwill display contextual text for DLP rule-matched events. To learn more about contextual text, see\nContextual summary\n.\nAdvanced label-based protection for all files on devices\nTurning this feature on allows users to work on files, including files other than Office and PDF files, that have sensitivity labels that apply access control settings in an unencrypted state, on their devices. Endpoint DLP will continue to monitor and enforce access control and label-based protections on these files even in unencrypted state and automatically encrypt them before they're transferred outside from a user's device. For more information on this feature, see\nLearn about Advanced Label Based Protection\n.\nNote\nThis feature is supported only on onboarded Windows devices.\nFile path exclusions\nIf you want to exclude certain paths from DLP monitoring, DLP alerts, and DLP policy enforcement on your devices, you can turn off those configuration settings by setting up file path exclusions. Files in excluded locations aren't audited and any files that are created or modified in those locations aren't subject to DLP policy enforcement. To configure path exclusions in DLP settings, navigate to\nMicrosoft Purview portal\n>\nData loss prevention\n>\nOverview\n>\nData loss prevention settings\n>\nEndpoint settings\n>\nFile path exclusions for Windows\n.\nFile path exclusions for Windows\nYou can use the following logic to construct your exclusion paths for Windows 10/11 devices:\nValid file path that ends with\n\\\n, means only files directly under the specified folder are excluded.\nExample:\nC:\\Temp\\\nValid file path that ends with\n\\*\n, means only files within subfolders of the specified folder are excluded. Files directly under the specified folder itself aren't excluded.\nExample:\nC:\\Temp\\*\nValid file path that ends without\n\\\nor\n\\*\n, means all files directly under the specified folder and all of its subfolders are excluded.\nExample:\nC:\\Temp\nA path with wildcard between\n\\\nfrom each side.\nExample:\nC:\\Users\\*\\Desktop\\\nA path with wildcard between\n\\\nfrom each side and with\n(number)\nto specify the exact number of subfolders to be excluded.\nExample:\nC:\\Users\\*(1)\\Downloads\\\nA path with SYSTEM environment variables.\nExample:\n%SystemDrive%\\Test\\*\nA mix of all the patterns described here.\nExample:\n%SystemDrive%\\Users\\*\\Documents\\*(2)\\Sub\\\nWindows file paths excluded by default\n%SystemDrive%\\\\Users\\\\*(1)\\\\AppData\\\\Roaming\n%SystemDrive%\\\\Users\\\\*(1)\\\\AppData\\\\Local\\\\Temp\n%%SystemDrive%\\\\Users\\\\*(1)\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\INetCache\nFile path exclusions for Mac\nYou can also add your own exclusions for macOS devices.\nFile path definitions are case insensitive, so\nUser\nis the same as\nuser\nWildcard values are supported. So a path definition can contain an asterisk (\n*\n) in the middle of the path or at the end of the path.\nExample:\n/Users/*/Library/Application Support/Microsoft/Teams/*\nmacOS file paths excluded by default\n/System\nRecommended file path exclusions for macOS\nFor performance reasons, Endpoint DLP includes a list of recommended file path exclusions for macOS devices. If the\nInclude recommended file path exclusions for Mac\ntoggle is set to\nOn\n, the following paths are also excluded:\n/Applications\n/usr\n/Library\n/private\n/opt\n/Users/*/Library/Logs\n/Users/*/Library/Containers\n/Users/*/Library/Application Support\n/Users/*/Library/Group Containers\n/Users/*/Library/Caches\n/Users/*/Library/Developer\nWe recommend leaving this toggle set to\nOn\n. However, you can stop excluding these paths by setting the toggle to\nOff\n.\nSet up evidence collection for file activities on devices\nWhen it identifies items that match policies on devices, DLP can copy them to an\nAzure storage account\n. This feature is useful for auditing policy activity and troubleshooting specific matches. Use this section to add the name and URL of the storage account.\nNote\nBefore you enable this feature, you must create an Azure storage account and a container in that storage account. You must also configure permissions for the account. As you set up your Azure storage account, keep in mind that you'll probably want to use a storage account that's in the same Azure region/geopolitical boundary as your tenant. You should also consider configuring\nAzure storage account access tiers\nand\nAzure storage account pricing\n.\nFor more information on this feature, see\nLearn about collecting files that match data loss prevention policies from devices\n.\nFor more information on how to configure this feature, see\nGet started with collecting files that match data loss prevention policies from devices\n.\nNetwork share coverage and exclusions\nNetwork share coverage and exclusions\nextends endpoint DLP policies and actions to new and edited files on network shares and mapped network drives. If\njust in time protection\nis also enabled, just in time protection coverage and exclusions are extended to network shares and mapped drives. If you want to exclude a specific network path for all monitored devices, add the path value in\nExclude these network share paths\n.\nImportant\nTo use\nNetwork share coverage and exclusions\n, devices must have the following updates applied:\nWindows 10 -\nMarch 21, 2023âKB5023773 (OS Builds 19042.2788, 19044.2788, and 19045.2788) Preview\n,\nMarch 28, 2023âKB5023774 (OS Build 22000.1761) Preview\nWindows 11 -\nMarch 28, 2023âKB5023778 (OS Build 22621.1485) Preview\nMicrosoft Defender\nApril-2023 (Platform: 4.18.2304.8 | Engine: 1.1.20300.3)\nMac OS Last 3 OS versions supported ; Minimum Defender app version supported - 101.24122.0005\nThis table shows the default settings for network share coverage and exclusions.\nNetwork share coverage and exclusions\nJust in time protection\nResultant behavior\nEnabled\nDisabled\n- DLP policies scoped to Devices are applied to all network shares and mapped drives that the device is connected to.\nSupported actions: Devices\nDisabled\nEnabled\n- Just-in-time protection is applied only to the files on storage devices that are local to the endpoint.\nEnabled\nEnabled\n- DLP policies scoped to Devices are applied to all network shares and mapped drives that the device is connected to.\nSupported actions: Devices\n- Just-in-time protection is applied to all network shares and mapped drives that the device is connected to.\nNetwork share coverage and exclusions\ncomplements\nDLP On-premises repository actions\n. This table shows the exclusion settings and the resulting behavior depending on whether DLP is enabled or disabled for on-premises repositories.\nNetwork share coverage and exclusions\nDLP on-premises repositories\nResultant behavior\nEnabled\nDisabled\n- DLP policies scoped to Devices are applied to all network shares and mapped drives that the device is connected to.\nSupported actions: Devices\nDisabled\nEnabled\n- Policies that are scoped to On-premises repositories can enforce protective actions on on-premises data-at-rest in file shares and SharePoint document libraries and folders.\nDLP On-premises repository actions\nEnabled\nEnabled\n- DLP policies scoped to Devices are applied to all network shares and mapped drives that the device is connected to.\nSupported actions: Devices\n- Policies that are scoped to On-premises repositories can enforce protective actions on on-premises data-at-rest in file shares and SharePoint document libraries and folders.\nDLP On-premises repository actions\nRestricted apps and app groups\nRestricted apps\nThe\nRestricted apps\nlist, is a custom list of applications that you create. You configure what actions DLP takes when someone uses an app on the list to\naccess\na DLP-protected file on a device. The\nRestricted apps\nlist is available for Windows 10/11 and macOS devices running any of the three latest macOS releases.\nSome apps have a web based interface in addition to a locally installed version of the application. In preview, when you add an app that can be accessed both locally and via a web based interface, to a\nRestricted app group\nor as a\nRestricted app\n, any DLP policies applicable to accessing a protected file will be enforced via Edge for the browser app interface and on the device for the application based interface.\nImportant\nDo not include the path to the executable for Windows devices. Include only the executable name (such as browser.exe).\nThe action (\naudit\n,\nblock with override\n, or\nblock\n) defined for apps that are on the restricted apps list only applies when a user attempts to\naccess\na protected item.\nWhen\nAccess by restricted apps\nis selected in a policy and a user uses an app that is on the restricted apps list to access a protected file, the activity is\naudited\n,\nblocked\n, or\nblocked with override\n, depending on how you configured the\nRestricted apps\nlist. EXCEPTION: If an app on the\nRestricted apps\nlist is also a member of a\nRestricted app group\n, the actions configured for activities in the\nRestricted app group\noverride the actions configured for the\nRestricted apps\nlist. All activity is audited and available for review in activity explorer.\nRestricted app groups\nRestricted app groups are collections of apps that you create in DLP settings and then add to a rule in a policy. When you add a restricted app group to a policy, you can take the actions defined in the following table.\nRestricted App group option\nWhat it allows you to do\nDon't restrict file activity\nTells DLP to allow users to access DLP protected items using apps in the app group without taking any action when the user attempts to\nCopy to clipboard\n,\nCopy to a USB removable drive\n,\nCopy to a network drive\n, or\nPrint\nfrom the app.\nApply a restriction to all activity\nTells DLP to\nAudit only\n,\nBlock with override\n, or\nBlock\nwhen a user attempts to access a DLP-protected item using an app that's in the relevant app group\nApply restrictions to a specific activity\nThis setting allows a user to access a DLP-protected item using an app that is in the app group. It also allows you to select a default action (\nAudit only\n,\nBlock\n, or\nBlock with override\n) for DLP to take when a user attempts to\nCopy to clipboard\n,\nCopy to a USB removable drive\n,\nCopy to a network drive\n, and\nPrint\n.\nYou can add a maximum of 50 apps into a single group and you can create a maximum of 10 groups. This gives a maximum of 500 apps that the policy actions can be assigned to.\nImportant\nSettings in a restricted app\ngroup\noverride any restrictions set in the restricted apps\nlist\nwhen they are in the same rule. So, if an app is on the restricted apps list and is also a member of a restricted apps group, the settings of the restricted apps group is applied.\nBlock all apps except for a list of allowed apps\nYou can create a list of allowed applications and block all others. This way, you don't need to create and manage a comprehensive list of untrusted applications. This feature helps simplify policy management and enhances your control over app-based file activities.\nNote\nCommon background applications such as\nteamsupdate.exe\nor\nsvchost.exe\nare preconfigured to bypass enforcement to prevent unintentional interference with essential operations.\nIn this procedure, we apply the restriction level of\nAllow\nto explicitly allow activity for a defined app group, and then block any apps that are not on this list. Therefore, apps that have no restriction level defined are effectively blocked, and apps that have a restriction level defined as\nAllow\nare explicitly allowed. Basically, we define a restricted app group in order to allow that app group, but we do this in order to block any apps that have no defined restrictions.\nNavigate to endpoint DLP settings.\nDefine allowed or sanctioned apps in the\nRestricted Apps and app groups\nlist.\nIn your existing or new endpoint DLP policy, locate the\nFile activities for apps in restricted app groups\nsetting.\nAdd the desired restricted app group.\nSelect\nApply restriction to all/specific activity\n, and select\nAllow\n.\nFor all other apps, set the\nAccess by apps that arenât on the 'unallowed apps' list\nsetting to\nBlock\n.\nHow DLP applies restrictions to activities\nInteractions between\nFile activities for apps in restricted app groups\n,\nFile activities for all apps\n, and the\nRestricted app activities\nlist are scoped to the same rule.\nRestricted app groups overrides\nConfigurations defined in\nFile activities for apps in restricted app groups\noverride the configurations in the\nRestricted app activities\nlist and\nFile activities for all apps\nin the same rule.\nRestricted app activities and File activities for all apps\nThe configurations of\nRestricted app activities\nand\nFile activities for all apps\nwork in concert if the action defined for\nRestricted app activities\nis either\nAudit only\n, or\nBlock with override\nin the same rule. Why? Actions defined for\nRestricted app activities\nonly apply when a user accesses a file using an app that's on the list. Once the user has access, the actions defined for activities in\nFile activities for all apps\napply.\nFor example, you add Notepad.exe to\nRestricted apps\nand configure\nFile activities for all apps\nto\nApply restrictions to specific activity\n. You configure both as shown in the following table:\nSetting in policy\nApp name\nUser activity\nDLP action to take\nRestricted app activities\nNotepad\nAccess a DLP protected item\nAudit only\nFile activities for all apps\nAll apps\nCopy to clipboard\nAudit only\nFile activities for all apps\nAll apps\nCopy to a USB removeable device\nBlock\nFile activities for all apps\nAll apps\nCopy to a network share\nAudit only\nFile activities for all apps\nAll apps\nPrint\nBlock\nFile activities for all apps\nAll apps\nCopy or move using unallowed Bluetooth app\nBlocked\nFile activities for all apps\nAll apps\nRemote desktop services\nBlock with override\nWhen User A opens a DLP-protected file using Notepad, DLP allows the access and audits the activity. While still in Notepad, User A then tries to copy content from the protected item to the clipboard. This action is successful, and DLP audits the activity. User A then tries to print the protected item from Notepad and the activity is blocked.\nNote\nWhen the DLP action to take in\nRestricted app activities\nis set to\nblock\n, all access is blocked and the user cannot perform any activities on the file.\nFile activities for all apps only\nIf an app\nisn't\nin the\nFile activities for apps in restricted app groups\nor the\nRestricted app activities\nlist, or\nis\nin the\nRestricted app activities\nlist, with an action of either\nAudit only\n, or\nBlock with override\n, any restrictions defined in the\nFile activities for all apps\nare applied in the same rule.\nmacOS devices\nYou can also prevent macOS apps from accessing sensitive data by defining them in the\nRestricted app activities\nlist.\nNote\nCross-platform apps must be entered with their unique paths respective to the OS they are running.\nTo find the full path of Mac apps:\nOn the macOS device, open\nActivity Monitor\n. Find and double-click the process you want to restrict.\nSelect the\nOpen Files and Ports\ntab.\nMake a note of the full path name, including the name of the app. For example,\n/System/Applications/TextEdit.app/Contents/MacOS/TextEdit\nAuto-quarantine\nTo prevent sensitive items from being synced to the cloud by cloud sync apps such as\nonedrive.exe\n, add the cloud sync app to the\nRestricted apps\nlist with\nAuto-quarantine\nWhen enabled, auto-quarantine is triggered when a restricted app attempts to access a DLP-protected sensitive item. Auto-quarantine moves the sensitive item to an admin-configured folder. If configured to do so, auto-quarrantine can leave a placeholder (\n.txt\n) file in place of the original. You can configure the text in the placeholder file to tell users the new location of the item, and other pertinent information.\nUse the auto-quarrantine feature when an unallowed cloud-sync app tries to access an item that is protected by a blocking DLP policy. DLP might generate repeated notifications. You can avoid these repeated notifications by enabling\nAuto-quarantine\n.\nYou can use also auto-quarantine to prevent an endless chain of DLP notifications for the user and admins. For more information, see\nScenario 4: Avoid looping DLP notifications from cloud synchronization apps with auto-quarantine\n.\nUnsupported file extension exclusions\nYou can use the\nDocument could not be scanned\ncondition together with\nApply restrictions to only unsupported file extensions\nin your DLP policies to restrict activities involving files with extensions that arenât supported by endpoint DLP. Because this can potentially include many unsupported file extensions, you can refine detection by adding unsupported extensions to exclude. For more information, see\nHelp protect files that Endpoint Data Loss Prevention doesn't scan\n,\nHelp protect against sharing of a defined set of unsupported files\n.\nNote\nDo not add â.â while you add extension and use latest Antimalware client version.\nImportant\nWhen you select\nActions\n>\nAudit or restrict activities on devices\nrule configuration the\nApply restrictions to only unsupported file extensions\nshows up.\nApply restrictions to only unsupported file extensions\nconfiguration option does not support scoping by\nDevice and device groups\nin the policy location setting.\nBlocking specific file extensions in DLP policies can lead to unexpected behavior if an application that is marked as unallowed needs to access files with those extensions as part of its normal operation. For example, certain apps may read or temporarily open files, like\n.dll\n,\n.json\n,\n.tmp\nduring routine processes such as rendering, caching, or validating content. If these extensions are blocked, the app may fail to function properly, causing errors, incomplete workflows, or enforcement pop-ups unrelated to user intent. Before implementing extension-based restrictions, make sure you know which apps interact with these file types during standard operations, and whether alternative controls, such as app restrictions or contextual rules can achieve the security goal without disrupting functionality.\nUnallowed Bluetooth apps\nTo prevent people from transferring files protected by your policies via specific Bluetooth apps, add those apps to the\nUnallowed Bluetooth apps\nlist in Endpoint DLP settings.\nBrowser and domain restrictions to sensitive data\nRestrict sensitive files that match your policies from being shared with unrestricted cloud service domains.\nUnallowed browsers\nFor Windows devices you can restrict the use of specified web browsers, identified by their executable names. The specified browsers are blocked from accessing files that match the conditions of an enforced a DLP policy where the upload-to-cloud services restriction is set to\nblock\nor\nblock override\n. When these browsers are blocked from accessing a file, end users see a toast notification asking them to open the file through Microsoft Edge.\nFor macOS devices, you must add the full file path. To find the full path of Mac apps:\nOn the macOS device, open\nActivity Monitor\n. Find and double-click the process you want to restrict.\nChoose\nOpen Files and Ports\ntab.\nMake sure to make a note of the full path name, including the name of the app.\nService domains\nThe\nService domains\nhere work together with the\nAudit or restrict activities on devices\nsetting found in the workflow for creating a rule within a DLP policy.\nWhen you create a rule, you use actions to protect your content when certain conditions are met. When creating rules for endpoint devices, you need to choose the\nAudit or restrict activities on devices\noption, and select one of these options:\nAudit only\nBlock with override\nBlock\nTo control whether sensitive files that are protected by your policies can be uploaded to specific service domains, you next need to navigate to\nEndpoint DLP Settings\n>\nBrowser and domain restrictions to sensitive data\nand choose whether to\nblock\nor\nallow\nService domains\nby default.\nNote\nThe\nService domains\nsetting only applies to files uploaded using Microsoft Edge, or using instances of Google Chrome or Mozilla Firefox that have the\nMicrosoft Purview Chrome Extension\ninstalled.\nBlock\nWhen the\nService domains\nlist is set to\nBlock\n, you use the\nAdd cloud service domain\nto specify domains that should be blocked. All other service domains are allowed. In this case, DLP policy restrictions are only applied when a user attempts to upload a sensitive file to any of the domains on the list.\nFor example, consider the following configurations:\nA DLP policy is configured to detect sensitive items that contain physical addresses and the\nAudit or restrict activities on devices\noption is set to\nAudit only\n.\nThe\nService domains\nsetting is set to\nBlock\n.\ncontoso.com IS NOT ON the list.\nwingtiptoys.com IS ON the list.\nIn this case, if a user attempts to upload a sensitive file with physical addresses to contoso.com, the upload is allowed to complete and an audit event is generated but no alert is triggered.\nIn contrast, if a user attempts to upload a sensitive file with credit card numbers to wingtiptoys.com, the user activity--the upload--is also allowed to complete and both an audit event and an alert are generated.\nAnother example, consider the following configuration:\nA DLP policy is configured to detect sensitive items that contain physical addresses and the\nAudit or restrict activities on devices\noption is set to\nBlock\n.\nThe\nService domains\nsetting is set to\nBlock\n.\ncontoso.com IS NOT ON the list.\nwingtiptoys.com IS ON the list.\nIn this case, if a user attempts to upload a sensitive file with physical addresses to contoso.com, the upload is allowed to complete and an audit event is triggered, an audit event is generated but no alert is triggered.\nIn contrast, if a user attempts to upload a sensitive file with credit card numbers to wingtiptoys.com, the user activity--the upload--is blocked and both an audit event and an alert are generated.\nAllow\nWhen the\nService domains\nlist is set to\nAllow\n, you use the\nAdd cloud service domain\nto specify domains that are allowed. All other service domains will have DLP Policy restrictions enforced. In this case, DLP policies are only applied when a user attempts to upload a sensitive file to any of the listed domains.\nFor example, here are two starting configurations:\nA DLP policy is configured to detect sensitive items that contain credit card numbers and the\nAudit or restrict activities on devices\noption is set to\nBlock with override\n.\nThe\nService domains\nsetting is set to\nAllow\n.\ncontoso.com IS NOT ON the\nAllow\nlist.\nwingtiptoys.com IS ON the\nAllow\nlist.\nIn this case, if a user attempts to upload a sensitive file with credit card numbers to contoso.com, the upload is blocked, a warning displays, giving the user the option to override the block. If the user chooses to override the block, an audit event is generated and an alert is triggered.\nHowever, if a user attempts to upload a sensitive file with credit card numbers to wingtiptoys.com, the policy restriction\nisn't\napplied. The upload is allowed to complete, and an audit event is generated but no alert is triggered.\nA DLP policy is configured to detect sensitive items that contain physical addresses and the Audit or restrict activities on devices option is set to Audit only.\nThe\nService domains\nsetting is set to Allow.\ncontoso.com is NOT on the list.\nwingtiptoys.com IS on the list.\nIn this case, if a user attempts to upload a sensitive file with physical addresses to contoso.com, the upload is allowed to complete and both an audit event and an alert are generated.\nIn contrast, if a user attempts to upload a sensitive file with credit card numbers to wingtiptoys.com, the user activity--the upload- is also allowed to complete, an audit event is generated but no alert is triggered.\nImportant\nWhen the service restriction mode is set to\nAllow\n, you must have at least one service domain configured before restrictions are enforced.\nSummary table: Allow/Block behavior\nThe following table shows how the system behaves depending on the settings listed.\nEndpoint DLP Service domain setting\nDLP policy rule Audit or restrict activities on devices setting\nUser goes to a listed site\nUser goes to a site NOT listed\nAllow\nAudit only\n- User activity is audited\n- No alert is generated\n- No DLP policies are applied\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Audit mode\nAllow\nBlock with override\n- User activity is audited\n- No alert is generated\n- No DLP policies are applied\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Block with override mode\nAllow\nBlock\n- User activity is audited\n- No alert is generated\n- No DLP policies are applied\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Block mode\nBlock\nAudit only\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Audit mode\n- User activity is audited\n- No alert is generated\n- No DLP policies are applied\nBlock\nBlock with override\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Block with override mode\n- User activity is audited - No alert is generated\n- No DLP policies are applied\nBlock\nBlock\n- User activity is audited\n- An alert is generated\n- DLP policies are applied in Block mode\n- User activity is audited\n- No alert is generated\n- No DLP policies are applied\nWhen adding a domain to the list, use the FQDN format of the service domain without the ending period (\n.\n). Use\n*.\nas a wildcard to specify all domains or subdomains. Exclude the protocol (anything before\n//\n) from the domain. Only include the host name, without any subsites.\nFor example:\nInput\nURL matching behavior\ncontoso.com\nMatches the specified domain name, and any subsite\n:\n://contoso.com\n://contoso.com/\n://contoso.com/anysubsite1\n://contoso.com/anysubsite1/anysubsite2 (etc.)\nDoes not match sub-domains or unspecified domains\n:\n://anysubdomain.contoso.com\n://anysubdomain.contoso.com.AU\n*\n.contoso.com\nMatches the specified domain name, any subdomain, and any site\n:\n://contoso.com\n://contoso.com/anysubsite\n://contoso.com/anysubsite1/anysubsite2\n://anysubdomain.contoso.com/\n://anysubdomain.contoso.com/anysubsite/\n://anysubdomain1.anysubdomain2.contoso.com/anysubsite/\n://anysubdomain1.anysubdomain2.contoso.com/anysubsite1/anysubsite2 (etc.)\nDoes not match unspecified domains\n://anysubdomain.contoso.com.AU/\nwww.contoso.com\nMatches the specified domain name\n:\nwww.contoso.com\nDoes not match unspecified domains or subdomains\n://anysubdomain.contoso.com/, in this case, you have to put the FQDN domain name itself\nwww.contoso.com\nYou can configure up to 50 domains under\nSensitive Service domains\n.\nNote\nThe Service domains list setting only applies to file uploads to websites. Actions like pasting into a browser do not follow the Service Domain list.\nSensitive service domain groups\nWhen you list a website in\nSensitive service domains\n, you can\naudit\n,\nblock with override\n, or fully\nblock\nuser activity when users attempt to take any of the following actions:\nprint from a website\ncopy data from a website\nsave a website as local files\nupload or drag/drop a sensitive file to an excluded website\npaste sensitive data to an excluded website\nThe following table shows which browsers support these features:\nBrowser\nSupported Feature\nMicrosoft Edge\n- Print the site\n- Copy data from the site\n- Save the site as local files (save-as)\n- Paste to supported browsers\n- Upload to a restricted cloud service domain\nGoogle Chrome (with the Microsoft Purview extension)\n- Paste to supported browsers\n- Upload to a restricted cloud service domain\nMozilla Firefox (with the Microsoft Purview extension)\n- Upload to a restricted cloud service\n- Paste to supported browsers\nFor the\nPaste to supported browsers\naction, there may be a brief time lag between when the user attempts to paste text into a web page and when the system finishes classifying it and responds. If this classification latency happens, you may see both policy-evaluation and check-complete notifications in Edge or policy-evaluation toast on Chrome and Firefox. Here are some tips for minimizing the number of notifications:\nNotifications are triggered when a policy for the target website is configured to\nBlock\nor\nBlock with override\nthe\nPaste to supported browsers\nfor that user. You can configure the overall action to\nAudit\nand then using the exceptions,\nBlock\nthe target websites. Alternately, you can set the overall action to\nBlock\nand then using the exceptions,\nAudit\nthe secure websites.\nUse latest Antimalware client version.\nEnsure your version of Microsoft Edge is 120 or higher.\nInstall these Windows KBs:\nWindows 10:\nKB5032278\n,\nKB5023773\nWindows 11 21H2:\nKB5023774\nWin 11 22H2:\nKB5032288\n,\nKB5023778\nOn macOS, ensure your anti-malware Client version is 101.25022.0003 or later\nThe\nPaste to supported browsers\naction does not follow the behavior defined in the Service Domain list. However, if Sensitive Service Domain Groups are configured on the rule for Paste To Browser, those are honored.\nNote\nThe\nService domains\nsetting only applies to files uploaded using Microsoft Edge or an instance of Google Chrome or Mozilla Firefox that has the\nMicrosoft Purview Chrome Extension\ninstalled.\nThe Generative AI Websites group contains these\nsupported sites\n. The group is used for default policies within Data Security Posture Management for AI and cannot be edited or deleted.\nFor devices, you must configure\nSensitive service domains\nlist to use the\nUpload to a restricted cloud service domain\naction in a DLP policy. You can also define website groups that you want to assign policy actions to that are different from the global website group actions. You can add a maximum of 100 websites into a single group and you can create a maximum of 150 groups. This gives a maximum of 15,000 websites that the policy actions can be assigned to. For more information, see\nScenario 6: Monitor or restrict user activities on sensitive service domains\n.\nImportant\nRegarding the\nPaste to supported browser\naction. If 'Collect original file as evidence for all selected file activities on Endpoint' is enabled on the rule for this feature, garbage characters might appear in the source text if the user's\nWindows device doesn't have Antimalware Client Version 4.18.23110 or newer installed. Select\nActions\n>\nDownload\nto view the actual content.\nFor more information, see\nScenario 7: Restrict pasting sensitive content into a browser\n.\nSupported syntax for designating websites in a website group\nIf you use URLs to identify websites, don't include the networking protocol as part of the URL (for instance,\nhttps://\nor\nfile://\n). Instead, use a flexible syntax to include and exclude domains, subdomains, websites, and subsites in your website groups. For example,\nUse\n*.\nas a wildcard to specify all domains or all subdomains.\nUse\n/\nas a terminator at the end of a URL to scope to that specific site only.\nWhen you add a URL without a terminating slash mark (\n/\n), that URL is scoped to that site and all subsites. You can only add\n*.\nto the beginning of a domain. The\n/\nterminator is only supported at the end of a domain.\nThis syntax applies to all http/https websites. Here are some examples:\nURL added to the website group\nURL will match\nURL won't match\ncontoso.com\nhttp://\ncontoso.com\nhttps://\ncontoso.com\nhttps://\ncontoso.com/\nhttps://\ncontoso.com/allsubsites1\nhttps://\ncontoso.com/allsubsites1/allsubsites2\nhttps://\nallsubdomains.contoso.com\nhttps://\nallsubdomains.contoso.com.au\nhttps://\nwww.contoso.com\ncontoso.com/\nhttp://\ncontoso.com\nhttps://\ncontoso.com\nhttps://\ncontoso.com/\nhttps://\ncontoso.com/allsubsites1\nhttps://\ncontoso.com/allsubsites1/allsubsites2\nhttps://\nallsubdomains.contoso.com\nhttps://\nallsubdomains.contoso.com/au\nhttps://\nwww.contoso.com\n*.contoso.com\nhttp://\ncontoso.com\nhttps://\ncontoso.com\nhttps://\nwww.contoso.com\nhttps://\nwww.contoso.com/allsubsites\nhttps://\ncontoso.com/allsubsites1/allsubsites2\nhttps://\nallsubdomains.contoso.com\nhttps://\nallsubdomains.contoso.com/allsubsites\nhttps://\nallsubdomains1.allsubdomains2.contoso.com/allsubsites1/allsubsites2\nhttps://\nallsubdomains.contoso.com.au\n*.contoso.com/xyz\nhttp://\ncontoso.com/xyz/\nhttps://\ncontoso.com/xyz/\nhttps://\ncontoso.com/xyz/allsubsites/\nhttps://\nallsubdomains.contoso.com/xyz/\nhttps://\nallsubdomains.contoso.com/xyz/allsubsites\nhttps://\nallsubdomains1.allsubdomains2.contoso.com/xyz/allsubsites\nhttps://\nallsubdomains1.allsubdomains2.contoso.com/xyz/allsubsites1/allsubsites2\nhttps://\ncontoso.com/xyz\nhttps://\nallsubdomains.contoso.com/xyz\n*.contoso.com/xyz/\nhttp://\ncontoso.com/xyz\nhttps://\ncontoso.com/xyz\nhttps://\ncontoso.com/xyz/\nhttps://\nallsubdomains.contoso.com/xyz\nhttps://\nallsubdomains.contoso.com/xyz/\nhttps://\ncontoso.com\nhttps://\ncontoso.com/xyz/allsubsites/\nhttps://\nallsubdomains.contoso.com/xyz/allsubsites/\nhttps://\nallsubdomains1.allsubdomains2.contoso.com/xyz/allsubsites/\nhttps://\nallsubdomains1.allsubdomains2.contoso.com/xyz/allsubsites1/allsubsites2\nSupported syntax for designating IP ranges or IP addresses (preview)\nIn preview, DLP supports using IP address and address ranges to identify websites. Set the Match type to\nIP address\nor\nIP address range\nand then enter a specific IP address or an IP range in the\nSensitive service domain\nfield, and click\nAdd site\nto add the selection to the Sensitive service domain group.\nExamples of supported syntax:\n1.1.1.1\n1.1.1.1-2.2.2.2\n2001:0db8:85a3:0000:0000:8a2e:0370:7334\n2001:0db8:85a3:0000:0000:8a2e:0370:7320-2001:0db8:85a3:0000:0000:8a2e:0370:7334\nImportant\nURLs support these actions:\nPrint the site\nCopy data from the site\nSave the site as local files (save-as)\nPaste to supported browsers\nUpload to a restricted cloud service domain\nIP address and IP address range support these actions:\nPrint the site\nCopy data from the site\nSave the site as local files (save-as)\nUpload to a restricted cloud service domain\n(Windows only)\nSensitive service domain groups contains a preconfigured group for\nGenerative AI websites\n. For a list of all the websites in this group see,\nList of AI sites supported by Microsoft Purview Data Security Posture Management for AI\nAdditional settings for Endpoint DLP\nBusiness justification in policy tips\nYou can control how users interact with the business justification option in\nOptions for configuring policy tips\n. This option appears when users perform an activity that's protected by the\nBlock with override\nsetting in a DLP policy. This is a global setting. You can choose from one the following options:\nShow default options and custom text box\n: By default, users can select either a built-in justification, or enter their own text.\nOnly show default options\n: Users are limited to selecting from a list of built-in justifications.\nOnly show custom text box\n: Users are limited to entering a custom justification. The text box appears in the end-user policy tip notification, without a list of options.\nCustomizing the options in the drop-down menu\nYou can create up to five customized options that appear when users interact with the policy notification tip by selecting the\nCustomize the options drop-down menu\n.\nOption\nDefault text\noption 1\nThis is part of an established business workflow\nor you can enter customized text\noption 2\nMy manager has approved this action\nor you can enter customized text\noption 3\nUrgent access required; I'll notify my manager separately\nor you can enter customized text\nShow false positive option\nThe information in these files is not sensitive\nor you can enter customized text\noption 5\nOther\nor you can enter customized text\nTurn on automatic diagnostic logging for endpoint DLP\nMicrosoft Purview Always-on diagnostics feature automatically records comprehensive trace logs, saving you time and enabling faster troubleshooting. For more information, see\nAlways-on diagnostics for endpoint DLP\n.\nEnable Endpoint DLP for Windows Servers\nEndpoint DLP supports the following versions of Windows Server:\nWindows Server 2019 (\nNovember 14, 2023âKB5032196 (OS Build 17763.5122) - Microsoft Support\n)\nWindows Server 2022 (\nNovember 14, 2023 Security update (KB5032198) - Microsoft Support\n)\nOnce you\nonboard a Windows Server\nyou must turn on Endpoint DLP support before endpoint protection will be applied.\nTo work with the DLP alert management dashboard:\nIn the Microsoft Purview portal, navigate to\nData loss prevention\n>\nOverview\n.\nChoose\nSettings\nin the top right corner.\nOn the\nSettings\npage, select\nEndpoint settings\nand expand\nEndpoint DLP support for onboarded servers\n.\nSet the toggle to\nOn\n.\nAlways audit file activity for devices\nBy default, when devices are onboarded, activity for Office, PDF, and CSV files is automatically audited and available for review in activity explorer. Turn off this feature if you want this activity to be audited only when onboarded devices are included in an active policy. The Always audit file activity for devices setting enables the auditing of file activities for documents where a DLP Rule did not match: File Created, File Modified, File Renamed, File created on removable media, and File created on network share.\nFile activity is always audited for onboarded devices, regardless of whether they're included in an active policy.\nPrinter groups\nUse this setting to define groups of printers that you want to assign policy actions to that are different from the global printing actions.\nThe most common use case for creating printer groups is to use them for limiting the printing of contracts to only those printers in an organization's Legal department. After you define a printer group here, you can use it in all of your policies that are scoped to\nDevices\n. For more information on configuring policy actions to use authorization groups, see\nScenario 8 Authorization groups\n.\nYou can create a maximum of 20 printer groups. Each group can contain a maximum of 50 printers.\nNote\nThis feature is available for devices running any of the following Windows versions:\nWindows 10 and later (21H1, 21H2, and later) -\nKB5020030\nWin 11 21H2 -\nKB5019157\nWin 11 22H2 -\nKB5020044\nWindows Server 2022 -\nKB5020032\nLet's look at an example. Say you want your DLP policy to block printing of contracts to all printers except for those that are in the legal department.\nUse the following parameters to assign printers in each group.\nFriendly printer\nname - the Friendly printer name is the value showing on the UX when you select the Printer.\nUSB printer\n- A printer connected through a computer's USB port. Select this option if you want to enforce any USB printer while leaving the USB product ID and USB vendor ID unselected. You can also assign a specific USB printer by specifying its USB product ID and USB vendor ID.\nUSB product ID\n- Get the\nDevice Instance\npath value from the printer device property details in device manager. Convert that value the to Product ID and Vendor ID format. For more information, see\nStandard USB identifiers\n.\nUSB vendor ID\n- Get the\nDevice Instance\npath value from the printer device property details in device manager. Convert that value to the Product ID and Vendor ID format. For more information, see\nStandard USB identifiers\n.\nIP range\nPrint to file\n- Microsoft Print to PDF or Microsoft XPS Document Writer. If you only want to enforce Microsoft Print to PDF, you should use Friendly printer name with 'Microsoft Print to PDF'.\nUniversal print deployed on a printer\n- For more information on universal printers, see\nSet up Universal Print\n.\nCorporate printer\n- is a print queue shared through on-premises Windows print server in your domain. Its path might look like this: \\print-server\\contoso.com\\legal_printer_001.\nPrint to local\n- Any printer connecting through Microsoft print port but not any of above types. For example: print through remote desktop or redirect printer.\nNote\nYou should not use multiple parameters of\nUSB printer\n,\nIP range\n,\nPrint to file\n,\nUniversal print deployed on a printer\n,\nCorporate printer\n, and\nPrint to local\n.\nAssign each printer in the group a\nDisplay name\n. These names appear only in the Microsoft Purview console.\nCreate a printer group\nnamed\nLegal printers\nand add individual printers (with an alias) by their friendly name; for instance:\nlegal_printer_001\n,\nlegal_printer_002\n, and\nlegal_color_printer\n.\n(You can select multiple parameters at once to help you unambiguously identify a specific printer.)\nAssign the policy actions to the group in a DLP policy:\nAllow\n(audit with no user notifications or alerts)\nAudit only\n(you can add notifications and alerts)\nBlock with override\n(blocks the action, but the user can override)\nPreview, a fix to address the unnecessary resubmission to queue the print job after initial override, has been implemented.\nBlock\n(blocks no matter what)\nCreate a Printer group\nOpen\nMicrosoft Purview portal\nand navigate to\nData Loss Prevention\n>\nOverview\n> settings gear icon in the upper right corner >\nData Loss Prevention\n>\nEndpoint DLP settings\n>\nPrinter groups\n.\nSelect\n+ Create printer group\n.\nGive the group a name.\nSelect\nAdd printer\n.\nGive the printer a\nFriendly name\n. Ensure the name matches the value from the printer's device property details in Device Manager.\nSelect the parameters and provide the values to unambiguously identify the specific printer.\nSelect\nAdd\n.\nAdd other printers as needed.\nSelect\nSave\nand then\nClose\n.\nFile extension groups\nUse this setting to define groups of file extensions that you want to assign policy actions to. For example, only apply a\nFile could not be scanned\npolicy to file extensions in the created groups.\nNote\nDo not add â.â while you add extension.\nDisable classification\nUse this setting to exclude specific file extensions from Endpoint DLP classification.\nFor files that are on the\nMonitored files\nlist, you can disable classification through this setting. Once you put a file extension in this setting, Endpoint DLP will not scan content in files with this extension. As a result, Endpoint DLP will not policy evaluation based on the content of those files. You will not be able to see content information for the purposes of conducting investigations.\nNote\nDo not add â.â while you add extension.\nRemovable USB device groups\nUse this setting to define groups of removable storage devices, such as USB thumb drives, that you want to assign policy actions to that are different from the global printing actions. For example, say you want your DLP policy to block items with engineering specifications from being copied to removable storage devices, except for designated USB-connected hard drives that are used to back up data for offsite storage.\nYou can create a maximum of 20 groups, with a maximum 50 removable storage devices in each group.\nNote\nThis feature is available for devices running any of the following Windows versions:\nWindows 10 and later (21H1, 21H2) with KB 5018482\nWin 11 21H2, 22H2 with KB 5018483\nWindows 10 RS5 (KB 5006744) and Windows Server 2022\nUse the following parameters to define your removable storage devices.\nStorage device friendly name\n- Get the Friendly name value from the storage device property details in device manager. Wildcard values (*) are supported.\nUSB product ID\n- Get the Device Instance path value from the USB device property details in device manager. Convert it to Product ID and Vendor ID format. For more information, see\nStandard USB identifiers\n.\nUSB vendor ID\n- Get the Device Instance path value from the USB device property details in device manager. Convert it to Product ID and Vendor ID format. For more information, see\nStandard USB identifiers\n.\nSerial number ID\n- Get the serial number ID value from the storage device property details in device manager. Wildcard values (*) are supported.\nDevice ID\n- Get the device ID value from the storage device property details in device manager. Wildcard values (*) are supported.\nInstance path ID\n- Get the device ID value from the storage device property details in device manager. Wildcard values (*) are supported.\nHardware ID\n- Get the hardware ID value from the storage device property details in device manager. Wildcard values (*) are supported.\nYou assign each removable storage device in the group an\nAlias\n. The alias is a friendly name that only appears in the Microsoft Purview console. So, continuing with the example, you would create a removable storage device group named\nBackup\nand add individual devices (with an alias) by their friendly name, like\nbackup_drive_001\n, and\nbackup_drive_002\n.\nYou can multi-select the parameters and then the printer group includes all devices that satisfy those parameters.\nYou can assign these policy actions to the group in a DLP policy:\nAllow\n(audit with no user notifications or alerts)\nAudit only\n(you can add notifications and alerts)\nBlock with\noverride (blocks the action, but the user can override)\nBlock\n(blocks no matter what)\nCreate a removable USB device group\nOpen\nMicrosoft Purview portal\nand navigate to\nData Loss Prevention\n>\nOverview\n> settings gear icon in the upper right corner >\nData Loss Prevention\n>\nEndpoint DLP settings\n>\nRemovable USB device groups\n.\nSelect\n+ Create removable storage device group\n.\nProvide a\nGroup name\n.\nSelect\nAdd removable storage device\n.\nProvide an\nAlias\n.\nSelect the parameters and provide the values to unambiguously identify the specific device.\nSelect\nAdd\n.\nAdd other devices to the group as needed.\nSelect\nSave\nand then\nClose\n.\nThe most common use case for creating removable storage groups is to use them to specify which removable storage devices users can copy files to. Generally, copying is only allowed for devices in a designated\nBackup\ngroup.\nAfter you define a removable storage device group, you can use it in all of your policies that are scoped to\nDevices\n. See\nScenario 8: Authorization groups\nfor more information on configuring policy actions to use authorization groups.\nNetwork share groups\nUse this setting to define groups of network share paths that you want to assign policy actions to that are different from the global network share path actions. For example, say you want your DLP policy to prevent users from saving or copying protected files to network shares except the network shares in a particular group.\nNote\nThis feature is available for devices running any of the following Windows versions:\nWindows 10 and later (21H1, 21H2) with KB 5018482\nWin 11 21H2, 22H2 with KB 5018483\nWindows 10 RS5 (KB 5006744) and Windows Server 2022\nTo include network share paths in a group, define the prefix that they all the shares start with. For example:\n'\\Library' will match:\n\\Library folder and all its subfolders.\nYou can use Wildcards, for example '\\Users*\\Desktop' will match:\n'\\Users\\user1\\Desktop'\n'\\Users\\user1\\user2\\Desktop'\n'\\Users*\\Desktop'\nYou can also use Environmental variables, for example:\n%AppData%\\app123\nWildcard values are supported. So a path definition can contain an asterisk (\n*\n) in the middle of the path or at the end of the path.\nExample:\n\\\\Lib*\nwill cover\n\\\\Libray\nYou can assign the following policy actions to the group in a DLP policy:\nAllow\n(audit with no user notifications or alerts)\nAudit only\n(you can add notifications and alerts)\nBlock with override\n(blocks the action, but the user can override)\nBlock\n(blocks no matter what)\nOnce you define a network share group, you can use it in all of your DLP policies that are scoped to\nDevices\n. For more information about configuring policy actions to use authorization groups, see\nScenario 8 Authorization groups\n.\nCreate a Network Share group\nOpen\nMicrosoft Purview portal\nand navigate to\nData Loss Prevention\n>\nOverview\n> settings gear icon in the upper right corner >\nData Loss Prevention\n>\nEndpoint DLP settings\n>\nNetwork share groups\n.\nSelect\n+ Create network share group\n.\nProvide a\nGroup name\n.\nAdd the file path to the share.\nSelect\nAdd\n.\nAdd other share paths to the group as needed.\nSelect\nSave\nand then\nClose\n.\nVPN settings\nUse the VPN list to control only those actions that are being carried out over that VPN.\nNote\nThis feature is available for devices running any of these versions of Windows:\nWindows 10 and later (21H1, 21H2) with KB 5018482\nWin 11 21H2, 22H2 with KB 5018483\nWindows 10 RS5 (KB 5006744)\nWhen you list a VPN in\nVPN Settings\n, you can assign the following policy actions to them:\nAllow\n(audit with no user notifications or alerts)\nAudit only\n(you can add notifications and alerts)\nBlock with override\n(blocks the action, but the user can override)\nBlock\n(blocks no matter what)\nThese actions can be applied individually or collectively to the following user activities:\nCopy to clipboard\nCopy to a USB removable device\nCopy to a network share\nPrint\nCopy or move using unallowed (restricted) Bluetooth app\nCopy or move using RDP\nWhen configuring a DLP policy to restrict activity on devices, you can control what happens to each activity performed when users are connected to your organization within any of the VPNs listed.\nUse the\nServer address\nor\nNetwork address\nparameters to define the VPN allowed.\nGet the Server address or Network address\nOn a DLP monitored Windows device, open a\nWindows PowerShell\nwindow as an administrator.\nRun the following cmdlet, which returns multiple fields and values.\nGet-VpnConnection\nAmong the results of the cmdlet, find the\nServerAddress\nfield and record that value. You use the\nServerAddress\nwhen you create a VPN entry in the VPN list.\nFind the\nName\nfield and record that value. The\nName\nfield maps to the\nNetwork address\nfield when you create a VPN entry in the VPN list.\nAdd a VPN\nOpen\nMicrosoft Purview portal\nand navigate to\nData Loss Prevention\n>\nOverview\n> settings gear icon in the upper right corner >\nData Loss Prevention\n>\nEndpoint DLP settings\n>\nVPN settings\n.\nSelect\nAdd or edit VPN addresses\n.\nProvide either the\nServer address\nor\nNetwork address\nthat you recorded after running\nGet-VpnConnection\n.\nSelect\nSave\n.\nClose the item.\nImportant\nUnder the\nNetwork restrictions\nsetting, you will also see\nCorporate network\nas an option.\nCorporate network\nconnections are all connections to your organizations resources. You can see if device is using a\nCorporate network\nby running the\nGet-NetConnectionProfile\ncmdlet as an administrator. If the\nNetworkCategoryId\nin the output is\nDomainAuthenticated\n, it means the machine is connected to the Corporate network. If the output is anything else, the machine is not .\nIn some cases, a machine can be both VPN connected and Corporate network connected. If both are selected under the\nNetwork restrictions\n, Endpoint DLP will apply the action based on the order. If you want the action for VPN to be the one that's applied, move the VPN entry above\nCorporate network to\nhave higher priority than the action for\nCorporate network\n.\nSee\nScenario 9: Network exceptions\nfor more information on configuring policy actions to use network exceptions.\nSee also\nLearn about Endpoint data loss prevention\nGet started with Endpoint data loss prevention\nLearn about data loss prevention\nGet started with Activity explorer\nMicrosoft Defender for Endpoint\nOnboard Windows 10 and Windows 11 devices into Microsoft Purview overview\nMicrosoft 365 subscription\nMicrosoft Entra joined\nDownload the new Microsoft Edge based on Chromium\nCreate and Deploy data loss prevention policies\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Configure Settings",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/information-barriers": {
      "content_hash": "sha256:f8c485354a9a73381edebb49d46063577cbe37d1579380efa24c5009465fa09e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLearn about Information Barriers\nFeedback\nSummarize this article for me\nMicrosoft Purview Information Barriers (IB) is a compliance solution that restricts two-way communication and collaboration between groups and users in Microsoft Teams, SharePoint, and OneDrive. Often used in highly regulated industries, IB helps avoid conflicts of interest and safeguards internal information between users and organizational areas.\nWhen you create IB policies, users who can't communicate or share files with other specific users can't find, select, chat, or call those users. IB policies automatically put checks in place to detect and prevent unauthorized communication and collaboration among defined groups and users. IB policies are independent from\ncompliance boundaries\nfor eDiscovery investigations that control user content locations that eDiscovery managers can search.\nIB policies can allow or prevent communication and collaboration between groups and users for the following example scenarios:\nUsers in the\nDay Trader\ngroup can't communicate or share files with the\nMarketing Team\nInstructors in one school can't communicate or share files with students in another school in the same school district.\nFinance personnel working on confidential company information can't communicate or share files with certain groups within their organization\nAn internal team with trade secret material can't call or chat online with users in certain groups within their organization\nA research team can only call or chat online with a product development team\nA SharePoint site for\nDay Trader\ngroup can't be shared or accessed by anyone outside of the\nDay Trader\ngroup\nImportant\nInformation Barriers\nonly supports\ntwo-way communication and collaboration restrictions. For example, a scenario where Marketing can communicate and collaborate with Day Traders, but Day Traders can't communicate and collaborate with Marketing\nisn't supported\n.\nInformation Barriers and Microsoft Teams\nIn Microsoft Teams, IB policies determine and prevent the following kinds of unauthorized communication and collaboration:\nSearching for a user\nAdding a member to a team\nStarting a chat session with someone\nStarting a group chat\nInviting someone to join a meeting\nSharing a screen\nPlacing a call\nSharing a file with another user\nAccessing a file through sharing a link\nIf the users conducting these activities in Microsoft Teams are included in an IB policy to prevent the activity, they can't proceed. In addition, everyone included in an IB policy can be potentially blocked from communicating with other users in Microsoft Teams. When users affected by IB policies are part of the same team or group chat, they might be removed from those chat sessions and further communication with the group might not be allowed.\nFor more information, see\nInformation Barriers in Microsoft Teams\n.\nInformation Barriers and SharePoint and OneDrive\nIn SharePoint and OneDrive, IB policies detect and prevent the following kinds of unauthorized collaboration:\nAdding a member to a site\nAccessing site or content by a user\nSharing site or content with another user\nSearching a site\nFor more information, see\nInformation Barriers in SharePoint\nand\nInformation Barriers in OneDrive\n.\nInformation Barriers and Microsoft Planner\nAs a work management tool,\nMicrosoft Planner\nenables users to collaborate on plans and tasks. If your compliance admin configures IB policies to restrict communication and collaboration between user segments, Microsoft Planner supports these restrictions.\nIB policies allow administrators to enable or disable search restrictions in the people picker. With IB support in Planner, when a user searches for others in the People picker to share a plan or to assign a task, they don't see users from segments they're restricted from communicating with. This restriction prevents users from one segment from sharing plans or assigning tasks to users in another segment.\nIB support in Microsoft Planner is available for basic plans in the following applications:\nPlanner Web\nPlanner in Teams web\nPlanner in Teams desktop\nPlanner in Teams mobile app\nWhen IB policy administrators create a new policy or modify an existing policy, users can still access existing plans shared with them or already assigned tasks. For any subsequent plan sharing or task assignment, an IB policy check is triggered and collaboration is permitted or restricted as defined by the policy.\nInformation Barriers and Exchange Online\nInformation barrier (IB) policies can't restrict communication and collaboration between groups and users in email messages. Only Exchange Online deployments currently support IB policies. If your organization needs to define and control email communications, consider using\nExchange mail flow rules\n.\nInformation Barriers and Exchange for single and multi-segment modes\nIf your organization uses\nsingle\nor\nmultisegment\nmode\n, Information Barriers no longer relies on Exchange Online Address Book Policies (ABPs). Enabling Information Barriers doesn't affect organizations that use ABPs. If users don't have an ABP defined with associated IB segments and policies, the system automatically creates an ABP with empty address lists for these users. You can change these ABPs as needed. We recommend that your ABPs are consistent with the segments you configure in Information Barriers. Avoid user visibility differences between your existing ABPs and your new Information Barriers configuration.\nInformation Barriers and Exchange for legacy mode\nIf your organization uses\nlegacy\nmode\n, IB policies rely on\nExchange Online Address Book Policies (ABPs)\n. ABPs let organizations virtually assign users into specific groups to provide customized views of the organization's global address list (GAL). When you create IB policies, the system automatically creates ABPs for the policies. As you add IB policies in your organization, the structure and behavior of your GAL changes to comply with IB policies.\nBefore you define and apply IB policies, remove all existing Exchange address book policies in your organization. IB policies rely on address book policies, and existing ABPs policies aren't compatible with the ABPs that IB creates. To remove your existing address book policies, see\nRemove an address book policy in Exchange Online\n. When you enable IB policies and enable hierarchical address book, all users not included in an IB segment see the\nhierarchical address book\nin Exchange Online.\nReady to get started?\nGet started with Information Barriers\nManage IB policies\nUse multi-segment support in Information Barriers\nSee the attributes that can be used for IB policies\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Information Barriers",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/encryption-sensitivity-labels": {
      "content_hash": "sha256:81ac941c857905dc72e86933a3666f0dcec765fdfb113c8b6041c213cd08da7f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRestrict access to content by using sensitivity labels to apply encryption\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nWhen you create a sensitivity label, you can restrict access to content that the label will be applied to. For example, with the encryption settings for a sensitivity label, you can protect content so that:\nOnly users within your organization can open a confidential document or email.\nOnly users in the marketing department can edit and print the promotion announcement document or email, while all other users in your organization can only read it.\nUsers can't forward an email or copy information from it that contains news about an internal reorganization.\nThe current price list that is sent to business partners can't be opened after a specified date.\nOnly the people sent a meeting invite to kick off a confidential project can open the meeting invite and they can't forward it to others.\nWhen a document, email, or meeting invite is encrypted, access to the content is restricted, so that it:\nCan be decrypted only by users authorized by the label's encryption settings.\nRemains encrypted no matter where it resides, inside or outside your organization, even if the file's renamed.\nIs encrypted both at rest (for example, in a OneDrive account) and in transit (for example, email as it traverses the internet).\nFinally, as an admin, when you configure a sensitivity label to apply encryption, you can choose either to:\nAssign permissions now\n, so that you determine exactly which users get which permissions to content with that label.\nLet users assign permissions\nwhen they apply the label to content. This way, you can allow people in your organization some flexibility that they might need to collaborate and get their work done.\nThe encryption settings are available when you\ncreate or edit a sensitivity label\nin the Microsoft Purview portal.\nNote\nA sensitivity label in Outlook can apply S/MIME protection rather than encryption and permissions from the Azure Rights Management service. For more information, see\nConfigure a label to apply S/MIME protection in Outlook\n.\nUnderstand how the encryption works\nUnless you're using\nS/MIME for Outlook\n, encryption that's applied by sensitivity labels to documents, emails, and meeting invites all use the Azure Rights Management service (Azure RMS) from Microsoft Purview Information Protection. This protection solution uses encryption, identity, and authorization policies. To learn more, see\nWhat is Azure Rights Management?\n.\nWhen you use this encryption solution, the\nsuper user\nfeature ensures that authorized people and services can always read and inspect the data that has been encrypted for your organization. If necessary, the encryption can then be removed or changed. For more information, see\nConfigure Azure Rights Management super users for discovery services or data recovery\n.\nImportant\nYou can also use\nsensitivity labels to apply encryption to audio and video streams for Teams meetings\n, but this uses a different method of encryption and not the Azure Rights Management service that's used for emails, meeting invites, and documents. For more information about the encryption used for Teams meetings, see the\nMedia encryption\nfrom the Teams security guide.\nImportant prerequisites\nBefore you can use encryption, you might need to do some configuration tasks. When you configure encryption settings, there's no check to validate that these prerequisites are met.\nActivate Azure Rights Management\nFor sensitivity labels to apply encryption with rights management, the Azure Rights Management service from Microsoft Purview Information Protection must be activated for your tenant. In newer tenants, this is the default setting, but you might need to manually activate the service. For more information, see\nActivate the Azure Rights Management service\n.\nCheck for network requirements\nYou might need to make some changes on your network devices such as firewalls. For details, see\nFirewalls and network infrastructure\n.\nCheck your Microsoft Entra configuration\nThere are some Microsoft Entra configurations that can prevent authorized access to encrypted content. For example, cross-tenant access settings and Conditional Access policies. For more information, see\nMicrosoft Entra configuration for encrypted content\n.\nConfigure Exchange for Azure Rights Management\nExchange doesn't have to be configured for Azure Rights Management before users can apply labels in Outlook to encrypt their emails. However, until Exchange is configured for Azure Rights Management, you don't get the full functionality of encryption with rights management.\nFor example, users can't view encrypted emails or encrypted meeting invites on mobile phones or with Outlook on the web, encrypted emails can't be indexed for search, and you can't configure Exchange Online DLP for Rights Management protection.\nTo ensure that Exchange can support these additional scenarios:\nFor Exchange Online, see the instructions for\nExchange Online: IRM Configuration\n.\nFor Exchange on-premises, you must deploy the\nRMS connector and configure your Exchange servers\n.\nHow to configure a label for encryption\nFollow the general instructions to\ncreate or edit a sensitivity label\nand make sure the\nFiles & other data assets\noption is selected for the\nlabel's scope\n:\nThen, on the\nChoose protection settings for the types of items you selected\npage, make sure you select\nControl access\n.\nOn the\nAccess control\npage, select one of the following options:\nRemove access control settings if already applied to items\n: When you select this option, applying the label removes existing encryption, even if it was applied independently from a sensitivity label.\nIt's important to understand that this setting can result in a sensitivity label that users might not be able to apply when they don't have sufficient permissions to remove the existing encryption. For more information about this scenario, see the\nWhat happens to existing encryption when a label's applied\nsection.\nConfigure access control settings\n: Turns on encryption with rights management and makes the following settings visible:\nInstructions for these settings are in the following\nConfigure encryption settings\nsection.\nEditing labels to newly apply encryption or change existing encryption settings\nIt's a common deployment strategy to initially configure sensitivity labels that don't apply encryption, and later edit some of the existing labels to apply encryption. When the label changes\nreach your apps\n, the labels that you edited will apply that encryption for newly labeled items.\nFor files accessed in SharePoint and OneDrive when you've\nenabled SharePoint and OneDrive for sensitivity labels\nthe new encryption status of files automatically change when these files are next accessed. For example, they're opened in Office for the web, or downloaded. There's no need to remove the label and reapply it. For example, files that were previously unencrypted become encrypted.\nFor other items that are already labeled, they retain their previous encryption status unless you remove the label and reapply it. For example, after changing the sensitivity label to now apply encryption, when you open previously labeled and unencrypted documents or emails in Office Desktop or Office Mobile, those items remain unencrypted unless you remove the label and reapply it. Similarly, if you change the sensitivity label settings to not apply encryption (remove the option for access control), those items remain encrypted unless you remove the label and reapply it.\nFor items that are already labeled with encryption and the assign permissions now option, when you change the encryption settings for users or permissions, the new settings will be applied for existing items when users authenticate with the encryption service. In most cases, there's no need to remove and reapply the label. However, if users have already opened an encrypted document or email, they won't get the new settings until their use license has expired and they must reauthenticate. For more information about this scenario, see the related\nfrequently asked question\nfor how the encryption works.\nWhenever you change the encryption options for letting users assign permissions, that change only applies to newly labeled or relabeled items. For example:\nYou change the label from assigning permissions now to let users assign permissions, or the other way around\nYou change the label from Do Not Forward to Encrypt-Only, or the other way around\nWhat happens to existing encryption when a label's applied\nIf a sensitivity label is applied to unencrypted content, the outcome for the encryption options you can select is self-explanatory. For example, if you didn't select\nControl access\n, the content remains unencrypted.\nHowever, the content might be already encrypted. For example, another user might have applied:\nTheir own permissions, which include user-defined permissions when prompted by a label, custom permissions by the Microsoft Purview Information Protection client, and the\nRestricted Access\ndocument protection from within an Office app.\nA rights management template that encrypts the content independently from a label. This category includes mail flow rules that apply encryption by using rights protection.\nA label that applies encryption with permissions assigned by the administrator.\nThe following table identifies what happens to existing encryption when a sensitivity label is applied to that content:\nEncryption: Not selected\nEncryption: Configured\nEncryption: Remove\nPermissions specified by a user\nOriginal encryption is removed\nNew label encryption is applied\nOriginal encryption is removed\nRights management template\nOriginal encryption is preserved\nNew label encryption is applied\nOriginal encryption is removed\nLabel with administator-defined permissions\nOriginal encryption is removed\nNew label encryption is applied\nOriginal encryption is removed\nIn the cases where the new label encryption is applied or the original encryption is removed, this happens only if the user who applies the label has a usage right or role that supports this action:\nThe\nusage right\nExport or Full Control.\nThe role of\nRights Management issuer or Rights Management owner\n, or\nsuper user\n.\nIf the user doesn't have one of these rights or roles, the label can't be applied and so the original encryption is preserved. The user sees the following message:\nYou don't have permission to make this change to the sensitivity label. Please contact the content owner.\nFor example, the person who applies Do Not Forward to an email message can relabel the thread to replace the encryption or remove it, because they're the Rights Management owner for the email. But except for super users, recipients of this email can't relabel it because they don't have the required usage rights.\nEmail attachments for encrypted email messages and meeting invites\nWhen an email message or meeting invite is encrypted by any method, any unencrypted Office documents that are attached to the email or invite automatically inherit the same encryption settings. You can't turn off this encryption inheritance, for example, with a setting or\nlabel scoping\n.\nAny sensitivity label from the email message or meeting invite is not inherited by the attachment but could be automatically applied when a user in the same tenant opens the document. For more information, see\nEncryption-based label matching for documents\n.\nDocuments that are already encrypted and then added as attachments always preserve their original encryption.\nConfigure encryption settings\nWhen you select\nConfigure access control settings\non the\nAccess control\npage to create or edit a sensitivity label, choose one of the following options:\nAssign permissions now\n, so that you can determine exactly which users get which permissions to content that has the label applied. For more information, see the next section\nAssign permissions now\n.\nLet users assign permissions\nwhen your users apply the label to content. With this option, you can allow people in your organization some flexibility that they might need to collaborate and get their work done. For more information, see the\nLet users assign permissions\nsection on this page.\nFor example, if you have a sensitivity label named\nHighly Confidential\nthat will be applied to your most sensitive content, you might want to decide now who gets what type of permissions to that content.\nAlternatively, if you have a sensitivity label named\nBusiness Contracts\n, and your organization's workflow requires that your people collaborate on this content with different people on an unplanned basis, you might want to allow your users to decide who gets permissions when they assign the label. This flexibility both helps your users' productivity and reduces the requests for your admins to update or create new sensitivity labels to address specific scenarios.\nChoosing whether to assign permissions now or let users assign permissions:\nAssign permissions now\nUse the following options to control who can access email, meeting invites (if enabled), or documents to which this label is applied. You can:\nAllow access to labeled content to expire\n, either on a specific date or after a specific number of days after the label is applied. After this time, users won't be able to open the labeled item. If you specify a date, it's effective midnight on that date in your current time zone. Some email clients might not enforce expiration and show emails past their expiration date, due to their caching mechanisms.\nAllow offline access\nnever, always, or for a specific number of days after the label is applied. Use this setting to balance any security requirements you have with the ability for users to open encrypted content when they don't have an internet connection. If you restrict offline access to never or a number of days, when that threshold is reached, users must be reauthenticated and their access is logged. For more information about how this process works, see the following section about the\nRights Management use license\n.\nAccess control settings for encrypted content:\nRecommendations for the expiry and offline access settings:\nSetting\nRecommended setting\nUser access to content expires\nNever\nunless the content has a specific time-bound requirement.\nAllow offline access\nDepends on the sensitivity of the content:\n-\nOnly for a number of days\n=\n7\nfor sensitive business data that could cause damage to the business if shared with unauthorized people. This recommendation offers a balanced compromise between flexibility and security. Examples include contracts, security reports, forecast summaries, and sales account data.\n-\nNever\nfor when the label is configured for\ndynamic watermarks\nand any very sensitive business data that would cause damage to the business if it was shared with unauthorized people. This recommendation prioritizes security over flexibility, and ensures that if you remove one or more users' access to the document, they won't be able to open it. Examples include employee and customer information, passwords, source code, and pre-announced financial reports.\n-\nAlways\nfor less sensitive content where it doesn't matter if users can continue to open encrypted content for up to 30 days (or the configured use license validity period for the tenant) after their access is removed and they have previously opened the encrypted content.\nOnly labels that are configured to assign permissions now support different values for offline access. Labels that let users assign the permissions automatically use the tenant's Rights Management use license validity period. For example, labels that are configured for Do Not Forward, Encrypt-Only, and prompt users to specify their own permissions. The default value for this setting is 30 days.\nRights Management use license for offline access\nNote\nAlthough you can configure the encryption setting to allow offline access, some apps might not support offline access for encrypted content. For example, labeled and encrypted files in\nPower BI Desktop\nwon't open if you're offline.\nWhen a user opens an item that's been protected by encryption from the Azure Rights Management service, an Azure Rights Management use license for that content is granted to the user. This use license is a certificate that contains the user's usage rights for the document or email, and the encryption key that was used to encrypt the content. The use license also contains an expiration date if this has been set, and how long the use license is valid.\nIf no expiration date has been set, the default use license validity period for a tenant is 30 days. For the duration of the use license, the user isn't reauthenticated or reauthorized for the content. This process lets the user continue to open the protected document or email without an internet connection. When the use license validity period expires, the next time the user accesses the protected document or email, the user must be reauthenticated and reauthorized.\nIn addition to reauthentication, the encryption settings and user group membership is reevaluated. This means that users could experience different access results for the same item if there are changes in the encryption settings or group membership from when they last accessed the content.\nTo learn how to change the default 30-day setting, see\nRights Management use license\n.\nAssign permissions to specific users or groups\nYou can grant permissions to specific people so that only they can interact with the labeled content:\nFirst, add users or groups that will be assigned permissions to the labeled content.\nThen, choose which permissions those users should have for the labeled content.\nAssigning permissions:\nAdd users or groups\nWhen you assign permissions, you can choose:\nEveryone in your organization (all tenant members). This setting excludes guest accounts.\nAny authenticated users. Make sure you understand the\nrequirements and limitations\nof this setting before selecting it.\nAny specific user or email-enabled security group, distribution group, or Microsoft 365 group in Microsoft Entra ID. The Microsoft 365 group can have static or\ndynamic membership\n. You can't use a\ndynamic distribution group from Exchange\nbecause this group type isn't synchronized to Microsoft Entra ID. You also can't use a security group that isn't email-enabled.\nAlthough you can specify groups that contain mail contacts as a convenient method to grant access to multiple people outside your organization, there's currently a known issue with this configuration. For more information, see\nMail contacts in groups have intermittent access to encrypted content\n.\nAny email address or domain. Use this option to specify all users in another organization who uses Microsoft Entra ID, by entering any domain name from that organization. You can also use this option for social providers, by entering their domain name such as\ngmail.com\n,\nhotmail.com\n, or\noutlook.com\n.\nNote\nIf you specify a domain from an organization that uses Microsoft Entra ID, you can't restrict access to that specific domain. Instead, all verified domains in Microsoft Entra ID are automatically included for the tenant that owns the domain name you specify.\nWhen you choose all users and groups in your organization or browse the directory, the users or groups must have an email address.\nAs a best practice, use groups rather than users. This strategy keeps your configuration simpler.\nRequirements and limitations for \"Add any authenticated users\"\nThis setting doesn't restrict who can access the content that the label encrypts, while still encrypting the content and providing you with options to restrict how the content can be used (permissions), and accessed (expiry and offline access). However, the application opening the encrypted content must be able to support the authentication being used. For this reason, federated social providers such as Google, and onetime passcode authentication work only for email and meeting invites, and only when you use Exchange Online. Microsoft accounts can be used with Office 365 apps and the\nMicrosoft Purview Information Protection viewer\n.\nNote\nConsider using this setting with\nSharePoint and OneDrive integration with Microsoft Entra B2B\nwhen sensitivity labels are\nenabled for Office files in SharePoint and OneDrive\n.\nSome typical scenarios for any authenticated users setting:\nYou don't mind who views the content, but you want to restrict how it's used. For example, you don't want the content to be edited, copied, or printed.\nYou don't need to restrict who accesses the content, but you want to be able to confirm who opens it.\nYou have a requirement that the content must be encrypted at rest and in transit, but it doesn't require access controls.\nChoose permissions\nWhen you choose which permissions to allow for those users or groups, you can select either:\nA\npredefined permissions level\nwith a preset group of rights, such as Editor or Restricted Editor.\nCustom permissions, where you choose one or more usage rights.\nFor more information to help you select the appropriate permissions, see\nUsage rights and descriptions\n.\nNote that the same label can grant different permissions to different users. For example, a single label can assign some users as Restricted Editor and a different user as Owner, as shown in the following screenshot.\nTo do this, add users or groups, assign them permissions, and save those settings. Then repeat these steps, adding users and assigning them permissions, saving the settings each time. You can repeat this configuration as often as necessary, to define different permissions for different users.\nRights Management issuer (user applying the sensitivity label) always has Full Control\nBy default, encryption for a sensitivity label uses the Azure Rights Management service from Microsoft Purview Information Protection. When a user applies a sensitivity label to protect a document or email by using encryption, that user becomes the Rights Management issuer for that content.\nThe Rights Management issuer is always granted Full Control permissions for the document or email, and in addition:\nIf the encryption settings include an expiration date, the Rights Management issuer can still open and edit the document or email after that date.\nThe Rights Management issuer can always access the document or email offline.\nThe Rights Management issuer can still open a document after it's revoked.\nFor more information, see\nRights Management issuer and Rights Management owner\n.\nDynamic watermarks\nIdentify the minimum versions of Office apps required by using the\ncapabilities tables\nand the rows for\nDynamic watermarks\n.\nWhen a user accesses a file with this sensitivity label applied, by default, their Universal Principal Name (UPN) is dynamically inserted as a watermark on each page of the file. Typically, a user's UPN is the same as their email address. If you select\nCustomize text (optional)\n, you can specify a custom string that also supports including the date and time.\nThis watermark is highly visible when viewing the file on a device, and persists when printed, although not when exported. This watermarking is more secure than the standard content markings for a label, because the user can't easily manually remove or change it.\nThe watermark is removed when a user relabels the document, choosing a sensitivity label that applies a different dynamic watermark, or no dynamic watermark. However, as with all encrypted content, a user must have the\nusage right\nof Export or Full Control to remove the existing encryption.\nThis protective watermarking is supported only for sensitivity labels that apply encryption and we also recommend that the encryption option of\nAllow offline access\nis set to\nNever\n. As with other encryption settings, dynamic watermarks are supported across tenants. Use it for your most sensitive documents as a visual deterrent against screen captures by the person who opened the document. However, be aware of the following considerations.\nLimitations in Office where dynamic watermarks are not yet supported, so the document opens without apply the watermark:\nFile preview\nfor attachments in Outlook\nPowerPoint Live in Microsoft Teams\nUnless opening the document falls into one of the exceptions previously listed, one of the following must be true to open a labeled document that applies dynamic watermarks:\nThe user is the Rights Management owner, which most of the time, means they applied the label themselves. For more information, see\nRights Management issuer and Rights Management owner\n.\nThe user opens the document with an app that understands dynamic watermarks. Use the\ncapabilities tables\nand the row\nDynamic watermarks\nto confirm supported versions.\nThe user opens the document in Office on the web.\nIf none of these conditions are met when a user opens the document in an Office app, and they're not one of the listed exceptions, the document won't open. Make sure you understand this restriction before you use this label configuration.\nCaution\nExcept for the listed limitations, Microsoft Office apps will either deny access if they don't support dynamic watermarks, or enforce dynamic watermarks if they do.\nConsiderations for previously labeled documents:\nLike all changed encryption settings, a newly configured dynamic watermark doesn't immediately get applied when you already have a valid\nRights Management use license\nfor a document. After the use license expires, you must reauthenticate to the Azure Rights Management service to open the document and then the dynamic watermark setting gets applied.\nThere's no automatic detection and resolution if the sensitivity label previously applied a standard watermark as a content marking.\nDouble Key Encryption\nNote\nFor built-in labeling, identify the minimum versions required by using the\ncapabilities tables\nand the row\nDouble Key Encryption (DKE)\n.\nSelect the\nDouble Key Encryption\nlabel option only after you've configured the Double Key Encryption service and you need to use this double key encryption for files and emails that will have this label applied. After the label is configured and saved, you won't be able to edit it.\nFor more information, prerequisites, and configuration instructions, see\nDouble Key Encryption (DKE)\n.\nLet users assign permissions\nImportant\nNot all labeling clients support all the options that let users assign their own permissions. Use this section to learn more.\nOften referred to as \"user-defined permissions\", you can use the following options to let users assign permissions when they manually apply a sensitivity label to content:\nIn Outlook, a user can select restrictions equivalent to the\nDo Not Forward\noption or\nEncrypt-only\nfor their chosen recipients.\nThe Do Not Forward option is supported by all email clients that support sensitivity labels. However, applying the\nEncrypt-Only\noption with a sensitivity label is a more recent release. For email clients that don't support this capability, the label won't be visible.\nTo check the minimum versions of Outlook apps that use built-in labeling to support applying the Encrypt-Only option with a sensitivity label, use the\ncapabilities table for Outlook\nand the row\nLet users assign permissions: - Encrypt-Only\n.\nIn Word, PowerPoint, and Excel, unless the label is configured to\nextend permissions for a SharePoint document library\n, a user is prompted to select their own permissions for specific users, groups, or organizations.\nFor Office apps that don't support this capability, the label either won't be visible for users, or the label is visible for consistency but it can't be applied with an explanation message to users.\nTo check which Office apps support this option, use the\ncapabilities table for Word, Excel, and PowerPoint\nand the rows for\nLet users assign permissions\n.\nNote\nYou won't be able to use these configurations if the label scope excludes email (for Do Not Forward and Encrypt-Only) or excludes files (for prompting users in Word, PowerPoint, and Excel). For more information, see\nScope labels to just files or emails\n.\nWhen the options are supported, use the following table to identify when users see the sensitivity label:\nSetting\nLabel visible in Outlook\nLabel visible in Word, Excel, PowerPoint\nIn Outlook, enforce restrictions with the Do Not Forward or Encrypt-Only option\nYes\nNo\nIn Word, PowerPoint, and Excel, prompt users to specify permissions\nNo\nYes\nWhen both settings are selected, the label is therefore visible in both Outlook and in Word, Excel, and PowerPoint.\nA sensitivity label that lets users assign permissions can be recommended to users, but can only be automatically applied for the Do Not Forward and Encrypt-Only options.\nConfiguring the user-assigned permissions:\nOutlook restrictions\nIn Outlook, when a user applies a sensitivity label that lets them assign permissions to a message, you can choose the\nDo Not Forward option\nor\nEncrypt-Only\n. The user will see the label name and description at the top of the message, which indicates the content's being protected. Unlike Word, PowerPoint, and Excel (see the\nnext section\n), users aren't prompted to select specific permissions. For this configuration, the administrator controls the permissions, but not who has access.\nWhen either of these options are applied to an email, the email is encrypted and recipients must be authenticated. Then, the recipients automatically have restricted usage rights:\nDo Not Forward\n: Recipients can't forward the email, print it, or copy from it. For example, in the Outlook client, the Forward button isn't available, the Save As and Print menu options aren't available, and you can't add or change recipients in the To, Cc, or Bcc boxes.\nFor more information about how this option works, see\nDo Not Forward option for emails\n.\nEncrypt-Only\n: Recipients have all usage rights except Save As, Export and Full Control. This combination of usage rights means that the recipients have no restrictions except that they can't remove the protection. For example, a recipient can copy from the email, print it, and forward it.\nFor more information about how this option works, see\nEncrypt-only option for emails\n.\nUnencrypted Office documents that are attached to the email or meeting invite automatically inherit the same restrictions. For Do Not Forward, the usage rights applied to these documents are Edit Content, Edit; Save; View, Open, Read; and Allow Macros. If the user wants different usage rights for an attachment, or the attachment isn't an Office document that supports this inherited protection, the user needs to encrypt the file before attaching it to the email or meeting invite.\nWord, PowerPoint, and Excel permissions\nIn Word, PowerPoint, and Excel, when a user applies a sensitivity label that lets them assign permissions to a document, the user is prompted to specify their choice of users and permissions for the encryption. For this configuration, the user and not the administrator controls both who can access the document, and what permissions they have.\nSupport for organization-wide custom permissions\nFor built-in labeling in Windows, users can additionally specify a domain name when they're prompted to specify their choice of users and permissions. When a domain name is entered, the permissions will apply to all users in an organization that owns the domain and it is in Microsoft Entra ID. To identify the minimum versions that support this setting, use the\ncapabilities table\nand the row\nLet users assign permissions:- Prompt users for custom permissions (users, groups, and organizations)\n.\nNote\nThe displayed dialog box is updated in the latest versions of Office apps, but the support for organization-wide custom permissions remains when a domain name is entered. Information about this support is included in the popup information box.\nFor example, a user types\n@contoso.com\n(or\ncontoso.com\n) and grants read access. Because Contoso Corporation owns the contoso.com domain, all users in that domain and all other domains that the organization owns in Microsoft Entra ID will be granted read access.\nNote\nWhen you specify these values, don't surround them with quotation marks.\nIt's important to let users know that access isn't restricted to just the users in the domain specified. For example,\n@sales.contoso.com\nwouldn't restrict access to users in just the sales subdomain, but also grant access to users in the marketing.contoso.com domain, and even users with a disjoint namespace in the same Microsoft Entra tenant.\nExample configurations for the encryption settings\nFor each example that follows, do the configuration from the\nAccess control\npage when the\nConfigure access control settings\noption is selected:\nExample 1: Label that applies Do Not Forward to send an encrypted email to a Gmail account\nThis label displays only in Outlook and Outlook on the web, and you must use Exchange Online. Instruct users to select this label when they need to send an encrypted email to people using a Gmail account (or any other email account outside your organization).\nYour users type the Gmail email address in the\nTo\nbox. Then, they select the label and the Do Not Forward option is automatically added to the email. The result is that recipients can't forward the email, or print it, copy from it, or save the email outside their mailbox by using the\nSave As\noption.\nOn the\nAccess control\npage: For\nAssign permissions now or let users decide?\nselect\nLet users assign permissions when they apply the label\n.\nSelect the checkbox:\nIn Outlook, enforce restrictions equivalent to the Do Not Forward option\n.\nIf selected, clear the checkbox:\nIn Word, PowerPoint, and Excel, prompt users to specify permissions\n.\nSelect\nNext\nand complete the configuration.\nExample 2: Label that restricts read-only permission to all users in another organization\nThis label is suitable for sharing very sensitive documents as read-only, and the documents always require an internet connection to view them.\nThis label isn't suitable for emails.\nOn the *\nAccess control\npage: For\nAssign permissions now or let users decide?\nselect\nAssign permissions now\n.\nFor\nAllow offline access\n, select\nNever\n.\nSelect\nAssign permissions\n.\nOn the\nAssign permissions\npane, select\nAdd specific email addresses or domains\n.\nIn the text box, enter the name of a domain from the other organization, for example,\nfabrikam.com\n. Then select\nAdd\n.\nSelect\nChoose permissions\n.\nOn the\nChoose permissions\npane, select the dropdown box, select\nViewer\n, and then select\nSave\n.\nBack on the\nAssign Permissions\npane, select\nSave\n.\nOn the\nAccess control\npage, select\nNext\nand complete the configuration.\nExample 3: Add external users to an existing label that encrypts content\nThe new users that you add will be able open documents and emails that have already been protected with this label. The permissions that you grant these users can be different from the permissions that the existing users have.\nOn the\nAccess control\npage: For\nAssign permissions now or let users decide?\nmake sure\nAssign permissions now\nis selected.\nSelect\nAssign permissions\n.\nOn the\nAssign permissions\npane, select\nAdd specific email addresses or domains\n.\nIn the text box, enter the email address of the first user (or group) to add, and then select\nAdd\n.\nSelect\nChoose permissions\n.\nOn the\nChoose permissions\npane, select the permissions for this user (or group), and then select\nSave\n.\nBack on the\nAssign Permissions\npane, repeat steps 3 through 6 for each user (or group) that you want to add to this label. Then click\nSave\n.\nOn the\nAccess control\npage, select\nNext\nand complete the configuration.\nExample 4: Label that encrypts content but doesn't restrict who can access it\nThis configuration has the advantage that you don't need to specify users, groups, or domains to encrypt an email or document. The content will still be encrypted and you can still specify usage rights, an expiry date, and offline access.\nUse this configuration only when you don't need to restrict who can open the protected document or email. See\nmore information about this setting\n.\nOn the\nAccess control\npage: For\nAssign permissions now or let users decide?\nmake sure\nAssign permissions now\nis selected.\nConfigure settings for\nUser access to content expires\nand\nAllow offline access\nas required.\nSelect\nAssign permissions\n.\nOn the\nAssign permissions\npane, select\nAdd any authenticated users\n.\nFor\nUsers and groups\n, you see\nAuthenticated users\nautomatically added. You can't change this value, only delete it, which cancels the\nAdd any authenticated users\nselection.\nSelect\nChoose permissions\n.\nOn the\nChoose permissions\npane, select the dropdown box, select the permissions you want, and then select\nSave\n.\nBack on the\nAssign Permissions\npane, select\nSave\n.\nOn the\nAccess control\npage, select\nNext\nand complete the configuration.\nConsiderations for encrypted content\nEncrypting your most sensitive documents and emails helps to ensure that only authorized people can access this data. However, there are some considerations to take into account:\nIf your organization hasn't\nenabled sensitivity labels for Office files in SharePoint and OneDrive\n:\nSearch, eDiscovery, and Delve won't work for encrypted files.\nDLP policies work for the metadata of these encrypted files (including retention label information) but not the content of these files (such as credit card numbers within files).\nUsers can't open encrypted files using Office for the web. When sensitivity labels for Office files in SharePoint and OneDrive are enabled, users can use Office for the web to open encrypted files, with some\nlimitations\nthat include encryption that has been applied with an on-premises key (known as \"hold your own key\", or HYOK),\ndouble key encryption\n, and encryption that has been applied independently from a sensitivity label.\nIf you share encrypted documents with people outside your organization, you might need to create guest accounts and modify Conditional Access policies. For more information, see\nSharing encrypted documents with external users\n.\nWhen authorized users open encrypted documents in their Office apps, they see the label name and description in a yellow message bar at the top of their app. When the encryption permissions extend to people outside your organization, carefully review the label names and descriptions that will be visible in this message bar when the document is opened.\nFor multiple users to edit an encrypted file at the same time, they must all be using Office for the web or you've\nenabled co-authoring for files encrypted with sensitivity labels\nand all users have\nOffice apps that support this feature\n. If this isn't the case, and the file is already open:\nIn Office apps (Windows, Mac, Android, and iOS), users see a\nFile In Use\nmessage with the name of the person who has checked out the file. They can then view a read-only copy or save and edit a copy of the file, and receive notification when the file is available.\nIn Office for the web, users see an error message that they can't edit the document with other people. They can then select\nOpen in Reading View\n.\nThe\nAutoSave\nfunctionality in Office apps is disabled for encrypted files if you haven't\nenabled co-authoring for files encrypted with sensitivity labels\n. Users see a message that the file has restricted permissions that must be removed before AutoSave can be turned on.\nOffice for Windows supports labels that apply encryption when users aren't connected to the internet. But for the other platforms (macOS, iOS, Android), users must be online to apply these labels in Office apps. The Microsoft Purview Information Protection client must also be online to apply these labels in File Explorer and PowerShell. Users don't have to be online to open encrypted content. For more information about offline access, see the\nRights Management use license for offline access\nsection.\nEncrypted files might take longer to open in Office apps (Windows, Mac, Android, and iOS).\nIf a label that applies encryption is added by using an Office app when the document is\nchecked out in SharePoint\n, and the user then discards the checkout, the document remains labeled and encrypted.\nUnless you've\nenabled co-authoring for files encrypted with sensitivity labels\n, the following actions for encrypted files aren't supported from Office apps (Windows, Mac, Android, and iOS), and users see an error message that something went wrong. However, SharePoint functionality can be used as an alternative:\nView, restore, and save copies of previous versions. As an alternative, users can do these actions using Office for the web when you\nenable and configure versioning for a list or library\n.\nChange the name or location of files. As an alternative, users can\nrename a file, folder, or link in a document library\nin SharePoint.\nFor the best collaboration experience for files that are encrypted by a sensitivity label, we recommend you use\nsensitivity labels for Office files in SharePoint and OneDrive\nand Office for the web.\nNext steps\nNeed to share your labeled and encrypted documents with people outside your organization? See\nSharing encrypted documents with external users\n.\nTo use sensitivity labels to encrypt video and audio streams for Teams meetings, see\nUse sensitivity labels to protect calendar items, Teams meetings and chat\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Information Rights Management",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/encryption": {
      "content_hash": "sha256:752fee4f42d02f3d5d54c171d5fb3d9188b056468d3c5a8f89264770ece27e7e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEncryption\nFeedback\nSummarize this article for me\nEncryption is an important part of your file protection and information protection strategy. This article provides an overview of encryption for Microsoft 365. Get help with encryption tasks like how to set up encryption for your organization and how to password-protect Microsoft 365 documents.\nFor information about certificates and technologies like TLS, see\nTechnical reference details about encryption in Microsoft 365\n.\nFor an overview of how to configure or set up encryption for your organization, see\nSet up encryption in Microsoft 365 Enterprise\n.\nWhat is encryption, and how does it work in Microsoft 365?\nThe encryption process encodes your data (referred to as plaintext) into ciphertext. Unlike plaintext, ciphertext can't be used by people or computers unless and until the ciphertext is decrypted. Decryption requires an encryption key that only authorized users have. Encryption helps ensure that only authorized recipients can decrypt your content. Content includes files, email messages, calendar entries, and so on.\nEncryption by itself doesn't prevent content interception. Encryption is part of a larger information protection strategy for your organization. By using encryption, you help ensure that only authorized parties can use the encrypted data.\nYou can have multiple layers of encryption in place at the same time. For example, you can encrypt email messages and also the communication channels through which your email flows. With Microsoft 365, your data is encrypted at rest and in transit, using several strong encryption protocols, and technologies that include Transport Layer Security/Secure Sockets Layer (TLS/SSL), Internet Protocol Security (IPSec), and Advanced Encryption Standard (AES).\nEncryption for data at rest and data in transit\nExamples of data at rest\ninclude files that you uploaded to a SharePoint library, Project Online data, documents that you uploaded in a Skype for Business meeting, email messages, and attachments that you stored in folders in your mailbox, and files you uploaded to OneDrive.\nExamples of data in transit\ninclude mail messages that are in the process of being delivered, or conversations that are taking place in an online meeting. In Microsoft 365, data is in transit whenever a user's device is communicating with a Microsoft server, or when a Microsoft server is communicating with another server.\nWith Microsoft 365, multiple layers and kinds of encryption work together to secure your data. The following table includes some examples, with links to additional information.\nKinds of Content\nEncryption Technologies\nResources to learn more\nFiles on a device. These files can include email messages saved in a folder, documents saved on a computer, tablet, or phone, or data saved to the Microsoft cloud.\nBitLocker in Microsoft data centers. BitLocker can also be used on client machines, such as Windows computers and tablets\nDistributed Key Manager (DKM) in Microsoft data centers\nCustomer Key for Microsoft 365\nWindows IT Center: BitLocker\nMicrosoft Trust Center: Encryption\nCloud security controls series: Encrypting Data at Rest\nHow Exchange Online secures your email secrets\nService encryption with Microsoft Purview Customer Key\nFiles in transit between users. These files can include Microsoft 365 documents or SharePoint list items shared between users.\nTLS for files in transit\nData Encryption in OneDrive and SharePoint\nSkype for Business Online: Security and Archiving\nEmail in transit between recipients. This email includes email hosted by Exchange Online.\nMicrosoft Purview Message Encryption with Azure Rights Management, S/MIME, and TLS for email in transit\nMessage Encryption\nEmail encryption in Microsoft 365\nHow Exchange Online uses TLS to secure email connections in Microsoft 365\nChats, messages, and files in transit between recipients using Microsoft Teams.\nTeams uses TLS and MTLS to encrypt instant messages. Media traffic is encrypted using Secure RTP (SRTP). Teams uses FIPS (Federal Information Processing Standard) compliant algorithms for encryption key exchanges.\nEncryption for Teams\nMicrosoft 365 Crypto Update\nIn late August 2023, Microsoft Purview Information Protection began to use Advanced Encryption Standard (AES) with 256-bit key length in Cipher Block Chaining mode (AES256-CBC). By October 2023, AES256-CBC became the default for encryption of Microsoft 365 Apps documents and emails. You might need to take action to support this change in your organization. For more information, see\nTechnical reference details about encryption\n.\nWhat if I need more control over encryption to meet security and compliance requirements?\nMicrosoft 365 provides Microsoft-managed solutions for volume encryption, file encryption, and mailbox encryption in Microsoft 365. In addition, Microsoft provides encryption solutions that you can manage and control. These encryption solutions are built on Azure.\nTo learn more, see the following resources:\nWhat is Azure Rights Management?\nActivate Rights Management in the admin center\nSet up Information Rights Management (IRM) in SharePoint admin center\nOverview of Customer Key\nDouble Key Encryption\nHow do I...\nTo do this task\nSee these resources\nSet up encryption for my organization\nSet up encryption in Microsoft 365 Enterprise\nView details about certificates, technologies, and TLS cipher suites\nTechnical details about encryption\nWork with encrypted messages on a mobile device\nView encrypted messages on your Android device\nView encrypted messages on your iPhone or iPad\nEncrypt a document using password protection. (Password protection isn't supported in a browser. Use desktop versions of Word, Excel, and PowerPoint for password protection.)\nAdd or remove protection in your document, workbook, or presentation\n. Choose an\nAdd protection\nsection, and then see\nEncrypt with Password\n.\nRemove encryption from a document\nAdd or remove protection in your document, workbook, or presentation\n. Choose a\nRemove protection\nsection, and then see\nRemove password encryption\n.\nRelated topics\nPlan for Microsoft 365 security and information protection capabilities\nSecure your business data with Microsoft 365 for business\nMicrosoft Stream Video level encryption and playback flow\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Encryption",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/purview/data-classification-activity-explorer": {
      "content_hash": "sha256:5ef7a14d5ec3f550b52b3b3324672859c7952af3c4ec318dbecc1c48913b3b39",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGet started with activity explorer\nFeedback\nSummarize this article for me\nActivity explorer\nlets you monitor what's being done with your labeled content. Activity explorer provides a historical view of activities on your labeled content. The activity information comes from the Microsoft 365 unified audit logs. It's transformed and then made available in the activity explorer UI. Activity explorer reports on up to 30 days worth of data.\nActivity explorer gives you multiple ways to sort and view the data.\nFilters\nFilters are the building blocks of activity explorer. Each filter focuses on a different dimension of the collected data. You can use about 50 different individual filters, including:\nDate range\nActivity type\nLocation\nSensitivity label\nUser\nClient IP\nDevice name\nIs protected\nTo see all the filters, open the filter pane in activity explorer and look at the dropdown list.\nNote\nFilter options are generated based on the first 500 records to ensure optimal performance. This limitation might cause some values to not appear in the filter dropdown.\nFor endpoint events, only the most restrictive DLP rule appears. Filters you apply in activity explorer also operate based on this most restrictive rule.\nFilter sets\nActivity explorer comes with predefined sets of filters to help save time when you want to focus on a specific activity. Use filter sets to quickly provide you with a view of higher level activities than individual filters do. Some of the predefined filter sets are:\nEndpoint DLP activities\nSensitivity labels applied, changed, or removed\nEgress activities\nDLP policies that detected activities\nNetwork DLP activities\nProtected Browser\nYou can also create and save your own filter sets by combining individual filters.\nMicrosoft Security Copilot in activity explorer (preview)\nIn\npreview\n,\nMicrosoft Security Copilot in Microsoft Purview\nis embedded in activity explorer. It can help efficiently drill down into Activity data and help you identify activities, files with sensitive info, users, and other details that are relevant to an investigation.\nImportant\nBe sure to check the responses from Security Copilot for accuracy and completeness before taking any action based on the information provided. You can provide feedback to help improve the accuracy of the responses.\nData hunting\nSecurity Copilot skills use all the data available to Microsoft Purview, filters, and filter sets available in activity explorer and use machine learning to provide you with insights into the activity (sometimes referred to as\ndata hunting\n) on your data that is most important to you.\nShow me the top 5 activities from the past week\nFilter and investigate activities\nFind files used in specific activities\nSelecting a prompt automatically opens the Security Copilot side card and shows you the results of the query. You can then further refine the query.\nNatural language to filter set generation\nUse the prompt box to enter complex natural language queries to generate filter sets. For example, you can enter:\nFilter and investigate files copied to cloud with sensitive info type credit card number for past 30 days.\nSecurity Copilot generates a filter set for your query. Review the filter to make sure it fits your needs, then apply it to the data.\nPrerequisites\nSKU/subscriptions licensing\nFor information on licensing, see\nMicrosoft 365 Enterprise Plans\nMicrosoft 365 Service Descriptions\nPermissions\nAn account must be explicitly assigned membership in any one of these role groups, or must be explicitly granted the role.\nRoles and role groups\nUse roles and role groups to fine-tune your access controls. For more information, see\nPermissions in the Microsoft Purview portal\n.\nMicrosoft Purview roles\nInformation Protection Admin\nInformation Protection Analyst\nInformation Protection Investigator\nInformation Protection Reader\nMicrosoft Purview role groups\nInformation Protection\nInformation Protection Admins\nInformation Protection Investigators\nInformation Protection Analysts\nInformation Protection Readers\nMicrosoft 365 roles\nCompliance Admins\nSecurity Admins\nCompliance Data Admins\nMicrosoft 365 role groups\nCompliance Administrator\nSecurity Administrator\nSecurity Reader\nActivity types\nActivity explorer gathers information from the audit logs of multiple sources of activities.\nSome examples of the\nSensitivity label activities\nand\nRetention labeling activities\nfrom applications native to Microsoft Office, the Microsoft Purview Information Protection client and scanner, SharePoint, Exchange (sensitivity labels only), and OneDrive include:\nLabel applied\nLabel changed (upgraded, downgraded, or removed)\nAuto-labeling simulation\nFile read\nFor the current list of activities listed in Activity explorer, go into Activity explorer and open the activity filter. The list of activities is available in the dropdown list.\nLabeling activity specific to the Microsoft Purview Information Protection client and scanner that comes into Activity explorer includes:\nProtection applied\nProtection changed\nProtection removed\nFiles discovered\nFor more detailed information on what labeling activity makes it into Activity explorer, see\nLabeling events available in Activity explorer\n.\nAdditionally, Activity Explorer gathers DLP policy match events from Microsoft 365 workloads such as Exchange, SharePoint, OneDrive, Teams chat and channels, and on-premises SharePoint folders, libraries, and file shares. When you enable Endpoint data loss prevention (DLP), Activity Explorer also includes device-level activities from onboarded Windows 10, Windows 11, and the three most recent major macOS versions.\nSome example events gathered from devices include the following actions taken on files:\nDeletion\nCreation\nCopy to clipboard\nModify\nRead\nPrint\nRename\nCopy to network share\nAccess by an unallowed app\nUnderstanding the actions that are taken on content with sensitivity labels helps you determine whether the controls that you have in place, such as\nMicrosoft Purview Data Loss Prevention\npolicies, are effective. If not, or if you discover something unexpected (such as a large number of items labeled\nhighly confidential\nthat are downgraded to\ngeneral\n), you can manage your policies and take new actions to restrict the undesired behavior.\nNote\nActivity explorer doesn't currently monitor retention activities for Exchange.\nNote\nIf a user reports the Teams DLP verdict as a false positive, the activity shows as\nDLP info\nin the list on Activity explorer. The entry doesn't have any rule and policy match details but shows synthetic values. There's also no incident report generated for false positive reporting.\nActivity type events and alerts\nThis table shows the events that Activity Explorer triggers for three sample policy configurations. The events depend on whether a policy match is detected.\nPolicy configuration\nActivity Explorer event triggered for this action type\nActivity Explorer event triggered when a DLP rule is matched\nActivity Explorer alert triggered\nPolicy contains a single rule allowing the activity without auditing it.\nYes\nNo\nNo\nPolicy contains two rules: Matches for Rule #1 are allowed; policy matches for Rule #2 are audited.\nYes\n(Rule #2 only)\nYes\n(Rule #2 only)\nYes\n(Rule #2 only)\nPolicy contains two rules: Matches for both rules are allowed and not audited.\nYes\nNo\nNo\nSee also\nLearn about sensitivity labels\nLearn about retention policies and retention labels\nLearn about sensitive information types\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Activity Explorer",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/purview/compliance-manager": {
      "content_hash": "sha256:f1fbbc943a7a65611aa197f3ce4c42b9ca3cdca6da1a406d9a136c289bcec04d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Purview Compliance Manager\nFeedback\nSummarize this article for me\nWhat is Compliance Manager?\nMicrosoft Purview Compliance Manager is a solution that helps you automatically assess and manage compliance across your multicloud environment. Compliance Manager can help you throughout your compliance journey, from taking inventory of your data protection risks to managing the complexities of implementing controls, staying current with regulations and certifications, and reporting to auditors.\nWatch the video below to learn how Compliance Manager can help simplify how your organization manages compliance:\nCompliance Manager helps simplify compliance and reduce risk by providing:\nPre-built assessments for common industry and regional standards and regulations, or custom assessments to meet your unique compliance needs (available assessments depend on your licensing agreement;\nlearn more\n).\nWorkflow capabilities to help you efficiently complete your risk assessments through a single tool.\nDetailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. For actions that are managed by Microsoft, youâll see implementation details and audit results.\nA risk-based compliance score to help you understand your compliance posture by measuring your progress in completing improvement actions.\nThe Compliance Manager overview page shows your current compliance score, helps you see what needs attention, and guides you to key improvement actions.\nUnderstanding your compliance score\nCompliance Manager awards you points for completing improvement actions taken to comply with a regulation, standard, or policy, and combines those points into an overall compliance score. Each action has a different impact on your score depending on the potential risks involved. Your compliance score can help prioritize which action to focus on to improve your overall compliance posture. Compliance Manager gives you an initial score based on the Microsoft 365 data protection baseline. This baseline is a set of controls that includes key regulations and standards for data protection and general data governance.\nLearn more\nUnderstand scoring in Compliance Manager\n.\nLearn how to work with improvement actions\n.\nKey elements: controls, assessments, regulations, improvement actions\nCompliance Manager uses several data elements to help you manage your compliance activities. As you use Compliance Manager to assign, test, and monitor compliance activities, itâs helpful to have a basic understanding of the key elements: controls, assessments, regulations, and improvement actions.\nBe sure to check out the\nCompliance Manager glossary of terms\n.\nControls\nA control is a requirement of a regulation, standard, or policy. It defines how you assess and manage system configuration, organizational process, and people responsible for meeting a specific requirement of a regulation, standard, or policy. Compliance Manager tracks the following types of controls:\nMicrosoft managed controls\n: controls for Microsoft cloud services, which Microsoft is responsible for implementing\nYour controls\n: sometimes referred to as customer managed controls, these are controls implemented and managed by your organization\nShared controls\n: these are controls that both your organization and Microsoft share responsibility for implementing\nLearn more about\nmonitoring control progress\n.\nAssessments\nAn assessment is grouping of controls from a specific regulation, standard, or policy. Completing the actions within an assessment help you meet the requirements of a standard, regulation, or law. For example, you may have an assessment that, when you complete all actions within it, helps to bring your Microsoft 365 settings in line with ISO 27001 requirements. Assessments have several components:\nIn-scope services\n: the specific set of Microsoft services applicable to the assessment\nMicrosoft managed controls\n: controls for Microsoft cloud services, which Microsoft implements on your behalf\nYour controls\n: sometimes referred to as customer managed controls, these are controls implemented and managed by your organization\nShared controls\n: these are controls that both your organization and Microsoft share responsibility for implementing\nAssessment score\n: shows your progress in achieving total possible points from actions within the assessment that are managed by your organization and by Microsoft\nLearn more about\ncreating and managing assessments\n.\nRegulations\nCompliance Manager provides over 360 regulatory templates to help you quickly create assessments. For organizations with unique compliance needs, you can also create custom regulation templates. Learn more about working with\nregulations in Compliance Manager\nand view the full\nlist of regulations\n. Learn more about\ncreating regulation templates\n.\nImprovement actions\nImprovement actions help centralize your compliance activities. Each improvement action provides recommended guidance thatâs intended to help you align with data protection regulations and standards. Improvement actions can be assigned to users in your organization to perform implementation and testing work. You can also store evidence, notes, and record status updates within the improvement action. Learn more about\nworking with improvement actions\n.\nSupported languages\nCompliance Manager is available in the following languages:\nEnglish\nBahasa Indonesian\nBahasa Malay\nChinese (Simplified)\nChinese (Traditional)\nCzech\nDanish\nDutch\nFinnish\nFrench\nGerman\nHebrew\nHungarian\nItalian\nJapanese\nKorean\nNorwegian\nPolish\nPortuguese (Brazilian)\nRussian\nSpanish\nSwedish\nThai\nTurkish\nNext steps\nSign in, assign permissions and roles, configure settings, and personalize your dashboard view\n.\nLearn about and set up multicloud support\n.\nCreate assessments to help you comply with industry standards that matter most to your organization\n.\nGet detailed scenario-based guidance on using Compliance Manager and other Purview solutions to help you manage data privacy and data protection\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Compliance Manager",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/purview/compliance-manager-assessments": {
      "content_hash": "sha256:0452877136fa9cc59d62ff14715312ced7c440d90b2bdaa32c8778c351119f73",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nBuild and manage assessments in Compliance Manager\nFeedback\nSummarize this article for me\nCompliance Manager assessments help your organization evaluate its compliance with industry and regional regulations. Setting up the most relevant assessments for your organization can help you implement policies and operational procedures to limit your compliance risk. Ready-to-use regulatory templates for over 360 regulations contain the necessary controls and improvement actions for completing the assessment.\nTip\nGet a comprehensive compliance overview before you deploy Microsoft services in your organization. Learn more about\npredeployment compliance with Compliance Manager (preview)\n.\nAssessments page\nAll of your assessments are listed on the\nAssessments\npage Compliance Manager. You can create one assessment that covers multiple services. For example, you can create a single EU GDPR assessment that covers Microsoft 365, Microsoft Azure, Amazon Web Services (AWS), and Google Cloud Platform (GCP). The assessment details page shows a breakdown of control progress by service to help you evaluate how youâre doing across all your services. Learn more about\nmonitoring assessment progress from the assessment details page\n.\nImportant\nThe regulations that are available for your organization's use by default depend on your licensing agreement.\nReview licensing details\n.\nThe\nFree regulation licenses used/Purchased regulation licenses used\ncounter near the top of the page shows the number of regulations currently in use out of the total number available for your organization to use. Learn more about\nregulation availability\n.\nAssessment status and details\nThe assessments page summarizes key information about each assessment:\nAssessment\n: Name of the assessment.\nStatus\n: See status types below.\nComplete\n: All controls have a status of âPassed,â or at least one is passed and the rest are âOut of scope.â\nIncomplete\n: At least one control has a status of âFailed.\" Review the failed controls and, within those controls, review both your improvement actions and Microsoft actions to see which have a \"Failed\" status.\nNone\n: Not all controls have been tested.\nIn progress\n: Improvement actions have a status of âIn progress,â âPartial credit,â or âUndetected.\"\nProgress\n: The percentage of the work done toward completion, as measured by the number of controls successfully tested.\nYour improvement actions\n: The number of completed actions to satisfy implementation of your controls.\nMicrosoft actions\n: The number of completed actions to satisfy implementation of Microsoft controls.\nGroup\n: The name of the group to which the assessment belongs.\nService\n: The services covered by the assessment, such as Microsoft 365, Microsoft Azure, or other cloud services.\nRegulation\n: The regulatory template serving as the basis for the assessment.\nTo filter your view of assessments:\nSelect\nFilter\nat the top-left corner of your assessments list.\nOn the\nFilters\nflyout pane, check your desired criteria.\nSelect the\nApply\nbutton. The filter pane closes and you see your filtered view.\nYou can also modify your view to see assessments by group, product, or regulation by selecting the type of grouping from the\nGroup\ndrop-down menu above your assessments list.\nData protection baseline default assessment\nTo get you started, Microsoft provides a default\nData Protection Baseline\nassessment that's included at all subscription levels. This baseline assessment has a set of controls for key regulations and standards for data protection and general data governance. This baseline draws elements primarily from NIST CSF (National Institute of Standards and Technology Cybersecurity Framework) and ISO (International Organization for Standardization), as well as from FedRAMP (Federal Risk and Authorization Management Program) and GDPR (General Data Protection Regulation of the European Union).\nThis assessment is used to calculate your initial compliance score the first time you come to Compliance Manager, before you configure any other assessments. Compliance Manager collects initial signals from your Microsoft 365 solutions. You see at a glance how your organization is performing relative to key data protection standards and regulations, and see suggested improvement actions to take. Compliance Manager becomes more helpful as you build and manage your own assessments to meet your organization's particular needs.\nAssessments for AI regulations\nCompliance Manager provides four premium\nregulatory templates\nto help your organization assess, implement, and strengthen its compliance against AI regulations. These templates are applicable to\nall generative AI apps that Microsoft Purview supports for AI interactions\n, such as Microsoft 365 Copilot, Security Copilot, ChatGPT Enterprise, Microsoft Foundry, Gemini and DeepSeek.\nThe AI regulations listed below align with compliance requirements such as monitoring AI interactions and preventing data loss in AI applications:\nEU Artificial Intelligence Act\nISO/IEC 23894:2023\nISO/IEC 42001:2023\nNIST AI Risk Management Framework (RMF) 1.0\nWhere to find them\nOn the\nRegulations\npage in Compliance Manager, the AI regulations are listed under the\nPremium AI templates\nheader. All other premium regulations are listed under the\nPremium templates\nheader.\nUsing an AI regulation counts toward your purchased premium licenses. Learn more about\nregulation availability and licensing\n.\nHow to use them\nThe\nRecommendations\nsection from\nData Security Posture Management for AI\nprovides guided assistance on working with AI regulations. This solution displays recent interactions with sensitive data and recommends actions to take to help you stay compliant with AI regulations.\nAutomatic Assessments for AI Apps and Agents in Compliance Manager\nCompliance Manager integrates with Azure AI Foundry to automate compliance evaluations for AI models and agents. This integration syncs evaluation results directly from AI Foundry into Compliance Manager, reducing manual effort and improving regulatory alignment. Organizations benefit from built-in assessments for key AI regulationsâincluding the EU AI Act, NIST AI RMF, and ISO/IEC standardsâprovided free for six months with Copilot or Agent licenses. This capability enables quick, automated compliance checks without additional purchases, streamlining governance for AI deployments.\nPrerequisites\nThe admin account must have either the Azure AI Project Manager or Azure AI User RBAC role assigned to the relevant AI Foundry accounts.\nThis access is required to add Agents during assessment creation for the AI Foundry service in Compliance Manager.\nKey Features\nScoped Assessments\nâ Users define the assessment scope directly in Compliance Manager.\nComprehensive Action Set\nâ AI Foundry provides 75 actions, including 15 automated evaluation actions for metrics like reliability, BLEU score, coherence, and fluency.\nAutomated Sync\nâ Compliance Manager regularly syncs these 15 evaluation actions from AI Foundry, displaying real-time pass/fail status and detailed metrics.\nFlexible Action Management\nâ Users can convert automated actions to manual actions through Compliance Manager settings.\nManual Update Support\nâ Allows manual updates for organizations without AI Foundry access.\nEffort Reduction\nâ Eliminates repetitive tasks by automatically syncing evaluation results.\nDetailed Insights\nâ Provides granular evaluation metrics alongside compliance status for transparency.\nBaseline Assessment for Microsoft 365 Copilot and Copilot Chat\nMicrosoft Purview Compliance Manager provides a baseline assessment for Microsoft Copilot for Microsoft 365 and Copilot Chat. This assessment is derived from the global AI regulations and includes recommended controls to help organizations maintain compliance and reduce risk.\nWhen a Microsoft Copilot for Microsoft 365 or Copilot Chat license is purchased, the baseline assessment is automatically provisioned in the Microsoft 365 admin center. Administrators can view completed actions and pending tasks within the portal to track compliance progress and implement required controls.\nInitial steps before creating assessments\nListed below are details about steps and information that will help you prepare for creating an assessment:\nPlan a\ngrouping strategy\nfor your assessments.\nUnderstand\nregulatory templates\n, which contain the controls and action recommendations for assessments.\nSet up\nconnectors\nif you're assessing non-Microsoft services.\nGroups for assessments\nWhen you create an assessment, you must assign it to a group. Groups are containers that allow you to organize assessments in a way that is logical to you, such as by year or regulation, or based on your organization's divisions or geographies. This is why we recommend planning a grouping strategy before you create assessments. Below are examples of two groups and their underlying assessments:\nFFIEC IS assessment 2020\nFFIEC IS\nData security and privacy assessments\nISO 27001:2013\nISO 27018:2014\nDifferent assessments within a group or groups can share improvement actions. Improvement actions can be changes you make within technical solutions mapped to your tenant, like turning on two-factor authentication, or to nontechnical actions you perform outside the system, like instituting a new workplace policy. Any updates in details or status that you make to a technical improvement action will be picked up by assessments across all groups. Nontechnical improvement action updates will be recognized by assessments within the group where you apply them. This allows you to implement one improvement action and meet several requirements simultaneously.\nWhat to know when working with groups\nYou can create a group during the process of creating an assessment.\nGroups can't be standalone entities. A group must contain at least one assessment.\nGroup names must be unique within your organization.\nGroups don't have security properties. All permissions are associated with assessments.\nOnce you add an assessment to a group, the grouping can't be changed.\nIf you add a new assessment to an existing group, common information from assessments in that group are copied to the new assessment.\nRelated assessment controls in different assessments within the same group automatically update when completed.\nGroups can contain assessments for the same certification or regulation, but each group can only contain one assessment for a specific product-certification pair. For example, a group can't contain two assessments for Office 365 and NIST CSF. A group can contain multiple assessments for the same product only if the corresponding certification or regulation for each one is different.\nDeleting an assessment breaks the relationship between that assessment and the group.\nGroups can't be deleted.\nSet up connectors\nCompliance Manager has an integrated set of connectors to build assessments that cover non-Microsoft services like Salesforce and Zoom. Visit\nWorking with connectors\nto learn more and start the setup process.\nCreate assessments\nTo create and modify an assessment, a user must hold a role of Compliance Manager Administration, Compliance Manager Assessor, or Global Administrator. Learn more about\nroles and permissions\n.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nBefore starting to create an assessment, be sure you know which group you'll assign it to, or be prepared to create a new group for this assessment. Read details about\ngroups and assessments\n. To create an assessment, you use a guided process to select a regulation and designate services.\nBuild a custom assessment\nYou can modify a regulatory template by adding controls and improvement actions to create a customized assessment. Visit\nBuild custom assessments (preview)\nfor instructions.\nCreate an assessment using a guided process\nFrom your\nAssessments\npage, select\nAdd assessment\nto begin the assessment creation wizard.\nOn the\nBase your assessment on a regulation\npage, select\nSelect regulation\nto choose the regulatory template for the assessment. The\nSelect regulation\nflyout page opens.\nUse the search box to find your desired regulation, then select the check bubble to the left of the regulation name. Select\nSave\n, confirm your selection, then select\nNext\n.\nOn the\nAdd name and group\npage, enter values in the following fields:\nAssessment name\n: Assessment names must be unique. If the name matches another assessment in any group, you receive an error asking you to create a different name.\nAssessment group\n: Assign your assessment to a group in one of two ways:\nUse existing group\nto assign it to a group you created; or\nCreate new group\nto which you'll assign the assessment. Enter a name for this group. You can also\nCopy data from an existing group\n, such as implementation and testing details and documents, by selecting the appropriate boxes.\nWhen finished, select\nNext\n.\nOn the\nSelect services\npage, designate which services this assessment applies to (learn more about\nmulticloud support\n) using the\nSelect services\ncommand. The flyout pane shows which services are available for your chosen regulation. Place a check next to your desired services, then select\nAdd\n. Then select\nNext\n.\nIf your desired service isn't listed, you can add it as a new service. When you add a new service, the\nuniversal version of the underlying regulation\nis used, and you perform manual implementation and testing work. To add a new service:\nOn the\nSelect services\npage, select\nAdd new service\n.\nEnter a name and description for the service.\nSelect\nAdd\n. The service is listed on the\nService\nsection\nof the assessment's details page.\nIf you selected a service that has more than one subscription covered by Microsoft Defender for Cloud, you arrive at a substep for\nSelect service subscriptions\n. Select\nManage subscriptions\n. On the flyout pane, a tab for each service displays a list of all subscriptions within that service. All subscriptions are selected by default, but you can remove any by selecting the\nX\nnext to the name. On the\nSelect services\npage, select\nNext\n.\nReview and finish:\nReview all your selections and make any necessary edits. When you're satisfied with the settings, select\nCreate assessment\n.\nThe next screen confirms the assessment was created. When you select\nDone\n, you're taken to your new assessment's details page. If you see an\nAssessment failed\nscreen after selecting\nCreate assessment\n, select\nTry again\nto re-create your assessment.\nEdit an assessment\nAfter creating an assessment, you can edit it to update its name and add or remove services and subscriptions. To update an assessment:\nFrom the assessment details page, select the ellipses in the upper right corner and select\nEdit assessment\n. The assessment update wizard opens.\nYou can update the assessment name on the\nUpdate assessment name\npage, or leave it as-is, then select\nNext\n.\nOn the\nSelect services\npage, add or remove services, then select\nNext\n.\nOn the\nSelect service subscriptions\npage, select\nManage subscriptions\nto make any changes to your subscriptions. Then select\nNext\n.\nReview your updates, then select\nModify assessment\nto save your changes.\nMonitor assessment progress and controls\nEach assessment has a details page that gives an at-a-glance view of your progress in completing the assessment. The page shows how your services are performing, and the status of controls and improvement actions. Expand the\nOverview\nsection at the left side of the page to see basic details about the assessment, including its group, regulation, associated services, completion status, and a description.\nThe\nProgress\ntab shows the percentage of progress toward assessment completion. The progress bar displays a breakdown showing the number of points achieved within each service covered by the assessment. Get details on each service by\nviewing service details\n. See all controls within the assessment and their current status on the\nControls tab\n. Quickly access the status of all your improvement actions for the assessment the\nYour improvement actions tab\n. The actions handled by Microsoft for the assessment are listed on the\nMicrosoft actions tab\n.\nAssessment progress by service\nThe\nService\nsection on the assessmentâs\nProgress\ntab helps you understand how youâre doing with respect to a regulation with each of your services individually, even at the subscription level, and collectively across your organization. The assessment gets its data on available subscriptions and improvement action status from Microsoft Defender for Cloud. Any errors associated with subscription accessibility should be addressed in your Defender for Cloud. See\nConfigure cloud settings\nfor more information.\nSelect the\nView service details\ncommand, located next to or under the\nAssessment progress\nbar graph or in the upper-right command bar, to view a flyout pane with more details. The\nView service details\nflyout pane lists each service and its progress toward completing the assessment. Selecting\nView\nnext to a service name displays another pane that lists each subscription within the service and its status.\nOn a service's details panel, you see the list of subscriptions within the service that are covered by the assessment. The\nService progress\ncounter indicates the number of points achieved so far by improvement actions pertaining to the service for the assessment out of the total number of achievable points.\nYou can add more subscriptions to the service that you want the assessment to cover by\nediting the assessment\n.\nControls tab\nThe\nControls\ntab displays detailed information for each control in the assessment. The\nControl status breakdown\nchart shows the status of controls by family (for example, Configuration Management and Incident Response) so you can see at a glance which groupings of controls need attention. The table underneath the breakdown chart lists all controls. You can filter the list by control family, status, and service. The table shows the following details about each control:\nControl title\nStatus\n: The test status of the improvement actions within the control:\nPassed\n: All improvement actions have a test status of \"passed,\" or at least one is passed and the rest are \"out of scope.\"\nFailed\nAt least one improvement action has a test status of \"failed.\"\nNone\n: All improvement actions haven't been tested.\nOut of scope\n: All improvement actions are out of scope for this assessment.\nIn progress\n: Improvement actions have a status other than the ones listed above, which could include \"in progress,\" \"partial credit,\" or \"undetected.\"\nControl ID\n: The control's identification number, assigned by its corresponding regulation, standard, or policy.\nPoints achieved\n: The number of points earned by completing actions, out of the total number achievable.\nYour improvement actions\n: The number of your actions completed out of the total number to be done.\nMicrosoft actions\n: The number of actions completed by Microsoft.\nSelect a control from the list to view its details page. A graph indicates the test status of the improvement actions within the control. A table below the graph lists the improvement actions for that control. Select an improvement action from the list to drill into the improvement action's details page, from where you can manage implementation and testing. Get details about\nworking with improvement actions\n.\nYour improvement actions tab\nThe\nImprovement actions\ntab on the assessment details page lists all your improvement actions for the control. The status bar chart details the aggregated test status of your improvement actions in the assessment so you can quickly gauge what has been tested and what still needs to be done. Hover over or select a test status label to highlight only that status on the bar.\nBeneath the bar, a table lists all the actions and key details, including: service, test status, the number of potential and earned points, associated regulations and standards, applicable solution, action type, and control family.\nFilter by\nService\nto view actions related to a service and their progress. From the table, select an improvement action to go to its details page, from where you can manage implementation and testing.\nGet details about\nworking with improvement actions\n.\nMicrosoft actions tab\nThe Microsoft actions tab appears for assessments based on templates that support Microsoft products. It lists all the actions in the assessment that are managed by Microsoft. The list shows key action details, including: service, test status, points that contribute to your overall compliance score, associated regulations and standards, applicable solution, action type, and control family. Select an improvement action to view its details page.\nGrant user access to individual assessments\nWhen you assign users a Compliance Manager role in the Microsoft Purview portal, they can view or edit data within all assessments by default (review the\nCompliance Manager role types\n). You can restrict user access to only certain assessments by managing user roles from within an assessment. Restricting access in this way can help ensure that users who play a role in overseeing compliance with particular regulations or standards have access only to the data and information they need to perform their duties. (You can also set\nuser access for regulations\n, which allows users to access all assessments created for that regulation.)\nExternal users who need access for auditing or other purposes can also be assigned a role for viewing assessments and editing test data. You provide access to external individual by assigning them a Microsoft Entra role. Learn more about\nassigning roles\n.\nSteps for granting access\nFollow the steps to grant user access to an assessment.\nFrom your\nAssessments\npage, find the assessment you want to grant access to. Select it to open its details page.\nIn the upper-right corner, select\nManage user access\n.\nA\nManage user access\nflyout pane appears. It has three tabs, one for each role of Readers, Assessors, and Contributors. Navigate to the tab for the role you want your user to hold for this assessment. Users who currently have access to the assessment will have a blue box with a check mark to the left of their name.\nSelect the\n+ Add\ncommand for the role tab you're on:\nAdd reader\n, or\nAdd assessor\nor\nAdd contributor\n.\nAnother flyout pane appears which lists all the users in your organization. You can select the checkbox next to the username you want to add, or you can enter their name in the search bar and select the user from there. You can select multiple users at once.\nAfter making all your selections, select\nAdd\n.\nNote\nIf you assign a role to someone who already has an existing role, the new role assignment you choose will override their existing role. In this case, you'll see a confirmation box asking you to confirm the change in role.\nThe flyout pane closes and you arrive back at your assessment details page. A confirmation message at the top confirms the new role assignment for that assessment.\nSteps for removing access\nYou can remove a user's access to individual assessments by following the steps below:\nOn the assessment's details page, select\nManage user access\n.\nOn the\nManage user access\nflyout pane, go the tab corresponding to the user's role you want to remove.\nFind the user whose role you want to remove. Check the circle to the left of their name, then select the\nRemove\ncommand just below the role tab. To remove all users at once, select the\nRemove all\ncommand without checking the circle next to every user's name.\nA\nRemove access?\ndialog appears, asking you to confirm the removal. Select\nRemove access\nto confirm the role removal.\nSelect\nSave\non the flyout pane. The users' roles will now be removed from the assessment.\nLearn how to get a broad\nview of all users with access to assessments\n.\nNote about multiple roles\nA user can have one role that applies to an assessment, while also holding another role that applies broadly to overall Compliance Manager access.\nFor example, if you assigned a user a\nCompliance Manager Reader\nrole, you can also assign that user a\nCompliance Manager Assessor\nrole for a specific assessment. In effect, the user holds the two roles at the same time, but their ability to edit data is limited to the assessment to which they've been assigned the\nAssessor\nrole.\nRemoving an assessment-based role won't remove the user's overall Compliance Manager role if they have one. If you want to change a user's overall role, you have to change it the Microsoft Purview portal. Learn more about\nassigning roles and permissions\n.\nFor an individual assessment, one user can only hold one assessment-based role at a time.\nFor example, if a user holds a reader role for a GDPR assessment and you want to change them to a contributor role, you'll first need to remove their reader role, and then reassign them the reader role.\nNote\nAdmins whose permissions for Compliance Manager were set in Microsoft Entra ID won't appear on the\nManage user access\nflyout pane. This means that if a user has access to one or more assessments, and their role is Global Administrator, Compliance Administrator, Compliance Data Administrator, or Security Administrator, they won't appear on this pane. Learn more about\nsetting Compliance Manager permissions and roles\n.\nAccept updates to assessments\nWhen an update is available for an assessment, you see a notification and have the option to accept the update or defer it for a later time. Updates are available for assessments based on the regulatory templates provided in Compliance Manager. If your organization is using universal templates for assessing other products, inheritance might not be supported.\nWhat causes an update\nAn assessment update occurs when there are underlying template changes that impact scoring. Changes might involve adjusting control mapping or other guidance based on regulatory changes or product changes. Assessment updates can originate from your organization and from Microsoft.\nIf Microsoft updates a Compliance Manager template that you extended, your assessment inherits those updates once you accept them. Your assessment retains the other attributes you applied to the assessment when you extended it.\nCustom assessments that you create don't receive any template updates from Microsoft. Custom assessments can receive improvement action updates, but any Microsoft updates to control mapping between assessments and improvement actions don't apply to custom templates.\nNote\nUpdates to assessments apply only at the group level. If you have two assessments built from the same template that exist in two different groups, each assessment will have a pending update notification, and you'll need to accept the update to each assessment in its respective group individually.\nWhere you see assessment update notifications\nThe assessment details page also shows a\nPending update\nlabel next to the assessment with an update. Select that assessment to get to its details page.\nA message near the top of the assessment details page shows that an update is available for that assessment. Select the\nReview update\nbutton in the banner to review the specific changes and accept or defer the update.\nThe assessment details page might also list improvement actions that have a\nPending update\nlabel next to them. Those updates are for specific changes to the improvement actions themselves and need to be accepted separately. Visit\nAccepting updates to improvement actions\nto learn more.\nReview update to accept or defer\nWhen you select\nReview update\nfrom the assessment details page, a flyout pane appears on the right side of your screen. The flyout pane provides the key details below about the pending update:\nThe template title\nSource of the update (Microsoft, your organization, or a specific user)\nThe date the update was created\nAn overview explaining the update\nSpecific details about the changes, including the impact to your compliance score, the amount of progress toward completion of the assessment, and the specific number of changes to improvement actions and controls.\nSelecting the\nUpdated template\ncommand downloads an Excel file containing control data for the version of the template with the pending updates. Selecting the\nCurrent template\ncommand downloads a file of the existing template without the updates.\nTo accept the update and make the changes to your assessment, select\nAccept update\n. Accepted changes are permanent.\nIf you select\nCancel\n, the update won't be applied to the assessment. However, you continue to see the\nPending update\nnotification until you accept the update.\nWhy we recommend accepting updates\n: Accepting updates helps ensure you have the most updated guidance on using solutions and taking appropriate improvement actions to help you meet the requirements of the certification at hand.\nWhy you might want to defer an update\n: If you're in the middle of completing an assessment, you might want to ensure you finished work on it before you accept an update to the assessment that could disrupt control mapping. You can defer the update for a later time by selecting\nCancel\non the review update flyout pane.\nExport an assessment report\nYou can export an assessment to an Excel file for compliance stakeholders in your organization or for external auditors and regulators. On the assessment details page, select the\nExport actions\nin the top right corner of the page, which creates an Excel file you can save and share. The report is a snapshot of the assessment as of the date and time of the export. It contains the details for controls managed by both you and Microsoft, including implementation status, test date, and test results.\nDelete an assessment\nDeleting an assessment removes it from the list on your assessments page. Note these important points about deleting assessments:\nDeleting an assessment is permanent; you cannot get it back.\nIf you want to use the same assessment again, you need to re-create it.\nIf the improvement actions in the assessment don't appear in any other assessment, they're deleted when the assessment is deleted.\nWe recommend\nexporting a report\nof the assessment before you permanently delete it.\nTo delete an assessment, follow the steps below:\nFrom the\nAssessments\npage, select the assessment you wish to delete.\nOn the assessment's details page, select\nDelete assessment\nin the upper-right corner of your screen. If you don't see this option, select the ellipsis (...) in the upper-right corner, then select\nDelete assessment\nfrom the list.\nA window appears asking you to confirm that you want to permanently delete the assessment. Select\nDelete assessment\nto close the window. You get a confirmation window that your assessment was deleted from Compliance Manager.\nNote\nYou can't delete all of your assessments. Organizations need at least one assessment for Compliance Manager to function properly. If the assessment you want to delete is the only one, add another assessment before deleting the other assessment.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Assessments",
      "section": "Microsoft Purview"
    },
    "https://learn.microsoft.com/en-us/entra/identity/conditional-access/overview": {
      "content_hash": "sha256:2de94a7483a40a25a7ebd27424ded4839fccb7d2fc4e4c885958d637fba63156",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Conditional Access?\nFeedback\nSummarize this article for me\nModern security extends beyond an organization's network perimeter to include user and device identity. Organizations now use identity-driven signals as part of their access control decisions. Microsoft Entra Conditional Access brings signals together, to make decisions, and enforce organizational policies. Conditional Access is Microsoft's\nZero Trust policy engine\ntaking signals from various sources into account when enforcing policy decisions.\nConditional Access policies at their simplest are if-then statements:\nif\na user wants to access a resource,\nthen\nthey must complete an action. For example: If a user wants to access an application or service like Microsoft 365, then they must perform multifactor authentication to gain access.\nAdmins are faced with two primary goals:\nEmpower users to be productive wherever and whenever\nProtect the organization's assets\nUse Conditional Access policies to apply the right access controls when needed to keep your organization secure and don't interfere with productivity.\nImportant\nConditional Access policies are enforced after first-factor authentication is completed. Conditional Access isn't intended to be an organization's frontline defense for scenarios like denial-of-service (DoS) attacks, but it can use signals from these events to determine access.\nCommon signals\nConditional Access uses signals from various sources to make access decisions.\nSome of these signals include:\nUser, group, or agent\nPolicies can be targeted to specific users, groups, and agents (Preview) giving admins fine-grained control over access.\nSupport for agent identities and agent users extends Zero Trust principles to AI workloads.\nIP location information\nOrganizations can create IP address ranges that can be used when making policy decisions.\nAdmins can specify entire countries/regions IP ranges to block or allow traffic from.\nDevice\nUsers with devices of specific platforms or marked with a specific state can be used when enforcing Conditional Access policies.\nUse filters for devices to target policies to specific devices like privileged access workstations.\nApplication\nTrigger different Conditional Access policies when users attempt to access specific applications.\nApply policies to traditional cloud apps, on-premises applications, and agent resources.\nReal-time and calculated risk detection\nIntegrates signals from\nMicrosoft Entra ID Protection\nto identify and remediate risky users, sign-in behavior, and agent activities.\nMicrosoft Defender for Cloud Apps\nMonitors and controls user application access and sessions in real time. This integration improves visibility and control over access and activities in your cloud environment.\nCommon decisions\nBlock access is the most restrictive decision.\nGrant access\nA less restrictive decision that might require one or more of the following options:\nRequire multifactor authentication\nRequire authentication strength\nRequire the device to be marked as compliant\nRequire a Microsoft Entra hybrid joined device\nRequire an approved client app\nRequire an app protection policy\nRequire a password change\nRequire terms of use\nCommonly applied policies\nMany organizations have\ncommon access concerns that Conditional Access policies can help with\n, such as:\nRequiring multifactor authentication for users with administrative roles\nRequiring multifactor authentication for Azure management tasks\nBlocking sign-ins for users who try to use legacy authentication protocols\nRequiring trusted locations for security information registration\nBlocking or granting access from specific locations\nBlocking risky sign-in behaviors\nRequiring organization-managed devices for specific applications\nAdmins can create policies from scratch or start with a template policy in the portal or by using the Microsoft Graph API.\nAdmin experience\nAdmins with at least the\nSecurity Reader\nrole can find Conditional Access in the\nMicrosoft Entra admin center\nunder\nEntra ID\n>\nConditional Access\n.\nThe\nOverview\npage shows a summary of policy state, agents, users, devices, and applications, along with general and security alerts with suggestions.\nThe\nCoverage\npage shows a summary of applications with and without Conditional Access policy coverage over the past seven days.\nOn the\nPolicies\npage, admins can filter Conditional Access policies based on items like the actor, target resource, condition, control applied, state, or date. This filtering lets admins quickly find specific policies based on their configuration.\nConditional Access optimization agent\nThe\nConditional Access optimization agent\n(preview) with Microsoft Security Copilot suggests new policies and changes to existing ones based on Zero Trust principles and Microsoft best practices. With one click, apply the suggestion to automatically update or create a Conditional Access policy. The agent needs at least the Microsoft Entra ID P1 license and\nsecurity compute units (SCU)\n.\nLicense requirements\nUsing this feature requires Microsoft Entra ID P1 licenses. To find the right license for your requirements, see\nCompare generally available features of Microsoft Entra ID\n.\nCustomers with\nMicrosoft 365 Business Premium licenses\ncan also use Conditional Access features.\nOther products and features that interact with Conditional Access policies require appropriate licensing for those products and features, including Microsoft Entra Workload ID, Microsoft Entra ID Protection, and Microsoft Purview.\nWhen the licenses required for Conditional Access expire, policies aren't automatically disabled or deleted. This graceful state lets customers migrate away from Conditional Access policies without a sudden change in their security posture. You can view and delete remaining policies, but you can't update them.\nSecurity defaults\nhelp protect against identity-related attacks and are available for all customers.\nZero Trust\nThis feature helps organizations to align their\nidentities\nwith the three guiding principles of a Zero Trust architecture:\nVerify explicitly\nUse least privilege\nAssume breach\nTo find out more about Zero Trust and other ways to align your organization to the guiding principles, see the\nZero Trust Guidance Center\n.\nNext steps\nPlan your Conditional Access deployment\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Conditional Access",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-conditional-access-policies": {
      "content_hash": "sha256:fafd80a9392260709377ecc5bb143e4ecda62a8e7791bd2b2ebc6734898a94ff",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nBuilding a Conditional Access policy\nFeedback\nSummarize this article for me\nAs explained in the article\nWhat is Conditional Access\n, a Conditional Access policy is an if-then statement of\nAssignments\nand\nAccess controls\n. A Conditional Access policy combines signals to make decisions and enforce organizational policies.\nHow does an organization create these policies? What is required? How are they applied?\nMultiple Conditional Access policies can apply to an individual user at any time. In this case, all applicable policies must be satisfied. For example, if one policy requires multifactor authentication and another requires a compliant device, you must complete MFA, and use a compliant device. All assignments are logically combined using\nAND\n. If you have more than one assignment configured, all assignments must be satisfied to trigger a policy.\nIf a policy with \"Require one of the selected controls\" is selected, prompts appear in the defined order. Once the policy requirements are satisfied, access is granted.\nAll policies are enforced in two phases:\nPhase 1\n: Collect session details\nGather session details, like network location and device identity necessary for policy evaluation.\nPhase 1 of policy evaluation occurs for enabled policies and policies in\nreport-only mode\n.\nPhase 2\n: Enforcement\nUse the session details gathered in phase 1 to identify any requirements that aren't met.\nIf there's a policy that is configured with the\nblock\ngrant control, enforcement stops here and the user is blocked.\nThe user is prompted to complete more grant control requirements that weren't satisfied during phase 1 in the following order, until policy is satisfied:\nMultifactor authenticationâ\nDevice to be marked as compliant\nMicrosoft Entra hybrid joined device\nApproved client app\nApp protection policy\nPassword change\nTerms of use\nCustom controls\nOnce all grant controls are satisfied, session controls are applied (App Enforced, Microsoft Defender for Cloud Apps, and token lifetime).\nPhase 2 of policy evaluation occurs for all enabled policies.\nAssignments\nThe assignments section defines who, what, and where for the Conditional Access policy.\nUsers and groups\nUsers and groups\nassign who the policy include or exclude when applied. This assignment can include all users, specific groups of users, directory roles, or external guest users. Organizations with Microsoft Entra Workload ID licenses might target\nworkload identities\nas well.\nPolicies targeting roles or groups are evaluated only when a token is issued. This means:\nNewly added users to a role or group aren't subject to the policy until they get a new token.\nIf a user already has a valid token before being added to the role or group, the policy doesn't apply retroactively.\nThe best practice is to trigger Conditional Access evaluation during role activation or group membership activation using\nMicrosoft Entra Privileged Identity Management\n.\nTarget resources\nTarget resources\ncan include or exclude cloud applications, user actions, or authentication contexts that are subjected to the policy.\nNetwork\nNetwork\ncontains IP addresses, geographies, and\nGlobal Secure Access' compliant network\nto Conditional Access policy decisions. Admins can define locations and mark some as trusted, such as their organization's primary network locations.\nConditions\nA policy can contain multiple\nconditions\n.\nSign-in risk\nFor organizations with\nMicrosoft Entra ID Protection\n, the risk detections generated there can influence your Conditional Access policies.\nDevice platforms\nOrganizations with multiple device operating system platforms might enforce specific policies on different platforms.\nThe information used to determine the device platform comes from unverified sources, like user agent strings that can be changed.\nClient apps\nThe software the user is employing to access the cloud app. For example, 'Browser' and 'Mobile apps and desktop clients'. By default, all newly created Conditional Access policies apply to all client app types even if the client apps condition isn't configured.\nFilter for devices\nThis control allows targeting specific devices based on their attributes in a policy.\nAccess controls\nThe access controls portion of the Conditional Access policy controls how a policy is enforced.\nGrant\nGrant\nprovides administrators with a means of policy enforcement where they can block or grant access.\nBlock access\nBlock access blocks access under the specified assignments. This control is powerful and requires appropriate knowledge to use effectively.\nGrant access\nThe grant control triggers enforcement of one or more controls.\nRequire multifactor authentication\nRequire authentication strength\nRequire device to be marked as compliant (Intune)\nRequire Microsoft Entra hybrid joined device\nRequire approved client app\nRequire app protection policy\nRequire password change\nRequire terms of use\nAdministrators choose to require one of the previous controls or all selected controls using the following options. By default, multiple controls require all.\nRequire all the selected controls (control and control)\nRequire one of the selected controls (control or control)\nSession\nSession controls\ncan limit the experience of users.\nUse app enforced restrictions:\nWorks only with Exchange Online and SharePoint Online.\nPasses device information to control the experience, granting full or limited access.\nUse Conditional Access App Control:\nUses signals from Microsoft Defender for Cloud Apps to do things like:\nBlock download, cut, copy, and print of sensitive documents.\nMonitor risky session behavior.\nRequire labeling of sensitive files.\nSign-in frequency:\nAbility to change the default sign in frequency for modern authentication.\nPersistent browser session:\nAllows users to remain signed in after closing and reopening their browser window.\nCustomize continuous access evaluation.\nDisable resilience defaults.\nSimple policies\nA Conditional Access policy must include at least the following to be enforced:\nName\nof the policy\nAssignments\nUsers and/or groups\nto apply the policy to\nTarget resources\nto apply the policy to\nAccess controls\nGrant\nor\nBlock\ncontrols\nThe article\nCommon Conditional Access policies\nincludes policies that might be useful to most organizations.\nRelated content\nCommon Conditional Access policies\nManaging device compliance with Intune\nMicrosoft Defender for Cloud Apps and Conditional Access\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Conditional Access Policies",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-conditional-access-cloud-apps#authentication-context": {
      "content_hash": "sha256:9d0d258864ae2e3203f2fc768eb20c42441ee039e8547a7baaa94fdc74111cda",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConditional Access: Target resources\nFeedback\nSummarize this article for me\nTarget resources (formerly cloud apps, actions, and authentication context) are key signals in a Conditional Access policy. Conditional Access policies let admins assign controls to specific applications, services, actions, or authentication context.\nAdmins can choose from the list of applications or services that include built-in Microsoft applications and any\nMicrosoft Entra integrated applications\n, including gallery, non-gallery, and applications published through\nApplication Proxy\n.\nAdmins might define a policy based on a\nuser action\nlike\nRegister security information\nor\nRegister or join devices\n, letting Conditional Access enforce controls around those actions.\nAdmins can target\ntraffic forwarding profiles\nfrom Global Secure Access for enhanced functionality.\nAdmins can use\nauthentication context\nto provide an extra layer of security in applications.\nMicrosoft cloud applications\nAdmins can assign a Conditional Access policy to Microsoft cloud apps if the service principal appears in their tenant, except for Microsoft Graph. Microsoft Graph functions as an umbrella resource. Use\nAudience Reporting\nto see the underlying services and target those services in your policies. Some apps like\nOffice 365\nand\nWindows Azure Service Management API\ninclude multiple related child apps or services. When new Microsoft cloud applications are created, they appear in the app picker list as soon as the service principal is created in the tenant.\nOffice 365\nMicrosoft 365 offers cloud-based productivity and collaboration services like Exchange, SharePoint, and Microsoft Teams. Microsoft 365 cloud services are deeply integrated to ensure smooth and collaborative experiences. This integration might cause confusion when creating policies because some apps, like Microsoft Teams, depend on others, like SharePoint or Exchange.\nThe Office 365 app grouping makes it possible to target these services all at once. We recommend using the Office 365 grouping, instead of targeting individual cloud apps to avoid issues with\nservice dependencies\n.\nTargeting this group of applications helps to avoid issues that might arise because of inconsistent policies and dependencies. For example: The Exchange Online app is tied to traditional Exchange Online data like mail, calendar, and contact information. Related metadata might be exposed through different resources like search. To ensure that all metadata is protected by as intended, admins should assign policies to the Office 365 app.\nAdmins can exclude the entire Office 365 suite or specific Office 365 cloud apps from Conditional Access policies.\nA complete list of all services included can be found in the article\nApps included in Conditional Access Office 365 app suite\n.\nWindows Azure Service Management API\nWhen you target the Windows Azure Service Management API application, policy is enforced for tokens issued to a set of services closely bound to the portal. This grouping includes the application IDs of:\nAzure Resource Manager\nAzure portal, which also covers the Microsoft Entra admin center and the Microsoft Engage Center\nAzure Data Lake\nApplication Insights API\nLog Analytics API\nBecause the policy is applied to the Azure management portal and API, any services or clients that depend on the Azure API can be indirectly affected. For example:\nAzure CLI\nAzure Data Factory portal\nAzure Event Hubs\nAzure PowerShell\nAzure Service Bus\nAzure SQL Database\nAzure Synapse\nClassic deployment model APIs\nMicrosoft 365 admin center\nMicrosoft IoT Central\nMicrosoft Defender Multitenant management\nSQL Managed Instance\nVisual Studio subscriptions administrator portal\nCaution\nConditional Access policies associated with the Windows Azure Service Management API\nno longer cover Azure DevOps\n.\nNote\nThe Windows Azure Service Management API application applies to\nAzure PowerShell\n, which calls the\nAzure Resource Manager API\n. It doesn't apply to\nMicrosoft Graph PowerShell\n, which calls the\nMicrosoft Graph API\n.\nTip\nFor Azure Government, you should target the Azure Government Cloud Management API application.\nMicrosoft Admin Portals\nWhen a Conditional Access policy targets the Microsoft Admin Portals cloud app, the policy is enforced for tokens issued to application IDs of the following Microsoft administrative portals:\nAzure portal\nExchange admin center\nMicrosoft 365 admin center\nMicrosoft 365 Defender portal\nMicrosoft Entra admin center\nMicrosoft Intune admin center\nMicrosoft Purview compliance portal\nMicrosoft Teams admin center\nWe're continually adding more administrative portals to the list.\nOther applications\nAdmins can add any Microsoft Entra registered application to Conditional Access policies. These applications might include:\nApplications published through\nMicrosoft Entra application proxy\nApplications added from the gallery\nCustom applications not in the gallery\nLegacy applications published through app delivery controllers and networks\nApplications that use\npassword based single sign-on\nNote\nSince Conditional Access policy sets the requirements for accessing a service, you aren't able to apply it to a client (public/native) application. In other words, the policy isn't set directly on a client (public/native) application, but is applied when a client calls a service. For example, a policy set on SharePoint service applies to all clients calling SharePoint. A policy set on Exchange applies to the attempt to access the email using Outlook client. That is why client (public/native) applications aren't available for selection in the app picker and Conditional Access option isn't available in the application settings for the client (public/native) application registered in your tenant.\nSome applications don't appear in the picker at all. The only way to include these applications in a Conditional Access policy is to includeâ¯\nAll resources (formerly 'All cloud apps')\nor add the missing service principal using the\nNew-MgServicePrincipal\nPowerShell cmdlet or by using the\nMicrosoft Graph API\n.\nUnderstanding Conditional Access for different client types\nConditional Access applies to resources not clients, except when the client is a confidential client requesting an ID token.\nPublic client\nPublic clients are those that run locally on devices like Microsoft Outlook on the desktop or mobile apps like Microsoft Teams.\nConditional Access policies don't apply to public clients themselves but are based on the resources they request.\nConfidential client\nConditional Access applies to the resources requested by the client and the confidential client itself if it requests an ID token.\nFor example: If Outlook Web requests a token for scopes\nMail.Read\nand\nFiles.Read\n, Conditional Access applies policies for Exchange and SharePoint. Additionally, if Outlook Web requests an ID token, Conditional Access also applies the policies for Outlook Web.\nTo view\nsign-in logs\nfor these client types from the Microsoft Entra admin center:\nSign in to the\nMicrosoft Entra admin center\nas at least a\nReports Reader\n.\nBrowse to\nEntra ID\n>\nMonitoring & health\n>\nSign-in logs\n.\nAdd a filter for\nClient credential type\n.\nAdjust the filter to view a specific set of logs based on the client credential used in the sign-in.\nFor more information, see the article\nPublic client and confidential client applications\n.\nAll resources\nApplying a Conditional Access policy to\nAll resources (formerly 'All cloud apps')\nwithout any app exclusions enforces the policy for all token requests from websites and services, including\nGlobal Secure Access traffic forwarding profiles\n. This option includes applications that aren't individually targetable in Conditional Access policy, such as\nWindows Azure Active Directory\n(00000002-0000-0000-c000-000000000000).\nImportant\nMicrosoft recommends creating a baseline multifactor authentication policy targeting all users and all resources (without any app exclusions), like the one explained in\nRequire multifactor authentication for all users\n.\nConditional Access behavior when an all resources policy has an app exclusion\nIf any app is excluded from the policy, in order to not inadvertently block user access, certain low privilege scopes are excluded from policy enforcement. These scopes allow calls to the underlying Graph APIs, like\nWindows Azure Active Directory\n(00000002-0000-0000-c000-000000000000) and\nMicrosoft Graph\n(00000003-0000-0000-c000-000000000000), to access user profile and group membership information commonly used by applications as part of authentication. For example: when Outlook requests a token for Exchange, it also asks for the\nUser.Read\nscope to be able to display the basic account information of the current user.\nMost apps have a similar dependency, which is why these low privilege scopes are automatically excluded whenever there's an app exclusion in an\nAll resources\npolicy. These low privilege scope exclusions don't allow data access beyond basic user profile and group information. The excluded scopes are listed as follows, consent is still required for apps to use these permissions.\nNative clients and Single page applications (SPAs) have access to the following low privilege scopes:\nAzure AD Graph:\nemail\n,\noffline_access\n,\nopenid\n,\nprofile\n,\nUser.Read\nMicrosoft Graph:\nemail\n,\noffline_access\n,\nopenid\n,\nprofile\n,\nUser.Read\n,\nPeople.Read\nConfidential clients have access to the following low privilege scopes, if they're excluded from an\nAll resources\npolicy:\nAzure AD Graph:\nemail\n,\noffline_access\n,\nopenid\n,\nprofile\n,\nUser.Read\n,\nUser.Read.All\n,\nUser.ReadBasic.All\nMicrosoft Graph:\nemail\n,\noffline_access\n,\nopenid\n,\nprofile\n,\nUser.Read\n,\nUser.Read.All\n,\nUser.ReadBasic.All\n,\nPeople.Read\n,\nPeople.Read.All\n,\nGroupMember.Read.All\n,\nMember.Read.Hidden\nFor more information on the scopes mentioned, see\nMicrosoft Graph permissions reference\nand\nScopes and permissions in the Microsoft identity platform\n.\nProtecting directory information\nIf the\nrecommended baseline MFA policy without app exclusions\ncan't be configured because of business reasons, and your organization's security policy must include directory-related low privilege scopes (\nUser.Read\n,\nUser.Read.All\n,\nUser.ReadBasic.All\n,\nPeople.Read\n,\nPeople.Read.All\n,\nGroupMember.Read.All\n,\nMember.Read.Hidden\n), create a separate Conditional Access policy targeting\nWindows Azure Active Directory\n(00000002-0000-0000-c000-000000000000). Windows Azure Active Directory (also called Azure AD Graph) is a resource representing data stored in the directory such as users, groups, and applications. The Windows Azure Active Directory resource is included in\nAll resources\nbut can be individually targeted in Conditional Access policies by using the following steps:\nSign in to the\nMicrosoft Entra admin center\nas an\nAttribute Definition Administrator\nand\nAttribute Assignment Administrator\n.\nBrowse to\nEntra ID\n>\nCustom security attributes\n.\nCreate a new attribute set and attribute definition. For more information, see\nAdd or deactivate custom security attribute definitions in Microsoft Entra ID\n.\nBrowse to\nEntra ID\n>\nEnterprise apps\n.\nRemove the\nApplication type\nfilter and search for\nApplication ID\nthat starts with 00000002-0000-0000-c000-000000000000.\nSelect\nWindows Azure Active Directory\n>\nCustom security attributes\n>\nAdd assignment\n.\nSelect the attribute set and attribute value that you plan to use in the policy.\nBrowse to\nEntra ID\n>\nConditional Access\n>\nPolicies\n.\nCreate or modify an existing policy.\nUnder\nTarget resources\n>\nResources (formerly cloud apps)\n>\nInclude\n, select >\nSelect resources\n>\nEdit filter\n.\nAdjust the filter to include your attribute set and definition from earlier.\nUnder\nAccess controls\n>\nGrant\n, select\nGrant access\n,\nRequire authentication strength\n, select\nMultifactor authentication\n, then select\nSelect\n.\nConfirm your settings and set\nEnable policy\nto\nReport-only\n.\nSelect\nCreate\nto create to enable your policy.\nNote\nConfigure this policy as described in the guidance above. Any deviations in creating the policy as described (such as defining app exclusions) may result in low privilege scopes being excluded and the policy not applying as intended.\nAll internet resources with Global Secure Access\nThe\nAll internet resources with Global Secure Access\noption allows admins to target the\ninternet access traffic forwarding profile\nfrom\nMicrosoft Entra Internet Access\n.\nThese profiles in Global Secure Access enable admins to define and control how traffic is routed through Microsoft Entra Internet Access and Microsoft Entra Private Access. Traffic forwarding profiles can be assigned to devices and remote networks. For an example of how to apply a Conditional Access policy to these traffic profiles, see the article\nHow to apply Conditional Access policies to the Microsoft 365 traffic profile\n.\nFor more information about these profiles, see the article\nGlobal Secure Access traffic forwarding profiles\n.\nAll agent resources (Preview)\nApplying a Conditional Access policy to All agent resources enforces the policy for all token requests to agent identity blueprint principals and agent identities.\nUser actions\nUser actions are tasks that a user performs. Conditional Access supports two user actions:\nRegister security information\n: This user action lets Conditional Access policies enforce rules when users try to register their security information. For more information, see\nCombined security information registration\n.\nNote\nIf admins apply a policy targeting user actions for registering security information and the user account is a guest from a\nMicrosoft personal account (MSA)\n, the 'Require multifactor authentication' control requires the MSA user to register security information with the organization. If the guest user is from another provider such as\nGoogle\n, access is blocked.\nRegister or join devices\n: This user action enables admins to enforce Conditional Access policy when users\nregister\nor\njoin\ndevices to Microsoft Entra ID. It lets admins configure multifactor authentication for registering or joining devices with more granularity than a tenant-wide policy. There are three key considerations with this user action:\nRequire multifactor authentication\nand\nRequire auth strength\nare the only access controls available with this user action and all others are disabled. This restriction prevents conflicts with access controls that are either dependent on Microsoft Entra device registration or not applicable to Microsoft Entra device registration.\nWindows Hello for Business and device-bound passkeys aren't supported because those scenarios require the device to be already registered.\nClient apps\n,\nFilters for devices\n, and\nDevice state\nconditions aren't available with this user action because they're dependent on Microsoft Entra device registration to enforce Conditional Access policies.\nWarning\nIf a Conditional Access policy is configured with the\nRegister or join devices\nuser action, set\nEntra ID\n>\nDevices\n>\nOverview\n>\nDevice Settings\n-\nRequire Multifactor Authentication to register or join devices with Microsoft Entra\nto\nNo\n. Otherwise, Conditional Access policies with this user action aren't properly enforced. Learn more about this device setting in\nConfigure device settings\n.\nAuthentication context\nAuthentication context secures data and actions in applications. These applications include custom applications, line-of-business (LOB) applications, SharePoint, or applications protected by Microsoft Defender for Cloud Apps. It can also be used with Microsoft Entra Privileged Identity Management (PIM) to enforce Conditional Access policies during role activation.\nFor example, an organization might store files in SharePoint sites like a lunch menu or a secret BBQ sauce recipe. Everyone might access the lunch menu site, but users accessing the secret BBQ sauce recipe site might need to use a managed device and agree to specific terms of use. Similarly, an administrator activating a privileged role through PIM might be required to perform multifactor authentication or use a compliant device.\nAuthentication context works with users or\nworkload identities\n, but not in the same Conditional Access policy.\nConfigure authentication contexts\nManage authentication contexts by going to\nEntra ID\n>\nConditional Access\n>\nAuthentication context\n.\nSelect\nNew authentication context\nto create an authentication context definition. Organizations can create up to 99 authentication context definitions (\nc1-c99\n). Configure these attributes:\nDisplay name\nis the name that is used to identify the authentication context in Microsoft Entra ID and across applications that consume authentication contexts. We recommend names that can be used across resources, like\ntrusted devices\n, to reduce the number of authentication contexts needed. Having a reduced set limits the number of redirects and provides a better end to end-user experience.\nDescription\nprovides more information about the policies. This information is used by admins and those applying authentication contexts to resources.\nPublish to apps\ncheckbox, when selected, advertises the authentication context to apps and makes it available to be assigned. If not selected, the authentication context is unavailable to downstream resources.\nID\nis read-only and used in tokens and apps for request-specific authentication context definitions. Listed here for troubleshooting and development use cases.\nAdd to Conditional Access policy\nAdmins can select published authentication contexts in Conditional Access policies by going to\nAssignments\n>\nCloud apps or actions\nand selecting\nAuthentication context\nfrom the\nSelect what this policy applies to\nmenu.\nDelete an authentication context\nBefore deleting an authentication context, ensure no applications use it. Otherwise, access to app data isn't protected. Confirm this by checking sign-in logs for cases where authentication context Conditional Access policies are applied.\nTo delete an authentication context, ensure it has no assigned Conditional Access policies and isn't published to apps. This prevents accidental deletion of an authentication context still in use.\nTag resources with authentication contexts\nTo learn more about using authentication contexts, see the following articles.\nUse sensitivity labels to protect content in Microsoft Teams, Microsoft 365 groups, and SharePoint sites\nMicrosoft Defender for Cloud Apps\nCustom applications\nPrivileged Identity Management - On activation, require Microsoft Entra Conditional Access authentication context\nRelated content\nConditional Access: Conditions\nâ Learn how to configure conditions to refine your policies.\nConditional Access common policies\nâ Explore common policy templates to get started quickly.\nClient application dependencies\nâ Understand how dependencies impact Conditional Access policies.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Authentication Contexts",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/conditional-access/howto-conditional-access-session-lifetime": {
      "content_hash": "sha256:07128d3504c34577f66f27b6d24df13e61433d0eadb76ef940ecef775776b86f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConfigure adaptive session lifetime policies\nFeedback\nSummarize this article for me\nWarning\nIf you're using the\nconfigurable token lifetime\nfeature currently in public preview, we don't support creating two different policies for the same user or app combination: one with this feature and another with the configurable token lifetime feature. Microsoft retired the configurable token lifetime feature for refresh and session token lifetimes on January 30, 2021, and replaced it with the Conditional Access authentication session management feature.\nBefore enabling Sign-in Frequency, make sure other reauthentication settings are disabled in your tenant. If \"Remember MFA on trusted devices\" is enabled, disable it before using Sign-in Frequency, as using these two settings together might prompt users unexpectedly. To learn more about reauthentication prompts and session lifetime, see the article,\nOptimize reauthentication prompts and understand session lifetime for Microsoft Entra multifactor authentication\n.\nPolicy deployment\nTo ensure your policy works as expected, test it before rolling it out into production. Use a test tenant to verify that your new policy works as intended. For more information, see the article\nPlan a Conditional Access deployment\n.\nPolicy 1: Sign-in frequency control\nSign in to the\nMicrosoft Entra admin center\nas at least a\nConditional Access Administrator\n.\nBrowse to\nEntra ID\n>\nConditional Access\n>\nPolicies\n.\nSelect\nNew policy\n.\nGive your policy a name. Create a meaningful standard for naming policies.\nChoose all required conditions for customerâs environment, including the target cloud apps.\nNote\nIt's recommended to set equal authentication prompt frequency for key Microsoft 365 apps such as Exchange Online and SharePoint Online for best user experience.\nUnder\nAccess controls\n>\nSession\n.\nSelect\nSign-in frequency\n.\nChoose\nPeriodic reauthentication\nand enter a value of hours or days or select\nEvery time\n.\nSave your policy.\nPolicy 2: Persistent browser session\nSign in to the\nMicrosoft Entra admin center\nas at least a\nConditional Access Administrator\n.\nBrowse to\nEntra ID\n>\nConditional Access\n>\nPolicies\n.\nSelect\nNew policy\n.\nGive your policy a name. We recommend that organizations create a meaningful standard for the names of their policies.\nChoose all required conditions.\nNote\nThis control requires selecting \"All Cloud Apps\" as a condition. Browser session persistence is controlled by authentication session token. All tabs in a browser session share a single session token and therefore they all must share persistence state.\nUnder\nAccess controls\n>\nSession\n.\nSelect\nPersistent browser session\n.\nNote\nPersistent browser session configuration in Microsoft Entra Conditional Access overrides the \"Stay signed in?\" setting in the company branding pane for the same user if both policies are configured.\nSelect a value from dropdown.\nSave your policy.\nNote\nSession lifetime settings, including sign-in frequency and persistent browser sessions, determine how often users must reauthenticate and whether sessions persist across browser restarts. Shorter lifetimes enhance security for high-risk apps, while longer ones improve convenience for trusted or managed devices.\nPolicy 3: Sign-in frequency control every time risky user\nSign in to the\nMicrosoft Entra admin center\nas at least a\nConditional Access Administrator\n.\nBrowse to\nEntra ID\n>\nConditional Access\n.\nSelect\nNew policy\n.\nGive your policy a name. We recommend that organizations create a meaningful standard for the names of their policies.\nUnder\nAssignments\n, select\nUsers or workload identities\n.\nUnder\nInclude\n, select\nAll users\n.\nUnder\nExclude\n, select\nUsers and groups\nand choose your organization's emergency access or break-glass accounts.\nSelect\nDone\n.\nUnder\nTarget resources\n>\nInclude\n, select\nAll resources (formerly 'All cloud apps')\n.\nUnder\nConditions\n>\nUser risk\n, set\nConfigure\nto\nYes\n.\nUnder\nConfigure user risk levels needed for policy to be enforced\n, select\nHigh\n.\nThis guidance is based on Microsoft recommendations and might be different for each organization\nSelect\nDone\n.\nUnder\nAccess controls\n>\nGrant\n, select\nGrant access\n.\nSelect\nRequire authentication strength\n, then select the built-in\nMultifactor authentication\nauthentication strength from the list.\nSelect\nRequire password change\n.\nSelect\nSelect\n.\nUnder\nSession\n.\nSelect\nSign-in frequency\n.\nEnsure\nEvery time\nis selected.\nSelect\nSelect\n.\nConfirm your settings and set\nEnable policy\nto\nReport-only\n.\nSelect\nCreate\nto create to enable your policy.\nAfter confirming your settings using\nreport-only mode\n, move the\nEnable policy\ntoggle from\nReport-only\nto\nOn\n.\nValidation\nUse the\nWhat If tool\nto simulate a sign-in to the target application and other conditions based on your policy configuration. The authentication session management controls show up in the result of the tool.\nPrompt tolerance\nWe account for five minutes of clock skew when\nevery time\nis selected in policy, so we donât prompt users more often than once every five minutes. If the user completes MFA in the last 5 minutes and encounters another Conditional Access policy that requires reauthentication, we don't prompt the user. Prompting users too often for reauthentication can affect their productivity and increase the risk of users approving MFA requests they didnât initiate. Use \"Sign-in frequency â every time\" only when there are specific business needs.\nKnown issues\nIf you configure sign-in frequency for mobile devices: Authentication after each sign-in frequency interval might be slow and can take 30 seconds on average. This issue might also occur across various apps simultaneously.\nOn iOS devices: If an app configures certificates as the first authentication factor and has both sign-in frequency and\nIntune mobile application management policies\napplied, users are blocked from signing in to the app when the policy triggers.\nMicrosoft Entra Private Access doesn't support setting sign-in frequency to every time.\nNext steps\nReady to configure Conditional Access policies for your environment? See\nPlan a Conditional Access deployment\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Session Controls",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/authentication/concept-authentication-strengths": {
      "content_hash": "sha256:917ad63f0f82dc89a4c7e59e5fb97e6a0faf82c2aca9b46dc56808ffe05fa128",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nConditional Access authentication strengths\nFeedback\nSummarize this article for me\nAn authentication strength is a Microsoft Entra Conditional Access control that specifies which combinations of authentication methods users can use to access a resource. Users can satisfy the strength requirements by authenticating with any of the allowed combinations.\nFor example, an authentication strength can require users to use only phishing-resistant authentication methods to access a sensitive resource. To access a nonsensitive resource, administrators can create another authentication strength that allows less secure multifactor authentication (MFA) combinations, such as a password and a text message.\nAn authentication strength is based on the\npolicy for authentication methods\n. That is, administrators can scope authentication methods for specific users and groups to be used across Microsoft Entra ID federated applications. An authentication strength allows further control over the usage of these methods, based on specific scenarios such as sensitive resource access, user risk, and location.\nPrerequisites\nTo use Conditional Access, your tenant needs to have Microsoft Entra ID P1 license. If you don't have this license, you can start a\nfree trial\n.\nScenarios for authentication strengths\nAuthentication strengths can help customers address these scenarios:\nRequire specific authentication methods to access a sensitive resource.\nRequire a specific authentication method when a user takes a sensitive action within an application (in combination with Conditional Access authentication context).\nRequire users to use a specific authentication method when they access sensitive applications outside the corporate network.\nRequire more secure authentication methods for users at high risk.\nRequire specific authentication methods from guest users who access a resource tenant (in combination with cross-tenant settings).\nBuilt-in and custom authentication strengths\nAdministrators can specify an authentication strength to access a resource by creating a Conditional Access policy with the\nRequire authentication strength\ncontrol. They can choose from three built-in authentication strengths:\nMultifactor authentication strength\n,\nPasswordless MFA strength\n, and\nPhishing-resistant MFA strength\n. They can also create a custom authentication strength based on the authentication method combinations that they want to allow.\nBuilt-in authentication strengths\nBuilt-in authentication strengths are combinations of authentication methods that Microsoft predefines. Built-in authentication strengths are always available and can't be modified. Microsoft updates built-in authentication strengths when new methods become available.\nFor example, the built-in\nPhishing-resistant MFA strength\nauthentication strength allows combinations of:\nWindows Hello for Business or platform credential\nFIDO2 security key\nMicrosoft Entra certificate-based authentication (multifactor)\nThe following table lists combinations of authentication methods for each built-in authentication strength. These combinations include methods that users need to register and that admins need to enable in the policy for authentication methods or the policy for legacy MFA settings:\nMFA strength\n: The same set of combinations that can be used to satisfy the\nRequire multifactor authentication\nsetting.\nPasswordless MFA strength\n: Includes authentication methods that satisfy MFA but don't require a password.\nPhishing-resistant MFA strength\n: Includes methods that require an interaction between the authentication method and the sign-in surface.\nAuthentication method combination\nMFA strength\nPasswordless MFA strength\nPhishing-resistant MFA strength\nFIDO2 security key\nâ\nâ\nâ\nWindows Hello for Business or platform credential\nâ\nâ\nâ\nCertificate-based authentication (multifactor)\nâ\nâ\nâ\nMicrosoft Authenticator (phone sign-in)\nâ\nâ\nTemporary Access Pass (one-time use and multiple use)\nâ\nPassword plus something the user has\n1\nâ\nFederated single-factor plus something the user has\n1\nâ\nFederated multifactor\nâ\nCertificate-based authentication (single-factor)\nSMS sign-in\nPassword\nFederated single-factor\n1\nSomething the user has\nrefers to one of the following methods: text message, voice, push notification, software OATH token, or hardware OATH token.\nYou can use the following API call to list definitions of all the built-in authentication strengths:\nGET https://graph.microsoft.com/beta/identity/conditionalAccess/authenticationStrength/policies?$filter=policyType eq 'builtIn'\nCustom authentication strengths\nConditional Access administrators can also create custom authentication strengths to exactly suit their access requirements. For more information, see\nCreate and manage custom Conditional Access authentication strengths\n.\nLimitations\nEffect of an authentication strength on authentication\n: Conditional Access policies are evaluated only after the initial authentication. As a result, an authentication strength doesn't restrict a user's initial authentication.\nSuppose you're using the built-in\nPhishing-resistant MFA strength\nauthentication strength. A user can still enter a password but must sign in by using a phishing-resistant method, such as a FIDO2 security key, before they can continue.\nUnsupported combination of grant controls\n: You can't use the\nRequire multifactor authentication\nand\nRequire authentication strength\ngrant controls together in the same Conditional Access policy. The reason is that the built-in\nMultifactor authentication\nauthentication strength is equivalent to the\nRequire multifactor authentication\ngrant control.\nUnsupported authentication method\n: The\nEmail one-time pass (Guest)\nauthentication method isn't currently supported in the available combinations.\nWindows Hello for Business\n: If the user signs in with Windows Hello for Business as the primary authentication method, it can be used to satisfy an authentication strength requirement that includes Windows Hello for Business. But if the user signs in with another method (like a password) as the primary authentication method, and the authentication strength requires Windows Hello for Business, the user isn't prompted to sign in with Windows Hello for Business. The user needs to restart the session, select\nSign-in options\n, and select a method that the authentication strength requires.\nKnown issues\nAuthentication strength and sign-in frequency\n: When a resource requires an authentication strength and a sign-in frequency, users can satisfy both requirements at two different times.\nFor example, let's say a resource requires a passkey (FIDO2) for the authentication strength, along with a 1-hour sign-in frequency. A user signed in with a passkey (FIDO2) to access the resource 24 hours ago.\nWhen the user unlocks their Windows device by using Windows Hello for Business, they can access the resource again. Yesterday's sign-in satisfies the authentication strength requirement, and today's device unlock satisfies the sign-in frequency requirement.\nFAQ\nShould I use an authentication strength or the policy for authentication methods?\nAn authentication strength is based on the\nAuthentication methods\npolicy. The\nAuthentication methods\npolicy helps to scope and configure authentication methods that users and groups can use across Microsoft Entra ID. An authentication strength allows another restriction of methods for specific scenarios, such as sensitive resource access, user risk, and location.\nFor example, assume that the administrator of an organization named Contoso wants to allow users to use Microsoft Authenticator with either push notifications or passwordless authentication mode. The administrator goes to the Authenticator settings in the\nAuthentication methods\npolicy, scopes the policy for the relevant users, and sets\nAuthentication mode\nto\nAny\n.\nFor Contoso's most sensitive resource, the administrator wants to restrict the access to only passwordless authentication methods. The administrator creates a new Conditional Access policy by using the built-in\nPasswordless MFA strength\nauthentication strength.\nAs a result, users in Contoso can access most of the resources in the tenant by using a password and a push notification from Authenticator, or by using only Authenticator (phone sign-in). However, when the users in the tenant access the sensitive application, they must use Authenticator (phone sign-in).\nRelated content\nCustom Conditional Access authentication strengths\nHow authentication strengths work for external users\nTroubleshoot authentication strengths\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Phishing-Resistant MFA",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/authentication/concept-authentication-methods": {
      "content_hash": "sha256:07945c2b7aa323aa48f97a30c885ab409b3c0c050819b1db55a02722805acf47",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Microsoft Entra authentication?\nFeedback\nSummarize this article for me\nAuthentication is the process of verifying a person's identity before granting access to a resource, application, service, device, or network. It's how a system makes sure\nusers are who they say they are\nwhen they try to sign in.\nAuthentication methodsâ¯supported by Microsoft Entra ID\nThe following table outlines when an authentication method can be used for primary or first factor authentication, secondary factor authentication when you use Microsoft Entra multifactor authentication (MFA) and for self-service password reset (SSPR). â¯\nMethod\nPrimary authentication\nSecondary authentication\nWindows Hello for Business\nYes\nMFA\n1\nPlatform Credential for macOS\nYes\nMFA\nPasskey (FIDO2)\nYes\nMFA\nPasskey in Microsoft Authenticator\nYes\nMFA\nSynced passkey (preview)\nYes\nMFA\nCertificate-based authentication\nYes\nMFA\nMicrosoft Authenticator passwordless\nYes\nNo\nMicrosoft Authenticator push notifications\nYes\nMFA and SSPR\nAuthenticator Lite\nNo\nMFA\nHardware OATH tokens (preview)\nNo\nMFA and SSPR\nSoftware OATH tokens\nNo\nMFA and SSPR\nExternal authentication methods (preview)\nNo\nMFA\nTemporary Access Pass (TAP)\nYes\nMFA\nShort Message Service (SMS) sign-in\nYes\nMFA and SSPR\nVoice call\nNo\nMFA and SSPR\nQR code\nYes\nNo\nEmail OTP\nNo\nSSPR and sign-in\n2\nPassword\nYes\nNo\n1\nWindows Hello for Business can serve as a step-up MFA credential if a user is enabled for passkey (FIDO2) and has a passkey registered.\n2\nEmail OTP is available for tenant members for\nSelf-Service Password Recovery (SSPR)\n. It may also be configured to be used for\nsign-in by guest users\n.\nPhishing-resistant authentication methodsâ¯â¯\nWhile traditional MFA with SMS, email OTP or authenticator apps significantly improves security over password-only systems, these options introduce frictionârequiring additional steps for users, like entering codes, approving push notifications, or using authenticator apps. Moreover, these options for MFA are prone to remote phishing attacks. Remote phishing is where attackers use social engineering and AI-driven tools to steal identity credentialsâlike passwords or one-time codesâwithout physical access to a user's device.â¯\nMicrosoft recommends using phishing-resistant authentication methods such as Windows Hello for Business, passkeys (FIDO2) and FIDO2 security keys, or certificate-based authentication (CBA) because they provide the most secure sign-in experience.\nThe following phishing-resistant authentication methods are available in Microsoft Entra ID.â¯\nWindows Hello for Business\nPlatform Credential for macOS\nSynced passkeys (FIDO2) (preview)\nFIDO2 security keys\nPasskeys in Microsoft Authenticator\nCertificate-based authentication (CBA)â¯\nHigh assurance account recovery\nAccount recovery is the process where users have lost all their credentials and can't access their account anymore. The traditional way to help users recover their credentials includes the user calling helpdesk, where they answer some questions to verify their identity, which allows helpdesk to reset their credentials. Microsoft Entra ID now supports government-issued ID and biometric verification, which offers AI powered biometric match against government issued IDs for high-assurance account recovery.\nOrganizations can choose amongst the leading identity verification providers (IDV) via\nMicrosoft Security Store\n: Idemia, Lexis Nexis, and Au10tix. These partners offer coverage across 192 countries/regions and remote verification for most government issued identity (Gov ID) documents, including driver's licenses and passports. Entra Verified ID Face Check, powered by Azure AI services, adds a critical layer of trust by matching a userâs real-time selfie and the photo from their identity document. By sharing only the match results and not any sensitive identity data, Face Check improves user privacy while allowing enterprises to be sure the person claiming an identity is really them.\nOnce enabled, this capability enables a natively integrated end-to-end flow for users to easily and securely regain access to their accounts. For more information, see\nOverview of Microsoft Entra ID Account Recovery\n.\nRelated content\nPasskeys (FIDO2)\nGet started with phishing-resistant MFA deployment in Microsoft Entra ID\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Authentication Methods",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/authentication/howto-authentication-passwordless-security-key": {
      "content_hash": "sha256:f7c991b9e00cdaa83d388ea4823dde76360797a8249e631c0dbb14833ca10e79",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nEnable passkeys (FIDO2) for your organization\nFeedback\nSummarize this article for me\nFor enterprises that use passwords today, passkeys (FIDO2) provide a seamless way for workers to authenticate without entering a username or password. Passkeys (FIDO2) provide improved productivity for workers, and have better security.\nThis article lists requirements and steps to enable passkeys in your organization. After you complete these steps, users in your organization can then register and sign in to their Microsoft Entra account using a passkey stored on a FIDO2 security key or in Microsoft Authenticator.\nFor more information about enabling passkeys in Microsoft Authenticator, see\nHow to enable passkeys in Microsoft Authenticator\n.\nFor more information about passkey authentication, see\nSupport for FIDO2 authentication with Microsoft Entra ID\n.\nNote\nMicrosoft Entra ID currently supports device-bound passkeys stored on FIDO2 security keys and in Microsoft Authenticator. Support for synced passkeys is currently in preview. For more information, see\nPasskeys (FIDO2) authentication method in Microsoft Entra ID\n.\nRequirements\nUsers must complete multifactor authentication (MFA) within the past five minutes before they can register a passkey (FIDO2).\nUsers need a\npasskey (FIDO2) eligible for attestation with Microsoft Entra ID\nor Microsoft Authenticator.\nDevices must support passkey (FIDO2) authentication. For Windows devices that are joined to Microsoft Entra ID, the best experience is on Windows 10 version 1903 or higher. Hybrid-joined devices must run Windows 10 version 2004 or higher.\nPasskeys (FIDO2) are supported across major scenarios on Windows, macOS, Android, and iOS. For more information on supported scenarios, see\nSupport for FIDO2 authentication in Microsoft Entra ID\n.\nNote\nSupport for same-device registration in Edge on Android is coming soon.\nPasskey (FIDO2) Authenticator Attestation GUID (AAGUID)\nThe FIDO2 specification requires each security key vendor to provide an Authenticator Attestation GUID (AAGUID) during registration. An AAGUID is a 128-bit identifier indicating the key type, such as the make and model. Passkey (FIDO2) providers on desktop and mobile devices are also expected to provide an AAGUID during registration.\nNote\nThe vendor must ensure that the AAGUID is identical across all substantially identical security keys or passkey (FIDO2) providers made by that vendor, and different (with high probability) from the AAGUIDs of all other types of security keys or passkey (FIDO2) providers. To ensure this, the AAGUID for a given security key model or passkey (FIDO2) provider should be randomly generated. For more information, see\nWeb Authentication: An API for accessing Public Key Credentials - Level 2 (w3.org)\n.\nYou can work with your security key vendor to determine the AAGUID of the passkey (FIDO2), or see\nFIDO2 security keys eligible for attestation with Microsoft Entra ID\n. If the passkey (FIDO2) is already registered, you can find the AAGUID by viewing the authentication method details of the passkey (FIDO2) for the user.\nEnable passkey (FIDO2) authentication method\nNote\nIf you would like to configure different passkey (FIDO2) settings for different groups of users, see\nHow to enable passkey profiles (preview) in Microsoft Entra ID\n.\nSign in to the\nMicrosoft Entra admin center\nas at least an\nAuthentication Policy Administrator\n.\nBrowse to\nEntra ID\n>\nAuthentication methods\n>\nPolicies\n.\nUnder the method\nPasskey (FIDO2)\n, set the toggle to\nEnable\n. Select\nAll users\nor\nAdd groups\nto select specific groups.\nOnly security groups are supported\n.\nOn the\nConfigure\ntab:\nSet\nAllow self-service set up\nto\nYes\n. If set to\nNo\n, users can't register a passkey by using\nSecurity info\n, even if passkeys (FIDO2) are enabled by the Authentication methods policy.\nSet\nEnforce attestation\nto\nYes\nif your organization wants to be assured that a FIDO2 security key model or passkey provider is genuine and comes from the legitimate vendor.\nMetadata for FIDO2 security keys needs to be published and verified with the FIDO Alliance Metadata Service, and also pass another set of validation testing by Microsoft. For more information, see\nBecome a Microsoft-compatible FIDO2 security key vendor\n.\nPasskeys in Microsoft Authenticator also support attestation. For more information, see\nHow passkey attestation works with Authenticator\n.\nWarning\nIf you set\nEnforce attestation\nto\nNo\n, users can register any type of passkey. Set\nEnforce attestation\nto\nYes\nto ensure that users can only register device-bound passkeys.\nAttestation enforcement governs whether a passkey (FIDO2) is allowed only during registration. Users who register a passkey (FIDO2) without attestation aren't blocked from sign-in if\nEnforce attestation\nis set to\nYes\nlater.\nKey Restriction Policy\nEnforce key restrictions\nshould be set to\nYes\nonly if your organization wants to only allow or disallow certain security key models or passkey providers, which are identified by their AAGUID. You can work with your security key vendor to determine the AAGUID of the passkey. If the passkey is already registered, you can find the AAGUID by viewing the authentication method details of the passkey for the user.\nWarning\nKey restrictions set the usability of specific models or providers for both registration and authentication. If you change key restrictions and remove an AAGUID that you previously allowed, users who previously registered an allowed method can no longer use it for sign-in.\nAfter you finish the configuration, select\nSave\n.\nNote\nIf you see an error when you try to save, replace multiple groups with a single group in one operation, and then click\nSave\nagain.\nProvision FIDO2 security keys using Microsoft Graph API (preview)\nCurrently in preview, administrators can use\nMicrosoft Graph and custom clients to provision FIDO2 security keys on behalf of users\n. Provisioning requires the\nAuthentication Administrator role\nor a client application with UserAuthenticationMethod.ReadWrite.All permission. The provisioning improvements include:\nThe ability to request WebAuthn\ncreation Options\nfrom Microsoft Entra ID\nThe ability to register the provisioned security key directly with Microsoft Entra ID\nWith these new APIs, organizations can build their own clients to provision passkey (FIDO2) credentials on security keys on behalf of a user. To simplify this process, three main steps are required.\nRequest\ncreationOptions for a user: Microsoft Entra ID returns the necessary data for your client to provision a passkey (FIDO2) credential. This includes information such as user information, relying party ID, credential policy requirements, algorithms, registration challenge and more.\nProvision\nthe passkey (FIDO2) credential with the creation Options: Use the\ncreationOptions\nand a client that supports the Client to Authenticator Protocol (CTAP) to provision the credential. During this step, you need to insert the security key and set a PIN.\nRegister\nthe provisioned credential with Microsoft Entra ID: Use the formatted output from the provisioning process to provide Microsoft Entra ID the necessary data to register the passkey (FIDO2) credential for the targeted user.\nEnable passkeys (FIDO2) using Microsoft Graph API\nIn addition to using the Microsoft Entra admin center, you can also enable passkeys (FIDO2) by using the Microsoft Graph API. To enable passkeys (FIDO2), you need to update the Authentication methods policy as at least an\nAuthentication Policy Administrator\n.\nTo configure the policy using Graph Explorer:\nSign in to\nGraph Explorer\nand consent to the\nPolicy.Read.All\nand\nPolicy.ReadWrite.AuthenticationMethod\npermissions.\nRetrieve the Authentication methods policy:\nGET https://graph.microsoft.com/v1.0/authenticationMethodsPolicy/authenticationMethodConfigurations/FIDO2\nTo disable attestation enforcement and enforce key restrictions to only allow the AAGUID for RSA DS100 for example, perform a PATCH operation using the following request body:\nPATCH https://graph.microsoft.com/v1.0/authenticationMethodsPolicy/authenticationMethodConfigurations/FIDO2\n\nRequest Body:\n{\n \"@odata.type\": \"#microsoft.graph.fido2AuthenticationMethodConfiguration\",\n \"isAttestationEnforced\": false,\n \"keyRestrictions\": {\n \"isEnforced\": true,\n \"enforcementType\": \"allow\",\n \"aaGuids\": [\n \"7e3f3d30-3557-4442-bdae-139312178b39\",\n\n <insert previous AAGUIDs here to keep them stored in policy>\n ]\n }\n}\nMake sure that the passkey (FIDO2) policy is updated properly.\nGET https://graph.microsoft.com/v1.0/authenticationMethodsPolicy/authenticationMethodConfigurations/FIDO2\nDelete a passkey (FIDO2)\nTo remove a passkey (FIDO2) associated with a user account, delete it from the user's authentication method.\nSign in to the\nMicrosoft Entra admin center\nand search for the user whose passkey (FIDO2) needs to be removed.\nSelect\nAuthentication methods\n> right-click\nPasskey (device-bound)\nand select\nDelete\n.\nEnforce passkey (FIDO2) sign-in\nTo make users sign in with a passkey (FIDO2) when they access a sensitive resource, you can:\nUse a built-in phishing-resistant authentication strength\nOr\nCreate a custom authentication strength\nThe following steps show how to create a custom authentication strength. It's a Conditional Access policy that allows passkey (FIDO2) sign-in for only a specific security key model or passkey (FIDO2) provider. For a list of FIDO2 providers, see\nFIDO2 security keys eligible for attestation with Microsoft Entra ID\n.\nSign in to the\nMicrosoft Entra admin center\nas at least a\nConditional Access Administrator\n.\nBrowse to\nEntra ID\n>\nAuthentication methods\n>\nAuthentication strengths\n.\nSelect\nNew authentication strength\n.\nProvide a\nName\nfor your new authentication strength.\nOptionally provide a\nDescription\n.\nSelect\nPasskeys (FIDO2)\n.\nOptionally, if you want to restrict a specific AAGUID, select\nAdvanced options\n>\nAdd AAGUID\n. Enter the AAGUID, and select\nSave\n.\nChoose\nNext\nand review the policy configuration.\nKnown issues\nSecurity key provisioning\nAdministrator provisioning of security keys is in preview. See\nMicrosoft Graph and custom clients to provision FIDO2 security keys on behalf of users\n.\nGuest users\nRegistration of passkey (FIDO2) credentials isn't supported for internal or external guest users, including B2B collaboration users in the resource tenant.\nUPN changes\nIf a user's UPN changes, you can no longer modify passkeys (FIDO2) to account for the change. If the user has a passkey (FIDO2), they need to sign in to\nSecurity info\n, delete the old passkey (FIDO2), and add a new one.\nNext steps\nNative app and browser support of passkey (FIDO2) passwordless authentication\nFIDO2 security key Windows 10 sign in\nEnable FIDO2 authentication to on-premises resources\nRegister security keys on behalf of users\nLearn more about device registration\nLearn more about Microsoft Entra multifactor authentication\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "FIDO2 Security Keys",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/custom-overview": {
      "content_hash": "sha256:f41a8169ac456d4be99bf202a1da4a15e0c003ff943158c45b47bb095a6bbaa6",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of role-based access control in Microsoft Entra ID\nFeedback\nSummarize this article for me\nThis article describes how to understand Microsoft Entra role-based access control. Microsoft Entra roles allow you to grant granular permissions to your admins, abiding by the principle of least privilege. Microsoft Entra built-in and custom roles operate on concepts similar to those you find in\nthe role-based access control system for Azure resources\n(Azure roles). The\ndifference between these two role-based access control systems\nis:\nMicrosoft Entra roles control access to Microsoft Entra resources such as users, groups, and applications using the Microsoft Graph API\nAzure roles control access to Azure resources such as virtual machines or storage using Azure Resource Management\nBoth systems contain similarly used role definitions and role assignments. However, Microsoft Entra role permissions can't be used in Azure custom roles and vice versa.\nUnderstand Microsoft Entra role-based access control\nMicrosoft Entra ID supports two types of roles definitions:\nBuilt-in roles\nCustom roles\nBuilt-in roles are out of box roles that have a fixed set of permissions. These role definitions cannot be modified. There are many\nbuilt-in roles\nthat Microsoft Entra ID supports, and the list is growing. To round off the edges and meet your sophisticated requirements, Microsoft Entra ID also supports\ncustom roles\n. Granting permission using custom Microsoft Entra roles is a two-step process that involves creating a custom role definition and then assigning it using a role assignment. A custom role definition is a collection of permissions that you add from a preset list. These permissions are the same permissions used in the built-in roles.\nOnce youâve created your custom role definition (or using a built-in role), you can assign it to a user by creating a role assignment. A role assignment grants the user the permissions in a role definition at a specified scope. This two-step process allows you to create a single role definition and assign it many times at different scopes. A scope defines the set of Microsoft Entra resources the role member has access to. The most common scope is organization-wide (org-wide) scope. A custom role can be assigned at org-wide scope, meaning the role member has the role permissions over all resources in the organization. A custom role can also be assigned at an object scope. An example of an object scope would be a single application. The same role can be assigned to one user over all applications in the organization and then to another user with a scope of only the Contoso Expense Reports app.\nHow Microsoft Entra ID determines if a user has access to a resource\nThe following are the high-level steps that Microsoft Entra ID uses to determine if you have access to a management resource. Use this information to troubleshoot access issues.\nA user (or service principal) acquires a token to the Microsoft Graph endpoint.\nThe user makes an API call to Microsoft Entra ID via Microsoft Graph using the issued token.\nDepending on the circumstance, Microsoft Entra ID takes one of the following actions:\nEvaluates the userâs role memberships based on the\nwids claim\nin the userâs access token.\nRetrieves all the role assignments that apply for the user, either directly or via group membership, to the resource on which the action is being taken.\nMicrosoft Entra ID determines if the action in the API call is included in the roles the user has for this resource.\nIf the user doesn't have a role with the action at the requested scope, access is not granted. Otherwise access is granted.\nRole assignment\nA role assignment is a Microsoft Entra resource that attaches a\nrole definition\nto a\nsecurity principal\nat a particular\nscope\nto grant access to Microsoft Entra resources. Access is granted by creating a role assignment, and access is revoked by removing a role assignment. At its core, a role assignment consists of three elements:\nSecurity principal - An identity that gets the permissions. It could be a user, group, or a service principal.\nRole definition - A collection of permissions.\nScope - A way to constrain where those permissions are applicable.\nYou can\ncreate role assignments\nand\nlist the role assignments\nusing the Microsoft Entra admin center,\nMicrosoft Graph PowerShell\n, or Microsoft Graph API. Azure CLI is not supported for Microsoft Entra role assignments.\nThe following diagram shows an example of a role assignment. In this example, Chris has been assigned the App Registration Administrator custom role at the scope of the Contoso Widget Builder app registration. The assignment grants Chris the permissions of the App Registration Administrator role for only this specific app registration.\nSecurity principal\nA security principal represents a user, group, or service principal that is assigned access to Microsoft Entra resources. A user is an individual who has a user profile in Microsoft Entra ID. A group is a new Microsoft 365 or security group that has been set as a\nrole-assignable group\n. A service principal is an identity created for use with applications, hosted services, and automated tools to access Microsoft Entra resources.\nRole definition\nA role definition, or role, is a collection of permissions. A role definition lists the operations that can be performed on Microsoft Entra resources, such as create, read, update, and delete. There are two types of roles in Microsoft Entra ID:\nBuilt-in roles created by Microsoft that can't be changed.\nCustom roles created and managed by your organization.\nScope\nA scope is a way to limit the permitted actions to a particular set of resources as part of a role assignment. For example, if you want to assign a custom role to a developer, but only to manage a specific application registration, you can include the specific application registration as a scope in the role assignment.\nWhen you assign a role, you specify one of the following types of scope:\nTenant\nAdministrative unit\nMicrosoft Entra resource\nIf you specify a Microsoft Entra resource as a scope, it can be one of the following:\nMicrosoft Entra groups\nEnterprise applications\nApplication registrations\nWhen a role is assigned over a container scope, such as the Tenant or an Administrative Unit, it grants permissions over the objects they contain but not on the container itself. On the contrary, when a role is assigned over a resource scope, it grants permissions over the resource itself but it does not extend beyond (in particular, it does not extend to the members of a Microsoft Entra group).\nFor more information, see\nAssign Microsoft Entra roles\n.\nRole assignment options\nMicrosoft Entra ID provides multiple options for assigning roles:\nYou can assign roles to users directly, which is the default way to assign roles. Both built-in and custom Microsoft Entra roles can be assigned to users, based on access requirements. For more information, see\nAssign Microsoft Entra roles\n.\nWith Microsoft Entra ID P1, you can create role-assignable groups and assign roles to these groups. Assigning roles to a group instead of individuals allows for easy addition or removal of users from a role and creates consistent permissions for all members of the group. For more information, see\nAssign Microsoft Entra roles\n.\nWith Microsoft Entra ID P2, you can use Microsoft Entra Privileged Identity Management (Microsoft Entra PIM) to provide just-in-time access to roles. This feature allows you to grant time-limited access to a role to users who require it, rather than granting permanent access. It also provides detailed reporting and auditing capabilities. For more information, see\nAssign Microsoft Entra roles in Privileged Identity Management\n.\nLicense requirements\nUsing built-in roles in Microsoft Entra ID is free. Using custom roles require a Microsoft Entra ID P1 license for every user with a custom role assignment. To find the right license for your requirements, see\nComparing generally available features of the Free and Premium editions\n.\nNext steps\nUnderstand Microsoft Entra roles\nAssign Microsoft Entra roles\nMicrosoft Entra forum\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Role-Based Access Control",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/permissions-reference": {
      "content_hash": "sha256:11432a95e91bfcae72b81367d565afb1a7de88d173256a97e03e458790a6115e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Entra built-in roles\nFeedback\nSummarize this article for me\nIn Microsoft Entra ID, if another administrator or nonadministrator needs to manage Microsoft Entra resources, you assign them a Microsoft Entra role that provides the permissions they need. For example, you can assign roles to allow adding or changing users, resetting user passwords, managing user licenses, or managing domain names.\nThis article lists the Microsoft Entra built-in roles you can assign to allow management of Microsoft Entra resources. For information about how to assign roles, see\nAssign Microsoft Entra roles\n. If you are looking for roles to manage Azure resources, see\nAzure built-in roles\n.\nAll roles\nRole\nDescription\nTemplate ID\nAgent ID Administrator\nManage all aspects of agents in a tenant including identity lifecycle operations for agent blueprints, agent service principals, agent identities, and agentic users.\ndb506228-d27e-4b7d-95e5-295956d6615f\nAgent ID Developer\nCreate an agent blueprint and its service principal in a tenant. User will be added as an owner of the agent blueprint and its service principal.\nadb2368d-a9be-41b5-8667-d96778e081b0\nAgent Registry Administrator\nManage all aspects of the Agent Registry service in Microsoft Entra ID\n6b942400-691f-4bf0-9d12-d8a254a2baf5\nAI Administrator\nManage all aspects of Microsoft 365 Copilot and AI-related enterprise services in Microsoft 365.\nd2562ede-74db-457e-a7b6-544e236ebb61\nApplication Administrator\nCan create and manage all aspects of app registrations and enterprise apps.\n9b895d92-2cd3-44c7-9d02-a6ac2d5ea5c3\nApplication Developer\nCan create application registrations independent of the 'Users can register applications' setting.\ncf1c38e5-3621-4004-a7cb-879624dced7c\nAttack Payload Author\nCan create attack payloads that an administrator can initiate later.\n9c6df0f2-1e7c-4dc3-b195-66dfbd24aa8f\nAttack Simulation Administrator\nCan create and manage all aspects of attack simulation campaigns.\nc430b396-e693-46cc-96f3-db01bf8bb62a\nAttribute Assignment Administrator\nAssign custom security attribute keys and values to supported Microsoft Entra objects.\n58a13ea3-c632-46ae-9ee0-9c0d43cd7f3d\nAttribute Assignment Reader\nRead custom security attribute keys and values for supported Microsoft Entra objects.\nffd52fa5-98dc-465c-991d-fc073eb59f8f\nAttribute Definition Administrator\nDefine and manage the definition of custom security attributes.\n8424c6f0-a189-499e-bbd0-26c1753c96d4\nAttribute Definition Reader\nRead the definition of custom security attributes.\n1d336d2c-4ae8-42ef-9711-b3604ce3fc2c\nAttribute Log Administrator\nRead audit logs and configure diagnostic settings for events related to custom security attributes.\n5b784334-f94b-471a-a387-e7219fc49ca2\nAttribute Log Reader\nRead audit logs related to custom security attributes.\n9c99539d-8186-4804-835f-fd51ef9e2dcd\nAttribute Provisioning Administrator\nRead and edit the provisioning configuration of all active custom security attributes for an application.\necb2c6bf-0ab6-418e-bd87-7986f8d63bbe\nAttribute Provisioning Reader\nRead the provisioning configuration of all active custom security attributes for an application.\n422218e4-db15-4ef9-bbe0-8afb41546d79\nAuthentication Administrator\nCan access to view, set and reset authentication method information for any non-admin user.\nc4e39bd9-1100-46d3-8c65-fb160da0071f\nAuthentication Extensibility Administrator\nCustomize sign in and sign up experiences for users by creating and managing custom authentication extensions.\n25a516ed-2fa0-40ea-a2d0-12923a21473a\nAuthentication Policy Administrator\nCan create and manage the authentication methods policy, tenant-wide MFA settings, password protection policy, and verifiable credentials.\n0526716b-113d-4c15-b2c8-68e3c22b9f80\nAzure DevOps Administrator\nCan manage Azure DevOps policies and settings.\ne3973bdf-4987-49ae-837a-ba8e231c7286\nAzure Information Protection Administrator\nCan manage all aspects of the Azure Information Protection product.\n7495fdc4-34c4-4d15-a289-98788ce399fd\nB2C IEF Keyset Administrator\nCan manage secrets for federation and encryption in the Identity Experience Framework (IEF).\naaf43236-0c0d-4d5f-883a-6955382ac081\nB2C IEF Policy Administrator\nCan create and manage trust framework policies in the Identity Experience Framework (IEF).\n3edaf663-341e-4475-9f94-5c398ef6c070\nBilling Administrator\nCan perform common billing related tasks like updating payment information.\nb0f54661-2d74-4c50-afa3-1ec803f12efe\nCloud App Security Administrator\nCan manage all aspects of the Defender for Cloud Apps product.\n892c5842-a9a6-463a-8041-72aa08ca3cf6\nCloud Application Administrator\nCan create and manage all aspects of app registrations and enterprise apps except App Proxy.\n158c047a-c907-4556-b7ef-446551a6b5f7\nCloud Device Administrator\nLimited access to manage devices in Microsoft Entra ID.\n7698a772-787b-4ac8-901f-60d6b08affd2\nCompliance Administrator\nCan read and manage compliance configuration and reports in Microsoft Entra ID and Microsoft 365.\n17315797-102d-40b4-93e0-432062caca18\nCompliance Data Administrator\nCreates and manages compliance content.\ne6d1a23a-da11-4be4-9570-befc86d067a7\nConditional Access Administrator\nCan manage Conditional Access capabilities.\nb1be1c3e-b65d-4f19-8427-f6fa0d97feb9\nCustomer LockBox Access Approver\nCan approve Microsoft support requests to access customer organizational data.\n5c4f9dcd-47dc-4cf7-8c9a-9e4207cbfc91\nDesktop Analytics Administrator\nCan access and manage Desktop management tools and services.\n38a96431-2bdf-4b4c-8b6e-5d3d8abac1a4\nDirectory Readers\nCan read basic directory information. Commonly used to grant directory read access to applications and guests.\n88d8e3e3-8f55-4a1e-953a-9b9898b8876b\nDirectory Synchronization Accounts\nOnly used by Microsoft Entra Connect service.\nd29b2b05-8046-44ba-8758-1e26182fcf32\nDirectory Writers\nCan read and write basic directory information. For granting access to applications, not intended for users.\n9360feb5-f418-4baa-8175-e2a00bac4301\nDomain Name Administrator\nCan manage domain names in cloud and on-premises.\n8329153b-31d0-4727-b945-745eb3bc5f31\nDragon Administrator\nManage all aspects of the Microsoft Dragon admin center.\ne93e3737-fa85-474a-aee4-7d3fb86510f3\nDynamics 365 Administrator\nCan manage all aspects of the Dynamics 365 product.\n44367163-eba1-44c3-98af-f5787879f96a\nDynamics 365 Business Central Administrator\nAccess and perform all administrative tasks on Dynamics 365 Business Central environments.\n963797fb-eb3b-4cde-8ce3-5878b3f32a3f\nEdge Administrator\nManage all aspects of Microsoft Edge.\n3f1acade-1e04-4fbc-9b69-f0302cd84aef\nExchange Administrator\nCan manage all aspects of the Exchange product.\n29232cdf-9323-42fd-ade2-1d097af3e4de\nExchange Backup Administrator\nBack up and restore content (including granular restore) for Exchange in Microsoft 365 Backup\n49eb8f75-97e9-4e37-9b2b-6c3ebfcffa31\nExchange Recipient Administrator\nCan create or update Exchange Online recipients within the Exchange Online organization.\n31392ffb-586c-42d1-9346-e59415a2cc4e\nExtended Directory User Administrator\nManage all aspects of external user profiles in the extended directory for Teams.\ndd13091a-6207-4fc0-82ba-3641e056ab95\nExternal ID User Flow Administrator\nCan create and manage all aspects of user flows.\n6e591065-9bad-43ed-90f3-e9424366d2f0\nExternal ID User Flow Attribute Administrator\nCan create and manage the attribute schema available to all user flows.\n0f971eea-41eb-4569-a71e-57bb8a3eff1e\nExternal Identity Provider Administrator\nCan configure identity providers for use in direct federation.\nbe2f45a1-457d-42af-a067-6ec1fa63bc45\nFabric Administrator\nCan manage all aspects of the Fabric and Power BI products.\na9ea8996-122f-4c74-9520-8edcd192826c\nGlobal Administrator\nCan manage all aspects of Microsoft Entra ID and Microsoft services that use Microsoft Entra identities.\n62e90394-69f5-4237-9190-012177145e10\nGlobal Reader\nCan read everything that a Global Administrator can, but not update anything.\nf2ef992c-3afb-46b9-b7cf-a126ee74c451\nGlobal Secure Access Administrator\nCreate and manage all aspects of Global Secure Internet Access and Microsoft Global Secure Private Access, including managing access to public and private endpoints.\nac434307-12b9-4fa1-a708-88bf58caabc1\nGlobal Secure Access Log Reader\nProvides designated security personnel with read-only access to network traffic logs in Microsoft Entra Internet Access and Microsoft Entra Private Access for detailed analysis.\n843318fb-79a6-4168-9e6f-aa9a07481cc4\nGroups Administrator\nMembers of this role can create/manage groups, create/manage groups settings like naming and expiration policies, and view groups activity and audit reports.\nfdd7a751-b60b-444a-984c-02652fe8fa1c\nGuest Inviter\nCan invite guest users independent of the 'members can invite guests' setting.\n95e79109-95c0-4d8e-aee3-d01accf2d47b\nHelpdesk Administrator\nCan reset passwords for non-administrators and Helpdesk Administrators.\n729827e3-9c14-49f7-bb1b-9608f156bbb8\nHybrid Identity Administrator\nManage Active Directory to Microsoft Entra cloud provisioning, Microsoft Entra Connect, pass-through authentication (PTA), password hash synchronization (PHS), seamless single sign-on (seamless SSO), and federation settings. Does not have access to manage Microsoft Entra Connect Health.\n8ac3fc64-6eca-42ea-9e69-59f4c7b60eb2\nIdentity Governance Administrator\nManage access using Microsoft Entra ID for identity governance scenarios.\n45d8d3c5-c802-45c6-b32a-1d70b5e1e86e\nInsights Administrator\nHas administrative access in the Microsoft 365 Insights app.\neb1f4a8d-243a-41f0-9fbd-c7cdf6c5ef7c\nInsights Analyst\nAccess the analytical capabilities in Microsoft Viva Insights and run custom queries.\n25df335f-86eb-4119-b717-0ff02de207e9\nInsights Business Leader\nCan view and share dashboards and insights via the Microsoft 365 Insights app.\n31e939ad-9672-4796-9c2e-873181342d2d\nIntune Administrator\nCan manage all aspects of the Intune product.\n3a2c62db-5318-420d-8d74-23affee5d9d5\nIoT Device Administrator\nProvision new IoT devices, manage their lifecycle, configure certificates, and manage device templates.\n2ea5ce4c-b2d8-4668-bd81-3680bd2d227a\nKaizala Administrator\nCan manage settings for Microsoft Kaizala.\n74ef975b-6605-40af-a5d2-b9539d836353\nKnowledge Administrator\nCan configure knowledge, learning, and other intelligent features.\nb5a8dcf3-09d5-43a9-a639-8e29ef291470\nKnowledge Manager\nCan organize, create, manage, and promote topics and knowledge.\n744ec460-397e-42ad-a462-8b3f9747a02c\nLicense Administrator\nCan manage product licenses on users and groups.\n4d6ac14f-3453-41d0-bef9-a3e0c569773a\nLifecycle Workflows Administrator\nCreate and manage all aspects of workflows and tasks associated with Lifecycle Workflows in Microsoft Entra ID.\n59d46f88-662b-457b-bceb-5c3809e5908f\nMessage Center Privacy Reader\nCan read security messages and updates in Office 365 Message Center only.\nac16e43d-7b2d-40e0-ac05-243ff356ab5b\nMessage Center Reader\nCan read messages and updates for their organization in Office 365 Message Center only.\n790c1fb9-7f7d-4f88-86a1-ef1f95c05c1b\nMicrosoft 365 Backup Administrator\nBack up and restore content across supported services (SharePoint, OneDrive, and Exchange Online) in Microsoft 365 Backup\n1707125e-0aa2-4d4d-8655-a7c786c76a25\nMicrosoft 365 Migration Administrator\nPerform all migration functionality to migrate content to Microsoft 365 using Migration Manager.\n8c8b803f-96e1-4129-9349-20738d9f9652\nMicrosoft Entra Joined Device Local Administrator\nUsers assigned to this role are added to the local administrators group on Microsoft Entra joined devices.\n9f06204d-73c1-4d4c-880a-6edb90606fd8\nMicrosoft Graph Data Connect Administrator\nManage aspects of Microsoft Graph Data Connect service in a tenant.\nee67aa9c-e510-4759-b906-227085a7fd4d\nMicrosoft Hardware Warranty Administrator\nCreate and manage all aspects warranty claims and entitlements for Microsoft manufactured hardware, like Surface and HoloLens.\n1501b917-7653-4ff9-a4b5-203eaf33784f\nMicrosoft Hardware Warranty Specialist\nCreate and read warranty claims for Microsoft manufactured hardware, like Surface and HoloLens.\n281fe777-fb20-4fbb-b7a3-ccebce5b0d96\nNetwork Administrator\nCan manage network locations and review enterprise network design insights for Microsoft 365 Software as a Service applications.\nd37c8bed-0711-4417-ba38-b4abe66ce4c2\nOffice Apps Administrator\nCan manage Office apps cloud services, including policy and settings management, and manage the ability to select, unselect and publish 'what's new' feature content to end-user's devices.\n2b745bdf-0803-4d80-aa65-822c4493daac\nOrganizational Branding Administrator\nManage all aspects of organizational branding in a tenant.\n92ed04bf-c94a-4b82-9729-b799a7a4c178\nOrganizational Data Source Administrator\nSet up and manage the ingestion of organizational data into Microsoft 365.\n9d70768a-0cbc-4b4c-aea3-2e124b2477f4\nOrganizational Messages Approver\nReview, approve, or reject new organizational messages for delivery in the Microsoft 365 admin center before they are sent to users.\ne48398e2-f4bb-4074-8f31-4586725e205b\nOrganizational Messages Writer\nWrite, publish, manage, and review the organizational messages for end-users through Microsoft product surfaces.\n507f53e4-4e52-4077-abd3-d2e1558b6ea2\nPartner Tier1 Support\nDo not use - not intended for general use.\n4ba39ca4-527c-499a-b93d-d9b492c50246\nPartner Tier2 Support\nDo not use - not intended for general use.\ne00e864a-17c5-4a4b-9c06-f5b95a8d5bd8\nPassword Administrator\nCan reset passwords for non-administrators and Password Administrators.\n966707d0-3269-4727-9be2-8c3a10f19b9d\nPeople Administrator\nManage profile photos of users and people settings for all users in the organization.\n024906de-61e5-49c8-8572-40335f1e0e10\nPermissions Management Administrator\nManage all aspects of Microsoft Entra Permissions Management.\naf78dc32-cf4d-46f9-ba4e-4428526346b5\nPlaces Administrator\nManage all aspects of the Microsoft Places service.\n78b0ccd1-afc2-4f92-9116-b41aedd09592\nPower Platform Administrator\nCan create and manage all aspects of Microsoft Dynamics 365, Power Apps and Power Automate.\n11648597-926c-4cf3-9c36-bcebb0ba8dcc\nPrinter Administrator\nCan manage all aspects of printers and printer connectors.\n644ef478-e28f-4e28-b9dc-3fdde9aa0b1f\nPrinter Technician\nCan register and unregister printers and update printer status.\ne8cef6f1-e4bd-4ea8-bc07-4b8d950f4477\nPrivileged Authentication Administrator\nCan access to view, set and reset authentication method information for any user (admin or non-admin).\n7be44c8a-adaf-4e2a-84d6-ab2649e08a13\nPrivileged Role Administrator\nCan manage role assignments in Microsoft Entra ID, and all aspects of Privileged Identity Management.\ne8611ab8-c189-46e8-94e1-60213ab1f814\nReports Reader\nCan read sign-in and audit reports.\n4a5d8f65-41da-4de4-8968-e035b65339cf\nSearch Administrator\nCan create and manage all aspects of Microsoft Search settings.\n0964bb5e-9bdb-4d7b-ac29-58e794862a40\nSearch Editor\nCan create and manage the editorial content such as bookmarks, Q and As, locations, floorplan.\n8835291a-918c-4fd7-a9ce-faa49f0cf7d9\nSecurity Administrator\nCan read security information and reports, and manage configuration in Microsoft Entra ID and Office 365.\n194ae4cb-b126-40b2-bd5b-6091b380977d\nSecurity Operator\nCreates and manages security events.\n5f2222b1-57c3-48ba-8ad5-d4759f1fde6f\nSecurity Reader\nCan read security information and reports in Microsoft Entra ID and Office 365.\n5d6b6bb7-de71-4623-b4af-96380a352509\nService Support Administrator\nCan read service health information and manage support tickets.\nf023fd81-a637-4b56-95fd-791ac0226033\nSharePoint Administrator\nCan manage all aspects of the SharePoint service.\nf28a1f50-f6e7-4571-818b-6a12f2af6b6c\nSharePoint Advanced Management Administrator\nManage all aspects of SharePoint Advanced Management.\n99009c4a-3b3f-4957-82a9-9d35e12db77e\nSharePoint Backup Administrator\nBack up and restore content (including granular restore) for SharePoint and OneDrive in Microsoft 365 Backup\n9d3e04ba-3ee4-4d1b-a3a7-9aef423a09be\nSharePoint Embedded Administrator\nManage all aspects of SharePoint Embedded containers.\n1a7d78b6-429f-476b-b8eb-35fb715fffd4\nSkype for Business Administrator\nCan manage all aspects of the Skype for Business product.\n75941009-915a-4869-abe7-691bff18279e\nTeams Administrator\nCan manage the Microsoft Teams service.\n69091246-20e8-4a56-aa4d-066075b2a7a8\nTeams Communications Administrator\nCan manage calling and meetings features within the Microsoft Teams service.\nbaf37b3a-610e-45da-9e62-d9d1e5e8914b\nTeams Communications Support Engineer\nCan troubleshoot communications issues within Teams using advanced tools.\nf70938a0-fc10-4177-9e90-2178f8765737\nTeams Communications Support Specialist\nCan troubleshoot communications issues within Teams using basic tools.\nfcf91098-03e3-41a9-b5ba-6f0ec8188a12\nTeams Devices Administrator\nCan perform management related tasks on Teams certified devices.\n3d762c5a-1b6c-493f-843e-55a3b42923d4\nTeams Reader\nRead everything in the Teams admin center, but not update anything.\n1076ac91-f3d9-41a7-a339-dcdf5f480acc\nTeams Telephony Administrator\nManage voice and telephony features and troubleshoot communication issues within the Microsoft Teams service.\naa38014f-0993-46e9-9b45-30501a20909d\nTenant Creator\nCreate new Microsoft Entra or Azure AD B2C tenants.\n112ca1a2-15ad-4102-995e-45b0bc479a6a\nUsage Summary Reports Reader\nRead Usage reports and Adoption Score, but can't access user details.\n75934031-6c7e-415a-99d7-48dbd49e875e\nUser Administrator\nCan manage all aspects of users and groups, including resetting passwords for limited admins.\nfe930be7-5e62-47db-91af-98c3a49a38b1\nUser Experience Success Manager\nView product feedback, survey results, and reports to find training and communication opportunities.\n27460883-1df1-4691-b032-3b79643e5e63\nVirtual Visits Administrator\nManage and share Virtual Visits information and metrics from admin centers or the Virtual Visits app.\ne300d9e7-4a2b-4295-9eff-f1c78b36cc98\nViva Glint Tenant Administrator\nManage and configure Microsoft Viva Glint settings in the Microsoft 365 admin center.\n0ec3f692-38d6-4d14-9e69-0377ca7797ad\nViva Goals Administrator\nManage and configure all aspects of Microsoft Viva Goals.\n92b086b3-e367-4ef2-b869-1de128fb986e\nViva Pulse Administrator\nCan manage all settings for Microsoft Viva Pulse app.\n87761b17-1ed2-4af3-9acd-92a150038160\nWindows 365 Administrator\nCan provision and manage all aspects of Cloud PCs.\n11451d60-acb2-45eb-a7d6-43d0f0125c13\nWindows Update Deployment Administrator\nCan create and manage all aspects of Windows Update deployments through the Windows Update for Business deployment service.\n32696413-001a-46ae-978c-ce0f6b3620d2\nYammer Administrator\nManage all aspects of the Yammer service.\n810a2642-a034-447f-a5e8-41beaa378541\nAgent ID Administrator\nAssign the Agent ID Administrator role to users who need to do the following:\nManage all aspects of agents in a tenant including identity lifecycle operations for agent blueprints, agent service principals, agent identities, and agentic users.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/agentIdentities/appRoleAssignedTo/update\nUpdate agent identity role assignments.\nmicrosoft.directory/agentIdentities/basic/update\nUpdate basic properties of agent identities.\nmicrosoft.directory/agentIdentities/create\nCreate agent identities.\nmicrosoft.directory/agentIdentities/delete\nDelete agent identities.\nmicrosoft.directory/agentIdentities/disable\nDisable agent identities.\nmicrosoft.directory/agentIdentities/enable\nEnable agent identities.\nmicrosoft.directory/agentIdentities/owners/update\nAdd and remove owners to agent identities.\nmicrosoft.directory/agentIdentities/tag/update\nUpdate tags for agent identities.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/appRoleAssignedTo/update\nUpdate agent identity blueprint principal role assignments.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/basic/update\nUpdate basic properties of agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/create\nCreate agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/delete\nDelete agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/disable\nDisable agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/enable\nEnable agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/owners/update\nAdd and remove owners to agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/tag/update\nUpdate tags for agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprints/allProperties/read\nRead all properties and settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/allProperties/update\nUpdate all properties and settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/appRoles/update\nModify app roles defined on agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/authentication/update\nUpdate authentication related settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/audience/update\nUpdate the sign-in audience setting for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/basic/update\nUpdate basic properties of agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/create\nCreate agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/credentials/update\nAdd and remove credentials to agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/delete\nDelete agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/owners/update\nAdd and remove owners to agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/permissions/update\nModify exposed permissions on agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/tag/update\nUpdate tags for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/verification/update\nUpdate publisher verification setting for agent identity blueprints.\nmicrosoft.directory/agentUsers/assignLicense\nManage agent user licenses\nmicrosoft.directory/agentUsers/basic/update\nUpdate basic properties on agent users\nmicrosoft.directory/agentUsers/create\nAdd agent users\nmicrosoft.directory/agentUsers/delete\nDelete agent users\nmicrosoft.directory/agentUsers/disable\nDisable agent users\nmicrosoft.directory/agentUsers/enable\nEnable agent users\nmicrosoft.directory/agentUsers/invalidateAllRefreshTokens\nForce sign-out by invalidating agent user refresh tokens\nmicrosoft.directory/agentUsers/lifeCycleInfo/read\nRead lifecycle information of agent users, such as employeeLeaveDateTime\nmicrosoft.directory/agentUsers/lifeCycleInfo/update\nUpdate lifecycle information of agent users, such as employeeLeaveDateTime\nmicrosoft.directory/agentUsers/manager/update\nUpdate manager for agent users\nmicrosoft.directory/agentUsers/restore\nRestore deleted agent users\nmicrosoft.directory/agentUsers/revokeSignInSessions\nRevoke sign-in sessions for a agent user\nmicrosoft.directory/agentUsers/sponsors/update\nUpdate sponsors of agent users\nmicrosoft.directory/agentUsers/usageLocation/update\nUpdate usage location of agent users\nmicrosoft.directory/agentUsers/userPrincipalName/update\nUpdate User Principal Name of agent users\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs.\nmicrosoft.directory/deletedItems.agentIdentityBlueprints/delete\nPermanently delete agent identity blueprints, which can no longer be restored\nmicrosoft.directory/deletedItems.agentIdentityBlueprints/restore\nRestore soft deleted agent identity blueprints to original state\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups.unified/createAsOwner\nCreate Microsoft 365 groups, excluding role-assignable groups. Creator is added as the first owner.\nmicrosoft.directory/policies/standard/read\nRead basic properties on policies\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties.\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nAgent ID Developer\nAssign the Agent ID Developer role to users who need to do the following:\nCreate agent blueprints and their service principals. The user is added as an owner of the agent blueprint and its service principal.\nActions\nDescription\nmicrosoft.directory/servicePrincipals/standard/read\nRead basic properties of service principals\nAgent Registry Administrator\nAssign the Agent Registry Administrator role to users who need to do the following tasks:\nManage metadata for AI agents in Microsoft Entra ID\nManage collections and visibility of agents\nAssign Agent Registry-specific roles to other users or agents to access the registry\nActions\nDescription\nmicrosoft.agentRegistry/allEntities/allProperties/allTasks\nManage all aspects of Agent Registry in Microsoft Entra ID\nAI Administrator\nAssign the AI Administrator role to users who need to do the following tasks:\nManage all aspects of Microsoft 365 Copilot\nManage AI-related enterprise services, extensibility, and copilot agents from the Integrated apps page in the Microsoft 365 admin center\nApprove and publish line-of-business copilot agents\nRead and configure Azure and Microsoft 365 service health dashboards\nView usage reports, adoption insights, and organizational insight\nCreate and manage support tickets in Azure and the Microsoft 365 admin center\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/entitlementManagement/allProperties/read\nRead all properties in Microsoft Entra entitlement management\nmicrosoft.office365.copilot/allEntities/allProperties/allTasks\nCreate and manage all settings for Microsoft 365 Copilot\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.search/content/manage\nCreate and delete content, and read and update all properties in Microsoft Search\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nApplication Administrator\nThis is a\nprivileged role\n. Users in this role can create and manage all aspects of enterprise applications, application registrations, and application proxy settings. Note that users assigned to this role are not added as owners when creating new application registrations or enterprise applications.\nThis role also grants the ability to consent for delegated permissions and application permissions, with the exception of application permissions for Azure AD Graph and Microsoft Graph.\nImportant\nThis exception means that you can still consent to application permissions for\nother\napps (for example, other Microsoft apps, 3rd-party apps, or apps that you have registered). You can still\nrequest\nthese permissions as part of the app registration, but\ngranting\n(that is, consenting to) these permissions requires a more privileged administrator, such as Privileged Role Administrator.\nThis role grants the ability to manage application credentials. Users assigned this role can add credentials to an application, and use those credentials to impersonate the application's identity. If the application's identity has been granted access to a resource, such as the ability to create or update User or other objects, then a user assigned to this role could perform those actions while impersonating the application. This ability to impersonate the application's identity may be an elevation of privilege over what the user can do via their role assignments. It is important to understand that assigning a user to the Application Administrator role gives them the ability to impersonate an application's identity.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/adminConsentRequestPolicy/allProperties/allTasks\nManage admin consent request policies in Microsoft Entra ID\nmicrosoft.directory/appConsent/appConsentRequests/allProperties/read\nRead all properties of consent requests for applications registered with Microsoft Entra ID\nmicrosoft.directory/applicationPolicies/basic/update\nUpdate standard properties of application policies\nmicrosoft.directory/applicationPolicies/create\nCreate application policies\nmicrosoft.directory/applicationPolicies/delete\nDelete application policies\nmicrosoft.directory/applicationPolicies/owners/read\nRead owners on application policies\nmicrosoft.directory/applicationPolicies/owners/update\nUpdate the owner property of application policies\nmicrosoft.directory/applicationPolicies/policyAppliedTo/read\nRead application policies applied to objects list\nmicrosoft.directory/applicationPolicies/standard/read\nRead standard properties of application policies\nmicrosoft.directory/applications/applicationProxy/read\nRead all application proxy properties\nmicrosoft.directory/applications/applicationProxy/update\nUpdate all application proxy properties\nmicrosoft.directory/applications/applicationProxyAuthentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/applicationProxySslCertificate/update\nUpdate SSL certificate settings for application proxy\nmicrosoft.directory/applications/applicationProxyUrlSettings/update\nUpdate URL settings for application proxy\nmicrosoft.directory/applications/appRoles/update\nUpdate the appRoles property on all types of applications\nmicrosoft.directory/applications/audience/update\nUpdate the audience property for applications\nmicrosoft.directory/applications/authentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/basic/update\nUpdate basic properties for applications\nmicrosoft.directory/applications/create\nCreate all types of applications\nmicrosoft.directory/applications/credentials/update\nUpdate application credentials\nmicrosoft.directory/applications/delete\nDelete all types of applications\nmicrosoft.directory/applications/extensionProperties/update\nUpdate extension properties on applications\nmicrosoft.directory/applications/notes/update\nUpdate notes of applications\nmicrosoft.directory/applications/owners/update\nUpdate owners of applications\nmicrosoft.directory/applications/permissions/update\nUpdate exposed permissions and required permissions on all types of applications\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/applications/synchronization/standard/read\nRead provisioning settings associated with the application object\nmicrosoft.directory/applications/tag/update\nUpdate tags of applications\nmicrosoft.directory/applications/verification/update\nUpdate applicationsverification property\nmicrosoft.directory/applicationTemplates/instantiate\nInstantiate gallery applications from application templates\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/connectorGroups/allProperties/read\nRead all properties of application proxy connector groups\nmicrosoft.directory/connectorGroups/allProperties/update\nUpdate all properties of application proxy connector groups\nmicrosoft.directory/connectorGroups/create\nCreate application proxy connector groups\nmicrosoft.directory/connectorGroups/delete\nDelete application proxy connector groups\nmicrosoft.directory/connectors/allProperties/read\nRead all properties of application proxy connectors\nmicrosoft.directory/connectors/create\nCreate application proxy connectors\nmicrosoft.directory/customAuthenticationExtensions/allProperties/allTasks\nCreate and manage custom authentication extensions\nmicrosoft.directory/deletedItems.applications/delete\nPermanently delete applications, which can no longer be restored\nmicrosoft.directory/deletedItems.applications/restore\nRestore soft deleted applications to original state\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/servicePrincipals/audience/update\nUpdate audience properties on service principals\nmicrosoft.directory/servicePrincipals/authentication/update\nUpdate authentication properties on service principals\nmicrosoft.directory/servicePrincipals/basic/update\nUpdate basic properties on service principals\nmicrosoft.directory/servicePrincipals/create\nCreate service principals\nmicrosoft.directory/servicePrincipals/credentials/update\nUpdate credentials of service principals\nmicrosoft.directory/servicePrincipals/delete\nDelete service principals\nmicrosoft.directory/servicePrincipals/disable\nDisable service principals\nmicrosoft.directory/servicePrincipals/enable\nEnable service principals\nmicrosoft.directory/servicePrincipals/getPasswordSingleSignOnCredentials\nManage password single sign-on credentials on service principals\nmicrosoft.directory/servicePrincipals/managePasswordSingleSignOnCredentials\nRead password single sign-on credentials on service principals\nmicrosoft.directory/servicePrincipals/managePermissionGrantsForAll.microsoft-application-admin\nGrant consent for application permissions and delegated permissions on behalf of any user or all users, except for application permissions for Microsoft Graph and Azure AD Graph\nmicrosoft.directory/servicePrincipals/notes/update\nUpdate notes of service principals\nmicrosoft.directory/servicePrincipals/owners/update\nUpdate owners of service principals\nmicrosoft.directory/servicePrincipals/permissions/update\nUpdate permissions of service principals\nmicrosoft.directory/servicePrincipals/policies/update\nUpdate policies of service principals\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/credentials/manage\nManage application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/jobs/manage\nStart, restart, and pause application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/schema/manage\nCreate and manage application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization/standard/read\nRead provisioning settings associated with your service principal\nmicrosoft.directory/servicePrincipals/synchronizationCredentials/manage\nManage application provisioning secrets and credentials\nmicrosoft.directory/servicePrincipals/synchronizationJobs/manage\nStart, restart, and pause application provisioning synchronization jobs\nmicrosoft.directory/servicePrincipals/synchronizationSchema/manage\nCreate and manage application provisioning synchronization jobs and schema\nmicrosoft.directory/servicePrincipals/tag/update\nUpdate the tag property for service principals\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nApplication Developer\nThis is a\nprivileged role\n. Users in this role can create application registrations when the \"Users can register applications\" setting is set to No. This role also grants permission to consent on one's own behalf when the \"Users can consent to apps accessing company data on their behalf\" setting is set to No. Users assigned to this role are added as owners when creating new application registrations.\nActions\nDescription\nmicrosoft.directory/applications/createAsOwner\nCreate all types of applications, and creator is added as the first owner\nmicrosoft.directory/oAuth2PermissionGrants/createAsOwner\nCreate OAuth 2.0 permission grants, with creator as the first owner\nmicrosoft.directory/servicePrincipals/createAsOwner\nCreate service principals, with creator as the first owner\nAttack Payload Author\nUsers in this role can create attack payloads but not actually launch or schedule them. Attack payloads are then available to all administrators in the tenant who can use them to create a simulation. Access to reports is limited to simulations executed by the user, and this role doesn't grant access to aggregate reports such as Training efficacy, Repeat offenders, Training completion, or User coverage.\nFor more information, see these articles:\nGet started using Attack simulation training\nMicrosoft Defender for Office 365 permissions in the Microsoft Defender portal\nPermissions in the Microsoft Purview portal\nActions\nDescription\nmicrosoft.office365.protectionCenter/attackSimulator/payload/allProperties/allTasks\nCreate and manage attack payloads in Attack Simulator\nmicrosoft.office365.protectionCenter/attackSimulator/reports/allProperties/read\nRead reports of attack simulation, responses, and associated training\nAttack Simulation Administrator\nUsers in this role can create and manage all aspects of attack simulation creation, launch/scheduling of a simulation, and the review of simulation results. Members of this role have this access for all simulations in the tenant.\nFor more information, see these articles:\nMicrosoft Defender for Office 365 permissions in the Microsoft Defender portal\nPermissions in the Microsoft Purview compliance portal\nActions\nDescription\nmicrosoft.office365.protectionCenter/attackSimulator/payload/allProperties/allTasks\nCreate and manage attack payloads in Attack Simulator\nmicrosoft.office365.protectionCenter/attackSimulator/reports/allProperties/read\nRead reports of attack simulation, responses, and associated training\nmicrosoft.office365.protectionCenter/attackSimulator/simulation/allProperties/allTasks\nCreate and manage attack simulation templates in Attack Simulator\nAttribute Assignment Administrator\nUsers with this role can assign and remove custom security attribute keys and values for supported Microsoft Entra objects such as users, service principals, and devices.\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.directory/attributeSets/allProperties/read\nRead all properties of attribute sets\nmicrosoft.directory/azureManagedIdentities/customSecurityAttributes/read\nRead custom security attribute values for Microsoft Entra managed identities\nmicrosoft.directory/azureManagedIdentities/customSecurityAttributes/update\nUpdate custom security attribute values for Microsoft Entra managed identities\nmicrosoft.directory/customSecurityAttributeDefinitions/allProperties/read\nRead all properties of custom security attribute definitions\nmicrosoft.directory/devices/customSecurityAttributes/read\nRead custom security attribute values for devices\nmicrosoft.directory/devices/customSecurityAttributes/update\nUpdate custom security attribute values for devices\nmicrosoft.directory/servicePrincipals/customSecurityAttributes/read\nRead custom security attribute values for service principals\nmicrosoft.directory/servicePrincipals/customSecurityAttributes/update\nUpdate custom security attribute values for service principals\nmicrosoft.directory/users/customSecurityAttributes/read\nRead custom security attribute values for users\nmicrosoft.directory/users/customSecurityAttributes/update\nUpdate custom security attribute values for users\nAttribute Assignment Reader\nUsers with this role can read custom security attribute keys and values for supported Microsoft Entra objects.\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.directory/attributeSets/allProperties/read\nRead all properties of attribute sets\nmicrosoft.directory/azureManagedIdentities/customSecurityAttributes/read\nRead custom security attribute values for Microsoft Entra managed identities\nmicrosoft.directory/customSecurityAttributeDefinitions/allProperties/read\nRead all properties of custom security attribute definitions\nmicrosoft.directory/devices/customSecurityAttributes/read\nRead custom security attribute values for devices\nmicrosoft.directory/servicePrincipals/customSecurityAttributes/read\nRead custom security attribute values for service principals\nmicrosoft.directory/users/customSecurityAttributes/read\nRead custom security attribute values for users\nAttribute Definition Administrator\nUsers with this role can define a valid set of custom security attributes that can be assigned to supported Microsoft Entra objects. This role can also activate and deactivate custom security attributes.\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.directory/attributeSets/allProperties/allTasks\nManage all aspects of attribute sets\nmicrosoft.directory/customSecurityAttributeDefinitions/allProperties/allTasks\nManage all aspects of custom security attribute definitions\nAttribute Definition Reader\nUsers with this role can read the definition of custom security attributes.\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.directory/attributeSets/allProperties/read\nRead all properties of attribute sets\nmicrosoft.directory/customSecurityAttributeDefinitions/allProperties/read\nRead all properties of custom security attribute definitions\nAttribute Log Administrator\nAssign the Attribute Log Reader role to users who need to do the following tasks:\nRead audit logs for custom security attribute value changes\nRead audit logs for custom security attribute definition changes and assignments\nConfigure diagnostic settings for custom security attributes\nUsers with this role\ncannot\nread audit logs for other events.\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.azure.customSecurityAttributeDiagnosticSettings/allEntities/allProperties/allTasks\nConfigure all aspects of custom security attributes diagnostic settings\nmicrosoft.directory/customSecurityAttributeAuditLogs/allProperties/read\nRead audit logs related to custom secruity attributes\nAttribute Log Reader\nAssign the Attribute Log Reader role to users who need to do the following tasks:\nRead audit logs for custom security attribute value changes\nRead audit logs for custom security attribute definition changes and assignments\nUsers with this role\ncannot\ndo the following tasks:\nConfigure diagnostic settings for custom security attributes\nRead audit logs for other events\nImportant\nBy default,\nGlobal Administrator\nand other administrator roles do not have permissions to read, define, or assign custom security attributes.\nFor more information, see\nManage access to custom security attributes in Microsoft Entra ID\n.\nActions\nDescription\nmicrosoft.directory/customSecurityAttributeAuditLogs/allProperties/read\nRead audit logs related to custom secruity attributes\nAttribute Provisioning Administrator\nThis is a\nprivileged role\n. Assign the Attribute Provisioning Administrator role to users who need to do the following tasks:\nRead and write attribute mappings for custom security attributes when provisioning in an application.\nRead and write provisioning and auditing logs for custom security attributes when provisioning in an application.\nUsers with this role cannot read audit logs for other events. This role must be used in conjunction with the Cloud Application Administrator or Application Administrator roles (from least to most privileged) to read provisioning configurations.\nImportant\nThis role does not have the ability to create custom security attribute sets or to directly assign or update custom security attribute values for the user object. This role can only configure the flow of the custom security attributes in the provisioning app.\nLearn more\nActions\nDescription\nmicrosoft.directory/servicePrincipals/synchronization.customSecurityAttributes/schema/read\nRead all custom security attributes in the synchronization schema\nmicrosoft.directory/servicePrincipals/synchronization.customSecurityAttributes/schema/update\nUpdate custom security attribute mappings in the synchronization schema\nAttribute Provisioning Reader\nThis is a\nprivileged role\n. Assign the Attribute Provisioning Reader role to users who need to do the following tasks:\nRead the attribute mappings for custom security attributes when provisioning in an application.\nRead the provisioning and auditing logs for custom security attributes when provisioning in an application.\nUsers with this role can't read audit logs for other events. This role must be used with the Cloud Application Administrator or Application Administrator roles (from least to most privileged) to read provisioning configurations.\nLearn more\nActions\nDescription\nmicrosoft.directory/servicePrincipals/synchronization.customSecurityAttributes/schema/read\nRead all custom security attributes in the synchronization schema\nAuthentication Administrator\nThis is a\nprivileged role\n. Assign the Authentication Administrator role to users who need to do the following:\nSet or reset any authentication method (including passwords) for nonadministrators and some roles. For a list of the roles that an Authentication Administrator can read or update authentication methods, see\nWho can reset passwords\n.\nRequire users who are nonadministrators or assigned to some roles to re-register against existing nonpassword credentials (for example, MFA or FIDO), and can also revoke\nremember MFA on the device\n, which prompts for MFA on the next sign-in.\nManage MFA settings in the legacy MFA management portal.\nPerform sensitive actions for some users. For more information, see\nWho can perform sensitive actions\n.\nCreate and manage support tickets in Azure and the Microsoft 365 admin center.\nUsers with this role\ncannot\ndo the following:\nCannot change the credentials or reset MFA for members and owners of a\nrole-assignable group\n.\nCannot manage Hardware OATH tokens.\nThe following table compares the capabilities of authentication-related roles.\nRole\nManage user's auth methods\nManage per-user MFA\nManage MFA settings\nManage auth method policy\nManage password protection policy\nUpdate sensitive properties\nDelete and restore users\nAuthentication Administrator\nYes for\nsome users\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nPrivileged Authentication Administrator\nYes for all users\nNo\nNo\nNo\nNo\nYes for all users\nYes for all users\nAuthentication Policy Administrator\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nUser Administrator\nNo\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nImportant\nUsers with this role can change credentials for people who may have access to sensitive or private information or critical configuration inside and outside of Microsoft Entra ID. Changing the credentials of a user may mean the ability to assume that user's identity and permissions. For example:\nApplication Registration and Enterprise Application owners, who can manage credentials of apps they own. Those apps may have privileged permissions in Microsoft Entra ID and elsewhere not granted to Authentication Administrators. Through this path, an Authentication Administrator can assume the identity of an application owner and then further assume the identity of a privileged application by updating the credentials for the application.\nAzure subscription owners, who may have access to sensitive or private information or critical configuration in Azure.\nSecurity Group and Microsoft 365 group owners, who can manage group membership. Those groups may grant access to sensitive or private information or critical configuration in Microsoft Entra ID and elsewhere.\nAdministrators in other services outside of Microsoft Entra ID like Exchange Online, Microsoft Defender XDR portal, Microsoft Purview portal, and human resources systems.\nNonadministrators like executives, legal counsel, and human resources employees who may have access to sensitive or private information.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/deletedItems.users/restore\nRestore soft deleted users to original state\nmicrosoft.directory/users/authenticationMethods/basic/update\nUpdate basic properties of authentication methods for users\nmicrosoft.directory/users/authenticationMethods/create\nUpdate authentication methods for users\nmicrosoft.directory/users/authenticationMethods/delete\nDelete authentication methods for users\nmicrosoft.directory/users/authenticationMethods/standard/restrictedRead\nRead standard properties of authentication methods that do not include personally identifiable information for users\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/delete\nDelete users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.directory/users/restore\nRestore deleted users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nAuthentication Extensibility Administrator\nThis is a\nprivileged role\n. Assign the Authentication Extensibility Administrator role to users who need to do the following tasks:\nCreate and manage all aspects of custom authentication extensions.\nUsers with this role\ncan't\ndo the following:\nCan't assign custom authentication extensions to applications to modify the authentication experiences, and can't consent to application permissions or create app registrations associated with the custom authentication extension. Instead, you must use the Application Administrator, Application Developer, or Cloud Application Administrator roles.\nA custom authentication extension is an API endpoint created by a developer for authentication events and is registered in Microsoft Entra ID. Application administrators and application owners can use custom authentication extensions to customize their application's authentication experiences, such as sign in and sign up, or password reset.\nLearn more\nActions\nDescription\nmicrosoft.directory/customAuthenticationExtensions/allProperties/allTasks\nCreate and manage custom authentication extensions\nAuthentication Policy Administrator\nAssign the Authentication Policy Administrator role to users who need to do the following:\nConfigure the authentication methods policy, tenant-wide MFA settings, and password protection policy that determine which methods each user can register and use.\nManage Password Protection settings: smart lockout configurations and updating the custom banned passwords list.\nManage MFA settings in the legacy MFA management portal.\nCreate and manage verifiable credentials.\nCreate and manage Azure support tickets.\nUsers with this role\ncannot\ndo the following:\nCannot update sensitive properties. For more information, see\nWho can perform sensitive actions\n.\nCannot delete or restore users. For more information, see\nWho can perform sensitive actions\n.\nCannot manage Hardware OATH tokens.\nThe following table compares the capabilities of authentication-related roles.\nRole\nManage user's auth methods\nManage per-user MFA\nManage MFA settings\nManage auth method policy\nManage password protection policy\nUpdate sensitive properties\nDelete and restore users\nAuthentication Administrator\nYes for\nsome users\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nPrivileged Authentication Administrator\nYes for all users\nNo\nNo\nNo\nNo\nYes for all users\nYes for all users\nAuthentication Policy Administrator\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nUser Administrator\nNo\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nActions\nDescription\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/organization/strongAuthentication/allTasks\nManage all aspects of strong authentication properties of an organization\nmicrosoft.directory/userCredentialPolicies/basic/update\nUpdate basic policies for users\nmicrosoft.directory/userCredentialPolicies/create\nCreate credential policies for users\nmicrosoft.directory/userCredentialPolicies/delete\nDelete credential policies for users\nmicrosoft.directory/userCredentialPolicies/owners/read\nRead owners of credential policies for users\nmicrosoft.directory/userCredentialPolicies/owners/update\nUpdate owners of credential policies for users\nmicrosoft.directory/userCredentialPolicies/policyAppliedTo/read\nRead policy.appliesTo navigation link\nmicrosoft.directory/userCredentialPolicies/standard/read\nRead standard properties of credential policies for users\nmicrosoft.directory/userCredentialPolicies/tenantDefault/update\nUpdate policy.isOrganizationDefault property\nmicrosoft.directory/verifiableCredentials/configuration/allProperties/read\nRead configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/allProperties/update\nUpdate configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/contracts/allProperties/read\nRead a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/contracts/allProperties/update\nUpdate a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/contracts/cards/allProperties/read\nRead a verifiable credential card\nmicrosoft.directory/verifiableCredentials/configuration/contracts/cards/revoke\nRevoke a verifiable credential card\nmicrosoft.directory/verifiableCredentials/configuration/contracts/create\nCreate a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/create\nCreate configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/delete\nDelete configuration required to create and manage verifiable credentials and delete all of its verifiable credentials\nAzure DevOps Administrator\nUsers with this role can manage all enterprise Azure DevOps policies, applicable to all Azure DevOps organizations backed by Microsoft Entra ID. Users in this role can manage these policies by navigating to any Azure DevOps organization that is backed by the company's Microsoft Entra ID. Additionally, users in this role can claim ownership of orphaned Azure DevOps organizations. This role grants no other Azure DevOps-specific permissions (for example, Project Collection Administrators) inside any of the Azure DevOps organizations backed by the company's Microsoft Entra organization.\nActions\nDescription\nmicrosoft.azure.devOps/allEntities/allTasks\nRead and configure Azure DevOps\nAzure Information Protection Administrator\nUsers with this role have all permissions in the Azure Information Protection service. This role allows configuring labels for the Azure Information Protection policy, managing protection templates, and activating protection. This role doesn't grant any permissions in Microsoft Entra ID Protection, Privileged Identity Management, Monitor Microsoft 365 Service Health, Microsoft Defender XDR portal, or Microsoft Purview portal.\nActions\nDescription\nmicrosoft.azure.informationProtection/allEntities/allTasks\nManage all aspects of Azure Information Protection\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nB2C IEF Keyset Administrator\nThis is a\nprivileged role\n. Users assigned to this role can create and manage policy keys and secrets used for token encryption, token signing, and claim encryption/decryption. They can add new keys to existing key containers, enabling secret rollover without affecting existing applications. Additionally, users in this role can view the complete details of these secrets, including their expiration dates, even after creation.\nImportant\nThis is a sensitive role. The keyset administrator role should be carefully audited and assigned with care during preproduction and production.\nActions\nDescription\nmicrosoft.directory/b2cTrustFrameworkKeySet/allProperties/allTasks\nRead and configure key sets in Azure Active Directory B2C\nB2C IEF Policy Administrator\nUsers in this role have the ability to create, read, update, and delete all custom policies in Azure AD B2C and therefore have full control over the Identity Experience Framework in the relevant Azure AD B2C organization. By editing policies, this user can establish direct federation with external identity providers, change the directory schema, change all user-facing content (HTML, CSS, JavaScript), change the requirements to complete an authentication, create new users, send user data to external systems including full migrations, and edit all user information including sensitive fields like passwords and phone numbers. Conversely, this role cannot change the encryption keys or edit the secrets used for federation in the organization.\nImportant\nThe B2 IEF Policy Administrator is a highly sensitive role that should be assigned on a very limited basis for organizations in production. Activities by these users should be closely audited, especially for organizations in production.\nActions\nDescription\nmicrosoft.directory/b2cTrustFrameworkPolicy/allProperties/allTasks\nRead and configure custom policies in Azure Active Directory B2C\nBilling Administrator\nMakes purchases, manages subscriptions, manages support tickets, and monitors service health.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.commerce.billing/allEntities/allProperties/allTasks\nManage all aspects of Office 365 billing\nmicrosoft.directory/organization/basic/update\nUpdate basic properties on organization\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nCloud App Security Administrator\nUsers with this role have full permissions in Defender for Cloud Apps. They can add administrators, add Microsoft Defender for Cloud Apps policies and settings, upload logs, and perform governance actions.\nActions\nDescription\nmicrosoft.directory/cloudAppSecurity/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Defender for Cloud Apps\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nCloud Application Administrator\nThis is a\nprivileged role\n. Users in this role have the same permissions as the Application Administrator role, excluding the ability to manage application proxy. This role grants the ability to create and manage all aspects of enterprise applications and application registrations. Users assigned to this role are not added as owners when creating new application registrations or enterprise applications.\nThis role also grants the ability to consent for delegated permissions and application permissions, with the exception of application permissions for Azure AD Graph and Microsoft Graph.\nImportant\nThis exception means that you can still consent to application permissions for\nother\napps (for example, other Microsoft apps, 3rd-party apps, or apps that you have registered). You can still\nrequest\nthese permissions as part of the app registration, but\ngranting\n(that is, consenting to) these permissions requires a more privileged administrator, such as Privileged Role Administrator.\nThis role grants the ability to manage application credentials. Users assigned this role can add credentials to an application, and use those credentials to impersonate the application's identity. If the application's identity has been granted access to a resource, such as the ability to create or update User or other objects, then a user assigned to this role could perform those actions while impersonating the application. This ability to impersonate the application's identity may be an elevation of privilege over what the user can do via their role assignments. It is important to understand that assigning a user to the Application Administrator role gives them the ability to impersonate an application's identity.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/adminConsentRequestPolicy/allProperties/allTasks\nManage admin consent request policies in Microsoft Entra ID\nmicrosoft.directory/appConsent/appConsentRequests/allProperties/read\nRead all properties of consent requests for applications registered with Microsoft Entra ID\nmicrosoft.directory/applicationPolicies/basic/update\nUpdate standard properties of application policies\nmicrosoft.directory/applicationPolicies/create\nCreate application policies\nmicrosoft.directory/applicationPolicies/delete\nDelete application policies\nmicrosoft.directory/applicationPolicies/owners/read\nRead owners on application policies\nmicrosoft.directory/applicationPolicies/owners/update\nUpdate the owner property of application policies\nmicrosoft.directory/applicationPolicies/policyAppliedTo/read\nRead application policies applied to objects list\nmicrosoft.directory/applicationPolicies/standard/read\nRead standard properties of application policies\nmicrosoft.directory/applications/appRoles/update\nUpdate the appRoles property on all types of applications\nmicrosoft.directory/applications/audience/update\nUpdate the audience property for applications\nmicrosoft.directory/applications/authentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/basic/update\nUpdate basic properties for applications\nmicrosoft.directory/applications/create\nCreate all types of applications\nmicrosoft.directory/applications/credentials/update\nUpdate application credentials\nmicrosoft.directory/applications/delete\nDelete all types of applications\nmicrosoft.directory/applications/extensionProperties/update\nUpdate extension properties on applications\nmicrosoft.directory/applications/notes/update\nUpdate notes of applications\nmicrosoft.directory/applications/owners/update\nUpdate owners of applications\nmicrosoft.directory/applications/permissions/update\nUpdate exposed permissions and required permissions on all types of applications\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/applications/synchronization/standard/read\nRead provisioning settings associated with the application object\nmicrosoft.directory/applications/tag/update\nUpdate tags of applications\nmicrosoft.directory/applications/verification/update\nUpdate applicationsverification property\nmicrosoft.directory/applicationTemplates/instantiate\nInstantiate gallery applications from application templates\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/deletedItems.applications/delete\nPermanently delete applications, which can no longer be restored\nmicrosoft.directory/deletedItems.applications/restore\nRestore soft deleted applications to original state\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/servicePrincipals/audience/update\nUpdate audience properties on service principals\nmicrosoft.directory/servicePrincipals/authentication/update\nUpdate authentication properties on service principals\nmicrosoft.directory/servicePrincipals/basic/update\nUpdate basic properties on service principals\nmicrosoft.directory/servicePrincipals/create\nCreate service principals\nmicrosoft.directory/servicePrincipals/credentials/update\nUpdate credentials of service principals\nmicrosoft.directory/servicePrincipals/delete\nDelete service principals\nmicrosoft.directory/servicePrincipals/disable\nDisable service principals\nmicrosoft.directory/servicePrincipals/enable\nEnable service principals\nmicrosoft.directory/servicePrincipals/getPasswordSingleSignOnCredentials\nManage password single sign-on credentials on service principals\nmicrosoft.directory/servicePrincipals/managePasswordSingleSignOnCredentials\nRead password single sign-on credentials on service principals\nmicrosoft.directory/servicePrincipals/managePermissionGrantsForAll.microsoft-application-admin\nGrant consent for application permissions and delegated permissions on behalf of any user or all users, except for application permissions for Microsoft Graph and Azure AD Graph\nmicrosoft.directory/servicePrincipals/notes/update\nUpdate notes of service principals\nmicrosoft.directory/servicePrincipals/owners/update\nUpdate owners of service principals\nmicrosoft.directory/servicePrincipals/permissions/update\nUpdate permissions of service principals\nmicrosoft.directory/servicePrincipals/policies/update\nUpdate policies of service principals\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/credentials/manage\nManage application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/jobs/manage\nStart, restart, and pause application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/schema/manage\nCreate and manage application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization/standard/read\nRead provisioning settings associated with your service principal\nmicrosoft.directory/servicePrincipals/synchronizationCredentials/manage\nManage application provisioning secrets and credentials\nmicrosoft.directory/servicePrincipals/synchronizationJobs/manage\nStart, restart, and pause application provisioning synchronization jobs\nmicrosoft.directory/servicePrincipals/synchronizationSchema/manage\nCreate and manage application provisioning synchronization jobs and schema\nmicrosoft.directory/servicePrincipals/tag/update\nUpdate the tag property for service principals\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nCloud Device Administrator\nThis is a\nprivileged role\n. Users in this role can enable, disable, and delete devices in Microsoft Entra ID and read Windows 10 BitLocker keys (if present) in the Azure portal. The role does not grant permissions to manage any other properties on the device.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/deletedItems.devices/delete\nPermanently delete devices, which can no longer be restored\nmicrosoft.directory/deletedItems.devices/restore\nRestore soft deleted devices to original state\nmicrosoft.directory/deviceLocalCredentials/password/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, including the password\nmicrosoft.directory/deviceManagementPolicies/basic/update\nUpdate basic properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/basic/update\nUpdate basic properties on device registration policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/delete\nDelete devices from Microsoft Entra ID\nmicrosoft.directory/devices/disable\nDisable devices in Microsoft Entra ID\nmicrosoft.directory/devices/enable\nEnable devices in Microsoft Entra ID\nmicrosoft.directory/devices/permissions/update\nUpdate the alternative name property on an IoT device\nmicrosoft.directory/deviceTemplates/owners/read\nRead owners on Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/owners/update\nUpdate owners on Internet of Things (IoT) device templates\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nCompliance Administrator\nUsers with this role have permissions to manage compliance-related features in the Microsoft Purview compliance portal, Microsoft 365 admin center, Azure, and Microsoft 365 Defender portal. Assignees can also manage all features within the Exchange admin center and create support tickets for Azure and Microsoft 365. For more information, see\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\n.\nIn\nCan do\nMicrosoft Purview compliance portal\nProtect and manage your organization's data across Microsoft 365 services\nManage compliance alerts\nMicrosoft Purview Compliance Manager\nTrack, assign, and verify your organization's regulatory compliance activities\nMicrosoft 365 Defender portal\nManage data governance\nPerform legal and data investigation\nManage Data Subject Request\nThis role has the same permissions as the\nCompliance Administrator role group\nin Microsoft 365 Defender portal role-based access control.\nIntune\nView all Intune audit data\nMicrosoft Defender for Cloud Apps\nHas read-only permissions and can manage alerts\nCan create and modify file policies and allow file governance actions\nCan view all the built-in reports under Data Management\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/entitlementManagement/allProperties/read\nRead all properties in Microsoft Entra entitlement management\nmicrosoft.office365.complianceManager/allEntities/allTasks\nManage all aspects of Office 365 Compliance Manager\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nCompliance Data Administrator\nUsers with this role have permissions to track data in the Microsoft Purview compliance portal, Microsoft 365 admin center, and Azure. Users can also track compliance data within the Exchange admin center, Compliance Manager, and Teams & Skype for Business admin center and create support tickets for Azure and Microsoft 365. For more information about the differences between Compliance Administrator and Compliance Data Administrator, see\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\n.\nIn\nCan do\nMicrosoft Purview compliance portal\nMonitor compliance-related policies across Microsoft 365 services\nManage compliance alerts\nMicrosoft Purview Compliance Manager\nTrack, assign, and verify your organization's regulatory compliance activities\nMicrosoft 365 Defender portal\nManage data governance\nPerform legal and data investigation\nManage Data Subject Request\nThis role has the same permissions as the\nCompliance Data Administrator role group\nin Microsoft 365 Defender portal role-based access control.\nIntune\nView all Intune audit data\nMicrosoft Defender for Cloud Apps\nHas read-only permissions and can manage alerts\nCan create and modify file policies and allow file governance actions\nCan view all the built-in reports under Data Management\nActions\nDescription\nmicrosoft.azure.informationProtection/allEntities/allTasks\nManage all aspects of Azure Information Protection\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/cloudAppSecurity/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Defender for Cloud Apps\nmicrosoft.office365.complianceManager/allEntities/allTasks\nManage all aspects of Office 365 Compliance Manager\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nConditional Access Administrator\nThis is a\nprivileged role\n. Users with this role have the ability to manage Microsoft Entra Conditional Access settings.\nActions\nDescription\nmicrosoft.directory/conditionalAccessPolicies/basic/update\nUpdate basic properties for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/create\nCreate Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/delete\nDelete Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/owners/read\nRead the owners of Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/owners/update\nUpdate owners for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/policyAppliedTo/read\nRead the \"applied to\" property for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/standard/read\nRead Conditional Access for policies\nmicrosoft.directory/conditionalAccessPolicies/tenantDefault/update\nUpdate the default tenant for Conditional Access policies\nmicrosoft.directory/namedLocations/basic/update\nUpdate basic properties of custom rules that define network locations\nmicrosoft.directory/namedLocations/create\nCreate custom rules that define network locations\nmicrosoft.directory/namedLocations/delete\nDelete custom rules that define network locations\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/resourceNamespaces/resourceActions/authenticationContext/update\nUpdate Conditional Access authentication context of Microsoft 365 role-based access control (RBAC) resource actions\nCustomer LockBox Access Approver\nManages\nMicrosoft Purview Customer Lockbox requests\nin your organization. They receive email notifications for Customer Lockbox requests and can approve and deny requests from the Microsoft 365 admin center. They can also turn the Customer Lockbox feature on or off. Only Global Administrators can reset the passwords of people assigned to this role.\nActions\nDescription\nmicrosoft.office365.lockbox/allEntities/allTasks\nManage all aspects of Customer Lockbox\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nDesktop Analytics Administrator\nUsers in this role can manage the Desktop Analytics service. This includes the ability to view asset inventory, create deployment plans, and view deployment and health status.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.desktopAnalytics/allEntities/allTasks\nManage all aspects of Desktop Analytics\nDirectory Readers\nUsers in this role can read basic directory information. This role should be used for:\nGranting a specific set of guest users read access instead of granting it to all guest users.\nGranting a specific set of non-admin users access to Microsoft Entra admin center when \"Restrict access to Microsoft Entra admin center\" is set to \"Yes\".\nGranting service principals access to directory where Directory.Read.All is not an option.\nActions\nDescription\nmicrosoft.directory/administrativeUnits/members/read\nRead members of administrative units\nmicrosoft.directory/administrativeUnits/standard/read\nRead basic properties on administrative units\nmicrosoft.directory/applicationPolicies/standard/read\nRead standard properties of application policies\nmicrosoft.directory/applications/owners/read\nRead owners of applications\nmicrosoft.directory/applications/policies/read\nRead policies of applications\nmicrosoft.directory/applications/standard/read\nRead standard properties of applications\nmicrosoft.directory/contacts/memberOf/read\nRead the group membership for all contacts in Microsoft Entra ID\nmicrosoft.directory/contacts/standard/read\nRead basic properties on contacts in Microsoft Entra ID\nmicrosoft.directory/contracts/standard/read\nRead basic properties on partner contracts\nmicrosoft.directory/devices/memberOf/read\nRead device memberships\nmicrosoft.directory/devices/registeredOwners/read\nRead registered owners of devices\nmicrosoft.directory/devices/registeredUsers/read\nRead registered users of devices\nmicrosoft.directory/devices/standard/read\nRead basic properties on devices\nmicrosoft.directory/directoryRoles/eligibleMembers/read\nRead the eligible members of Microsoft Entra roles\nmicrosoft.directory/directoryRoles/members/read\nRead all members of Microsoft Entra roles\nmicrosoft.directory/directoryRoles/standard/read\nRead basic properties of Microsoft Entra roles\nmicrosoft.directory/domains/standard/read\nRead basic properties on domains\nmicrosoft.directory/groups/appRoleAssignments/read\nRead application role assignments of groups\nmicrosoft.directory/groups/memberOf/read\nRead the memberOf property on Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/members/read\nRead members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/owners/read\nRead owners of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/settings/read\nRead settings of groups\nmicrosoft.directory/groups/standard/read\nRead standard properties of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groupSettings/standard/read\nRead basic properties on group settings\nmicrosoft.directory/groupSettingTemplates/standard/read\nRead basic properties on group setting templates\nmicrosoft.directory/oAuth2PermissionGrants/standard/read\nRead basic properties on OAuth 2.0 permission grants\nmicrosoft.directory/organization/standard/read\nRead basic properties on an organization\nmicrosoft.directory/organization/trustedCAsForPasswordlessAuth/read\nRead trusted certificate authorities for passwordless authentication\nmicrosoft.directory/roleAssignments/standard/read\nRead basic properties on role assignments\nmicrosoft.directory/roleDefinitions/standard/read\nRead basic properties on role definitions\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/read\nRead service principal role assignments\nmicrosoft.directory/servicePrincipals/appRoleAssignments/read\nRead role assignments assigned to service principals\nmicrosoft.directory/servicePrincipals/memberOf/read\nRead the group memberships on service principals\nmicrosoft.directory/servicePrincipals/oAuth2PermissionGrants/read\nRead delegated permission grants on service principals\nmicrosoft.directory/servicePrincipals/ownedObjects/read\nRead owned objects of service principals\nmicrosoft.directory/servicePrincipals/owners/read\nRead owners of service principals\nmicrosoft.directory/servicePrincipals/policies/read\nRead policies of service principals\nmicrosoft.directory/servicePrincipals/standard/read\nRead basic properties of service principals\nmicrosoft.directory/subscribedSkus/standard/read\nRead basic properties on subscriptions\nmicrosoft.directory/users/appRoleAssignments/read\nRead application role assignments for users\nmicrosoft.directory/users/deviceForResourceAccount/read\nRead deviceForResourceAccount of users\nmicrosoft.directory/users/directReports/read\nRead the direct reports for users\nmicrosoft.directory/users/invitedBy/read\nRead the user that invited an external user to a tenant\nmicrosoft.directory/users/licenseDetails/read\nRead license details of users\nmicrosoft.directory/users/manager/read\nRead manager of users\nmicrosoft.directory/users/memberOf/read\nRead the group memberships of users\nmicrosoft.directory/users/oAuth2PermissionGrants/read\nRead delegated permission grants on users\nmicrosoft.directory/users/ownedDevices/read\nRead owned devices of users\nmicrosoft.directory/users/ownedObjects/read\nRead owned objects of users\nmicrosoft.directory/users/photo/read\nRead photo of users\nmicrosoft.directory/users/registeredDevices/read\nRead registered devices of users\nmicrosoft.directory/users/scopedRoleMemberOf/read\nRead user's membership of a Microsoft Entra role, that is scoped to an administrative unit\nmicrosoft.directory/users/sponsors/read\nRead sponsors of users\nmicrosoft.directory/users/standard/read\nRead basic properties on users\nDirectory Synchronization Accounts\nDo not use. This role is automatically assigned to the Microsoft Entra Connect service, and is not intended or supported for any other use.\nActions\nDescription\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nDirectory Writers\nThis is a\nprivileged role\n. Users in this role can read and update basic information of users, groups, and service principals.\nActions\nDescription\nmicrosoft.directory/applications/extensionProperties/update\nUpdate extension properties on applications\nmicrosoft.directory/contacts/create\nCreate contacts\nmicrosoft.directory/groups/assignedLabels/update\nUpdate the assigned labels property on groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups/assignLicense\nAssign product licenses to groups for group-based licensing\nmicrosoft.directory/groups/basic/update\nUpdate basic properties on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/classification/update\nUpdate the classification property on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/create\nCreate Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/dynamicMembershipRule/update\nUpdate the dynamic membership rule on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/groupType/update\nUpdate properties that would affect the group type of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/onPremWriteBack/update\nUpdate Microsoft Entra groups to be written back to on-premises with Microsoft Entra Connect\nmicrosoft.directory/groups/owners/update\nUpdate owners of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/reprocessLicenseAssignment\nReprocess license assignments for group-based licensing\nmicrosoft.directory/groups/settings/update\nUpdate settings of groups\nmicrosoft.directory/groups/visibility/update\nUpdate the visibility property of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groupSettings/basic/update\nUpdate basic properties on group settings\nmicrosoft.directory/groupSettings/create\nCreate group settings\nmicrosoft.directory/groupSettings/delete\nDelete group settings\nmicrosoft.directory/oAuth2PermissionGrants/basic/update\nUpdate OAuth 2.0 permission grants\nmicrosoft.directory/oAuth2PermissionGrants/create\nCreate OAuth 2.0 permission grants\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/credentials/manage\nManage cloud tenant to cloud tenant application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/jobs/manage\nStart, restart, and pause cloud tenant to cloud tenant application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/schema/manage\nCreate and manage cloud tenant to cloud tenant application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/credentials/manage\nManage application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/jobs/manage\nStart, restart, and pause application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/schema/manage\nCreate and manage application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronizationCredentials/manage\nManage application provisioning secrets and credentials\nmicrosoft.directory/servicePrincipals/synchronizationJobs/manage\nStart, restart, and pause application provisioning synchronization jobs\nmicrosoft.directory/servicePrincipals/synchronizationSchema/manage\nCreate and manage application provisioning synchronization jobs and schema\nmicrosoft.directory/users/assignLicense\nManage user licenses\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/create\nAdd users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/inviteGuest\nInvite guest users\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/photo/update\nUpdate photo of users\nmicrosoft.directory/users/reprocessLicenseAssignment\nReprocess license assignments for users\nmicrosoft.directory/users/sponsors/update\nUpdate sponsors of users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nDomain Name Administrator\nThis is a\nprivileged role\n. Users with this role can manage (read, add, verify, update, and delete) domain names. They can also read directory information about users, groups, and applications, as these objects possess domain dependencies. For on-premises environments, users with this role can configure domain names for federation so that associated users are always authenticated on-premises. These users can then sign into Microsoft Entra based services with their on-premises passwords via single sign-on. Federation settings need to be synced via Microsoft Entra Connect, so users also have permissions to manage Microsoft Entra Connect.\nActions\nDescription\nmicrosoft.directory/domains/allProperties/allTasks\nCreate and delete domains, and read and update all properties\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nDragon Administrator\nAssign the Dragon Administrator role to users who need to do the following tasks:\nManage all aspects of the administrative experience in the Dragon admin center\nProvision clinical applications\nCreate and manage the organization hierarchy\nOversee healthcare groups\nManage experiences of various clinical applications embedded in Electronic Health Record (EHR) systems\nConfigure clinical applications, such as manage settings, view analytics, and handle library objects\nCreate, manage, and view support tickets for their organization in the Dragon admin center\nCreate, view, manage, and monitor billing plans for licenses purchased by their organization (additional roles may be required)\nLearn more\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.healthPlatform/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Dragon admin center\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nDynamics 365 Administrator\nAssign the Dynamics 365 Administrator role to users who need to manage all aspects of Dynamics 365 services, including configuration, user management, and support tickets.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.dynamics365/allEntities/allTasks\nManage all aspects of Dynamics 365\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nDynamics 365 Business Central Administrator\nAssign the Dynamics 365 Business Central Administrator role to users who need to do the following tasks:\nAccess Dynamics 365 Business Central environments\nPerform all administrative tasks on environments\nManage the lifecycle of customer's environments\nSupervise the extensions installed on environments\nControl upgrades of environments\nPerform data exports of environments\nRead and configure Azure and Microsoft 365 service health dashboards\nThis role does not provide any permissions for other Dynamics 365 products.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/domains/standard/read\nRead basic properties on domains\nmicrosoft.directory/organization/standard/read\nRead basic properties on an organization\nmicrosoft.directory/subscribedSkus/standard/read\nRead basic properties on subscriptions\nmicrosoft.directory/users/standard/read\nRead basic properties on users\nmicrosoft.dynamics365.businessCentral/allEntities/allProperties/allTasks\nManage all aspects of Dynamics 365 Business Central\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nEdge Administrator\nUsers in this role can create and manage the enterprise site list required for Internet Explorer mode on Microsoft Edge. This role grants permissions to create, edit, and publish the site list and additionally allows access to manage support tickets.\nLearn more\nActions\nDescription\nmicrosoft.edge/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Edge\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nExchange Administrator\nUsers with this role have global permissions within Microsoft Exchange Online, when the service is present. Also has the ability to create and manage all Microsoft 365 groups, manage support tickets, and monitor service health. For more information, see\nAbout admin roles in the Microsoft 365 admin center\n.\nNote\nIn the Microsoft Graph API and Microsoft Graph PowerShell, this role is named Exchange Service Administrator. In the\nAzure portal\n, it is named Exchange Administrator. In the\nExchange admin center\n, it is named Exchange Online administrator.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/exchangeProtectionPolicies/allProperties/allTasks\nCreate and manage Exchange Online protection policy in Microsoft 365 Backup\nmicrosoft.backup/exchangeRestoreSessions/allProperties/allTasks\nRead and configure restore session for Exchange Online in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/userMailboxes/allProperties/allTasks\nManage all restore points associated with selected Exchange Online mailboxes in M365 Backup\nmicrosoft.backup/userMailboxProtectionUnits/allProperties/allTasks\nManage mailboxes added to Exchange Online protection policy in Microsoft 365 Backup\nmicrosoft.backup/userMailboxRestoreArtifacts/allProperties/allTasks\nManage mailboxes added to restore session for Exchange Online in Microsoft 365 Backup\nmicrosoft.directory/contacts/allProperties/read\nRead all properties for contacts\nmicrosoft.directory/contacts/memberOf/read\nRead the group membership for all contacts in Microsoft Entra ID\nmicrosoft.directory/contacts/standard/read\nRead basic properties on contacts in Microsoft Entra ID\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.unified/basic/update\nUpdate basic properties on Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/create\nCreate Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/delete\nDelete Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/members/update\nUpdate members of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/owners/update\nUpdate owners of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/restore\nRestore Microsoft 365 groups from soft-deleted container, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nmicrosoft.office365.exchange/allEntities/basic/allTasks\nManage all aspects of Exchange Online\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nExchange Backup Administrator\nAssign the Exchange Backup Administrator role to users who need to do the following tasks:\nManage all aspects of Microsoft 365 Backup for Exchange Online\nBack up and restore content including granular restore for Exchange Online\nCreate, edit, and manage backup configuration policies for Exchange Online\nPerform restore operations for Exchange Online\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/exchangeProtectionPolicies/allProperties/allTasks\nCreate and manage Exchange Online protection policy in Microsoft 365 Backup\nmicrosoft.backup/exchangeRestoreSessions/allProperties/allTasks\nRead and configure restore session for Exchange Online in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/userMailboxes/allProperties/allTasks\nManage all restore points associated with selected Exchange Online mailboxes in M365 Backup\nmicrosoft.backup/userMailboxProtectionUnits/allProperties/allTasks\nManage mailboxes added to Exchange Online protection policy in Microsoft 365 Backup\nmicrosoft.backup/userMailboxRestoreArtifacts/allProperties/allTasks\nManage mailboxes added to restore session for Exchange Online in Microsoft 365 Backup\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nExchange Recipient Administrator\nUsers with this role have read access to recipients and write access to the attributes of those recipients in Exchange Online. For more information, see\nRecipients in Exchange Server\n.\nActions\nDescription\nmicrosoft.office365.exchange/migration/allProperties/allTasks\nManage all tasks related to migration of recipients in Exchange Online\nmicrosoft.office365.exchange/recipients/allProperties/allTasks\nCreate and delete all recipients, and read and update all properties of recipients in Exchange Online\nExtended Directory User Administrator\nActions\nDescription\nmicrosoft.directory/externalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/create\nCreate external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nExternal ID User Flow Administrator\nUsers with this role can create and manage user flows (also called \"built-in\" policies) in the Azure portal. These users can customize HTML/CSS/JavaScript content, change MFA requirements, select claims in the token, manage API connectors and their credentials, and configure session settings for all user flows in the Microsoft Entra organization. On the other hand, this role does not include the ability to review user data or make changes to the attributes that are included in the organization schema. Changes to Identity Experience Framework policies (also known as custom policies) are also outside the scope of this role.\nActions\nDescription\nmicrosoft.directory/b2cUserFlow/allProperties/allTasks\nRead and configure user flow in Azure Active Directory B2C\nExternal ID User Flow Attribute Administrator\nUsers with this role add or delete custom attributes available to all user flows in the Microsoft Entra organization. As such, users with this role can change or add new elements to the end-user schema and impact the behavior of all user flows, and indirectly result in changes to what data may be asked of end users and ultimately sent as claims to applications. This role can't edit user flows.\nActions\nDescription\nmicrosoft.directory/b2cUserAttribute/allProperties/allTasks\nRead and configure user attribute in Azure Active Directory B2C\nExternal Identity Provider Administrator\nThis is a\nprivileged role\n. This administrator manages federation between Microsoft Entra organizations and external identity providers. With this role, users can add new identity providers and configure all available settings (e.g. authentication path, service ID, assigned key containers). This user can enable the Microsoft Entra organization to trust authentications from external identity providers. The resulting impact on end-user experiences depends on the type of organization:\nMicrosoft Entra organizations for employees and partners: The addition of a federation (e.g. with Gmail) will immediately impact all guest invitations not yet redeemed. See\nAdding Google as an identity provider for B2B guest users\n.\nAzure Active Directory B2C organizations: The addition of a federation (for example, with Facebook, or with another Microsoft Entra organization) does not immediately impact end-user flows until the identity provider is added as an option in a user flow (also called a built-in policy). See\nConfiguring a Microsoft account as an identity provider\nfor an example. To change user flows, the limited role of \"B2C User Flow Administrator\" is required.\nActions\nDescription\nmicrosoft.directory/domains/federation/update\nUpdate federation property of domains\nmicrosoft.directory/identityProviders/allProperties/allTasks\nRead and configure identity providers in Azure Active Directory B2C\nFabric Administrator\nUsers with this role have global permissions within Microsoft Fabric and Power BI, when the service is present, as well as the ability to manage support tickets and monitor service health. For more information, see\nUnderstanding Fabric admin roles\n.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.powerApps.powerBI/allEntities/allTasks\nManage all aspects of Fabric and Power BI\nGlobal Administrator\nThis is a\nprivileged role\n. Users with this role have access to all administrative features in Microsoft Entra ID, as well as services that use Microsoft Entra identities like the Microsoft 365 Defender portal, the Microsoft Purview compliance portal, Exchange Online, SharePoint Online, and Skype for Business Online. Global Administrators can view Directory Activity logs. Furthermore, Global Administrators can\nelevate their access\nto manage all Azure subscriptions and management groups. This allows Global Administrators to get full access to all Azure resources using the respective Microsoft Entra tenant. The person who signs up for the Microsoft Entra organization becomes a Global Administrator. There can be more than one Global Administrator at your company. Global Administrators can reset the password for any user and all other administrators. A Global Administrator cannot remove their own Global Administrator assignment. This is to prevent a situation where an organization has zero Global Administrators.\nNote\nAs a best practice, Microsoft recommends that you assign the Global Administrator role to fewer than five people in your organization. For more information, see\nBest practices for Microsoft Entra roles\n.\nActions\nDescription\nmicrosoft.agentRegistry/allEntities/allProperties/allTasks\nManage all aspects of Agent Registry in Microsoft Entra ID\nmicrosoft.azure.advancedThreatProtection/allEntities/allTasks\nManage all aspects of Azure Advanced Threat Protection\nmicrosoft.azure.informationProtection/allEntities/allTasks\nManage all aspects of Azure Information Protection\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 Backup\nmicrosoft.cloudPC/allEntities/allProperties/allTasks\nManage all aspects of Windows 365\nmicrosoft.commerce.billing/allEntities/allProperties/allTasks\nManage all aspects of Office 365 billing\nmicrosoft.commerce.billing/purchases/standard/read\nRead purchase services in Microsoft 365 admin center.\nmicrosoft.directory/accessReviews/allProperties/allTasks\nCreate and delete access reviews, and read and update all properties of access reviews in Microsoft Entra ID\nmicrosoft.directory/accessReviews/definitions/allProperties/allTasks\nManage access reviews of all reviewable resources in Microsoft Entra ID\nmicrosoft.directory/adminConsentRequestPolicy/allProperties/allTasks\nManage admin consent request policies in Microsoft Entra ID\nmicrosoft.directory/administrativeUnits/allProperties/allTasks\nCreate and manage administrative units (including members)\nmicrosoft.directory/agentIdentities/appRoleAssignedTo/update\nUpdate agent identity role assignments.\nmicrosoft.directory/agentIdentities/basic/update\nUpdate basic properties of agent identities.\nmicrosoft.directory/agentIdentities/create\nCreate agent identities.\nmicrosoft.directory/agentIdentities/delete\nDelete agent identities.\nmicrosoft.directory/agentIdentities/disable\nDisable agent identities.\nmicrosoft.directory/agentIdentities/enable\nEnable agent identities.\nmicrosoft.directory/agentIdentities/owners/update\nAdd and remove owners to agent identities.\nmicrosoft.directory/agentIdentities/tag/update\nUpdate tags for agent identities.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/appRoleAssignedTo/update\nUpdate agent identity blueprint principal role assignments.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/basic/update\nUpdate basic properties of agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/create\nCreate agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/delete\nDelete agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/disable\nDisable agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/enable\nEnable agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/owners/update\nAdd and remove owners to agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprintPrincipals/tag/update\nUpdate tags for agent identity blueprint principals.\nmicrosoft.directory/agentIdentityBlueprints/allProperties/read\nRead all properties and settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/allProperties/update\nUpdate all properties and settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/appRoles/update\nModify app roles defined on agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/authentication/update\nUpdate authentication related settings for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/audience/update\nUpdate the sign-in audience setting for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/basic/update\nUpdate basic properties of agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/create\nCreate agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/credentials/update\nAdd and remove credentials to agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/delete\nDelete agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/owners/update\nAdd and remove owners to agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/permissions/update\nModify exposed permissions on agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/tag/update\nUpdate tags for agent identity blueprints.\nmicrosoft.directory/agentIdentityBlueprints/verification/update\nUpdate publisher verification setting for agent identity blueprints.\nmicrosoft.directory/agentUsers/assignLicense\nManage agent user licenses\nmicrosoft.directory/agentUsers/basic/update\nUpdate basic properties on agent users\nmicrosoft.directory/agentUsers/create\nAdd agent users\nmicrosoft.directory/agentUsers/delete\nDelete agent users\nmicrosoft.directory/agentUsers/disable\nDisable agent users\nmicrosoft.directory/agentUsers/enable\nEnable agent users\nmicrosoft.directory/agentUsers/invalidateAllRefreshTokens\nForce sign-out by invalidating agent user refresh tokens\nmicrosoft.directory/agentUsers/lifeCycleInfo/read\nRead lifecycle information of agent users, such as employeeLeaveDateTime\nmicrosoft.directory/agentUsers/lifeCycleInfo/update\nUpdate lifecycle information of agent users, such as employeeLeaveDateTime\nmicrosoft.directory/agentUsers/manager/update\nUpdate manager for agent users\nmicrosoft.directory/agentUsers/photo/update\nUpdate photo of agent users\nmicrosoft.directory/agentUsers/reprocessLicenseAssignment\nReprocess license assignments for agent users\nmicrosoft.directory/agentUsers/restore\nRestore deleted agent users\nmicrosoft.directory/agentUsers/revokeSignInSessions\nRevoke sign-in sessions for a agent user\nmicrosoft.directory/agentUsers/sponsors/update\nUpdate sponsors of agent users\nmicrosoft.directory/agentUsers/usageLocation/update\nUpdate usage location of agent users\nmicrosoft.directory/agentUsers/userPrincipalName/update\nUpdate User Principal Name of agent users\nmicrosoft.directory/appConsent/appConsentRequests/allProperties/read\nRead all properties of consent requests for applications registered with Microsoft Entra ID\nmicrosoft.directory/applications/allProperties/allTasks\nCreate and delete applications, and read and update all properties\nmicrosoft.directory/applications/synchronization/standard/read\nRead provisioning settings associated with the application object\nmicrosoft.directory/applicationTemplates/instantiate\nInstantiate gallery applications from application templates\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/allProperties/allTasks\nManage all aspects of authorization policy\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/bulkJobs/basic/update\nUpdate all the bulk jobs in a directory\nmicrosoft.directory/bulkJobs/create\nCreate all bulk jobs in a directory\nmicrosoft.directory/cloudAppSecurity/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Defender for Cloud Apps\nmicrosoft.directory/conditionalAccessPolicies/allProperties/allTasks\nManage all properties of Conditional Access policies\nmicrosoft.directory/connectorGroups/allProperties/read\nRead all properties of application proxy connector groups\nmicrosoft.directory/connectorGroups/allProperties/update\nUpdate all properties of application proxy connector groups\nmicrosoft.directory/connectorGroups/create\nCreate application proxy connector groups\nmicrosoft.directory/connectorGroups/delete\nDelete application proxy connector groups\nmicrosoft.directory/connectors/allProperties/read\nRead all properties of application proxy connectors\nmicrosoft.directory/connectors/create\nCreate application proxy connectors\nmicrosoft.directory/contacts/allProperties/allTasks\nCreate and delete contacts, and read and update all properties\nmicrosoft.directory/contracts/allProperties/allTasks\nCreate and delete partner contracts, and read and update all properties\nmicrosoft.directory/crossTenantAccessPolicy/allowedCloudEndpoints/update\nUpdate allowed cloud endpoints of cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/basic/update\nUpdate basic settings of cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/b2bCollaboration/update\nUpdate Microsoft Entra B2B collaboration settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/b2bDirectConnect/update\nUpdate Microsoft Entra B2B direct connect settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/tenantRestrictions/update\nUpdate tenant restrictions of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/b2bCollaboration/update\nUpdate Microsoft Entra B2B collaboration settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/b2bDirectConnect/update\nUpdate Microsoft Entra B2B direct connect settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/create\nCreate cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/delete\nDelete cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/basic/update\nUpdate basic settings of cross-tenant sync policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/create\nCreate cross-tenant sync policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/standard/read\nRead basic properties of cross-tenant sync policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/standard/read\nRead basic properties of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/basic/update\nUpdate cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/resetToDefaultSettings\nReset cross tenant sync policy template for multi-tenant organization to default settings\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/standard/read\nRead basic properties of cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/basic/update\nUpdate cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/resetToDefaultSettings\nReset cross tenant access policy template for multi-tenant organization to default settings\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/standard/read\nRead basic properties of cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/tenantRestrictions/update\nUpdate tenant restrictions of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/standard/read\nRead basic properties of cross-tenant access policy\nmicrosoft.directory/customAuthenticationExtensions/allProperties/allTasks\nCreate and manage custom authentication extensions\nmicrosoft.directory/deletedItems/delete\nPermanently delete objects, which can no longer be restored\nmicrosoft.directory/deletedItems/restore\nRestore soft deleted objects to original state\nmicrosoft.directory/deviceLocalCredentials/password/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, including the password\nmicrosoft.directory/deviceManagementPolicies/basic/update\nUpdate basic properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/basic/update\nUpdate basic properties on device registration policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/allProperties/allTasks\nCreate and delete devices, and read and update all properties\nmicrosoft.directory/devices/permissions/update\nUpdate the alternative name property on an IoT device\nmicrosoft.directory/deviceTemplates/owners/read\nRead owners on Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/owners/update\nUpdate owners on Internet of Things (IoT) device templates\nmicrosoft.directory/directoryRoles/allProperties/allTasks\nCreate and delete directory roles, and read and update all properties\nmicrosoft.directory/directoryRoleTemplates/allProperties/allTasks\nCreate and delete Microsoft Entra role templates, and read and update all properties\nmicrosoft.directory/domains/allProperties/allTasks\nCreate and delete domains, and read and update all properties\nmicrosoft.directory/domains/federationConfiguration/basic/update\nUpdate basic federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/create\nCreate federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/delete\nDelete federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/standard/read\nRead standard properties of federation configuration for domains\nmicrosoft.directory/entitlementManagement/allProperties/allTasks\nCreate and delete resources, and read and update all properties in Microsoft Entra entitlement management\nmicrosoft.directory/externalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/groups/allProperties/allTasks\nCreate and delete groups, and read and update all properties\nmicrosoft.directory/groupsAssignableToRoles/allProperties/update\nUpdate role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/assignLicense\nAssign a license to role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/create\nCreate role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/delete\nDelete role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/reprocessLicenseAssignment\nReprocess license assignments to role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/restore\nRestore role-assignable groups\nmicrosoft.directory/groupSettings/allProperties/allTasks\nCreate and delete group settings, and read and update all properties\nmicrosoft.directory/groupSettingTemplates/allProperties/allTasks\nCreate and delete group setting templates, and read and update all properties\nmicrosoft.directory/hybridAuthenticationPolicy/allProperties/allTasks\nManage hybrid authentication policy in Microsoft Entra ID\nmicrosoft.directory/identityProtection/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Entra ID Protection\nmicrosoft.directory/lifecycleWorkflows/workflows/allProperties/allTasks\nManage all aspects of lifecycle workflows and tasks in Microsoft Entra ID\nmicrosoft.directory/loginOrganizationBranding/allProperties/allTasks\nCreate and delete loginTenantBranding, and read and update all properties\nmicrosoft.directory/multiTenantOrganization/basic/update\nUpdate basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/create\nCreate a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/joinRequest/organizationDetails/update\nJoin a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/joinRequest/standard/read\nRead properties of a multi-tenant organization join request\nmicrosoft.directory/multiTenantOrganization/standard/read\nRead basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/create\nCreate a tenant in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/delete\nDelete a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/read\nRead organization details of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/update\nUpdate basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/standard/read\nRead basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/namedLocations/basic/update\nUpdate basic properties of custom rules that define network locations\nmicrosoft.directory/namedLocations/create\nCreate custom rules that define network locations\nmicrosoft.directory/namedLocations/delete\nDelete custom rules that define network locations\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/onPremisesSynchronization/basic/update\nUpdate basic on-premises directory synchronization information\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nmicrosoft.directory/organization/allProperties/allTasks\nRead and update all properties for an organization\nmicrosoft.directory/passwordHashSync/allProperties/allTasks\nManage all aspects of Password Hash Synchronization (PHS) in Microsoft Entra ID\nmicrosoft.directory/pendingExternalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/create\nCreate external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/permissionGrantPolicies/basic/update\nUpdate basic properties of permission grant policies\nmicrosoft.directory/permissionGrantPolicies/create\nCreate permission grant policies\nmicrosoft.directory/permissionGrantPolicies/delete\nDelete permission grant policies\nmicrosoft.directory/permissionGrantPolicies/standard/read\nRead standard properties of permission grant policies\nmicrosoft.directory/policies/allProperties/allTasks\nCreate and delete policies, and read and update all properties\nmicrosoft.directory/privilegedIdentityManagement/allProperties/read\nRead all resources in Privileged Identity Management\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/resourceNamespaces/resourceActions/authenticationContext/update\nUpdate Conditional Access authentication context of Microsoft 365 role-based access control (RBAC) resource actions\nmicrosoft.directory/roleAssignments/allProperties/allTasks\nCreate and delete role assignments, and read and update all role assignment properties\nmicrosoft.directory/roleDefinitions/allProperties/allTasks\nCreate and delete role definitions, and read and update all properties\nmicrosoft.directory/scopedRoleMemberships/allProperties/allTasks\nCreate and delete scopedRoleMemberships, and read and update all properties\nmicrosoft.directory/serviceAction/activateService\nCan perform the \"activate service\" action for a service\nmicrosoft.directory/serviceAction/disableDirectoryFeature\nCan perform the \"disable directory feature\" service action\nmicrosoft.directory/serviceAction/enableDirectoryFeature\nCan perform the \"enable directory feature\" service action\nmicrosoft.directory/serviceAction/getAvailableExtentionProperties\nCan perform the getAvailableExtentionProperties service action\nmicrosoft.directory/servicePrincipalCreationPolicies/basic/update\nUpdate basic properties of service principal creation policies\nmicrosoft.directory/servicePrincipalCreationPolicies/create\nCreate service principal creation policies\nmicrosoft.directory/servicePrincipalCreationPolicies/delete\nDelete service principal creation policies\nmicrosoft.directory/servicePrincipalCreationPolicies/standard/read\nRead standard properties of service principal creation policies\nmicrosoft.directory/servicePrincipals/allProperties/allTasks\nCreate and delete service principals, and read and update all properties\nmicrosoft.directory/servicePrincipals/managePermissionGrantsForAll.microsoft-company-admin\nGrant consent for any permission to any application\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/credentials/manage\nManage cloud tenant to cloud tenant application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/jobs/manage\nStart, restart, and pause cloud tenant to cloud tenant application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/schema/manage\nCreate and manage cloud tenant to cloud tenant application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/credentials/manage\nManage application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/jobs/manage\nStart, restart, and pause application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/schema/manage\nCreate and manage application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization/standard/read\nRead provisioning settings associated with your service principal\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.directory/subscribedSkus/allProperties/allTasks\nBuy and manage subscriptions and delete subscriptions\nmicrosoft.directory/tenantManagement/tenants/create\nCreate new tenants in Microsoft Entra ID\nmicrosoft.directory/users/allProperties/allTasks\nCreate and delete users, and read and update all properties\nmicrosoft.directory/users/authenticationMethods/basic/update\nUpdate basic properties of authentication methods for users\nmicrosoft.directory/users/authenticationMethods/create\nUpdate authentication methods for users\nmicrosoft.directory/users/authenticationMethods/delete\nDelete authentication methods for users\nmicrosoft.directory/users/authenticationMethods/standard/read\nRead standard properties of authentication methods for users\nmicrosoft.directory/users/convertExternalToInternalMemberUser\nConvert external user to internal user\nmicrosoft.directory/verifiableCredentials/configuration/allProperties/read\nRead configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/allProperties/update\nUpdate configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/contracts/allProperties/read\nRead a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/contracts/allProperties/update\nUpdate a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/contracts/cards/allProperties/read\nRead a verifiable credential card\nmicrosoft.directory/verifiableCredentials/configuration/contracts/cards/revoke\nRevoke a verifiable credential card\nmicrosoft.directory/verifiableCredentials/configuration/contracts/create\nCreate a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/create\nCreate configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/delete\nDelete configuration required to create and manage verifiable credentials and delete all of its verifiable credentials\nmicrosoft.dynamics365/allEntities/allTasks\nManage all aspects of Dynamics 365\nmicrosoft.edge/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Edge\nmicrosoft.flow/allEntities/allTasks\nManage all aspects of Microsoft Power Automate\nmicrosoft.graph.dataConnect/allEntities/allProperties/allTasks\nManage aspects of Microsoft Graph Data Connect\nmicrosoft.hardware.support/shippingAddress/allProperties/allTasks\nCreate, read, update, and delete shipping addresses for Microsoft hardware warranty claims, including shipping addresses created by others\nmicrosoft.hardware.support/shippingStatus/allProperties/read\nRead shipping status for open Microsoft hardware warranty claims\nmicrosoft.hardware.support/warrantyClaims/allProperties/allTasks\nCreate and manage all aspects of Microsoft hardware warranty claims\nmicrosoft.healthPlatform/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Dragon admin center\nmicrosoft.insights/allEntities/allProperties/allTasks\nManage all aspects of Insights app\nmicrosoft.intune/allEntities/allTasks\nManage all aspects of Microsoft Intune\nmicrosoft.microsoft365.organizationalData/allEntities/allProperties/allTasks\nManage all aspects of organizational data in Microsoft 365\nmicrosoft.networkAccess/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Entra Network Access\nmicrosoft.networkAccess/trafficLogs/standard/read\nRead standard properties of traffic logs such as DeviceId, DestinationIp and PolicyRuleId\nmicrosoft.office365.complianceManager/allEntities/allTasks\nManage all aspects of Office 365 Compliance Manager\nmicrosoft.office365.copilot/allEntities/allProperties/allTasks\nCreate and manage all settings for Microsoft 365 Copilot\nmicrosoft.office365.desktopAnalytics/allEntities/allTasks\nManage all aspects of Desktop Analytics\nmicrosoft.office365.exchange/allEntities/basic/allTasks\nManage all aspects of Exchange Online\nmicrosoft.office365.fileStorageContainers/allEntities/allProperties/allTasks\nManage all aspects of SharePoint Embedded containers\nmicrosoft.office365.knowledge/contentUnderstanding/allProperties/allTasks\nRead and update all properties of content understanding in Microsoft 365 admin center\nmicrosoft.office365.knowledge/contentUnderstanding/analytics/allProperties/read\nRead analytics reports of content understanding in Microsoft 365 admin center\nmicrosoft.office365.knowledge/knowledgeNetwork/allProperties/allTasks\nRead and update all properties of knowledge network in Microsoft 365 admin center\nmicrosoft.office365.knowledge/knowledgeNetwork/topicVisibility/allProperties/allTasks\nManage topic visibility of knowledge network in Microsoft 365 admin center\nmicrosoft.office365.knowledge/learningSources/allProperties/allTasks\nManage learning sources and all their properties in Learning App.\nmicrosoft.office365.lockbox/allEntities/allTasks\nManage all aspects of Customer Lockbox\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.messageCenter/securityMessages/read\nRead security messages in Message Center in the Microsoft 365 admin center\nmicrosoft.office365.migrations/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 migrations\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/allTasks\nManage all authoring aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.protectionCenter/allEntities/allProperties/allTasks\nManage all aspects of the Security and Compliance centers\nmicrosoft.office365.search/content/manage\nCreate and delete content, and read and update all properties in Microsoft Search\nmicrosoft.office365.securityComplianceCenter/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in the Microsoft 365 Security and Compliance Center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.sharePoint/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in SharePoint\nmicrosoft.office365.sharePointAdvancedManagement/allEntities/allProperties/allTasks\nManage all aspects of SharePoint Advanced Management\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.userCommunication/allEntities/allTasks\nRead and update what's new messages visibility\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.office365.yammer/allEntities/allProperties/allTasks\nManage all aspects of Yammer\nmicrosoft.people/users/photo/read\nRead profile photo of user\nmicrosoft.people/users/photo/update\nUpdate profile photo of user\nmicrosoft.peopleAdmin/organization/allProperties/read\nRead people settings for users, such as pronouns, name pronunciation, and profile card settings\nmicrosoft.peopleAdmin/organization/allProperties/update\nUpdate people settings for users, such as pronouns, name pronunciation, and profile card settings\nmicrosoft.permissionsManagement/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Entra Permissions Management\nmicrosoft.powerApps.powerBI/allEntities/allTasks\nManage all aspects of Fabric and Power BI\nmicrosoft.powerApps/allEntities/allTasks\nManage all aspects of Power Apps\nmicrosoft.teams/allEntities/allProperties/allTasks\nManage all resources in Teams\nmicrosoft.virtualVisits/allEntities/allProperties/allTasks\nManage and share Virtual Visits information and metrics from admin centers or the Virtual Visits app\nmicrosoft.viva.glint/allEntities/allProperties/allTasks\nManage and configure all Microsoft Viva Glint settings in the Microsoft 365 admin center\nmicrosoft.viva.goals/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Viva Goals\nmicrosoft.viva.pulse/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Viva Pulse\nmicrosoft.windows.defenderAdvancedThreatProtection/allEntities/allTasks\nManage all aspects of Microsoft Defender for Endpoint\nmicrosoft.windows.updatesDeployments/allEntities/allProperties/allTasks\nRead and configure all aspects of Windows Update Service\nGlobal Reader\nThis is a\nprivileged role\n. Users in this role can read settings and administrative information across Microsoft 365 services but can't take management actions. Global Reader is the read-only counterpart to Global Administrator. Assign Global Reader instead of Global Administrator for planning, audits, or investigations. Use Global Reader in combination with other limited admin roles like Exchange Administrator to make it easier to get work done without the assigning the Global Administrator role. Global Reader works with Microsoft 365 admin center, Exchange admin center, SharePoint admin center, Teams admin center, Microsoft 365 Defender portal, Microsoft Purview compliance portal, Azure portal, and Device Management admin center.\nUsers with this role\ncannot\ndo the following:\nCannot access the Purchase Services area in the Microsoft 365 admin center.\nNote\nGlobal Reader role has the following limitations:\nOneDrive admin center - OneDrive admin center does not support the Global Reader role\nMicrosoft 365 Defender portal\n- Global Reader can't do content search or see Secure Score.\nTeams admin center\n- Global Reader cannot read\nTeams lifecycle\n,\nAnalytics & reports\n,\nIP phone device management\n, and\nApp catalog\n. For more information, see\nUse Microsoft Teams administrator roles to manage Teams\n.\nPrivileged Access Management\ndoesn't support the Global Reader role.\nAzure Information Protection\n- Global Reader is supported\nfor central reporting\nonly, and when your Microsoft Entra organization isn't on the\nunified labeling platform\n.\nSharePoint\n- Global Reader has read access to SharePoint Online PowerShell cmdlets and Read APIs.\nPower Platform admin center\n- Global Reader is not yet supported in the Power Platform admin center.\nMicrosoft Purview doesn't support the Global Reader role.\nActions\nDescription\nmicrosoft.agentRegistry/allEntities/allProperties/read\nRead all properties of Agent Registry in Microsoft Entra ID\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.backup/allEntities/allProperties/read\nRead all aspects of Microsoft 365 Backup\nmicrosoft.cloudPC/allEntities/allProperties/read\nRead all aspects of Windows 365\nmicrosoft.commerce.billing/allEntities/allProperties/read\nRead all resources of Office 365 billing\nmicrosoft.commerce.billing/purchases/standard/read\nRead purchase services in Microsoft 365 admin center.\nmicrosoft.directory/accessReviews/allProperties/read\nRead all properties of access reviews\nmicrosoft.directory/accessReviews/definitions/allProperties/read\nRead all properties of access reviews of all reviewable resources in Microsoft Entra ID\nmicrosoft.directory/adminConsentRequestPolicy/allProperties/read\nRead all properties of admin consent request policies in Microsoft Entra ID\nmicrosoft.directory/administrativeUnits/allProperties/read\nRead all properties of administrative units, including members\nmicrosoft.directory/appConsent/appConsentRequests/allProperties/read\nRead all properties of consent requests for applications registered with Microsoft Entra ID\nmicrosoft.directory/applications/allProperties/read\nRead all properties (including privileged properties) on all types of applications\nmicrosoft.directory/applications/synchronization/standard/read\nRead provisioning settings associated with the application object\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/cloudAppSecurity/allProperties/read\nRead all properties for Cloud app security\nmicrosoft.directory/conditionalAccessPolicies/allProperties/read\nRead all properties of Conditional Access policies\nmicrosoft.directory/connectorGroups/allProperties/read\nRead all properties of application proxy connector groups\nmicrosoft.directory/connectors/allProperties/read\nRead all properties of application proxy connectors\nmicrosoft.directory/contacts/allProperties/read\nRead all properties for contacts\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/standard/read\nRead basic properties of cross-tenant sync policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/standard/read\nRead basic properties of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/standard/read\nRead basic properties of cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/standard/read\nRead basic properties of cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/standard/read\nRead basic properties of cross-tenant access policy\nmicrosoft.directory/customAuthenticationExtensions/allProperties/read\nRead custom authentication extensions\nmicrosoft.directory/deviceLocalCredentials/standard/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, except the password\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/allProperties/read\nRead all properties of devices\nmicrosoft.directory/directoryRoles/allProperties/read\nRead all properties of directory roles\nmicrosoft.directory/directoryRoleTemplates/allProperties/read\nRead all properties of directory role templates\nmicrosoft.directory/domains/allProperties/read\nRead all properties of domains\nmicrosoft.directory/domains/federationConfiguration/standard/read\nRead standard properties of federation configuration for domains\nmicrosoft.directory/entitlementManagement/allProperties/read\nRead all properties in Microsoft Entra entitlement management\nmicrosoft.directory/externalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/groups/allProperties/read\nRead all properties (including privileged properties) on Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groupSettings/allProperties/read\nRead all properties of group settings\nmicrosoft.directory/groupSettingTemplates/allProperties/read\nRead all properties of group setting templates\nmicrosoft.directory/identityProtection/allProperties/read\nRead all resources in Microsoft Entra ID Protection\nmicrosoft.directory/lifecycleWorkflows/workflows/allProperties/read\nRead all properties of lifecycle workflows and tasks in Microsoft Entra ID\nmicrosoft.directory/loginOrganizationBranding/allProperties/read\nRead all properties for your organization's branded sign-in page\nmicrosoft.directory/multiTenantOrganization/joinRequest/standard/read\nRead properties of a multi-tenant organization join request\nmicrosoft.directory/multiTenantOrganization/standard/read\nRead basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/read\nRead organization details of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/standard/read\nRead basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/read\nRead all properties of OAuth 2.0 permission grants\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nmicrosoft.directory/organization/allProperties/read\nRead all properties for an organization\nmicrosoft.directory/pendingExternalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/permissionGrantPolicies/standard/read\nRead standard properties of permission grant policies\nmicrosoft.directory/policies/allProperties/read\nRead all properties of policies\nmicrosoft.directory/privilegedIdentityManagement/allProperties/read\nRead all resources in Privileged Identity Management\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/roleAssignments/allProperties/read\nRead all properties of role assignments\nmicrosoft.directory/roleDefinitions/allProperties/read\nRead all properties of role definitions\nmicrosoft.directory/scopedRoleMemberships/allProperties/read\nView members in administrative units\nmicrosoft.directory/serviceAction/getAvailableExtentionProperties\nCan perform the getAvailableExtentionProperties service action\nmicrosoft.directory/servicePrincipalCreationPolicies/standard/read\nRead standard properties of service principal creation policies\nmicrosoft.directory/servicePrincipals/allProperties/read\nRead all properties (including privileged properties) on servicePrincipals\nmicrosoft.directory/servicePrincipals/synchronization/standard/read\nRead provisioning settings associated with your service principal\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.directory/subscribedSkus/allProperties/read\nRead all properties of product subscriptions\nmicrosoft.directory/users/allProperties/read\nRead all properties of users\nmicrosoft.directory/users/authenticationMethods/standard/restrictedRead\nRead standard properties of authentication methods that do not include personally identifiable information for users\nmicrosoft.directory/verifiableCredentials/configuration/allProperties/read\nRead configuration required to create and manage verifiable credentials\nmicrosoft.directory/verifiableCredentials/configuration/contracts/allProperties/read\nRead a verifiable credential contract\nmicrosoft.directory/verifiableCredentials/configuration/contracts/cards/allProperties/read\nRead a verifiable credential card\nmicrosoft.edge/allEntities/allProperties/read\nRead all aspects of Microsoft Edge\nmicrosoft.graph.dataConnect/allEntities/allProperties/read\nRead aspects of Microsoft Graph Data Connect\nmicrosoft.hardware.support/shippingAddress/allProperties/read\nRead shipping addresses for Microsoft hardware warranty claims, including existing shipping addresses created by others\nmicrosoft.hardware.support/shippingStatus/allProperties/read\nRead shipping status for open Microsoft hardware warranty claims\nmicrosoft.hardware.support/warrantyClaims/allProperties/read\nRead Microsoft hardware warranty claims\nmicrosoft.healthPlatform/allEntities/allProperties/read\nRead all aspects of Microsoft Dragon admin center\nmicrosoft.insights/allEntities/allProperties/read\nRead all aspects of Viva Insights\nmicrosoft.microsoft365.organizationalData/allEntities/allProperties/read\nRead all aspects of organizational data in Microsoft 365\nmicrosoft.networkAccess/allEntities/allProperties/read\nRead all aspects of Microsoft Entra Network Access\nmicrosoft.office365.copilot/allEntities/allProperties/read\nRead all settings for Microsoft 365 Copilot\nmicrosoft.office365.fileStorageContainers/allEntities/allProperties/read\nRead entities and permissions of SharePoint Embedded containers\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.messageCenter/securityMessages/read\nRead security messages in Message Center in the Microsoft 365 admin center\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/read\nRead all aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.protectionCenter/allEntities/allProperties/read\nRead all properties in the Security and Compliance centers\nmicrosoft.office365.securityComplianceCenter/allEntities/read\nRead standard properties in Microsoft 365 Security and Compliance Center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.office365.yammer/allEntities/allProperties/read\nRead all aspects of Yammer\nmicrosoft.permissionsManagement/allEntities/allProperties/read\nRead all aspects of Microsoft Entra Permissions Management\nmicrosoft.teams/allEntities/allProperties/read\nRead all properties of Microsoft Teams\nmicrosoft.virtualVisits/allEntities/allProperties/read\nRead all aspects of Virtual Visits\nmicrosoft.viva.glint/allEntities/allProperties/read\nRead all Microsoft Viva Glint settings in the Microsoft 365 admin center\nmicrosoft.viva.goals/allEntities/allProperties/read\nRead all aspects of Microsoft Viva Goals\nmicrosoft.viva.pulse/allEntities/allProperties/read\nRead all aspects of Microsoft Viva Pulse\nmicrosoft.windows.updatesDeployments/allEntities/allProperties/read\nRead all aspects of Windows Update Service\nGlobal Secure Access Administrator\nAssign the Global Secure Access Administrator role to users who need to do the following:\nCreate and manage all aspectsâ¯of Microsoft Entra Internet Access and Microsoft Entra Private Access\nManage access to public and private endpoints\nUsers with this role\ncannot\ndo the following:\nCannot manage enterprise applications, application registrations, Conditional Access, or application proxy settings\nLearn more\nActions\nDescription\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/applicationPolicies/standard/read\nRead standard properties of application policies\nmicrosoft.directory/applications/applicationProxy/read\nRead all application proxy properties\nmicrosoft.directory/applications/owners/read\nRead owners of applications\nmicrosoft.directory/applications/policies/read\nRead policies of applications\nmicrosoft.directory/applications/standard/read\nRead standard properties of applications\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/conditionalAccessPolicies/standard/read\nRead Conditional Access for policies\nmicrosoft.directory/connectorGroups/allProperties/read\nRead all properties of application proxy connector groups\nmicrosoft.directory/connectors/allProperties/read\nRead all properties of application proxy connectors\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/standard/read\nRead basic properties of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/standard/read\nRead basic properties of cross-tenant access policy\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.networkAccess/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Entra Network Access\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nGlobal Secure Access Log Reader\nAssign the Global Secure Access Log Reader role to users who need to do the following:\nRead network traffic logs in Microsoft Entra Internet Access and Microsoft Entra Private Access for analysis by designated security personnel\nView log details such as session, connection, and transaction\nFilter logs based on criteria such as IP address and domain\nLearn more\nActions\nDescription\nmicrosoft.networkAccess/trafficLogs/standard/read\nRead standard properties of traffic logs such as DeviceId, DestinationIp and PolicyRuleId\nGroups Administrator\nUsers in this role can create/manage groups and its settings like naming and expiration policies. It is important to understand that assigning a user to this role gives them the ability to manage all groups in the organization across various workloads like Teams, SharePoint, Yammer in addition to Outlook. Also the user will be able to manage the various groups settings across various admin portals like Microsoft admin center, Azure portal, as well as workload specific ones like Teams and SharePoint admin centers.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/bulkJobs.groups/basic/update\nUpdate bulk jobs related to groups\nmicrosoft.directory/bulkJobs.groups/create\nCreate bulk jobs related to groups\nmicrosoft.directory/bulkJobs.groups/standard/read\nRead bulk jobs related to groups\nmicrosoft.directory/deletedItems.groups/delete\nPermanently delete groups, which can no longer be restored\nmicrosoft.directory/deletedItems.groups/restore\nRestore soft deleted groups to original state\nmicrosoft.directory/groups/assignedLabels/update\nUpdate the assigned labels property on groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups/assignLicense\nAssign product licenses to groups for group-based licensing\nmicrosoft.directory/groups/basic/update\nUpdate basic properties on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/classification/update\nUpdate the classification property on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/create\nCreate Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/delete\nDelete Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/dynamicMembershipRule/update\nUpdate the dynamic membership rule on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/groupType/update\nUpdate properties that would affect the group type of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/onPremWriteBack/update\nUpdate Microsoft Entra groups to be written back to on-premises with Microsoft Entra Connect\nmicrosoft.directory/groups/owners/update\nUpdate owners of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/reprocessLicenseAssignment\nReprocess license assignments for group-based licensing\nmicrosoft.directory/groups/restore\nRestore groups from soft-deleted container\nmicrosoft.directory/groups/settings/update\nUpdate settings of groups\nmicrosoft.directory/groups/visibility/update\nUpdate the visibility property of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nGuest Inviter\nUsers in this role can manage Microsoft Entra B2B guest user invitations when the\nMembers can invite\nuser setting is set to No. More information about B2B collaboration at\nAbout Microsoft Entra B2B collaboration\n. It does not include any other permissions.\nActions\nDescription\nmicrosoft.directory/users/appRoleAssignments/read\nRead application role assignments for users\nmicrosoft.directory/users/deviceForResourceAccount/read\nRead deviceForResourceAccount of users\nmicrosoft.directory/users/directReports/read\nRead the direct reports for users\nmicrosoft.directory/users/invitedBy/read\nRead the user that invited an external user to a tenant\nmicrosoft.directory/users/inviteGuest\nInvite guest users\nmicrosoft.directory/users/licenseDetails/read\nRead license details of users\nmicrosoft.directory/users/manager/read\nRead manager of users\nmicrosoft.directory/users/memberOf/read\nRead the group memberships of users\nmicrosoft.directory/users/oAuth2PermissionGrants/read\nRead delegated permission grants on users\nmicrosoft.directory/users/ownedDevices/read\nRead owned devices of users\nmicrosoft.directory/users/ownedObjects/read\nRead owned objects of users\nmicrosoft.directory/users/photo/read\nRead photo of users\nmicrosoft.directory/users/registeredDevices/read\nRead registered devices of users\nmicrosoft.directory/users/scopedRoleMemberOf/read\nRead user's membership of a Microsoft Entra role, that is scoped to an administrative unit\nmicrosoft.directory/users/sponsors/read\nRead sponsors of users\nmicrosoft.directory/users/standard/read\nRead basic properties on users\nHelpdesk Administrator\nThis is a\nprivileged role\n. Users with this role can change passwords, invalidate refresh tokens, create and manage support requests with Microsoft for Azure and Microsoft 365 services, and monitor service health. Invalidating a refresh token forces the user to sign in again. Whether a Helpdesk Administrator can reset a user's password and invalidate refresh tokens depends on the role the user is assigned. For a list of the roles that a Helpdesk Administrator can reset passwords for and invalidate refresh tokens, see\nWho can reset passwords\n.\nUsers with this role\ncannot\ndo the following:\nCannot change the credentials or reset MFA for members and owners of a\nrole-assignable group\n.\nImportant\nUsers with this role can change passwords for people who may have access to sensitive or private information or critical configuration inside and outside of Microsoft Entra ID. Changing the password of a user may mean the ability to assume that user's identity and permissions. For example:\nApplication Registration and Enterprise Application owners, who can manage credentials of apps they own. Those apps may have privileged permissions in Microsoft Entra ID and elsewhere not granted to Helpdesk Administrators. Through this path a Helpdesk Administrator may be able to assume the identity of an application owner and then further assume the identity of a privileged application by updating the credentials for the application.\nAzure subscription owners, who might have access to sensitive or private information or critical configuration in Azure.\nSecurity Group and Microsoft 365 group owners, who can manage group membership. Those groups may grant access to sensitive or private information or critical configuration in Microsoft Entra ID and elsewhere.\nAdministrators in other services outside of Microsoft Entra ID like Exchange Online, Microsoft 365 Defender portal, Microsoft Purview compliance portal, and human resources systems.\nNon-administrators like executives, legal counsel, and human resources employees who may have access to sensitive or private information.\nDelegating administrative permissions over subsets of users and applying policies to a subset of users is possible with\nAdministrative Units\n.\nThis role was previously named Password Administrator in the\nAzure portal\n. It was renamed to Helpdesk Administrator to align with the existing name in the Microsoft Graph API and Microsoft Graph PowerShell.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/deviceLocalCredentials/standard/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, except the password\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nHybrid Identity Administrator\nThis is a\nprivileged role\n. Users in this role can create, manage and deploy provisioning configuration setup from Active Directory to Microsoft Entra ID using Cloud Provisioning as well as manage Microsoft Entra Connect, pass-through authentication (PTA), password hash synchronization (PHS), seamless single sign-on (seamless SSO), and federation settings. Does not have access to manage Microsoft Entra Connect Health. Users can also troubleshoot and monitor logs using this role.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/applications/appRoles/update\nUpdate the appRoles property on all types of applications\nmicrosoft.directory/applications/audience/update\nUpdate the audience property for applications\nmicrosoft.directory/applications/authentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/basic/update\nUpdate basic properties for applications\nmicrosoft.directory/applications/create\nCreate all types of applications\nmicrosoft.directory/applications/delete\nDelete all types of applications\nmicrosoft.directory/applications/notes/update\nUpdate notes of applications\nmicrosoft.directory/applications/owners/update\nUpdate owners of applications\nmicrosoft.directory/applications/permissions/update\nUpdate exposed permissions and required permissions on all types of applications\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/applications/synchronization/standard/read\nRead provisioning settings associated with the application object\nmicrosoft.directory/applications/tag/update\nUpdate tags of applications\nmicrosoft.directory/applicationTemplates/instantiate\nInstantiate gallery applications from application templates\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/cloudProvisioning/allProperties/allTasks\nRead and configure all properties of Microsoft Entra cloud provisioning service.\nmicrosoft.directory/deletedItems.applications/delete\nPermanently delete applications, which can no longer be restored\nmicrosoft.directory/deletedItems.applications/restore\nRestore soft deleted applications to original state\nmicrosoft.directory/domains/allProperties/read\nRead all properties of domains\nmicrosoft.directory/domains/federation/update\nUpdate federation property of domains\nmicrosoft.directory/domains/federationConfiguration/basic/update\nUpdate basic federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/create\nCreate federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/delete\nDelete federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/standard/read\nRead standard properties of federation configuration for domains\nmicrosoft.directory/hybridAuthenticationPolicy/allProperties/allTasks\nManage hybrid authentication policy in Microsoft Entra ID\nmicrosoft.directory/onPremisesSynchronization/basic/update\nUpdate basic on-premises directory synchronization information\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nmicrosoft.directory/organization/dirSync/update\nUpdate the organization directory sync property\nmicrosoft.directory/passwordHashSync/allProperties/allTasks\nManage all aspects of Password Hash Synchronization (PHS) in Microsoft Entra ID\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/servicePrincipals/audience/update\nUpdate audience properties on service principals\nmicrosoft.directory/servicePrincipals/authentication/update\nUpdate authentication properties on service principals\nmicrosoft.directory/servicePrincipals/basic/update\nUpdate basic properties on service principals\nmicrosoft.directory/servicePrincipals/create\nCreate service principals\nmicrosoft.directory/servicePrincipals/delete\nDelete service principals\nmicrosoft.directory/servicePrincipals/disable\nDisable service principals\nmicrosoft.directory/servicePrincipals/enable\nEnable service principals\nmicrosoft.directory/servicePrincipals/notes/update\nUpdate notes of service principals\nmicrosoft.directory/servicePrincipals/owners/update\nUpdate owners of service principals\nmicrosoft.directory/servicePrincipals/permissions/update\nUpdate permissions of service principals\nmicrosoft.directory/servicePrincipals/policies/update\nUpdate policies of service principals\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/credentials/manage\nManage cloud tenant to cloud tenant application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/jobs/manage\nStart, restart, and pause cloud tenant to cloud tenant application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToCloudTenant/schema/manage\nCreate and manage cloud tenant to cloud tenant application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/credentials/manage\nManage application provisioning secrets and credentials.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/jobs/manage\nStart, restart, and pause application provisioning synchronization jobs.\nmicrosoft.directory/servicePrincipals/synchronization.cloudTenantToExternalSystem/schema/manage\nCreate and manage application provisioning synchronization jobs and schema.\nmicrosoft.directory/servicePrincipals/synchronization/standard/read\nRead provisioning settings associated with your service principal\nmicrosoft.directory/servicePrincipals/synchronizationCredentials/manage\nManage application provisioning secrets and credentials\nmicrosoft.directory/servicePrincipals/synchronizationJobs/manage\nStart, restart, and pause application provisioning synchronization jobs\nmicrosoft.directory/servicePrincipals/synchronizationSchema/manage\nCreate and manage application provisioning synchronization jobs and schema\nmicrosoft.directory/servicePrincipals/tag/update\nUpdate the tag property for service principals\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.directory/users/authorizationInfo/update\nUpdate the multivalued Certificate user IDs property of users\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nIdentity Governance Administrator\nUsers with this role can manage Microsoft Entra ID Governance configuration, including access packages, access reviews, catalogs and policies, ensuring access is approved and reviewed and guest users who no longer need access are removed.\nActions\nDescription\nmicrosoft.directory/accessReviews/allProperties/allTasks\nCreate and delete access reviews, and read and update all properties of access reviews in Microsoft Entra ID\nmicrosoft.directory/accessReviews/definitions.applications/allProperties/allTasks\nManage access reviews of application role assignments in Microsoft Entra ID\nmicrosoft.directory/accessReviews/definitions.entitlementManagement/allProperties/allTasks\nManage access reviews for access package assignments in entitlement management\nmicrosoft.directory/accessReviews/definitions.groups/allProperties/read\nRead all properties of access reviews for membership in Security and Microsoft 365 groups, including role-assignable groups.\nmicrosoft.directory/accessReviews/definitions.groups/allProperties/update\nUpdate all properties of access reviews for membership in Security and Microsoft 365 groups, excluding role-assignable groups.\nmicrosoft.directory/accessReviews/definitions.groups/create\nCreate access reviews for membership in Security and Microsoft 365 groups.\nmicrosoft.directory/accessReviews/definitions.groups/delete\nDelete access reviews for membership in Security and Microsoft 365 groups.\nmicrosoft.directory/entitlementManagement/allProperties/allTasks\nCreate and delete resources, and read and update all properties in Microsoft Entra entitlement management\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nInsights Administrator\nUsers in this role can access the full set of administrative capabilities in the Microsoft Viva Insights app. This role has the ability to read directory information, monitor service health, file support tickets, and access the Insights Administrator settings aspects.\nLearn more\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.insights/allEntities/allProperties/allTasks\nManage all aspects of Insights app\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nInsights Analyst\nAssign the Insights Analyst role to users who need to do the following:\nAnalyze data in the Microsoft Viva Insights app, but can't manage any configuration settings\nCreate, manage, and run queries\nView basic settings and reports in the Microsoft 365 admin center\nCreate and manage service requests in the Microsoft 365 admin center\nLearn more\nActions\nDescription\nmicrosoft.insights/queries/allProperties/allTasks\nRun and manage queries in Viva Insights\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nInsights Business Leader\nUsers in this role can access a set of dashboards and insights via the Microsoft Viva Insights app. This includes full access to all dashboards and presented insights and data exploration functionality. Users in this role do not have access to product configuration settings, which is the responsibility of the Insights Administrator role.\nLearn more\nActions\nDescription\nmicrosoft.insights/programs/allProperties/update\nDeploy and manage programs in Insights app\nmicrosoft.insights/reports/allProperties/read\nView reports and dashboard in Insights app\nIntune Administrator\nThis is a\nprivileged role\n. Users with this role have global permissions within Microsoft Intune Online, when the service is present. Additionally, this role contains the ability to manage users and devices in order to associate policy, as well as create and manage groups. For more information, see\nRole-based administration control (RBAC) with Microsoft Intune\n.\nThis role can create and manage all security groups. However, Intune Administrator does not have admin rights over Microsoft 365 groups. That means the admin cannot update owners or memberships of all Microsoft 365 groups in the organization. However, he/she can manage the Microsoft 365 group that he creates which comes as a part of his/her end-user privileges. So, any Microsoft 365 group (not security group) that he/she creates should be counted against his/her quota of 250.\nNote\nIn the Microsoft Graph API and Microsoft Graph PowerShell, this role is named Intune Service Administrator. In the\nAzure portal\n, it is named Intune Administrator.\nActions\nDescription\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.cloudPC/allEntities/allProperties/allTasks\nManage all aspects of Windows 365\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/contacts/basic/update\nUpdate basic properties on contacts\nmicrosoft.directory/contacts/create\nCreate contacts\nmicrosoft.directory/contacts/delete\nDelete contacts\nmicrosoft.directory/deletedItems.devices/delete\nPermanently delete devices, which can no longer be restored\nmicrosoft.directory/deletedItems.devices/restore\nRestore soft deleted devices to original state\nmicrosoft.directory/deviceLocalCredentials/password/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, including the password\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/basic/update\nUpdate basic properties on devices\nmicrosoft.directory/devices/create\nCreate devices (enroll in Microsoft Entra ID)\nmicrosoft.directory/devices/delete\nDelete devices from Microsoft Entra ID\nmicrosoft.directory/devices/disable\nDisable devices in Microsoft Entra ID\nmicrosoft.directory/devices/enable\nEnable devices in Microsoft Entra ID\nmicrosoft.directory/devices/extensionAttributeSet1/update\nUpdate the extensionAttribute1 to extensionAttribute5 properties on devices\nmicrosoft.directory/devices/extensionAttributeSet2/update\nUpdate the extensionAttribute6 to extensionAttribute10 properties on devices\nmicrosoft.directory/devices/extensionAttributeSet3/update\nUpdate the extensionAttribute11 to extensionAttribute15 properties on devices\nmicrosoft.directory/devices/registeredOwners/update\nUpdate registered owners of devices\nmicrosoft.directory/devices/registeredUsers/update\nUpdate registered users of devices\nmicrosoft.directory/groups.security/assignedLabels/update\nUpdate the assigned labels property on Security groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.security/basic/update\nUpdate basic properties on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/classification/update\nUpdate the classification property on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/create\nCreate Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/delete\nDelete Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/dynamicMembershipRule/update\nUpdate the dynamic membership rule on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/members/update\nUpdate members of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/owners/update\nUpdate owners of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/visibility/update\nUpdate the visibility property on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/photo/update\nUpdate photo of users\nmicrosoft.intune/allEntities/allTasks\nManage all aspects of Microsoft Intune\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/read\nRead all aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nIoT Device Administrator\nAssign the IoT Device Administrator role to users who need to do the following tasks:\nProvision new IoT devices using device templates\nManage the lifecycle of IoT devices\nConfigure certificates used for IoT device authentication\nManage the lifecycle of IoT device templates\nLearn more\nActions\nDescription\nmicrosoft.directory/certificateBasedDeviceAuthConfigurations/create\nCreate Certificate Authorities configurations for IoT Device trust and authentication\nmicrosoft.directory/certificateBasedDeviceAuthConfigurations/credentials/update\nUpdate crendential related properties on certificate authority configurations for Internet of Things (IoT) device trust and authentication\nmicrosoft.directory/certificateBasedDeviceAuthConfigurations/delete\nDelete certificate authority configurations for Internet of Things (IoT) device\nmicrosoft.directory/certificateBasedDeviceAuthConfigurations/standard/read\nRead standard properties on certificate authority configurations for Internet of Things (IoT) device trust and authentication\nmicrosoft.directory/deviceTemplates/create\nCreate Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/createDeviceFromTemplate\nCreate IoT Device from Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/delete\nDelete Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/deviceInstances/read\nRead device instances from Internet of Things (IoT) device links\nmicrosoft.directory/deviceTemplates/owners/read\nRead owners on Internet of Things (IoT) device templates\nmicrosoft.directory/deviceTemplates/owners/update\nUpdate owners on Internet of Things (IoT) device templates\nKaizala Administrator\nUsers with this role have global permissions to manage settings within Microsoft Kaizala, when the service is present, as well as the ability to manage support tickets and monitor service health. Additionally, the user can access reports related to adoption & usage of Kaizala by Organization members and business reports generated using the Kaizala actions.\nActions\nDescription\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nKnowledge Administrator\nUsers in this role have full access to all knowledge, learning and intelligent features settings in the Microsoft 365 admin center. They have a general understanding of the suite of products, licensing details and have responsibility to control access. Knowledge Administrator can create and manage content, like topics, acronyms and learning resources. Additionally, these users can create content centers, monitor service health, and create service requests.\nActions\nDescription\nmicrosoft.directory/groups.security/basic/update\nUpdate basic properties on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/create\nCreate Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/createAsOwner\nCreate Security groups, excluding role-assignable groups. Creator is added as the first owner.\nmicrosoft.directory/groups.security/delete\nDelete Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/members/update\nUpdate members of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/owners/update\nUpdate owners of Security groups, excluding role-assignable groups\nmicrosoft.office365.knowledge/contentUnderstanding/allProperties/allTasks\nRead and update all properties of content understanding in Microsoft 365 admin center\nmicrosoft.office365.knowledge/knowledgeNetwork/allProperties/allTasks\nRead and update all properties of knowledge network in Microsoft 365 admin center\nmicrosoft.office365.knowledge/learningSources/allProperties/allTasks\nManage learning sources and all their properties in Learning App.\nmicrosoft.office365.protectionCenter/sensitivityLabels/allProperties/read\nRead all properties of sensitivity labels in the Security and Compliance centers\nmicrosoft.office365.sharePoint/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in SharePoint\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nKnowledge Manager\nUsers in this role can create and manage content, like topics, acronyms and learning content. These users are primarily responsible for the quality and structure of knowledge. This user has full rights to topic management actions to confirm a topic, approve edits, or delete a topic. This role can also manage taxonomies as part of the term store management tool and create content centers.\nActions\nDescription\nmicrosoft.directory/groups.security/basic/update\nUpdate basic properties on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/create\nCreate Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/createAsOwner\nCreate Security groups, excluding role-assignable groups. Creator is added as the first owner.\nmicrosoft.directory/groups.security/delete\nDelete Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/members/update\nUpdate members of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/owners/update\nUpdate owners of Security groups, excluding role-assignable groups\nmicrosoft.office365.knowledge/contentUnderstanding/analytics/allProperties/read\nRead analytics reports of content understanding in Microsoft 365 admin center\nmicrosoft.office365.knowledge/knowledgeNetwork/topicVisibility/allProperties/allTasks\nManage topic visibility of knowledge network in Microsoft 365 admin center\nmicrosoft.office365.sharePoint/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in SharePoint\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nLicense Administrator\nUsers in this role can read, add, remove, and update license assignments on users, groups (using group-based licensing), and manage the usage location on users. The role does not grant the ability to purchase or manage subscriptions, create or manage groups, or create or manage users beyond the usage location. This role has no access to view, create, or manage support tickets.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/groups/assignLicense\nAssign product licenses to groups for group-based licensing\nmicrosoft.directory/groups/reprocessLicenseAssignment\nReprocess license assignments for group-based licensing\nmicrosoft.directory/users/assignLicense\nManage user licenses\nmicrosoft.directory/users/reprocessLicenseAssignment\nReprocess license assignments for users\nmicrosoft.directory/users/usageLocation/update\nUpdate usage location of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nLifecycle Workflows Administrator\nThis is a\nprivileged role\n. Assign the Lifecycle Workflows Administrator role to users who need to do the following tasks:\nCreate and manage all aspects of workflows and tasks associated with Lifecycle Workflows in Microsoft Entra ID\nCheck the execution of scheduled workflows\nLaunch on-demand workflow runs\nInspect workflow execution logs\nActions\nDescription\nmicrosoft.directory/lifecycleWorkflows/workflows/allProperties/allTasks\nManage all aspects of lifecycle workflows and tasks in Microsoft Entra ID\nmicrosoft.directory/organization/strongAuthentication/read\nRead strong authentication properties of an organization\nmicrosoft.directory/users/lifeCycleInfo/read\nRead lifecycle information of users, such as employeeLeaveDateTime\nMessage Center Privacy Reader\nUsers in this role can monitor all notifications in the Message Center, including data privacy messages. Message Center Privacy Readers get email notifications including those related to data privacy and they can unsubscribe using Message Center Preferences. Only the Global Administrator and the Message Center Privacy Reader can read data privacy messages. Additionally, this role contains the ability to view groups, domains, and subscriptions. This role has no permission to view, create, or manage service requests.\nActions\nDescription\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.messageCenter/securityMessages/read\nRead security messages in Message Center in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMessage Center Reader\nUsers in this role can monitor notifications and advisory health updates in\nMessage center\nfor their organization on configured services such as Exchange, Intune, and Microsoft Teams. Message Center Readers receive weekly email digests of posts, updates, and can share message center posts in Microsoft 365. In Microsoft Entra ID, users assigned to this role will only have read-only access on Microsoft Entra services such as users and groups. This role has no access to view, create, or manage support tickets.\nActions\nDescription\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMicrosoft 365 Backup Administrator\nAssign the Microsoft 365 Backup Administrator role to users who need to do the following tasks:\nManage all aspects of Microsoft 365 Backup\nCreate, edit, and manage backup configuration policies for SharePoint, OneDrive, and Exchange Online\nPerform restore operations for backed-up SharePoint sites, OneDrive accounts, and Exchange mailboxes\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 Backup\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMicrosoft 365 Migration Administrator\nAssign the Microsoft 365 Migration Administrator role to users who need to do the following tasks:\nUse Migration Manager in the Microsoft 365 admin center to manage content migration to Microsoft 365, including Teams, OneDrive for Business, and SharePoint sites, from Google Drive, Dropbox, Box, and Egnyte\nSelect migration sources, create migration inventories (such as Google Drive user lists), schedule and execute migrations, and download reports\nCreate new SharePoint sites if the destination sites don't already exist, create SharePoint lists under the SharePoint admin sites, and create and update items in SharePoint lists\nManage migration project settings and migration lifecycle for tasks\nManage permission mappings from source to destination\nNote\nThis role doesn't allow you to migrate from file share sources using the SharePoint admin center. You can use the SharePoint Administrator role to migrate from file share sources.\nLearn more\nActions\nDescription\nmicrosoft.office365.migrations/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 migrations\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMicrosoft Entra Joined Device Local Administrator\nThis role is available for assignment only as an additional local administrator in\nDevice settings\n. Users with this role become local machine administrators on all Windows 10 devices that are joined to Microsoft Entra ID. They do not have the ability to manage devices objects in Microsoft Entra ID.\nActions\nDescription\nmicrosoft.directory/groupSettings/standard/read\nRead basic properties on group settings\nmicrosoft.directory/groupSettingTemplates/standard/read\nRead basic properties on group setting templates\nMicrosoft Graph Data Connect Administrator\nAssign the Microsoft Graph Data Connect Administrator role to users who need to do the following tasks:\nAccess the full set of administrative capabilities of Microsoft Graph Data Connect\nManage Microsoft Graph Data Connect settings in a tenant\nEnable or disable the Microsoft Graph Data Connect service\nConfigure dataset workload selections in Microsoft Graph Data Connect\nConfigure cross-tenant data movement settings in Microsoft Graph Data Connect\nView, approve, or deny application authorization requests for Microsoft Graph Data Connect\nView, create, update, or delete application registrations for Microsoft Graph Data Connect\nLearn more\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.graph.dataConnect/allEntities/allProperties/allTasks\nManage aspects of Microsoft Graph Data Connect\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMicrosoft Hardware Warranty Administrator\nAssign the Microsoft Hardware Warranty Administrator role to users who need to do the following tasks:\nCreate new warranty claims for Microsoft manufactured hardware, like Surface and HoloLens\nSearch and read opened or closed warranty claims\nSearch and read warranty claims by serial number\nCreate, read, update, and delete shipping addresses\nRead shipping status for open warranty claims\nCreate and manage service requests in the Microsoft 365 admin center\nRead Message center announcements in the Microsoft 365 admin center\nA warranty claim is a request to have the hardware repaired or replaced in accordance with the terms of the warranty. For more information, see\nSelf-serve your Surface warranty & service requests\n.\nActions\nDescription\nmicrosoft.hardware.support/shippingAddress/allProperties/allTasks\nCreate, read, update, and delete shipping addresses for Microsoft hardware warranty claims, including shipping addresses created by others\nmicrosoft.hardware.support/shippingStatus/allProperties/read\nRead shipping status for open Microsoft hardware warranty claims\nmicrosoft.hardware.support/warrantyClaims/allProperties/allTasks\nCreate and manage all aspects of Microsoft hardware warranty claims\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nMicrosoft Hardware Warranty Specialist\nAssign the Microsoft Hardware Warranty Specialist role to users who need to do the following tasks:\nCreate new warranty claims for Microsoft manufactured hardware, like Surface and HoloLens\nRead warranty claims that they created\nRead and update existing shipping addresses\nRead shipping status for open warranty claims they created\nCreate and manage service requests in the Microsoft 365 admin center\nA warranty claim is a request to have the hardware repaired or replaced in accordance with the terms of the warranty. For more information, see\nSelf-serve your Surface warranty & service requests\n.\nActions\nDescription\nmicrosoft.hardware.support/shippingAddress/allProperties/read\nRead shipping addresses for Microsoft hardware warranty claims, including existing shipping addresses created by others\nmicrosoft.hardware.support/shippingStatus/allProperties/read\nRead shipping status for open Microsoft hardware warranty claims\nmicrosoft.hardware.support/warrantyClaims/allProperties/read\nRead Microsoft hardware warranty claims\nmicrosoft.hardware.support/warrantyClaims/createAsOwner\nCreate Microsoft hardware warranty claims where creator is the owner\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nNetwork Administrator\nUsers in this role can review network perimeter architecture recommendations from Microsoft that are based on network telemetry from their user locations. Network performance for Microsoft 365 relies on careful enterprise customer network perimeter architecture which is generally user location specific. This role allows for editing of discovered user locations and configuration of network parameters for those locations to facilitate improved telemetry measurements and design recommendations.\nActions\nDescription\nmicrosoft.office365.network/locations/allProperties/allTasks\nManage all aspects of network locations\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nOffice Apps Administrator\nUsers in this role can manage Microsoft 365 apps' cloud settings. This includes managing cloud policies, self-service download management and the ability to view Office apps related report. This role additionally grants the ability to manage support tickets, and monitor service health within the main admin center. Users assigned to this role can also manage communication of new features in Office apps.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.userCommunication/allEntities/allTasks\nRead and update what's new messages visibility\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nOrganizational Branding Administrator\nAssign the Organizational Branding Administrator role to users who need to do the following tasks:\nManage all aspects of organizational branding in a tenant\nRead, create, update, and delete branding themes\nManage the default branding theme and all branding localization themes\nActions\nDescription\nmicrosoft.directory/loginOrganizationBranding/allProperties/allTasks\nCreate and delete loginTenantBranding, and read and update all properties\nOrganizational Data Source Administrator\nAssign the Organizational Data Source Administrator role to users who need to do the following tasks:\nManage settings related to ingesting and managing organizational data for Microsoft 365 and Microsoft Viva applications\nUpload, update, and delete the ingested organizational data in Microsoft 365 and Microsoft Viva applications\nExport organizational data from the authorized applications\nLearn more\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.microsoft365.organizationalData/allEntities/allProperties/allTasks\nManage all aspects of organizational data in Microsoft 365\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nOrganizational Messages Approver\nAssign the Organizational Messages Approver role to users who need to do the following tasks:\nReview, approve, or reject new organizational messages for delivery in the Microsoft 365 admin center before they are sent to users using the Microsoft 365 Organizational Messages platform\nRead all aspects of organizational messages\nRead basic properties on all resources in the Microsoft 365 admin center\nActions\nDescription\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/read\nRead all aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/update\nApprove or reject new organizational messages for delivery in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nOrganizational Messages Writer\nAssign the Organizational Messages Writer role to users who need to do the following tasks:\nWrite, publish, and delete organizational messages using Microsoft 365 admin center or Microsoft Intune\nManage organizational message delivery options using Microsoft 365 admin center or Microsoft Intune\nRead organizational message delivery results using Microsoft 365 admin center or Microsoft Intune\nView usage reports and most settings in the Microsoft 365 admin center, but can't make changes\nActions\nDescription\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/allTasks\nManage all authoring aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.usageReports/allEntities/standard/read\nRead tenant-level aggregated Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nPartner Tier1 Support\nThis is a\nprivileged role\n. Do not use. This role has been deprecated and will be removed from Microsoft Entra ID in the future. This role is intended for use by a small number of Microsoft resale partners, and is not intended for general use.\nImportant\nThis role can reset passwords and invalidate refresh tokens for only non-administrators. This role should not be used because it is deprecated.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/applications/appRoles/update\nUpdate the appRoles property on all types of applications\nmicrosoft.directory/applications/audience/update\nUpdate the audience property for applications\nmicrosoft.directory/applications/authentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/basic/update\nUpdate basic properties for applications\nmicrosoft.directory/applications/credentials/update\nUpdate application credentials\nmicrosoft.directory/applications/notes/update\nUpdate notes of applications\nmicrosoft.directory/applications/owners/update\nUpdate owners of applications\nmicrosoft.directory/applications/permissions/update\nUpdate exposed permissions and required permissions on all types of applications\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/applications/tag/update\nUpdate tags of applications\nmicrosoft.directory/contacts/basic/update\nUpdate basic properties on contacts\nmicrosoft.directory/contacts/create\nCreate contacts\nmicrosoft.directory/contacts/delete\nDelete contacts\nmicrosoft.directory/deletedItems.groups/restore\nRestore soft deleted groups to original state\nmicrosoft.directory/deletedItems.users/restore\nRestore soft deleted users to original state\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups/create\nCreate Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/delete\nDelete Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/owners/update\nUpdate owners of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/restore\nRestore groups from soft-deleted container\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/users/assignLicense\nManage user licenses\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/create\nAdd users\nmicrosoft.directory/users/delete\nDelete users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.directory/users/photo/update\nUpdate photo of users\nmicrosoft.directory/users/restore\nRestore deleted users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nPartner Tier2 Support\nThis is a\nprivileged role\n. Do not use. This role has been deprecated and will be removed from Microsoft Entra ID in the future. This role is intended for use by a small number of Microsoft resale partners, and is not intended for general use.\nImportant\nThis role can reset passwords and invalidate refresh tokens for all non-administrators and administrators (including Global Administrators). This role should not be used because it is deprecated.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/applications/appRoles/update\nUpdate the appRoles property on all types of applications\nmicrosoft.directory/applications/audience/update\nUpdate the audience property for applications\nmicrosoft.directory/applications/authentication/update\nUpdate authentication on all types of applications\nmicrosoft.directory/applications/basic/update\nUpdate basic properties for applications\nmicrosoft.directory/applications/credentials/update\nUpdate application credentials\nmicrosoft.directory/applications/notes/update\nUpdate notes of applications\nmicrosoft.directory/applications/owners/update\nUpdate owners of applications\nmicrosoft.directory/applications/permissions/update\nUpdate exposed permissions and required permissions on all types of applications\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/applications/tag/update\nUpdate tags of applications\nmicrosoft.directory/contacts/basic/update\nUpdate basic properties on contacts\nmicrosoft.directory/contacts/create\nCreate contacts\nmicrosoft.directory/contacts/delete\nDelete contacts\nmicrosoft.directory/deletedItems.groups/restore\nRestore soft deleted groups to original state\nmicrosoft.directory/deletedItems.users/restore\nRestore soft deleted users to original state\nmicrosoft.directory/domains/allProperties/allTasks\nCreate and delete domains, and read and update all properties\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups/create\nCreate Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/delete\nDelete Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/owners/update\nUpdate owners of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/restore\nRestore groups from soft-deleted container\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/organization/basic/update\nUpdate basic properties on organization\nmicrosoft.directory/roleAssignments/allProperties/allTasks\nCreate and delete role assignments, and read and update all role assignment properties\nmicrosoft.directory/roleDefinitions/allProperties/allTasks\nCreate and delete role definitions, and read and update all properties\nmicrosoft.directory/scopedRoleMemberships/allProperties/allTasks\nCreate and delete scopedRoleMemberships, and read and update all properties\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/subscribedSkus/standard/read\nRead basic properties on subscriptions\nmicrosoft.directory/users/assignLicense\nManage user licenses\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/create\nAdd users\nmicrosoft.directory/users/delete\nDelete users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.directory/users/photo/update\nUpdate photo of users\nmicrosoft.directory/users/restore\nRestore deleted users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nPassword Administrator\nThis is a\nprivileged role\n. Users with this role have limited ability to manage passwords. This role does not grant the ability to manage service requests or monitor service health. Whether a Password Administrator can reset a user's password depends on the role the user is assigned. For a list of the roles that a Password Administrator can reset passwords for, see\nWho can reset passwords\n.\nUsers with this role\ncannot\ndo the following:\nCannot change the credentials or reset MFA for members and owners of a\nrole-assignable group\n.\nActions\nDescription\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nPeople Administrator\nAssign the People Administrator role to users who need to do the following tasks:\nUpdate profile photos for all users including administrators\nUpdate people settings for all users, such as pronouns, name pronunciation, and profile card settings\nActions\nDescription\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.people/users/photo/read\nRead profile photo of user\nmicrosoft.people/users/photo/update\nUpdate profile photo of user\nmicrosoft.peopleAdmin/organization/allProperties/read\nRead people settings for users, such as pronouns, name pronunciation, and profile card settings\nmicrosoft.peopleAdmin/organization/allProperties/update\nUpdate people settings for users, such as pronouns, name pronunciation, and profile card settings\nPermissions Management Administrator\nAssign the Permissions Management Administrator role to users who need to do the following tasks:\nManage all aspects of Microsoft Entra Permissions Management, when the service is present\nLearn more about Permissions Management roles and polices at\nView information about roles/policies\n.\nActions\nDescription\nmicrosoft.permissionsManagement/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Entra Permissions Management\nPlaces Administrator\nAssign the Places Administrator role to users who need to do the following tasks:\nManage all aspects of the Microsoft Places service\nConfigure and manage buildings, floors, rooms, and desks\nOversee and manage associated booking policies\nLearn more\nActions\nDescription\nmicrosoft.places/allEntities/allProperties/allTasks\nManage all aspects of the Microsoft Places service\nPower Platform Administrator\nUsers in this role can create and manage all aspects of environments, Power Apps, Flows, Data Loss Prevention policies. Additionally, users with this role have the ability to manage support tickets and monitor service health.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.dynamics365/allEntities/allTasks\nManage all aspects of Dynamics 365\nmicrosoft.flow/allEntities/allTasks\nManage all aspects of Microsoft Power Automate\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.powerApps/allEntities/allTasks\nManage all aspects of Power Apps\nPrinter Administrator\nUsers in this role can register printers and manage all aspects of all printer configurations in the Microsoft Universal Print solution, including the Universal Print Connector settings. They can consent to all delegated print permission requests. Printer Administrators also have access to print reports.\nActions\nDescription\nmicrosoft.azure.print/allEntities/allProperties/allTasks\nCreate and delete printers and connectors, and read and update all properties in Microsoft Print\nPrinter Technician\nUsers with this role can register printers and manage printer status in the Microsoft Universal Print solution. They can also read all connector information. Key task a Printer Technician cannot do is set user permissions on printers and sharing printers.\nActions\nDescription\nmicrosoft.azure.print/connectors/allProperties/read\nRead all properties of connectors in Microsoft Print\nmicrosoft.azure.print/printers/allProperties/read\nRead all properties of printers in Microsoft Print\nmicrosoft.azure.print/printers/basic/update\nUpdate basic properties of printers in Microsoft Print\nmicrosoft.azure.print/printers/register\nRegister printers in Microsoft Print\nmicrosoft.azure.print/printers/unregister\nUnregister printers in Microsoft Print\nPrivileged Authentication Administrator\nThis is a\nprivileged role\n. Assign the Privileged Authentication Administrator role to users who need to do the following:\nSet or reset any authentication method (including passwords) for any user, including Global Administrators.\nDelete or restore any users, including Global Administrators. For more information, see\nWho can perform sensitive actions\n.\nForce users to re-register against existing non-password credential (such as MFA or FIDO2) and revoke\nremember MFA on the device\n, prompting for MFA on the next sign-in of all users.\nUpdate sensitive properties for all users. For more information, see\nWho can perform sensitive actions\n.\nCreate and manage support tickets in Azure and the Microsoft 365 admin center.\nConfigure certificate authorities with a PKI-based trust store (preview)\nUsers with this role\ncannot\ndo the following:\nCannot manage per-user MFA in the legacy MFA management portal.\nThe following table compares the capabilities of authentication-related roles.\nRole\nManage user's auth methods\nManage per-user MFA\nManage MFA settings\nManage auth method policy\nManage password protection policy\nUpdate sensitive properties\nDelete and restore users\nAuthentication Administrator\nYes for\nsome users\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nPrivileged Authentication Administrator\nYes for all users\nNo\nNo\nNo\nNo\nYes for all users\nYes for all users\nAuthentication Policy Administrator\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nUser Administrator\nNo\nNo\nNo\nNo\nNo\nYes for\nsome users\nYes for\nsome users\nImportant\nUsers with this role can change credentials for people who may have access to sensitive or private information or critical configuration inside and outside of Microsoft Entra ID. Changing the credentials of a user may mean the ability to assume that user's identity and permissions. For example:\nApplication Registration and Enterprise Application owners, who can manage credentials of apps they own. Those apps may have privileged permissions in Microsoft Entra ID and elsewhere not granted to Authentication Administrators. Through this path an Authentication Administrator can assume the identity of an application owner and then further assume the identity of a privileged application by updating the credentials for the application.\nAzure subscription owners, who may have access to sensitive or private information or critical configuration in Azure.\nSecurity Group and Microsoft 365 group owners, who can manage group membership. Those groups may grant access to sensitive or private information or critical configuration in Microsoft Entra ID and elsewhere.\nAdministrators in other services outside of Microsoft Entra ID like Exchange Online, Microsoft 365 Defender portal, and Microsoft Purview compliance portal, and human resources systems.\nNon-administrators like executives, legal counsel, and human resources employees who may have access to sensitive or private information.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/deletedItems.users/restore\nRestore soft deleted users to original state\nmicrosoft.directory/users/authenticationMethods/basic/update\nUpdate basic properties of authentication methods for users\nmicrosoft.directory/users/authenticationMethods/create\nUpdate authentication methods for users\nmicrosoft.directory/users/authenticationMethods/delete\nDelete authentication methods for users\nmicrosoft.directory/users/authenticationMethods/standard/read\nRead standard properties of authentication methods for users\nmicrosoft.directory/users/authorizationInfo/update\nUpdate the multivalued Certificate user IDs property of users\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/delete\nDelete users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.directory/users/restore\nRestore deleted users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nPrivileged Role Administrator\nThis is a\nprivileged role\n. Users with this role can manage role assignments in Microsoft Entra ID, as well as within Microsoft Entra Privileged Identity Management. They can create and manage groups that can be assigned to Microsoft Entra roles. In addition, this role allows management of all aspects of Privileged Identity Management and administrative units.\nImportant\nThis role grants the ability to manage assignments for all Microsoft Entra roles including the Global Administrator role. This role does not include any other privileged abilities in Microsoft Entra ID like creating or updating users. However, users assigned to this role can grant themselves or others additional privilege by assigning additional roles.\nActions\nDescription\nmicrosoft.directory/accessReviews/definitions.applications/allProperties/read\nRead all properties of access reviews of application role assignments in Microsoft Entra ID\nmicrosoft.directory/accessReviews/definitions.directoryRoles/allProperties/allTasks\nManage access reviews for Microsoft Entra role assignments\nmicrosoft.directory/accessReviews/definitions.groups/allProperties/read\nRead all properties of access reviews for membership in Security and Microsoft 365 groups, including role-assignable groups.\nmicrosoft.directory/accessReviews/definitions.groupsAssignableToRoles/allProperties/update\nUpdate all properties of access reviews for membership in groups that are assignable to Microsoft Entra roles\nmicrosoft.directory/accessReviews/definitions.groupsAssignableToRoles/create\nCreate access reviews for membership in groups that are assignable to Microsoft Entra roles\nmicrosoft.directory/accessReviews/definitions.groupsAssignableToRoles/delete\nDelete access reviews for membership in groups that are assignable to Microsoft Entra roles\nmicrosoft.directory/administrativeUnits/allProperties/allTasks\nCreate and manage administrative units (including members)\nmicrosoft.directory/authorizationPolicy/allProperties/allTasks\nManage all aspects of authorization policy\nmicrosoft.directory/directoryRoles/allProperties/allTasks\nCreate and delete directory roles, and read and update all properties\nmicrosoft.directory/groupsAssignableToRoles/allProperties/update\nUpdate role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/assignLicense\nAssign a license to role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/create\nCreate role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/delete\nDelete role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/reprocessLicenseAssignment\nReprocess license assignments to role-assignable groups\nmicrosoft.directory/groupsAssignableToRoles/restore\nRestore role-assignable groups\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/permissionGrantPolicies/allProperties/read\nRead all properties of permission grant policies\nmicrosoft.directory/permissionGrantPolicies/allProperties/update\nUpdate all properties of permission grant policies\nmicrosoft.directory/permissionGrantPolicies/create\nCreate permission grant policies\nmicrosoft.directory/permissionGrantPolicies/delete\nDelete permission grant policies\nmicrosoft.directory/privilegedIdentityManagement/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Privileged Identity Management\nmicrosoft.directory/roleAssignments/allProperties/allTasks\nCreate and delete role assignments, and read and update all role assignment properties\nmicrosoft.directory/roleDefinitions/allProperties/allTasks\nCreate and delete role definitions, and read and update all properties\nmicrosoft.directory/scopedRoleMemberships/allProperties/allTasks\nCreate and delete scopedRoleMemberships, and read and update all properties\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/servicePrincipals/managePermissionGrantsForAll.microsoft-company-admin\nGrant consent for any permission to any application\nmicrosoft.directory/servicePrincipals/permissions/update\nUpdate permissions of service principals\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nReports Reader\nUsers with this role can view usage reporting data and the reports dashboard in Microsoft 365 admin center and the adoption context pack in Fabric and Power BI. Additionally, the role provides access to all sign-in logs, audit logs, and activity reports in Microsoft Entra ID and data returned by the Microsoft Graph reporting API. A user assigned to the Reports Reader role can access only relevant usage and adoption metrics. They don't have any admin permissions to configure settings or access the product-specific admin centers like Exchange. This role has no access to view, create, or manage support tickets.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSearch Administrator\nUsers in this role have full access to all Microsoft Search management features in the Microsoft 365 admin center. Additionally, these users can view the message center, monitor service health, and create service requests.\nActions\nDescription\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.search/content/manage\nCreate and delete content, and read and update all properties in Microsoft Search\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSearch Editor\nUsers in this role can create, manage, and delete content for Microsoft Search in the Microsoft 365 admin center, including bookmarks, Q&As, and locations.\nActions\nDescription\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.search/content/manage\nCreate and delete content, and read and update all properties in Microsoft Search\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSecurity Administrator\nThis is a\nprivileged role\n. Users with this role have permissions to manage security-related features in the Microsoft 365 Defender portal, Microsoft Entra ID Protection, Microsoft Entra Authentication, Azure Information Protection, and Microsoft Purview compliance portal. For more information about Office 365 permissions, see\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\n.\nIn\nCan do\nMicrosoft 365 Defender portal\nMonitor security-related policies across Microsoft 365 services\nManage security threats and alerts\nView reports\nMicrosoft Entra ID Protection\nAll permissions of the Security Reader role\nPerform all ID Protection operations except for resetting passwords\nPrivileged Identity Management\nAll permissions of the Security Reader role\nCannot\nmanage Microsoft Entra role assignments or settings\nMicrosoft Purview compliance portal\nManage security policies\nView, investigate, and respond to security threats\nView reports\nAzure Advanced Threat Protection\nMonitor and respond to suspicious security activity\nMicrosoft Defender for Endpoint\nAssign roles\nManage machine groups\nConfigure endpoint threat detection and automated remediation\nView, investigate, and respond to alerts\nView machines/device inventory\nIntune\nMaps to the\nIntune Endpoint Security Manager role\nMicrosoft Defender for Cloud Apps\nAdd admins, add policies and settings, upload logs and perform governance actions\nMicrosoft 365 service health\nView the health of Microsoft 365 services\nSmart lockout\nDefine the threshold and duration for lockouts when failed sign-in events happen.\nPassword Protection\nConfigure custom banned password list or on-premises password protection.\nCross-tenant synchronization\nConfigure cross-tenant access settings for users in another tenant. Security Administrators can't directly create and delete users, but can indirectly create and delete synchronized users from another tenant when both tenants are configured for cross-tenant synchronization, which is a privileged permission.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/applications/policies/update\nUpdate policies of applications\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/conditionalAccessPolicies/basic/update\nUpdate basic properties for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/create\nCreate Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/delete\nDelete Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/owners/read\nRead the owners of Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/owners/update\nUpdate owners for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/policyAppliedTo/read\nRead the \"applied to\" property for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/standard/read\nRead Conditional Access for policies\nmicrosoft.directory/conditionalAccessPolicies/tenantDefault/update\nUpdate the default tenant for Conditional Access policies\nmicrosoft.directory/crossTenantAccessPolicy/allowedCloudEndpoints/update\nUpdate allowed cloud endpoints of cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/basic/update\nUpdate basic settings of cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/b2bCollaboration/update\nUpdate Microsoft Entra B2B collaboration settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/b2bDirectConnect/update\nUpdate Microsoft Entra B2B direct connect settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/tenantRestrictions/update\nUpdate tenant restrictions of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/b2bCollaboration/update\nUpdate Microsoft Entra B2B collaboration settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/b2bDirectConnect/update\nUpdate Microsoft Entra B2B direct connect settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/create\nCreate cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/delete\nDelete cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/basic/update\nUpdate basic settings of cross-tenant sync policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/create\nCreate cross-tenant sync policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/identitySynchronization/standard/read\nRead basic properties of cross-tenant sync policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/standard/read\nRead basic properties of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/basic/update\nUpdate cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/resetToDefaultSettings\nReset cross tenant sync policy template for multi-tenant organization to default settings\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/standard/read\nRead basic properties of cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/basic/update\nUpdate cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/resetToDefaultSettings\nReset cross tenant access policy template for multi-tenant organization to default settings\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/standard/read\nRead basic properties of cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/tenantRestrictions/update\nUpdate tenant restrictions of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/standard/read\nRead basic properties of cross-tenant access policy\nmicrosoft.directory/deviceLocalCredentials/standard/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, except the password\nmicrosoft.directory/domains/federation/update\nUpdate federation property of domains\nmicrosoft.directory/domains/federationConfiguration/basic/update\nUpdate basic federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/create\nCreate federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/delete\nDelete federation configuration for domains\nmicrosoft.directory/domains/federationConfiguration/standard/read\nRead standard properties of federation configuration for domains\nmicrosoft.directory/entitlementManagement/allProperties/read\nRead all properties in Microsoft Entra entitlement management\nmicrosoft.directory/identityProtection/allProperties/read\nRead all resources in Microsoft Entra ID Protection\nmicrosoft.directory/identityProtection/allProperties/update\nUpdate all resources in Microsoft Entra ID Protection\nmicrosoft.directory/multiTenantOrganization/basic/update\nUpdate basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/create\nCreate a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/joinRequest/organizationDetails/update\nJoin a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/joinRequest/standard/read\nRead properties of a multi-tenant organization join request\nmicrosoft.directory/multiTenantOrganization/standard/read\nRead basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/create\nCreate a tenant in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/delete\nDelete a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/read\nRead organization details of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/update\nUpdate basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/standard/read\nRead basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/namedLocations/basic/update\nUpdate basic properties of custom rules that define network locations\nmicrosoft.directory/namedLocations/create\nCreate custom rules that define network locations\nmicrosoft.directory/namedLocations/delete\nDelete custom rules that define network locations\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/policies/basic/update\nUpdate basic properties on policies\nmicrosoft.directory/policies/create\nCreate policies in Microsoft Entra ID\nmicrosoft.directory/policies/delete\nDelete policies in Microsoft Entra ID\nmicrosoft.directory/policies/owners/update\nUpdate owners of policies\nmicrosoft.directory/policies/tenantDefault/update\nUpdate default organization policies\nmicrosoft.directory/privilegedIdentityManagement/allProperties/read\nRead all resources in Privileged Identity Management\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/resourceNamespaces/resourceActions/authenticationContext/update\nUpdate Conditional Access authentication context of Microsoft 365 role-based access control (RBAC) resource actions\nmicrosoft.directory/servicePrincipals/policies/update\nUpdate policies of service principals\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.networkAccess/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Entra Network Access\nmicrosoft.office365.protectionCenter/allEntities/basic/update\nUpdate basic properties of all resources in the Security and Compliance centers\nmicrosoft.office365.protectionCenter/allEntities/standard/read\nRead standard properties of all resources in the Security and Compliance centers\nmicrosoft.office365.protectionCenter/attackSimulator/payload/allProperties/allTasks\nCreate and manage attack payloads in Attack Simulator\nmicrosoft.office365.protectionCenter/attackSimulator/reports/allProperties/read\nRead reports of attack simulation, responses, and associated training\nmicrosoft.office365.protectionCenter/attackSimulator/simulation/allProperties/allTasks\nCreate and manage attack simulation templates in Attack Simulator\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSecurity Operator\nThis is a\nprivileged role\n. Users with this role can manage alerts and have global read-only access on security-related features, including all information in Microsoft 365 Defender portal, Microsoft Entra ID Protection, Privileged Identity Management, and Microsoft Purview compliance portal. For more information about Office 365 permissions, see\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\n.\nIn\nCan do\nMicrosoft 365 Defender portal\nAll permissions of the Security Reader role\nView, investigate, and respond to security threats alerts\nManage security settings in Microsoft 365 Defender portal\nMicrosoft Entra ID Protection\nAll permissions of the Security Reader role\nPerform all ID Protection operations except for configuring or changing risk-based policies, resetting passwords, and configuring alert e-mails.\nPrivileged Identity Management\nAll permissions of the Security Reader role\nMicrosoft Purview compliance portal\nAll permissions of the Security Reader role\nView, investigate, and respond to security alerts\nMicrosoft Defender for Endpoint\nAll permissions of the Security Reader role\nView, investigate, and respond to security alerts\nWhen you turn on role-based access control in Microsoft Defender for Endpoint, users with read-only permissions such as the Security Reader role lose access until they're assigned a Microsoft Defender for Endpoint role.\nIntune\nAll permissions of the Security Reader role\nMicrosoft Defender for Cloud Apps\nAll permissions of the Security Reader role\nView, investigate, and respond to security alerts\nMicrosoft 365 service health\nView the health of Microsoft 365 services\nActions\nDescription\nmicrosoft.azure.advancedThreatProtection/allEntities/allTasks\nManage all aspects of Azure Advanced Threat Protection\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/cloudAppSecurity/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Defender for Cloud Apps\nmicrosoft.directory/identityProtection/allProperties/allTasks\nCreate and delete all resources, and read and update standard properties in Microsoft Entra ID Protection\nmicrosoft.directory/privilegedIdentityManagement/allProperties/read\nRead all resources in Privileged Identity Management\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.intune/allEntities/read\nRead all resources in Microsoft Intune\nmicrosoft.office365.securityComplianceCenter/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in the Microsoft 365 Security and Compliance Center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.windows.defenderAdvancedThreatProtection/allEntities/allTasks\nManage all aspects of Microsoft Defender for Endpoint\nSecurity Reader\nThis is a\nprivileged role\n. Users with this role have global read-only access on security-related feature, including all information in Microsoft 365 Defender portal, Microsoft Entra ID Protection, Privileged Identity Management, and the ability to read Microsoft Entra sign-in reports and audit logs, and in Microsoft Purview compliance portal. For more information about Office 365 permissions, see\nRoles and role groups in Microsoft Defender for Office 365 and Microsoft Purview compliance\n.\nIn\nCan do\nMicrosoft 365 Defender portal\nView security-related policies across Microsoft 365 services\nView security threats and alerts\nView reports\nMicrosoft Entra ID Protection\nView all ID Protection reports and Overview\nPrivileged Identity Management\nHas read-only access to all information surfaced in Microsoft Entra Privileged Identity Management: Policies and reports for Microsoft Entra role assignments and security reviews.\nCannot\nsign up for Microsoft Entra Privileged Identity Management or make any changes to it. In the Privileged Identity Management portal or via PowerShell, someone in this role can activate additional roles (for example, Privileged Role Administrator), if the user is eligible for them.\nMicrosoft Purview compliance portal\nView security policies\nView and investigate security threats\nView reports\nMicrosoft Defender for Endpoint\nView and investigate alerts\nWhen you turn on role-based access control in Microsoft Defender for Endpoint, users with read-only permissions such as the Security Reader role lose access until they're assigned a Microsoft Defender for Endpoint role.\nIntune\nViews user, device, enrollment, configuration, and application information. Cannot make changes to Intune.\nMicrosoft Defender for Cloud Apps\nHas read permissions.\nMicrosoft 365 service health\nView the health of Microsoft 365 services\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/accessReviews/definitions/allProperties/read\nRead all properties of access reviews of all reviewable resources in Microsoft Entra ID\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/bitlockerKeys/key/read\nRead bitlocker metadata and key on devices\nmicrosoft.directory/conditionalAccessPolicies/owners/read\nRead the owners of Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/policyAppliedTo/read\nRead the \"applied to\" property for Conditional Access policies\nmicrosoft.directory/conditionalAccessPolicies/standard/read\nRead Conditional Access for policies\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationIdentitySynchronization/standard/read\nRead basic properties of cross tenant sync policy templates for multi-tenant organization\nmicrosoft.directory/crossTenantAccessPolicy/partners/templates/multiTenantOrganizationPartnerConfiguration/standard/read\nRead basic properties of cross tenant access policy templates for multi-tenant organization\nmicrosoft.directory/deviceLocalCredentials/standard/read\nRead all properties of the backed up local administrator account credentials for Microsoft Entra joined devices, except the password\nmicrosoft.directory/domains/federationConfiguration/standard/read\nRead standard properties of federation configuration for domains\nmicrosoft.directory/entitlementManagement/allProperties/read\nRead all properties in Microsoft Entra entitlement management\nmicrosoft.directory/identityProtection/allProperties/read\nRead all resources in Microsoft Entra ID Protection\nmicrosoft.directory/multiTenantOrganization/joinRequest/standard/read\nRead properties of a multi-tenant organization join request\nmicrosoft.directory/multiTenantOrganization/standard/read\nRead basic properties of a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/organizationDetails/read\nRead organization details of a tenant participating in a multi-tenant organization\nmicrosoft.directory/multiTenantOrganization/tenants/standard/read\nRead basic properties of a tenant participating in a multi-tenant organization\nmicrosoft.directory/namedLocations/standard/read\nRead basic properties of custom rules that define network locations\nmicrosoft.directory/policies/owners/read\nRead owners of policies\nmicrosoft.directory/policies/policyAppliedTo/read\nRead policies.policyAppliedTo property\nmicrosoft.directory/policies/standard/read\nRead basic properties on policies\nmicrosoft.directory/privilegedIdentityManagement/allProperties/read\nRead all resources in Privileged Identity Management\nmicrosoft.directory/provisioningLogs/allProperties/read\nRead all properties of provisioning logs\nmicrosoft.directory/signInReports/allProperties/read\nRead all properties on sign-in reports, including privileged properties\nmicrosoft.networkAccess/allEntities/allProperties/read\nRead all aspects of Microsoft Entra Network Access\nmicrosoft.office365.protectionCenter/allEntities/standard/read\nRead standard properties of all resources in the Security and Compliance centers\nmicrosoft.office365.protectionCenter/attackSimulator/payload/allProperties/read\nRead all properties of attack payloads in Attack Simulator\nmicrosoft.office365.protectionCenter/attackSimulator/reports/allProperties/read\nRead reports of attack simulation, responses, and associated training\nmicrosoft.office365.protectionCenter/attackSimulator/simulation/allProperties/read\nRead all properties of attack simulation templates in Attack Simulator\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nService Support Administrator\nUsers with this role can create and manage support requests with Microsoft for Azure and Microsoft 365 services, and view the service dashboard and message center in the\nAzure portal\nand\nMicrosoft 365 admin center\n. For more information, see\nAbout admin roles in the Microsoft 365 admin center\n.\nNote\nThis role was previously named Service Administrator in the\nAzure portal\nand\nMicrosoft 365 admin center\n. It was renamed to Service Support Administrator to align with the existing name in the Microsoft Graph API and Microsoft Graph PowerShell.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSharePoint Administrator\nUsers with this role have global permissions within Microsoft SharePoint Online, when the service is present, as well as the ability to create and manage all Microsoft 365 groups, manage support tickets, and monitor service health. For more information, see\nAbout admin roles in the Microsoft 365 admin center\n.\nNote\nIn the Microsoft Graph API and Microsoft Graph PowerShell, this role is named SharePoint Service Administrator. In the\nAzure portal\n, it is named SharePoint Administrator.\nNote\nThis role also grants scoped permissions to the Microsoft Graph API for Microsoft Intune, allowing the management and configuration of policies related to SharePoint and OneDrive resources.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/oneDriveForBusinessProtectionPolicies/allProperties/allTasks\nCreate and manage OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/oneDriveForBusinessRestoreSessions/allProperties/allTasks\nRead and configure restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/sites/allProperties/allTasks\nManage all restore points associated with selected SharePoint sites in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/userDrives/allProperties/allTasks\nManage all restore points associated with selected OneDrive accounts in Microsoft 365 Backup\nmicrosoft.backup/sharePointProtectionPolicies/allProperties/allTasks\nCreate and manage SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/sharePointRestoreSessions/allProperties/allTasks\nRead and configure restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/siteProtectionUnits/allProperties/allTasks\nManage sites added to SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/siteRestoreArtifacts/allProperties/allTasks\nManage sites added to restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/userDriveProtectionUnits/allProperties/allTasks\nManage accounts added to OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/userDriveRestoreArtifacts/allProperties/allTasks\nManage accounts added to restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.unified/basic/update\nUpdate basic properties on Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/create\nCreate Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/delete\nDelete Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/members/update\nUpdate members of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/owners/update\nUpdate owners of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/restore\nRestore Microsoft 365 groups from soft-deleted container, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.office365.migrations/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 migrations\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.sharePoint/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in SharePoint\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSharePoint Advanced Management Administrator\nAssign the SharePoint Advanced Management Administrator role to users who need to do the following tasks:\nPerform all actions available to SharePoint Administrators, including global management of SharePoint Online, support ticket handling, and service health monitoring\nView names, paths, and URLs of files, folders, libraries, documents, and lists within SharePoint sites, without accessing file or item content\nRemove permissions from files, folders, libraries, documents, and lists within SharePoint sites\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/oneDriveForBusinessProtectionPolicies/allProperties/allTasks\nCreate and manage OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/oneDriveForBusinessRestoreSessions/allProperties/allTasks\nRead and configure restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/sites/allProperties/allTasks\nManage all restore points associated with selected SharePoint sites in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/userDrives/allProperties/allTasks\nManage all restore points associated with selected OneDrive accounts in Microsoft 365 Backup\nmicrosoft.backup/sharePointProtectionPolicies/allProperties/allTasks\nCreate and manage SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/sharePointRestoreSessions/allProperties/allTasks\nRead and configure restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/siteProtectionUnits/allProperties/allTasks\nManage sites added to SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/siteRestoreArtifacts/allProperties/allTasks\nManage sites added to restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/userDriveProtectionUnits/allProperties/allTasks\nManage accounts added to OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/userDriveRestoreArtifacts/allProperties/allTasks\nManage accounts added to restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.unified/basic/update\nUpdate basic properties on Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/create\nCreate Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/delete\nDelete Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/members/update\nUpdate members of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/owners/update\nUpdate owners of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/restore\nRestore Microsoft 365 groups from soft-deleted container, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.office365.migrations/allEntities/allProperties/allTasks\nManage all aspects of Microsoft 365 migrations\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.sharePoint/allEntities/allTasks\nCreate and delete all resources, and read and update standard properties in SharePoint\nmicrosoft.office365.sharePointAdvancedManagement/allEntities/allProperties/allTasks\nManage all aspects of SharePoint Advanced Management\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSharePoint Backup Administrator\nAssign the SharePoint Backup Administrator role to users who need to do the following tasks:\nManage all aspects of Microsoft 365 Backup for SharePoint and OneDrive\nBack up and restore content including granular restore across SharePoint and OneDrive\nCreate, edit, and manage backup configuration policies for SharePoint and OneDrive\nPerform restore operations for SharePoint and OneDrive\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.backup/oneDriveForBusinessProtectionPolicies/allProperties/allTasks\nCreate and manage OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/oneDriveForBusinessRestoreSessions/allProperties/allTasks\nRead and configure restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/sites/allProperties/allTasks\nManage all restore points associated with selected SharePoint sites in Microsoft 365 Backup\nmicrosoft.backup/restorePoints/userDrives/allProperties/allTasks\nManage all restore points associated with selected OneDrive accounts in Microsoft 365 Backup\nmicrosoft.backup/sharePointProtectionPolicies/allProperties/allTasks\nCreate and manage SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/sharePointRestoreSessions/allProperties/allTasks\nRead and configure restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/siteProtectionUnits/allProperties/allTasks\nManage sites added to SharePoint protection policy in Microsoft 365 Backup\nmicrosoft.backup/siteRestoreArtifacts/allProperties/allTasks\nManage sites added to restore session for SharePoint in Microsoft 365 Backup\nmicrosoft.backup/userDriveProtectionUnits/allProperties/allTasks\nManage accounts added to OneDrive protection policy in Microsoft 365 Backup\nmicrosoft.backup/userDriveRestoreArtifacts/allProperties/allTasks\nManage accounts added to restore session for OneDrive in Microsoft 365 Backup\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSharePoint Embedded Administrator\nAssign the SharePoint Embedded Administrator role to users who need to do the following tasks:\nPerform all tasks using PowerShell, Microsoft Graph API, or SharePoint admin center\nManage, configure, and maintain SharePoint Embedded containers\nEnumerate and manage SharePoint Embedded containers\nEnumerate and manage permissions for SharePoint Embedded containers\nManage storage of SharePoint Embedded containers in a tenant\nAssign security and compliance policies on SharePoint Embedded containers\nApply security and compliance policies on SharePoint Embedded containers in a tenant\nLearn more\nActions\nDescription\nmicrosoft.office365.fileStorageContainers/allEntities/allProperties/allTasks\nManage all aspects of SharePoint Embedded containers\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nSkype for Business Administrator\nUsers with this role have global permissions within Microsoft Skype for Business, when the service is present, as well as manage Skype-specific user attributes in Microsoft Entra ID. Additionally, this role grants the ability to manage support tickets and monitor service health, and to access the Teams and Skype for Business admin center. The account must also be licensed for Teams or it can't run Teams PowerShell cmdlets. For more information, see\nSkype for Business Online Admin\nand Teams licensing information at\nSkype for Business add-on licensing\n.\nNote\nIn the Microsoft Graph API and Microsoft Graph PowerShell, this role is named Lync Service Administrator. In the\nAzure portal\n, it is named Skype for Business Administrator.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nTeams Administrator\nUsers in this role can manage all aspects of the Microsoft Teams workload via the Microsoft Teams & Skype for Business admin center and the respective PowerShell modules. This includes, among other areas, all management tools related to telephony, messaging, meetings, and the teams themselves. This role additionally grants the ability to create and manage all Microsoft 365 groups, manage support tickets, and monitor service health.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/crossTenantAccessPolicy/allowedCloudEndpoints/update\nUpdate allowed cloud endpoints of cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/crossTenantAccessPolicy/partners/create\nCreate cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/crossCloudMeetings/update\nUpdate cross-cloud Teams meeting settings of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/partners/standard/read\nRead basic properties of cross-tenant access policy for partners\nmicrosoft.directory/crossTenantAccessPolicy/standard/read\nRead basic properties of cross-tenant access policy\nmicrosoft.directory/externalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/externalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.unified/basic/update\nUpdate basic properties on Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/create\nCreate Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/delete\nDelete Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/members/update\nUpdate members of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/owners/update\nUpdate owners of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/restore\nRestore Microsoft 365 groups from soft-deleted container, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/pendingExternalUserProfiles/basic/update\nUpdate basic properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/create\nCreate external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/delete\nDelete external user profiles in the extended directory for Teams\nmicrosoft.directory/pendingExternalUserProfiles/standard/read\nRead standard properties of external user profiles in the extended directory for Teams\nmicrosoft.directory/permissionGrantPolicies/standard/read\nRead standard properties of permission grant policies\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/allEntities/allProperties/allTasks\nManage all resources in Teams\nTeams Communications Administrator\nUsers in this role can manage aspects of the Microsoft Teams workload related to voice & telephony. This includes the management tools for telephone number assignment, voice and meeting policies, and full access to the call analytics toolset.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/callQuality/allProperties/read\nRead all data in the Call Quality Dashboard (CQD)\nmicrosoft.teams/meetings/allProperties/allTasks\nManage meetings including meeting policies, configurations, and conference bridges\nmicrosoft.teams/voice/allProperties/allTasks\nManage voice including calling policies and phone number inventory and assignment\nTeams Communications Support Engineer\nUsers in this role can troubleshoot communication issues within Microsoft Teams & Skype for Business using the user call troubleshooting tools in the Microsoft Teams & Skype for Business admin center. Users in this role can view full call record information for all participants involved. This role has no access to view, create, or manage support tickets.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/callQuality/allProperties/read\nRead all data in the Call Quality Dashboard (CQD)\nTeams Communications Support Specialist\nUsers in this role can troubleshoot communication issues within Microsoft Teams & Skype for Business using the user call troubleshooting tools in the Microsoft Teams & Skype for Business admin center. Users in this role can only view user details in the call for the specific user they have looked up. This role has no access to view, create, or manage support tickets.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/callQuality/standard/read\nRead basic data in the Call Quality Dashboard (CQD)\nTeams Devices Administrator\nUsers with this role can manage\nTeams-certified devices\nfrom the Teams admin center. This role allows viewing all devices at single glance, with ability to search and filter devices. The user can check details of each device including logged-in account, make and model of the device. The user can change the settings on the device and update the software versions. This role does not grant permissions to check Teams activity and call quality of the device.\nActions\nDescription\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/devices/standard/read\nManage all aspects of Teams-certified devices including configuration policies\nTeams Reader\nAssign the Teams Reader role to users who need to do the following tasks:\nRead settings and administrative information in the Teams admin center, but not perform any management actions\nRead the Microsoft Call Quality Dashboard (CQD), but not access any troubleshooting capabilities\nUsers with this role\ncannot\ndo the following tasks:\nCannot view Teams management\nCannot access Meetings & Calls details of users\nCannot access Notifications & Rules management\nCannot access Frontline worker deployment management\nCannot access the advanced collaboration insights dashboard\nLearn more\nActions\nDescription\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/allEntities/allProperties/read\nRead all properties of Microsoft Teams\nTeams Telephony Administrator\nAssign the Teams Telephony Administrator role to users who need to do the following tasks:\nManage voice and telephony, including calling policies, phone number management and assignment, and voice applications\nAccess to only Public Switched Telephone Network (PSTN) usage reports from Teams admin center\nView user profile page\nCreate and manage support tickets in Azure and the Microsoft 365 admin center\nLearn more\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.skypeForBusiness/allEntities/allTasks\nManage all aspects of Skype for Business Online\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.teams/callQuality/allProperties/read\nRead all data in the Call Quality Dashboard (CQD)\nmicrosoft.teams/voice/allProperties/allTasks\nManage voice including calling policies and phone number inventory and assignment\nTenant Creator\nAssign the Tenant Creator role to users who need to do the following tasks:\nCreate both Microsoft Entra and Azure Active Directory B2C tenants even if the tenant creation toggle is turned off in the user settings\nNote\nThe tenant creators will be assigned the Global Administrator role on the new tenants they create.\nActions\nDescription\nmicrosoft.directory/tenantManagement/tenants/create\nCreate new tenants in Microsoft Entra ID\nUsage Summary Reports Reader\nAssign the Usage Summary Reports Reader role to users who need to do the following tasks in the Microsoft 365 admin center:\nView the Usage reports and Adoption Score\nRead organizational insights, but not personally identifiable information (PII) of users\nThis role only allows users to view organizational-level data with the following exceptions:\nMember users can view user management data and settings.\nGuest users assigned this role cannot view user management data and settings.\nActions\nDescription\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.usageReports/allEntities/standard/read\nRead tenant-level aggregated Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nUser Administrator\nThis is a\nprivileged role\n. Assign the User Administrator role to users who need to do the following:\nPermission\nMore information\nCreate users\nUpdate most user properties for all users, including all administrators\nWho can perform sensitive actions\nUpdate sensitive properties (including user principal name) for some users\nWho can perform sensitive actions\nDisable or enable some users\nWho can perform sensitive actions\nDelete or restore some users\nWho can perform sensitive actions\nCreate and manage user views\nCreate and manage all groups\nAssign and read licenses for all users, including all administrators\nReset passwords\nWho can reset passwords\nInvalidate refresh tokens\nWho can reset passwords\nUpdate (FIDO) device keys\nUpdate password expiration policies\nCreate and manage support tickets in Azure and the Microsoft 365 admin center\nMonitor service health\nUsers with this role\ncannot\ndo the following:\nCannot manage MFA.\nCannot change the credentials or reset MFA for members and owners of a\nrole-assignable group\n.\nCannot manage shared mailboxes.\nCannot modify security questions for password reset operation.\nImportant\nUsers with this role can change passwords for people who may have access to sensitive or private information or critical configuration inside and outside of Microsoft Entra ID. Changing the password of a user may mean the ability to assume that user's identity and permissions. For example:\nApplication Registration and Enterprise Application owners, who can manage credentials of apps they own. Those apps may have privileged permissions in Microsoft Entra ID and elsewhere not granted to User Administrators. Through this path a User Administrator may be able to assume the identity of an application owner and then further assume the identity of a privileged application by updating the credentials for the application.\nAzure subscription owners, who may have access to sensitive or private information or critical configuration in Azure.\nSecurity Group and Microsoft 365 group owners, who can manage group membership. Those groups may grant access to sensitive or private information or critical configuration in Microsoft Entra ID and elsewhere.\nAdministrators in other services outside of Microsoft Entra ID like Exchange Online, Microsoft 365 Defender portal, Microsoft Purview compliance portal, and human resources systems.\nNon-administrators like executives, legal counsel, and human resources employees who may have access to sensitive or private information.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.directory/accessReviews/definitions.applications/allProperties/allTasks\nManage access reviews of application role assignments in Microsoft Entra ID\nmicrosoft.directory/accessReviews/definitions.directoryRoles/allProperties/read\nRead all properties of access reviews for Microsoft Entra role assignments\nmicrosoft.directory/accessReviews/definitions.entitlementManagement/allProperties/allTasks\nManage access reviews for access package assignments in entitlement management\nmicrosoft.directory/accessReviews/definitions.groups/allProperties/read\nRead all properties of access reviews for membership in Security and Microsoft 365 groups, including role-assignable groups.\nmicrosoft.directory/accessReviews/definitions.groups/allProperties/update\nUpdate all properties of access reviews for membership in Security and Microsoft 365 groups, excluding role-assignable groups.\nmicrosoft.directory/accessReviews/definitions.groups/create\nCreate access reviews for membership in Security and Microsoft 365 groups.\nmicrosoft.directory/accessReviews/definitions.groups/delete\nDelete access reviews for membership in Security and Microsoft 365 groups.\nmicrosoft.directory/contacts/basic/update\nUpdate basic properties on contacts\nmicrosoft.directory/contacts/create\nCreate contacts\nmicrosoft.directory/contacts/delete\nDelete contacts\nmicrosoft.directory/deletedItems.groups/restore\nRestore soft deleted groups to original state\nmicrosoft.directory/deletedItems.users/restore\nRestore soft deleted users to original state\nmicrosoft.directory/entitlementManagement/allProperties/allTasks\nCreate and delete resources, and read and update all properties in Microsoft Entra entitlement management\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups/assignLicense\nAssign product licenses to groups for group-based licensing\nmicrosoft.directory/groups/basic/update\nUpdate basic properties on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/classification/update\nUpdate the classification property on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/create\nCreate Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/delete\nDelete Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/dynamicMembershipRule/update\nUpdate the dynamic membership rule on Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/groupType/update\nUpdate properties that would affect the group type of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/members/update\nUpdate members of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/onPremWriteBack/update\nUpdate Microsoft Entra groups to be written back to on-premises with Microsoft Entra Connect\nmicrosoft.directory/groups/owners/update\nUpdate owners of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups/reprocessLicenseAssignment\nReprocess license assignments for group-based licensing\nmicrosoft.directory/groups/restore\nRestore groups from soft-deleted container\nmicrosoft.directory/groups/settings/update\nUpdate settings of groups\nmicrosoft.directory/groups/visibility/update\nUpdate the visibility property of Security groups and Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/oAuth2PermissionGrants/allProperties/allTasks\nCreate and delete OAuth 2.0 permission grants, and read and update all properties\nmicrosoft.directory/onPremisesSynchronization/standard/read\nRead standard on-premises directory synchronization information\nmicrosoft.directory/policies/standard/read\nRead basic properties on policies\nmicrosoft.directory/servicePrincipals/appRoleAssignedTo/update\nUpdate service principal role assignments\nmicrosoft.directory/users/assignLicense\nManage user licenses\nmicrosoft.directory/users/basic/update\nUpdate basic properties on users\nmicrosoft.directory/users/convertExternalToInternalMemberUser\nConvert external user to internal user\nmicrosoft.directory/users/create\nAdd users\nmicrosoft.directory/users/delete\nDelete users\nmicrosoft.directory/users/disable\nDisable users\nmicrosoft.directory/users/enable\nEnable users\nmicrosoft.directory/users/invalidateAllRefreshTokens\nForce sign-out by invalidating user refresh tokens\nmicrosoft.directory/users/inviteGuest\nInvite guest users\nmicrosoft.directory/users/lifeCycleInfo/read\nRead lifecycle information of users, such as employeeLeaveDateTime\nmicrosoft.directory/users/manager/update\nUpdate manager for users\nmicrosoft.directory/users/password/update\nReset passwords for all users\nmicrosoft.directory/users/photo/update\nUpdate photo of users\nmicrosoft.directory/users/reprocessLicenseAssignment\nReprocess license assignments for users\nmicrosoft.directory/users/restore\nRestore deleted users\nmicrosoft.directory/users/sponsors/update\nUpdate sponsors of users\nmicrosoft.directory/users/usageLocation/update\nUpdate usage location of users\nmicrosoft.directory/users/userPrincipalName/update\nUpdate User Principal Name of users\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nUser Experience Success Manager\nAssign the User Experience Success Manager role to users who need to do the following tasks:\nRead organizational-level usage reports for Microsoft 365 Apps and services, but not user details\nView your organization's product feedback, Net Promoter Score (NPS) survey results, and help article views to identify communication and training opportunities\nRead message center posts and service health data\nLearn more\nActions\nDescription\nmicrosoft.commerce.billing/purchases/standard/read\nRead purchase services in Microsoft 365 admin center.\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.organizationalMessages/allEntities/allProperties/read\nRead all aspects of Microsoft 365 Organizational Messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.usageReports/allEntities/standard/read\nRead tenant-level aggregated Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nVirtual Visits Administrator\nUsers with this role can do the following tasks:\nManage and configure all aspects of Virtual Visits in Bookings in the Microsoft 365 admin center, and in the Teams EHR connector\nView usage reports for Virtual Visits in the Teams admin center, Microsoft 365 admin center, Fabric, and Power BI\nView features and settings in the Microsoft 365 admin center, but can't edit any settings\nVirtual Visits are a simple way to schedule and manage online and video appointments for staff and attendees. For example, usage reporting can show how sending SMS text messages before appointments can reduce the number of people who don't show up for appointments.\nActions\nDescription\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.virtualVisits/allEntities/allProperties/allTasks\nManage and share Virtual Visits information and metrics from admin centers or the Virtual Visits app\nActions\nDescription\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.virtualVisits/allEntities/allProperties/allTasks\nManage and share Virtual Visits information and metrics from admin centers or the Virtual Visits app\nViva Glint Tenant Administrator\nAssign the Viva Glint Tenant Administrator role to users who need to do the following tasks:\nRead and configure Viva Glint settings in the Microsoft 365 admin center\nAssign or remove Viva Glint service admins\nCreate and manage Viva Feature Access Management policies\nView and manage Viva Glint experiences (if applicable)\nCreate and manage Azure support tickets\nFor more information, see\nKey roles for Viva Glint\nand\nAssign Viva Glint Tenant and Service Administrators\n.\nActions\nDescription\nmicrosoft.azure.serviceHealth/allEntities/allTasks\nRead and configure Azure Service Health\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.viva.glint/allEntities/allProperties/allTasks\nManage and configure all Microsoft Viva Glint settings in the Microsoft 365 admin center\nViva Goals Administrator\nAssign the Viva Goals Administrator role to users who need to do the following tasks:\nManage and configure all aspects of the Microsoft Viva Goals application\nConfigure Microsoft Viva Goals admin settings\nRead Microsoft Entra tenant information\nMonitor Microsoft 365 service health\nCreate and manage Microsoft 365 service requests\nFor more information, see\nRoles and permissions in Viva Goals\nand\nIntroduction to Microsoft Viva Goals\n.\nActions\nDescription\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.viva.goals/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Viva Goals\nViva Pulse Administrator\nAssign the Viva Pulse Administrator role to users who need to do the following tasks:\nRead and configure all settings of Viva Pulse\nRead basic properties on all resources in the Microsoft 365 admin center\nRead and configure Azure Service Health\nCreate and manage Azure support tickets\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nRead usage reports in the Microsoft 365 admin center\nFor more information, see\nAssign a Viva Pulse admin in the Microsoft 365 admin center\n.\nActions\nDescription\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.viva.pulse/allEntities/allProperties/allTasks\nManage all aspects of Microsoft Viva Pulse\nWindows 365 Administrator\nUsers with this role have global permissions on Windows 365 resources, when the service is present. Additionally, this role contains the ability to manage users and devices in order to associate policy, as well as create and manage groups.\nThis role can create and manage security groups, but does not have administrator rights over Microsoft 365 groups. That means administrators cannot update owners or memberships of Microsoft 365 groups in the organization. However, they can manage the Microsoft 365 group they create, which is a part of their end-user privileges. So, any Microsoft 365 group (not security group) they create is counted against their quota of 250.\nAssign the Windows 365 Administrator role to users who need to do the following tasks:\nManage Windows 365 Cloud PCs in Microsoft Intune\nEnroll and manage devices in Microsoft Entra ID, including assigning users and policies\nCreate and manage security groups, but not role-assignable groups\nView basic properties in the Microsoft 365 admin center\nRead usage reports in the Microsoft 365 admin center\nCreate and manage support tickets in Azure and the Microsoft 365 admin center\nActions\nDescription\nmicrosoft.azure.supportTickets/allEntities/allTasks\nCreate and manage Azure support tickets\nmicrosoft.cloudPC/allEntities/allProperties/allTasks\nManage all aspects of Windows 365\nmicrosoft.directory/deletedItems.devices/delete\nPermanently delete devices, which can no longer be restored\nmicrosoft.directory/deletedItems.devices/restore\nRestore soft deleted devices to original state\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/basic/update\nUpdate basic properties on devices\nmicrosoft.directory/devices/create\nCreate devices (enroll in Microsoft Entra ID)\nmicrosoft.directory/devices/delete\nDelete devices from Microsoft Entra ID\nmicrosoft.directory/devices/disable\nDisable devices in Microsoft Entra ID\nmicrosoft.directory/devices/enable\nEnable devices in Microsoft Entra ID\nmicrosoft.directory/devices/extensionAttributeSet1/update\nUpdate the extensionAttribute1 to extensionAttribute5 properties on devices\nmicrosoft.directory/devices/extensionAttributeSet2/update\nUpdate the extensionAttribute6 to extensionAttribute10 properties on devices\nmicrosoft.directory/devices/extensionAttributeSet3/update\nUpdate the extensionAttribute11 to extensionAttribute15 properties on devices\nmicrosoft.directory/devices/registeredOwners/update\nUpdate registered owners of devices\nmicrosoft.directory/devices/registeredUsers/update\nUpdate registered users of devices\nmicrosoft.directory/groups.security/assignedLabels/update\nUpdate the assigned labels property on Security groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.security/basic/update\nUpdate basic properties on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/classification/update\nUpdate the classification property on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/create\nCreate Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/delete\nDelete Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/dynamicMembershipRule/update\nUpdate the dynamic membership rule on Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/members/update\nUpdate members of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/owners/update\nUpdate owners of Security groups, excluding role-assignable groups\nmicrosoft.directory/groups.security/visibility/update\nUpdate the visibility property on Security groups, excluding role-assignable groups\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nWindows Update Deployment Administrator\nUUsers in this role can create and manage all aspects of Windows Update deployments through the Windows Update for Business deployment service. The deployment service enables users to define settings for when and how updates are deployed, and specify which updates are offered to groups of devices in their tenant. It also allows users to monitor the update progress.\nActions\nDescription\nmicrosoft.windows.updatesDeployments/allEntities/allProperties/allTasks\nRead and configure all aspects of Windows Update Service\nYammer Administrator\nAssign the Yammer Administrator role to users who need to do the following tasks:\nManage all aspects of Yammer\nCreate, manage, and restore Microsoft 365 Groups, but not role-assignable groups\nView the hidden members of Security groups and Microsoft 365 groups, including role assignable groups\nRead usage reports in the Microsoft 365 admin center\nCreate and manage service requests in the Microsoft 365 admin center\nView announcements in the Message center, but not security announcements\nView service health\nLearn more\nActions\nDescription\nmicrosoft.directory/groups.unified/assignedLabels/update\nUpdate the assigned labels property on Microsoft 365 groups of assigned membership type, excluding role-assignable groups\nmicrosoft.directory/groups.unified/basic/update\nUpdate basic properties on Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/create\nCreate Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/delete\nDelete Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/members/update\nUpdate members of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/owners/update\nUpdate owners of Microsoft 365 groups, excluding role-assignable groups\nmicrosoft.directory/groups.unified/restore\nRestore Microsoft 365 groups from soft-deleted container, excluding role-assignable groups\nmicrosoft.directory/groups/hiddenMembers/read\nRead hidden members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.office365.messageCenter/messages/read\nRead messages in Message Center in the Microsoft 365 admin center, excluding security messages\nmicrosoft.office365.network/performance/allProperties/read\nRead all network performance properties in the Microsoft 365 admin center\nmicrosoft.office365.serviceHealth/allEntities/allTasks\nRead and configure Service Health in the Microsoft 365 admin center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.usageReports/allEntities/allProperties/read\nRead Office 365 usage reports\nmicrosoft.office365.webPortal/allEntities/standard/read\nRead basic properties on all resources in the Microsoft 365 admin center\nmicrosoft.office365.yammer/allEntities/allProperties/allTasks\nManage all aspects of Yammer\nDeprecated roles\nThe following roles should not be used. They have been deprecated and will be removed from Microsoft Entra ID in the future.\nAdHoc License Administrator\nDevice Join\nDevice Managers\nDevice Users\nEmail Verified User Creator\nMailbox Administrator\nWorkplace Device Join\nRoles not shown in the portal\nNot every role returned by PowerShell or Microsoft Graph API is visible in Microsoft Entra roles interface. The following table organizes those differences.\nAPI name\nMicrosoft Entra admin center portal name\nNotes\nAgent User\nNot shown because it's implicitly assigned to users of agents\nNA\nDevice Join\nDeprecated\nDeprecated roles documentation\nDevice Managers\nDeprecated\nDeprecated roles documentation\nDevice Users\nDeprecated\nDeprecated roles documentation\nDirectory Synchronization Accounts\nNot shown because it shouldn't be used\nDirectory Synchronization Accounts documentation\nGuest User\nNot shown because it can't be used\nNA\nMicrosoft 365 Support Engineer\nNot shown because it shouldn't be used\nMicrosoft 365 Support Engineer documentation\nModern Commerce Administrator\nNot shown because it can't be used\nModern Commerce Administrator\nPartner Tier 1 Support\nNot shown because it shouldn't be used\nPartner Tier1 Support documentation\nPartner Tier 2 Support\nNot shown because it shouldn't be used\nPartner Tier2 Support documentation\nRestricted Guest User\nNot shown because it can't be used\nNA\nUser\nNot shown because it can't be used\nNA\nWorkplace Device Join\nDeprecated\nDeprecated roles documentation\nMicrosoft 365 Support Engineer\nTemplate ID: 00cf5c54-4693-4f59-a0ac-ab79ef0a974d\nDo not use - not intended for general use.\nActions\nDescription\nmicrosoft.directory/applications/allProperties/read\nRead all properties (including privileged properties) on all types of applications\nmicrosoft.directory/auditLogs/allProperties/read\nRead all properties on audit logs, excluding custom security attributes audit logs\nmicrosoft.directory/authorizationPolicy/standard/read\nRead standard properties of authorization policy\nmicrosoft.directory/conditionalAccessPolicies/standard/read\nRead Conditional Access for policies\nmicrosoft.directory/crossTenantAccessPolicy/default/standard/read\nRead basic properties of the default cross-tenant access policy\nmicrosoft.directory/deviceManagementPolicies/standard/read\nRead standard properties on mobile device management and mobile app management policies\nmicrosoft.directory/deviceRegistrationPolicy/standard/read\nRead standard properties on device registration policies\nmicrosoft.directory/devices/standard/read\nRead basic properties on devices\nmicrosoft.directory/directoryRoles/allProperties/read\nRead all properties of directory roles\nmicrosoft.directory/directoryRoles/members/read\nRead all members of Microsoft Entra roles\nmicrosoft.directory/domains/allProperties/read\nRead all properties of domains\nmicrosoft.directory/domains/standard/read\nRead basic properties on domains\nmicrosoft.directory/groups/allProperties/read\nRead all properties (including privileged properties) on Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groupSettings/allProperties/read\nRead all properties of group settings\nmicrosoft.directory/groups/members/read\nRead members of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/owners/read\nRead owners of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/groups/standard/read\nRead standard properties of Security groups and Microsoft 365 groups, including role-assignable groups\nmicrosoft.directory/organization/allProperties/read\nRead all properties for an organization\nmicrosoft.directory/policies/standard/read\nRead basic properties on policies\nmicrosoft.directory/securityRiskPolicy/standard/read\nRead basic properties of security risk policy that includes Microsoft Entra security defaults, strong authentication, and account compromise\nmicrosoft.directory/servicePrincipals/allProperties/read\nRead all properties (including privileged properties) on servicePrincipals\nmicrosoft.directory/servicePrincipals/appRoleAssignments/limitedRead\nRead application roles assigned to a specific service principal, but cannot enumerate service principals\nmicrosoft.directory/servicePrincipals/standard/read\nRead basic properties of service principals\nmicrosoft.directory/subscribedSkus/allProperties/read\nRead all properties of product subscriptions\nmicrosoft.directory/users/directReports/read\nRead the direct reports for users\nmicrosoft.directory/users/licenseDetails/read\nRead license details of users\nmicrosoft.directory/users/manager/read\nRead manager of users\nmicrosoft.directory/users/memberOf/read\nRead the group memberships of users\nmicrosoft.directory/users/registeredDevices/read\nRead registered devices of users\nmicrosoft.directory/users/standard/read\nRead basic properties on users\nmicrosoft.office365.protectionCenter/attackSimulator/payload/allProperties/read\nRead all properties of attack payloads in Attack Simulator\nmicrosoft.office365.protectionCenter/attackSimulator/reports/allProperties/read\nRead reports of attack simulation, responses, and associated training\nmicrosoft.teams/allEntities/allProperties/read\nRead all properties of Microsoft Teams\nModern Commerce Administrator\nTemplate ID: d24aef57-1500-4070-84db-2666f29cf966\nDon't use. This role isn't returned by PowerShell or the Microsoft Graph API. It's automatically assigned from Commerce, and isn't intended or supported for any other use.\nThe Modern Commerce Administrator role gives certain users permission to access Microsoft 365 admin center and see the left navigation entries for\nHome\n,\nBilling\n, and\nSupport\n. The content available in these areas is controlled by\ncommerce-specific roles\nassigned to users to manage products that they bought for themselves or your organization. This might include tasks like paying bills, or for access to billing accounts and billing profiles.\nUsers with the Modern Commerce Administrator role typically have administrative permissions in other Microsoft purchasing systems, but don't have Global Administrator or Billing Administrator roles used to access the admin center.\nWhen is the Modern Commerce Administrator role assigned?\nSelf-service purchase in Microsoft 365 admin center\nâ Self-service purchase gives users a chance to try out new products by buying or signing up for them on their own. These products are managed in the admin center. Users who make a self-service purchase are assigned a role in the commerce system, and the Modern Commerce Administrator role so they can manage their purchases in admin center. Admins can block self-service purchases (for Fabric, Power BI, Power Apps, Power Automate) through\nPowerShell\n. For more information, see\nSelf-service purchase FAQ\n.\nPurchases from Microsoft commercial marketplace\nâ Similar to self-service purchase, when a user buys a product or service from Microsoft AppSource or Azure Marketplace, the Modern Commerce Administrator role is assigned if they don't have the Global Administrator or Billing Administrator role. In some cases, users might be blocked from making these purchases. For more information, see\nMicrosoft commercial marketplace\n.\nProposals from Microsoft\nâ A proposal is a formal offer from Microsoft for your organization to buy Microsoft products and services. When the person who is accepting the proposal doesn't have a Global Administrator or Billing Administrator role in Microsoft Entra ID, they're assigned both a commerce-specific role to complete the proposal and the Modern Commerce Administrator role to access admin center. When they access the admin center, they can only use features that are authorized by their commerce-specific role.\nCommerce-specific roles\nâ Some users are assigned commerce-specific roles. If a user isn't a Global Administrator or Billing Administrator, they get the Modern Commerce Administrator role so they can access the admin center.\nIf the Modern Commerce Administrator role is unassigned from a user, they lose access to Microsoft 365 admin center. If they were managing any products, either for themselves or for your organization, they won't be able to manage them. This might include assigning licenses, changing payment methods, paying bills, or other tasks for managing subscriptions.\nActions\nDescription\nmicrosoft.commerce.billing/partners/read\nmicrosoft.commerce.volumeLicenseServiceCenter/allEntities/allTasks\nManage all aspects of Volume Licensing Service Center\nmicrosoft.office365.supportTickets/allEntities/allTasks\nCreate and manage Microsoft 365 service requests\nmicrosoft.office365.webPortal/allEntities/basic/read\nRead basic properties on all resources in the Microsoft 365 admin center\nNext steps\nAssign Microsoft Entra roles\nUnderstand the different roles\nAssign a user as an administrator of an Azure subscription\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Admin Roles",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/id-governance/access-reviews-overview": {
      "content_hash": "sha256:e5919b9659682c8742627fba247152252311007a3077d7a63def468e336ef63d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat are access reviews?\nFeedback\nSummarize this article for me\nAccess reviews in Microsoft Entra ID, part of Microsoft Entra, enable organizations to efficiently manage group memberships, access to enterprise applications, and role assignments. User access can be reviewed regularly to make sure only the right people have continued access.\nHere's a video that provides a quick overview of access reviews:\nWhy are access reviews important?\nMicrosoft Entra ID enables you to collaborate with users from inside your organization, and with external users. Users can join groups, invite guests, connect to cloud apps, and work remotely from either their work or personal devices. The convenience of using self-service has led to a need for better access management capabilities.\nAs new employees join, how do you ensure they have the access they need to be productive?\nAs people move teams or leave the company, how do you make sure that their old access is removed?\nExcessive access rights can lead to compromises.\nExcessive access right can also lead audit findings as they indicate a lack of control over access.\nYou have to proactively engage with resource owners to ensure they regularly review who has access to their resources.\nWhen should you use access reviews?\nToo many users in privileged roles:\nIt's a good idea to check how many users have administrative access, how many of them are Global Administrators, and if there are any invited guests or partners that haven't been removed after being assigned to do an administrative task. You can recertify the role assignment users in\nMicrosoft Entra roles\nsuch as Global Administrators, or\nAzure resources roles\nsuch as User Access Administrator in the\nMicrosoft Entra Privileged Identity Management (PIM)\nexperience.\nWhen automation is not possible:\nYou can create rules for dynamic membership groups, security groups, or Microsoft 365 Groups, but what if the HR data isn't in Microsoft Entra ID or if users still need access after leaving the group to train their replacement? You can then create a review on that group to ensure those who still need access keeps access.\nWhen a group is used for a new purpose:\nIf you have a group that is going to be synced to Microsoft Entra ID, or if you plan to enable the application Salesforce for everyone in the Sales team group, it would be useful to ask the group owner to review the dynamic membership group before it's used in a different risk content.\nBusiness critical data access:\nfor certain resources, such as\nbusiness critical applications\n, it might be required as part of compliance processes to ask people to regularly reconfirm and give a justification on why they need continued access.\nTo maintain a policy's exception list:\nIn an ideal world, all users would follow the access policies to secure access to your organization's resources. However, sometimes there are business cases that require you to make exceptions. As the IT admin, you can manage this task, avoid oversight of policy exceptions, and provide auditors with proof that these exceptions are reviewed regularly.\nAsk group owners to confirm they still need guests in their groups:\nEmployee access might be automated with other identity and access management features such lifecycle workflows based on data from an HR source, but not invited guests. If a group gives guests access to business sensitive content, then it's the group owner's responsibility to confirm the guests still have a legitimate business need for access.\nHave reviews recur periodically:\nYou can set up recurring access reviews of users at set frequencies such as weekly, monthly, quarterly or annually, and the reviewers are notified at the start of each review. Reviewers can approve or deny access with a friendly interface and with the help of smart recommendations.\nNote\nIf you're ready to try Access reviews take a look at\nCreate an access review of groups or applications\nWhere do you create reviews?\nDepending on what you want to review, you either create your access review in access reviews, Microsoft Entra enterprise apps, PIM, or entitlement management.\nAccess rights of users\nReviewers can be\nReview created in\nReviewer experience\nSecurity group members\nOffice group members\nSpecified reviewers\nGroup owners\nSelf-review\naccess reviews\nMicrosoft Entra groups\nAccess panel\nAssigned to a connected app\nSpecified reviewers\nSelf-review\naccess reviews\nMicrosoft Entra enterprise apps\nAccess panel\nMicrosoft Entra role\nSpecified reviewers\nSelf-review\nPIM\nMicrosoft Entra admin center\nAzure resource role\nSpecified reviewers\nSelf-review\nPIM\nMicrosoft Entra admin center\nAccess package assignments\nSpecified reviewers\nGroup members\nSelf-review\nentitlement management\nAccess panel\nAccess rights from custom data resources (preview)\nManagers\naccess reviews\nAccess panel\nLicense requirements\nThis feature requires Microsoft Entra ID Governance or Microsoft Entra Suite subscriptions, for your organization's users. Some capabilities, within this feature, may operate with a Microsoft Entra ID P2 subscription. For more information, see the articles of each capability for more details. To find the right license for your requirements, see\nMicrosoft Entra ID Governance licensing fundamentals\n.\nNote\nCreating a review on inactive users and with\nuser-to-group affiliation\nrecommendations, or an\naccess review of multiple resources together (preview)\n, requires a Microsoft Entra ID Governance license.\nAccess Review Agent (Preview)\nThe Access Review Agent works for your reviewers by automatically gathering insights and generating recommendations. It then guides reviewers through the review process in Microsoft Teams with natural language, with simple summaries and proposed decisions, so they can make the final call with confidence and clarity. For more information, see\nAccess Review Agent\n.\nNext steps\nPrepare for an access review of users' access to an application\nCreate an access review of groups or applications\nCreate an access review of users in a Microsoft Entra administrative role\nCreate an access review to multiple resources in a catalog (preview)\nReview access to groups or applications\nComplete an access review of groups or applications\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Access Reviews",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/id-governance/create-access-review": {
      "content_hash": "sha256:0baf457b37e5e4c8f6d13c163eb9998c0baf4108c681052b69d36334d94aa998",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate an access review of groups and applications in Microsoft Entra ID\nFeedback\nSummarize this article for me\nAccess to groups and applications for employees and guests changes over time. To reduce the risk associated with stale access assignments, administrators can use Microsoft Entra ID to create access reviews for group members or application access.\nMicrosoft 365 and Security group owners can also use Microsoft Entra ID to create access reviews for group members as long as a user with at least the Identity Governance Administrator role enables the setting via the\nAccess Reviews Settings\npane. For more information about these scenarios, see\nManage access reviews\n.\nWatch a short video that talks about enabling access reviews.\nThis article describes how to create one or more access reviews for group members or application access.\nTo review access package assignments, see\nconfigure an access review in entitlement management\n.\nTo review Azure resource or Microsoft Entra roles, see\nCreate an access review of Azure resource and Microsoft Entra roles in Privileged Identity Management\n.\nFor reviews of PIM for Groups, see\ncreate an access review of PIM for Groups\n.\nFor reviews across multiple groups, applications and custom data providers, see\ncatalog access reviews (preview)\n.\nPrerequisites\nUsing this feature requires Microsoft Entra ID Governance or Microsoft Entra Suite licenses. To find the right license for your requirements, see\nMicrosoft Entra ID Governance licensing fundamentals\n.\nIf you're reviewing access to an application, then before you create the review, see the article on how to\nprepare for an access review of users' access to an application\nto ensure the application is integrated with Microsoft Entra ID in your tenant.\nNote\nAccess reviews capture a snapshot of access at the beginning of each review instance. Any changes made during the review process will be reflected in the subsequent review cycle. Essentially, with the commencement of each new recurrence, pertinent data regarding the users, resources under review, and their respective reviewers is retrieved.\nNote\nIn a group review, nested groups are automatically flattened, so users from nested groups appear as individual users. If a user is flagged for removal due to their membership in a nested group, they won't be automatically removed from the nested group, but only from direct group membership.\nCreate a single-stage access review\nScope\nSign in to the\nMicrosoft Entra admin center\nas at least an\nIdentity Governance Administrator\n.\nBrowse to\nID Governance\n>\nAccess Reviews\n.\nSelect\nNew access review\nto create a new access review.\nOn the Access reviews template screen, select\nReview access to a resource type\n.\nIn the\nSelect what to review\nbox, select which resource you want to review.\nIf you selected\nTeams + Groups\n, you have two options:\nAll Microsoft 365 groups with guest users\n: Select this option if you want to create recurring reviews on all your guest users across all your Microsoft Teams and Microsoft 365 groups in your organization. Dynamic groups and role-assignable groups aren't included. You can also choose to exclude individual groups by selecting\nSelect group(s) to exclude\n.\nSelect Teams + groups\n: Select this option if you want to specify a finite set of teams or groups to review. A list of groups to choose from appears on the right.\nIf you selected\nApplications\n, select one or more applications.\nNote\nSelecting multiple groups or applications results in the creation of multiple access reviews. For example, if you select five groups to review, the result is five separate access reviews.\nNow you can select a scope for the review. Your options are:\nGuest users only\n: This option limits the access review to only the Microsoft Entra B2B guest users in your directory.\nEveryone\n: This option scopes the access review to all user objects associated with the resource.\nNote\nIf you selected\nAll Microsoft 365 groups with guest users\n, your only option is to review\nGuest users only\n.\nOr if you're conducting group membership review, you can create access reviews for only the inactive users in the group. In the\nUsers scope\nsection, check the box next to\nInactive users (on tenant level)\n. If you check the box, the scope of the review focuses on inactive users only, those who haven't signed in either interactively or non-interactively to the tenant. Then, specify\nDays inactive\nwith many days inactive up to 730 days (two years). Users in the group inactive for the specified number of days are the only users in the review.\nNote\nRecently created users aren't affected when configuring the inactivity time. The Access Review checks if a user has been created in the time frame configured and disregard users who havenât existed for at least that amount of time. For example, if you set the inactivity time as 90 days and a guest user was created or invited less than 90 days ago, the guest user won't be in scope of the Access Review. This ensures that a user can sign in at least once before being removed.\nSelect\nNext: Reviews\n.\nNext: Reviews\nYou can create a single-stage or multi-stage review. For a single stage review, continue here. To create a multi-stage access review, follow the steps in\nCreate a multi-stage access review\nIn the\nSpecify reviewers\nsection, in the\nSelect reviewers\nbox, select either one or more people to make decisions in the access reviews. You can choose from:\nGroup owner(s)\n: This option is only available when you do a review on a team or group.\nSelected user(s) or groups(s)\nUsers review their own access\nManagers of users\nIf you choose either\nManagers of users\nor\nGroup owner(s)\n, you can also specify a fallback reviewer. Fallback reviewers are asked to do a review when the user has no manager specified in the directory or if the group doesn't have an owner.\nNote\nIn a team or group access review, only the group owners (at the time a review starts) are considered as reviewers. During a review, if the list of group owners is updated, new group owners won't be considered reviewers and old group owners will still be considered reviewers. However, in the case of a recurring review, any changes on the group owners list will be considered in the next instance of that review.\nImportant\nFor access reviews of PIM for Groups (preview), when selecting the group owner as the reviewer, it's mandatory to assign at least one fallback reviewer. The review will only assign active owner(s) as the reviewer(s). Eligible owners aren't included. If there are no active owners when the review begins, the fallback reviewer(s) will be assigned to the review.\nIn the\nSpecify recurrence of review\nsection, specify the following selections:\nDuration (in days)\n: How long a review is open for input from reviewers.\nStart date\n: When the series of reviews begins.\nEnd date\n: When the series of reviews ends. You can specify that it\nNever\nends. Or, you can select\nEnd on a specific date\nor\nEnd after number of occurrences\n.\nSelect\nNext: Settings\n.\nNote\nWhen creating an access review, you're able to specify the start date, but the start time could vary a few hours based on system processing. For example, if you create an access review at 03:00 UTC on 09/09 that is set to run on 09/12, then the review is scheduled to run at 03:00 UTC on the start date, but could be delayed due to system processing.\nYou're able to specify the start date, but the start time can vary a few hours based on system processing.\nNext: Settings\nIn the\nUpon completion settings\nsection, you can specify what happens after the review finishes.\nAuto apply results to resource\n: Select this checkbox if you want access of denied users to be removed automatically after the review duration ends. If the option is disabled, you have to manually apply the results when the review finishes. To learn more about applying the results of the review, see\nManage access reviews\n.\nIf reviewers don't respond\n: Use this option to specify what happens for users not reviewed by any reviewer within the review period. This setting doesn't affect users who were reviewed by a reviewer. The dropdown list shows the following options:\nNo change\n: Leaves a user's access unchanged.\nRemove access\n: Removes a user's access.\nApprove access\n: Approves a user's access.\nTake recommendations\n: Takes the system's recommendation to deny or approve the user's continued access.\nWarning\nIf the settings\nIf reviewers don't respond\nis set to\nRemove access\nor\nTake recommendations\nand\nAuto apply results to resource\nis enabled, all access to this resource could potentially be revoked if the reviewers fail to respond.\nAction to apply on denied guest users\n: This option is only available if the access review is scoped to include only guest users to specify what happens to guest users if they're denied either by a reviewer or by the\nIf reviewers don't respond\nsetting.\nRemove user's membership from the resource\n: This option removes a denied guest user's access to the group or application being reviewed. They can still sign in to the tenant and won't lose any other access.\nBlock user from signing-in for 30 days, then remove user from the tenant\n: This option blocks a denied guest user from signing in to the tenant, no matter if they have access to other resources. If this action was taken in error, admins can reenable the guest user's access within 30 days after the guest user was disabled. If no action is taken on the disabled guest user after 30 days, they're deleted from the tenant.\nTo learn more about best practices for removing guest users who no longer have access to resources in your organization, see\nUse Microsoft Entra ID Governance to review and remove external users who no longer have resource access\n.\nNote\nAction to apply on denied guest users\nisn't configurable on reviews scoped to more than guest users. It's also not configurable for reviews of\nAll Microsoft 365 groups with guest users.\nWhen not configurable, the default option of removing a user's membership from the resource is used on denied users.\nUse the\nAt end of review, send notification to\noption to send notifications to other users or groups with completion updates. This feature allows for stakeholders other than the review creator to be updated on the progress of the review. To use this feature, choose\nSelect User(s) or Group(s)\nand add another user or group for which you want to receive the status of completion.\nIn the\nEnable review decision helpers\nsection choose whether you want your reviewer to receive recommendations during the review process:\nIf you select\nNo sign-in within 30 days\n, users who have signed in during the previous 30-day period are recommended for approval. Users who haven't signed in during the past 30 days are recommended for denial. This 30-day interval is irrespective of whether the sign-ins were interactive or not. The last sign-in date for the specified user will also display along with the recommendation.\nIf you select\nUser-to-Group Affiliation\n, reviewers get the recommendation to Approve or Deny access for the users based on userâs average distance in the organizationâs reporting-structure. Users who are distant from all the other users within the group are considered to have \"low affiliation\" and will get a deny recommendation in the group access reviews.\nNote\nIf you create an access review based on applications, your recommendations are based on the 30-day interval period depending on when the user last signed in to the application rather than the tenant.\nIn the\nAdvanced settings\nsection, you can choose the following:\nJustification required\n: Select this checkbox to require the reviewer to supply a reason for approval or denial.\nEmail notifications\n: Select this checkbox to have Microsoft Entra ID send email notifications to reviewers when an access review starts and to administrators when a review finishes.\nReminders\n: Select this checkbox to have Microsoft Entra ID send reminders of access reviews in progress to all reviewers. Reviewers receive the reminders halfway through the review, no matter if they've finished their review or not.\nAdditional content for reviewer email\n: The content of the email sent to reviewers is autogenerated based on the review details, such as review name, resource name, and due date. If you need to communicate more information, you can specify details such as instructions or contact information in the box. The information that you enter is included in the invitation, and reminder emails are sent to assigned reviewers. The section highlighted in the following image shows where this information appears.\nAccess Review Agent (Preview)\n: Select this checkbox to allow reviewers to complete the access review in Microsoft Teams with natural language, insights, and recommendations.\nNote\nThis setting is only available for review configurations currently supported by the Access Review Agent and additional setup steps are required. For more information, see:\nAccess Review Agent with Microsoft Security Copilot\n.\nSelect\nNext: Review + Create\n.\nNext: Review + Create\nName the access review. Optionally, give the review a description. The name and description are shown to the reviewers.\nReview the information and select\nCreate\n.\nCreate a multi-stage access review\nA multi-stage review allows the administrator to define two or three sets of reviewers to complete a review one after another. In a single-stage review, all reviewers make a decision within the same period and the last reviewer to make a decision, has their decision applied. In a multi-stage review, two or three independent sets of reviewers each make a decision within their own stage. The stages are sequential, and the next stage doesn't happen until a decision is recorded in the previous stage. Multi-stage reviews can be used to reduce the burden on later-stage reviewers, allow for escalation of reviewers, or have independent groups of reviewers agree on decisions.\nNote\nData of users included in multi-stage access reviews are a part of the audit record at the start of the review. Administrators can delete the data at any time by deleting the multi-stage access review series. For general information about GDPR and protecting user data, see the\nGDPR section of the Microsoft Trust Center\nand the\nGDPR section of the Service Trust portal\n.\nAfter you have selected the resource and scope of your review, move on to the\nReviews\ntab.\nSelect the checkbox next to\nMulti-stage review\n.\nUnder\nFirst stage review\n, select the reviewers from the dropdown menu next to\nSelect reviewers\n.\nIf you select\nGroup owner(s)\nor\nManagers of Users\n, you have the option to add a fallback reviewer. To add a fallback, select\nSelect fallback reviewers\nand add the users you want to be fallback reviewers.\nAdd the duration for the first stage. To add the duration, enter a number in the field next to\nStage duration (in days)\n. This is the number of days you wish for the first stage to be open to the first stage reviewers to make decisions.\nUnder\nSecond stage review\n, select the reviewers from the dropdown menu next to\nSelect reviewers\n. These reviewers will be asked to review after the duration of the first stage review ends.\nAdd any fallback reviewers if necessary.\nAdd the duration for the second stage.\nBy default, you see two stages when you create a multi-stage review. However, you can add up to three stages. If you want to add a third stage, select\n+ Add a stage\nand complete the required fields.\nYou can decide to allow 2nd and 3rd stage reviewers to see decisions made in the previous stage(s). If you want to allow them to see the decisions made prior, select the box next to\nShow previous stage(s) decisions to later stage reviewers\nunder\nReveal review results\n. Leave the box unchecked to disable this setting if youâd like your reviewers to review independently.\nThe duration of each recurrence is set to the sum of the duration day(s) you specified in each stage.\nSpecify the\nReview recurrence\n, the\nStart date\n, and\nEnd date\nfor the review. The recurrence type must be at least as long as the total duration of the recurrence (that is, the max duration for a weekly review recurrence is 7 days).\nTo specify which reviewees will continue from stage to stage, select one or multiple of the following options next to\nSpecify reviewees to go to next stage\n:\nApproved reviewees\n- Only reviewees that were approved move on to the next stage(s).\nDenied reviewees\n- Only reviewees that were denied move on to the next stage(s).\nNot reviewed reviewees\n- Only reviewees that haven't been reviewed will move on to the next stage(s).\nReviewees marked as \"Don't Know\"\n- Only reviewees marked as \"Don't know\" move on to the next stage(s).\nAll\n: everyone moves on to the next stage if youâd like all stages of reviewers to make a decision.\nContinue on to the\nsettings tab\nand finish the rest of the settings and create the review. Follow the instructions in\nNext: Settings\n.\nInclude B2B direct connect users and teams accessing Teams Shared Channels in access reviews\nYou can create access reviews for B2B direct connect users via shared channels in Microsoft Teams. As you collaborate externally, you can use Microsoft Entra access reviews to make sure external access to shared channels stays current. External users in the shared channels are called B2B direct connect users. To learn more about Teams Shared Channels and B2B direct connect users, read the\nB2B direct connect\narticle.\nWhen you create an access review on a Team with shared channels, your reviewers can review continued need for access of those external users and Teams in the shared channels. You can review access of B2B connect users and other supported B2B collaboration users and non-B2B internal users in the same review.\nNote\nCurrently, B2B direct connect users and teams are only included in single-stage reviews. If multi-stage reviews are enabled, the B2B direct connect users and teams won't be included in the access review.\nB2B direct connect users and teams are included in access reviews of the Teams-enabled Microsoft 365 group that the shared channels are a part of. To create the review, you must have at least the role of User Administrator or Identity Governance Administrator.\nUse the following instructions to create an access review on a team with shared channels:\nSign in to the\nMicrosoft Entra admin center\nas at least an\nIdentity Governance Administrator\n.\nBrowse to\nID Governance\n>\nAccess Reviews\n.\nSelect\n+ New access review\n.\nSelect\nTeams + Groups\nand then select\nSelect teams + groups\nto set the\nReview scope\n. B2B direct connect users and teams aren't included in reviews of\nAll Microsoft 365 groups with guest users\n.\nSelect a Team that has shared channels shared with 1 or more B2B direct connect users or Teams.\nSet the\nScope\n.\nChoose\nAll users\nto include:\nAll internal users\nB2B collaboration users that are members of the Team\nB2B direct connect users\nTeams that access shared channels\nOr, choose\nGuest users only\nto only include B2B direct connect users and Teams and B2B collaboration users.\nContinue on to the\nReviews\ntab. Select a reviewer to complete the review, then specify the\nDuration\nand\nReview recurrence\n.\nNote\nIf you set\nSelect reviewers\nto\nUsers review their own access\nor\nManagers of users\n, B2B direct connect users and Teams won't be able to review their own access in your tenant. The owner of the Team under review gets an email that asks the owner to review the B2B direct connect user and Teams.\nIf you select\nManagers of users\n, a selected fallback reviewer reviews any user without a manager in the home tenant. This includes B2B direct connect users and Teams without a manager.\nGo on to the\nSettings\ntab and configure additional settings. Then go to the\nReview and Create\ntab to start your access review. For more detailed information about creating a review and configuration settings, see our\nCreate a single-stage access review\n.\nAllow group owners to create and manage access reviews of their groups\nSign in to the\nMicrosoft Entra admin center\nas at least an\nIdentity Governance Administrator\n.\nBrowse to\nID Governance\n>\nAccess Reviews\n>\nSettings\n.\nOn the\nDelegate who can create and manage access reviews\npage, set\nGroup owners can create and manage access reviews for groups they own\nto\nYes\n.\nNote\nBy default, the setting is set to\nNo\n. To allow group owners to create and manage access reviews, change the setting to\nYes\n.\nCreate an access review programmatically\nYou can also create an access review using Microsoft Graph or PowerShell.\nTo create an access review using Graph, call the Graph API to\ncreate an access review schedule definition\n. The caller must either be a user in an appropriate role with an application that has the delegated\nAccessReview.ReadWrite.All\npermission, or an application with the\nAccessReview.ReadWrite.All\napplication permission. For more information, see the\nOverview of access reviews APIs\nand the tutorials for how to\nreview members of a security group\nor\nreview guests in Microsoft 365 groups\n.\nYou can also create an access review in PowerShell with the\nNew-MgIdentityGovernanceAccessReviewDefinition\ncmdlet from the\nMicrosoft Graph PowerShell cmdlets for Identity Governance\nmodule. For more information, see the\nexamples\n.\nWhen an access review starts\nAfter you've specified the settings for an access review, and created it, the access review appears in your list with an indicator of its status.\nBy default, Microsoft Entra ID sends an email to reviewers shortly after a one-time review, or a recurrence of a recurring review, starts. If you choose not to have Microsoft Entra ID send the email, be sure to inform the reviewers that an access review is waiting for them to complete. You can show them the instructions for how to\nreview access to groups or applications\n. If your review is for guests to review their own access, show them the instructions for how to\nreview access for yourself to groups or applications\n.\nIf you've assigned guests as reviewers and they haven't accepted their invitation to the tenant, they won't receive an email from access reviews. They must first accept the invitation before they can begin reviewing.\nUpdate the access review\nAfter one or more access reviews have started, you might want to modify or update the settings of your existing access reviews. Here are some common scenarios to consider:\nUpdate settings or reviewers:\nIf an access review is recurring, there are separate settings under\nCurrent\nand under\nSeries\n. Updating the settings or reviewers under\nCurrent\nonly applies changes to the current access review. Updating the settings under\nSeries\nupdates the settings for all future recurrences.\nAdd and remove reviewers:\nWhen you update access reviews, you might choose to add a fallback reviewer in addition to the primary reviewer. Primary reviewers might be removed when you update an access review. Fallback reviewers aren't removable by design.\nNote\nFallback reviewers can only be added when the reviewer type is a manager or a group owner. Primary reviewers can be added when the reviewer type is the selected user.\nRemind the reviewers:\nWhen you update access reviews, you might choose to enable the\nReminders\noption under\nAdvanced settings\n. Users then receive an email notification at the midpoint of the review period, whether they've finished the review or not.\nNote\nOnce the access review is initiated, you can use the\ncontactedReviewers\nAPI call to see the list of all reviewers notified, or who would be if notifications are turned off, via email for an access review. Time stamps for when these users were notified are also provided.\nNote\nGroups and users in a restricted management administrative unit can't be managed with Microsoft Entra ID Governance features such as\nAccess reviews\n.\nNext steps\nComplete an access review of groups or applications\nAccess Review Agent (preview)\nCreate an access review of PIM for Groups (preview)\nReview access to groups or applications\nReview access for yourself to groups or applications\nCreate an access review of Azure resource and Microsoft Entra roles in PIM\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Create Access Review",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-configure": {
      "content_hash": "sha256:08650143a2c92e3c677d7d9393f32360beaaa4823f5c477190043a11a674d819",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Microsoft Entra Privileged Identity Management?\nFeedback\nSummarize this article for me\nPrivileged Identity Management (PIM) is a service in Microsoft Entra ID that enables you to manage, control, and monitor access to important resources in your organization. These resources include resources in Microsoft Entra ID, Azure, and other Microsoft Online Services such as Microsoft 365 or Microsoft Intune. The following video explains important PIM concepts and features.\nReasons to use\nOrganizations want to minimize the number of people who have access to secure information or resources, because that reduces the chance of\na malicious actor getting access\nan authorized user inadvertently impacting a sensitive resource\nHowever, users still need to carry out privileged operations in Microsoft Entra ID, Azure, Microsoft 365, or SaaS apps. Organizations can give users just-in-time privileged access to Azure and Microsoft Entra resources and can oversee what those users are doing with their privileged access.\nLicense requirements\nUsing Privileged Identity Management requires licenses. For more information on licensing, see\nMicrosoft Entra ID Governance licensing fundamentals\n.\nWhat does it do?\nPrivileged Identity Management provides time-based and approval-based role activation to mitigate the risks of excessive, unnecessary, or misused access permissions on resources that you care about. Here are some of the key features of Privileged Identity Management:\nProvide\njust-in-time\nprivileged access to Microsoft Entra ID and Azure resources\nAssign\ntime-bound\naccess to resources using start and end dates\nRequire\napproval\nto activate privileged roles\nEnforce\nmultifactor authentication\nto activate any role\nUse\njustification\nto understand why users activate\nGet\nnotifications\nwhen privileged roles are activated\nConduct\naccess reviews\nto ensure users still need roles\nDownload\naudit history\nfor internal or external audit\nPrevents removal of the\nlast active Global Administrator\nand\nPrivileged Role Administrator\nrole assignments\nWhat can I do with it?\nOnce you set up Privileged Identity Management, you'll see\nTasks\n,\nManage\n, and\nActivity\noptions in the left navigation menu. As an administrator, you can choose between options such as managing\nMicrosoft Entra roles\n, managing\nAzure resource\nroles, or PIM for Groups. When you choose what you want to manage, you see the appropriate set of options for that option.\nWho can do what?\nFor Microsoft Entra roles in Privileged Identity Management, only a user who is in the Privileged Role Administrator or Global Administrator role can manage assignments for other administrators. Global Administrators, Security Administrators, Global Readers, and Security Readers can also view assignments to Microsoft Entra roles in Privileged Identity Management.\nFor Azure resource roles in Privileged Identity Management, only a subscription administrator, a resource Owner, or a resource User Access Administrator can manage assignments for other administrators. Users who are Privileged Role Administrators, Security Administrators, or Security Readers don't by default have access to view assignments to Azure resource roles in Privileged Identity Management.\nTerminology\nTo better understand Privileged Identity Management and its documentation, you should review the following terms.\nTerm or concept\nRole assignment category\nDescription\neligible\nType\nA role assignment that requires a user to perform one or more actions to use the role. If a user is eligible for a role, they can activate the role when they need to perform privileged tasks. There's no difference in the access given to someone with a permanent versus an eligible role assignment. The only difference is that some people don't need that access all the time.\nactive\nType\nA role assignment that doesn't require a user to perform any action to use the role. Users assigned as active have the privileges assigned to the role.\nactivate\nThe process of performing one or more actions to use a role that a user is eligible for. Actions might include performing a multifactor authentication (MFA) check, providing a business justification, or requesting approval from designated approvers.\nassigned\nState\nA user that has an active role assignment.\nactivated\nState\nA user that has an eligible role assignment, performed the actions to activate the role, and is now active. Once activated, the user can use the role for a preconfigured period of time before they need to activate again.\npermanent eligible\nDuration\nA role assignment where a user is always eligible to activate the role.\npermanent active\nDuration\nA role assignment where a user can always use the role without performing any actions.\ntime-bound eligible\nDuration\nA role assignment where a user is eligible to activate the role only within start and end dates.\ntime-bound active\nDuration\nA role assignment where a user can use the role only within start and end dates.\njust-in-time (JIT) access\nA model in which users receive temporary permissions to perform privileged tasks, which prevents malicious or unauthorized users from gaining access after the permissions expire. Access is granted only when users need it.\nprinciple of least privilege access\nA recommended security practice in which every user is provided with only the minimum privileges needed to accomplish the tasks they're authorized to perform. This practice minimizes the number of Global Administrators and instead uses specific administrator roles for certain scenarios.\nRole assignment overview\nThe PIM role assignments give you a secure way to grant access to resources in your organization. This section describes the assignment process. It includes assign roles to members, activate assignments, approve or deny requests, extend and renew assignments.\nPIM keeps you informed by sending you and other participants\nemail notifications\n. These emails might also include links to relevant tasks, such activating, approve or deny a request.\nThe following screenshot shows an email message sent by PIM. The email informs Patti that Alex updated a role assignment for Emily.\nAssign\nThe assignment process starts by assigning roles to members. To grant access to a resource, the administrator assigns roles to users, groups, service principals, or managed identities. The assignment includes the following data:\nThe members or owners to assign the role.\nThe scope of the assignment. The scope limits the assigned role to a particular set of resources.\nThe type of the assignment\nEligible\nassignments require the member of the role to perform an action to use the role. Actions might include activation, or requesting approval from designated approvers.\nActive\nassignments don't require the member to perform any action to use the role. Members assigned as active have the privileges assigned to the role.\nThe duration of the assignment, using start and end dates or permanent. For eligible assignments, the members can activate or requesting approval during the start and end dates. For active assignments, the members can use the assigned role during this period of time.\nThe following screenshot shows how administrator assigns a role to members.\nFor more information, check out the following articles:\nAssign Microsoft Entra roles\n,\nAssign Azure resource roles\n, and\nAssign eligibility for a PIM for Groups\nActivate\nIf users are eligible for a role, then they must activate the role assignment before using the role. To activate the role, users select specific activation duration within the maximum (configured by administrators), and the reason for the activation request.\nThe following screenshot shows how members activate their role to a limited time.\nIf the role requires\napproval\nto activate, a notification appears in the upper right corner of the user's browser informing them the request is pending approval. If an approval isn't required, the member can start using the role.\nFor more information, check out the following articles:\nActivate Microsoft Entra roles\n,\nActivate my Azure resource roles\n, and\nActivate my PIM for Groups roles\nApprove or deny\nDelegated approvers receive email notifications when a role request is pending their approval. Approvers can view, approve, or deny these pending requests in PIM. After the request is approved, the member can start using the role. For example, if a user or a group was assigned with Contribution role to a resource group, they are able to manage that particular resource group.\nFor more information, check out the following articles:\nApprove or deny requests for Microsoft Entra roles\n,\nApprove or deny requests for Azure resource roles\n, and\nApprove activation requests for PIM for Groups\nExtend and renew assignments\nAfter administrators set up time-bound owner or member assignments, the first question you might ask is what happens if an assignment expires? In this new version, we provide two options for this scenario:\nExtend\nâ When a role assignment nears expiration, the user can use Privileged Identity Management to request an extension for the role assignment\nRenew\nâ When a role assignment expires, the user can use Privileged Identity Management to request a renewal for the role assignment\nBoth user-initiated actions require an approval from a Global Administrator or Privileged Role Administrator. Admins don't need to be in the business of managing assignment expirations. You can just wait for the extension or renewal requests to arrive for simple approval or denial.\nFor more information, check out the following articles:\nExtend or renew Microsoft Entra role assignments\n,\nExtend or renew Azure resource role assignments\n, and\nExtend or renew PIM for Groups assignments\nScenarios\nPrivileged Identity Management supports the following scenarios:\nPrivileged Role Administrator permissions\nEnable approval for specific roles\nSpecify approver users or groups to approve requests\nView request and approval history for all privileged roles\nApprover permissions\nView pending approvals (requests)\nApprove or reject requests for role elevation (single and bulk)\nProvide justification for my approval or rejection\nEligible role user permissions\nRequest activation of a role that requires approval\nView the status of your request to activate\nComplete your task in Microsoft Entra ID if activation was approved\nMicrosoft Graph APIs\nYou can use Privileged Identity Management programmatically through the following Microsoft Graph APIs:\nPIM for Microsoft Entra roles APIs\nPIM for groups APIs\nNext steps\nLicense requirements to use Privileged Identity Management\nSecuring privileged access for hybrid and cloud deployments in Microsoft Entra ID\nDeploy Privileged Identity Management\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Privileged Identity Management",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/identity/users/": {
      "content_hash": "sha256:4e79ca0128d4634567c01f8f89ae01ca8d1a2e1e7198c3abee14070a82513e02",
      "normalized_content": "Table of contents\nRead in English\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nEnterprise user management documentation\nMicrosoft Entra ID provides user management services so that you can assign licenses, manage your groups and users, and add or manage domain names.\nAbout enterprise user management\nOverview\nUsers, groups, domains, and licenses\nCustom roles overview\nConcept\nMicrosoft Entra organizational independence\nManage access using groups\nGet started\nQuickstart\nAdd a user\nSet expiration policy for groups\nAssign licenses to users\nManage Microsoft Entra domain names\nHow-To Guide\nAdd your custom domain name\nManaging custom domain names\nManage groups\nHow-To Guide\nCreate a dynamic group\nGroup settings in PowerShell\nSet naming policy for groups\nAdd domains\nHow-To Guide\nAdd a custom domain name\nManaging custom domain names",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "User Management",
      "section": "Microsoft Entra ID"
    },
    "https://learn.microsoft.com/en-us/entra/agent-id/": {
      "content_hash": "sha256:793b4b04f5c3b0bceddeefc7c285bd30892bebfb6f11b7a1ae1e03de0edde016",
      "normalized_content": "Microsoft Entra Agent ID documentation\nSecure and govern AI agents at enterprise scale with Microsoft Entra Agent ID and the Microsoft agent identity platform. Create agent identities, apply Zero Trust controls, and manage agent access to your organization's resources.\nOverview\nWhat is Microsoft Entra Agent ID?\nOverview\nMicrosoft agent identity platform for developers\nOverview\nWhat is an agent identity?\nHow-To Guide\nCreate an agent identity\nMicrosoft Entra Agent ID\nThe comprehensive solution for protecting and governing AI agents in enterprise environments. Includes advanced security controls, and governance policies for agent identities and access management.\nRegister and manage agents\nWhat is Microsoft Entra Agent ID?\nWhat is the Agent Registry?\nOrganize agents with collections\nAgent governance and lifecycles\nIdentity Governance for agents\nAgent identity lifecycle management\nProtect agent access to resources\nConditional Access for agents\nIdentity Protection for agents\nNetwork controls for agents\nMicrosoft agent identity platform for developers\nThe platform that enables you to create, register, and manage agent identities. Includes the Agent Registry for discovering and organizing agents across your organization.\nMicrosoft agent identity platform for developers\nWhat is an agent identity blueprint?\nCreate an agent identity blueprint\nWhat is an agent identity?\nCreate an agent identity\nConfigure Microsoft Entra SDK for agent identities\nAgent Registry\nWhat is the Agent Registry?\nRegister agents with the Agent Registry\nAgent Registry collections\nAgent Registry metadata and discoverability\nAgent communications\nLearn more\nExplore SDK references, API documentation, and code samples to build and manage agent identities.\nTechnical references\nSDK Reference\nMicrosoft Graph API reference\nOAuth protocols for Agent identities\nRelated content\nSecurity for AI\nSecurity Copilot + Microsoft Entra",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent ID Overview",
      "section": "Microsoft Entra Agent ID"
    },
    "https://learn.microsoft.com/en-us/entra/agent-id/identity-professional/microsoft-entra-agent-identities-for-ai-agents": {
      "content_hash": "sha256:2f4b36afdea16c977e20df35c1f37c78668693e670732121ae9a1e1dcdf0ed84",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Microsoft Entra Agent ID?\nFeedback\nSummarize this article for me\nImportant\nMicrosoft Entra Agent ID\nis currently in PREVIEW.\nThis information relates to a prerelease product that may be substantially modified before it's released. Microsoft makes no warranties, expressed or implied, with respect to the information provided here.\nAs assistive and autonomous agents become more prevalent in organizations, new security, governance, and compliance challenges must be addressed. Microsoft Entra Agent ID extends the comprehensive security capabilities of Microsoft Entra to agents, enabling organizations to build, discover, govern, and protect agent identities.\nSecurity for AI\nspans multiple Microsoft Entra features and is integrated through Microsoft Entra Agent ID and the\nMicrosoft agent identity platform for developers\n.\nThis article explains how Microsoft Entra Agent ID extends security capabilities to agents through conditional access policies, identity protection, identity governance, network-level controls, and the agent identity platform.\nImportant\nMicrosoft Entra Agent ID is part of Microsoft Agent 365, available now in Frontier, the Microsoft early access program for the latest AI innovations. For more information, see\nMicrosoft Entra Agent ID\n.\nConditional access for agents\nConditional access enables organizations to define and enforce adaptive policies that evaluate agent context and risk before granting access to resources. It's achieved by:\nEnforcing adaptive access control policies for all agent patterns across assistive, autonomous, and agent user types.\nUsing real-time signals such as agent identities risk controlling agent access to resources, with Microsoft Managed Policies providing a secure baseline by blocking high-risk agents.\nDeploying conditional access policies at scale using custom security attributes, while still supporting fine-grained controls for individual agents.\nFor more information, see\nConditional Access\n.\nIdentity governance for agents\nMicrosoft Entra Agent ID brings agent IDs into similar identity governance processes as users, enabling them to be managed at scale. You can establish controls for agent access lifecycle using features such as entitlement management access packages.\nGovern agent IDs at scale, from deployment to expiration.\nEnsure sponsors and owners are assigned and maintained for each agent ID, preventing orphaned agent IDs.\nEnforce that agent access to resources is intentional, auditable, and time-bound through access packages.\nFor more information, see\nidentity governance for agents\n.\nIdentity protection for agents\nIdentity protection detects and blocks threats by flagging anomalous activities involving agents. Risk signals are used to enforce risk-based access policies and inform agent discoverability.\nDetect agent identity risk derived from user risk and based on agents' own actions, including unusual or unauthorized activities.\nProvide risk signals to conditional access to enforce risk-based policies and session management controls.\nProvide risk signals to the Agent Registry to inform agent discoverability and access, with automatic remediation of compromised agents using preconfigured policies.\nFor more information, see\nidentity protection for agents\nNetwork controls for agents\nNetwork controls enforce consistent network security policies across users and agents across any platform or application. Provide full network visibility to all agent actions, filter malicious web content, enable network-based security controls, and prevent data exfiltration.\nLog agent network activity to remote tools for audit and threat detection, and apply web categorization to control access to APIs and MCP servers.\nRestrict file uploads and downloads using file-type policies to minimize risk, and automatically block and alert on malicious destinations using threat intelligence-based filtering.\nDetect and block prompt injection attacks that attempt to manipulate agent behavior through malicious instructions.\nFor more information, see\nNetwork controls for agents\n.\nMicrosoft Entra Agent identity platform for developers\nThe Microsoft Entra Agent identity platform enables you to assign identities to agents, autodiscover them across your organization, and manage all agent metadata in one place including capabilities, tasks, and protocols.\nProvides visibility into all organization agents with agent-to-agent discovery and authorization based on standard protocols such as MCP and A2A.\nAssign secure, scalable identities to every agent.â Authenticates and authorizes agents based on standard protocols.\nLog and monitor agent activity for compliance.â\nFor more information, see\nMicrosoft Entra Agent Identity Platform\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent Identities for AI Agents",
      "section": "Microsoft Entra Agent ID"
    },
    "https://learn.microsoft.com/en-us/entra/id-governance/agent-id-governance-overview": {
      "content_hash": "sha256:504fb04d20bd21866ba1bba1ffce6b2df99770d938e234e8b6492c2f21eca9ba",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGoverning Agent Identities (Preview)\nFeedback\nSummarize this article for me\nMicrosoft Entra allows you to ensure that the right people have the right access to the right apps and services at the right time. With the addition of the Microsoft agent identity platform, managing agents in the same way is just as important in the governance lifecycle of your organization. The Microsoft agent identity platform introduces the concept of Agent Identities (IDs). Agent identities are accounts within Microsoft Entra ID that provide unique identification and authentication capabilities for AI agents.\nThis allows agent identities to be governed with Microsoft Entra features in the same style as you would govern human identities. With Agent identities, you can govern and manage the identity and access lifecycle of agents, ensuring the agents have a responsible person providing oversight throughout the agent lifecycle and agent's access does not persist longer than it is needed. This article provides an overview of how Microsoft Entra can be utilized to govern agent identities.\nLicense requirements\nImportant\nMicrosoft Entra Agent ID is part of Microsoft Agent 365, available now in Frontier, the Microsoft early access program for the latest AI innovations. For more information, see\nMicrosoft Entra Agent ID\n.\nAgent identities basics\nHistorically, AI agents would rely upon tools to interact with various applications and systems, and each of those tools would have their own identities in those applications and systems. Some of those tools would use service principals to authenticate to Microsoft services via Microsoft Graph or Microsoft Azure APIs.\nMicrosoft Entra Agent ID\nintroduces support for identities for the agents themselves, with four new types of object: agent identity blueprint, agent identity blueprint principal, agent identity, and agent user. Through the\nagent identity blueprint\n, the agent can create one or more agent identities, and optionally an agent user for each agent identity. Each agent identity and agent user can have distinct access rights.\nFor a multi-tenant-capable agent, an agent identity blueprint principal can be brought into the tenant with resources so it can create agent identities in that tenant, similar to how a multi-tenant application can have a service principal in each tenant.\nThe agent identity and the agent user allow AI agents to take on digital identities within Microsoft Entra. Once agent identities are created, these agent identities are able to be governed using lifecycle and access features. Sponsors can be assigned to agent identities after creation. Sponsors of agent identities are human users accountable for making decisions about its lifecycle and access. For more information about the role of a sponsor of agent identities, see:\nAdministrative relationships for agent IDs\n.\nAgent identities in other Microsoft products and portals\nMicrosoft Foundry\nautomatically provisions and manages agent identities throughout the agent lifecycle. When the first agent in a Foundry project is created, Microsoft Foundry provisions a default agent identity blueprint and a default agent identity for the project, and agents in the project authenticate by using the shared project's agent identity. Publishing an agent automatically creates a dedicated agent identity blueprint and agent identity, and the agent will authenticate by using the unique agent identity. Foundry supports use of the agent identity for authentication in Model Context Protocol (MCP) and Agent-to-Agent (A2A) tools. For more information, see\nAgent identity concepts in Microsoft Foundry\n.\nYou can configure an\nAzure App Service or Azure Functions app\nto use the Microsoft Entra agent identity platform to securely connect to resources as an agent. For more information, see\nHow to use an agent identity in App Service and Azure Functions\n.\nAgents created in\nMicrosoft Copilot Studio\ncan be configured to automatically be assigned to an agent identity. When an agent identity is first created in a Power Platform environment after enabling this setting, a Microsoft Copilot Studio agent identity blueprint, and an agent identity blueprint principal, are automatically created. For more information, see\nAutomatically create Entra agent identities for Copilot Studio agents (preview)\n.\nFor agents in the\nMicrosoft Teams\nplatform, a developer can create and manage agent identity blueprints in the Developer Portal for Teams. For more information, see\nManage your apps in Developer Portal\n.\nMicrosoft Agent 365\ngives each AI agent its own Microsoft Entra Agent ID, for identity, lifecycle, and access management. For more information, see\nAgent identity platform capabilities for Agent 365\n.\nAssigning access to agent identities\nWhen created, agent identities have limited permissions, such as OAuth 2 delegated permission scopes\ninherited from their parent agent identity blueprint\n. In addition, agent identities can have resource access assigned to them directly via access packages. Agents can request an access package for own agent IDs, or have their owner or sponsor request one on their behalf. With access packages, you're able to assign agent identities access to the following resources:\nSecurity Group memberships\nApplication roles and API permissions\n, including Graph application permissions\nMicrosoft Entra roles\nTo use access packages for agent identities, configure an access package with the required policy settings. When creating an access package assignment policy, in the\nWho can get access\nsection, select\nFor users, service principals, and agent identities in your directory\n, and then select the option of\nAll agents (preview)\n.\nNote\nIf your agents aren't using Microsoft Entra agent IDs, then also create an access package assignment policy with the option\nAll Service principals (preview)\nto allow service principals in your directory to be able to request this access package.\nAgents can then be assigned access packages through three different request pathways.\nThe agent identity itself can programmatically request an access package when needed for its operations, by creating an\naccessPackageAssignmentRequest\n.\nThe agent's sponsor can request access on behalf of the agent ID, providing human oversight in the access request process. For more information, see\nRequest an access package on behalf of an agent identity (Preview)\n.\nAn administrator can\ndirectly assign the agent identity or agent user to the access package\n.\nAfter submission, the access request is routed to designated approvers based on the access package configuration.\nWhen the agent identity has received an access package assignment with an expiry date, and if a sponsor is set on the agent identity, as the expiry date approaches, the sponsor receives notifications about the pending expiration. The sponsor then has two options: they can request an extension of the access package (if permitted by policy), or they can allow the access package assignment to expire. If the sponsor requests an extension, this request can trigger a new approval cycle, where approvers again confirm whether continued access is appropriate. If the sponsor takes no action, the access package assignment automatically expires on its end date, and the agent identity loses access to the target resources.\nFor a guide on creating an access package, see:\nCreate an access package in entitlement management\n. For a guide on assigning identities to an existing access package, see:\nView, add, and remove assignments for an access package in entitlement management\n.\nManagement of agents\nWhen agent identities are created, owners and sponsors of the agent can manually make decisions for the agent identity via both the My Account portal, and the My Access Portal.\nFrom the\nMy Account portal\n, Sponsors and Owners are able to manage the identity lifecycle of agents such as enabling and disabling the agent. You are also able to see information about its access, activity, and lifecycle. For more information about Managing agents, see:\nManage Agents in Microsoft Entra ID (Preview)\n.\nFrom the\nMy Access portal\n, Sponsors and Owners of agent identities are able to request access packages on behalf of their agent identities. For a guide on requesting access packages, see:\nRequest an access package on behalf of an agent identity (Preview)\n.\nAgent identities sponsor administration\nOne of the most important parts of governing agent identities is making sure that a delegated human user is always assigned to make sure the agent identity's access to resources are current. If the sponsor is leaving the organization, sponsorship of the agent identities is automatically transferred to their manager. With sponsorship transferred, there's always a human user accountable for managing the access and lifecycle of the agent identities. Microsoft Entra ID Governance features can help streamline this process within your organization. Lifecycle workflows include multiple tasks around notifying cosponsors, and managers of sponsors, of impending sponsorship changes. For a guide on setting up a workflow for agent identities sponsors, see:\nAgent identity sponsor tasks in Lifecycle Workflows (Preview)\n.\nRelated content\nWhat is entitlement management?\nWhat is Microsoft Entra ID Governance?\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Governing Agent Identities",
      "section": "Microsoft Entra Agent ID"
    },
    "https://learn.microsoft.com/en-us/sharepoint/sharepoint-admin-role": {
      "content_hash": "sha256:0a73476682580ff95aeb86beeac349bedf5de33c78a0915d8d50e10f2e4381d3",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAbout the SharePoint Administrator role in Microsoft 365\nFeedback\nSummarize this article for me\nUsers assigned the SharePoint Administrator role have access to the\nSharePoint admin center\nand can create and manage sites, designate site admins, manage sharing settings, and manage Microsoft 365 groups, including creating, deleting, and restoring groups, and changing group owners.\nGlobal Administrators in Microsoft 365 can assign users the SharePoint Administrator. The Global Administrator role already has all the permissions of the SharePoint Administrator role.\nFor info about assigning a user the SharePoint administrator role, see\nAssign admin roles in the Microsoft 365 admin center\n. If a user's role is changed so they gain or lose access to the SharePoint admin center, it takes about an hour for the change to take effect.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Using lower permissioned accounts helps improve security for your organization. Global Administrator is a highly privileged role that should be limited to emergency scenarios when you can't use an existing role.\nSite management\nGlobal Administrators and SharePoint Administrators don't have automatic access to all sites and each user's OneDrive, but they can give themselves access to any site or OneDrive. They can also use Microsoft PowerShell to manage SharePoint and OneDrive. See more about this role's\nKey tasks of the SharePoint admin\n.\nSite admins have permission to manage sites, but they don't need to have an admin role in Microsoft 365, and don't have access to the SharePoint admin center.\nFor info about adding or removing a site admin, see\nManage site admins\n.\nTerm store administration\nThere's a separate role within SharePoint called the Term Store administrator. Users assigned to this role can add or change terms in the term store (a directory of common terms you want to use across your organization). To learn more, see\nAssign roles and permissions to manage term sets\n.\nAPI access\nTo manage API access in the SharePoint admin center, you need at least a\napplication administrator role\n. For more information, see\nManage access to Microsoft Entra ID-secured APIs\n.\nKey tasks of the SharePoint admin\nHere are some of the key tasks users can do when they're assigned to the SharePoint Administrator role:\nCreate sites\nDelete sites\nManage sharing settings at the organization level\nAdd and remove site admins\nManage site storage limits\nRelated articles\nAbout Microsoft 365 admin roles\nGetting started with SharePoint Online Management Shell\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "SharePoint Admin Center",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/site-permissions": {
      "content_hash": "sha256:ffad727d1c318868d7e5703724e4268958af2b40bfcbec1a923cdacf486a97cd",
      "normalized_content": "Admin center site permissions reference\nOn the\nMembership\ntab, you can manage permissions for the site and also for any associated Microsoft 365 group or Microsoft Teams team. These roles are specific to the selected site or group and don't give users access to the SharePoint admin center.\nOwners\nMicrosoft 365 group owners can manage group membership, privacy, and classification, as well as the associated SharePoint site. If the Microsoft 365 group is associated with a team, then the group owners are also team owners.\nMembers\nMicrosoft 365 group members can participate in the group and have access to the associated SharePoint site. If the Microsoft 365 group is associated with a team, then the group members are also team members and can send messages and participate in channels if allowed by the team owner.\nSite admins\nSite admins (formerly called site collection administrators) have the highest level of SharePoint permissions. They have the same Full Control permissions of a site owner, plus they can do more things, such as managing search, the recycle bin, and site collection features. They also have access to any items in the site, including in subsites, even if permissions inheritance has been broken.\nIf there's a Microsoft 365 group or team connected to the site, then group or team owners are automatically included as site admins and group or team members are automatically included as site members. Managing site permissions through group or team membership is recommended over giving people permissions directly to the site. This method allows for easier administration and consistent access for users across group and team resources.\nNon-primary admins\nAdditional admins beyond the\nPrimary\nadmin are site admins only and can only manage the SharePoint site. They have no access to the associated Microsoft 365 group or team unless they have also been directly added to the group or team.\nSite owners\nSite owners have full control of the SharePoint site. If the site has an associated Microsoft 365 group or team, then group or team owners are automatically included as site owners. However, people added directly to the site owners group don't have access to the Microsoft 365 group or team unless they are added there directly.\nSite members\nSite members have edit permissions to the SharePoint site and can add and remove files, lists, and libraries. If the site has an associated Microsoft 365 group or team, then group or team members are automatically included as site members. However, people added directly to the site members group don't have access to the Microsoft 365 group or team unless they are added there directly.\nSite visitors\nSite visitors have view-only permissions to the SharePoint site. This permission level is only used by SharePoint and isn't related to permissions in an associated Microsoft 365 group or team.\nNote\nFor information on how to manage Site owners, Site members and Site visitors permission groups, see\nSharing and permissions in the SharePoint modern experience\n.\nAdditional permissions\nThere are additional\npermission levels\nin SharePoint beyond those shown on this panel. Users may have access to the site or its contents through those roles. Users may also have access to files or folders in the site through sharing links.\nSee also\nExternal sharing overview\nOverview of Microsoft 365 Groups for administrators",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Site Permissions",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/modern-experience-sharing-permissions": {
      "content_hash": "sha256:be74f8c2d68af63917b44960a1b9c8c31c97ecbb5be4aa272bd12481bd9dace5",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSharing and permissions in the SharePoint modern experience\nFeedback\nSummarize this article for me\nTraditionally, SharePoint permissions have been managed through a set of permissions groups within a site (Owners, Members, Visitors, etc.). In SharePoint in Microsoft 365, this remains true for some types of sites, but additional options are available and SharePoint is part of a much broader set of capabilities for\nsecure collaboration with Microsoft 365\n.\nThe main types of sites in SharePoint are:\nTeam sites\n- Team sites provide a collaboration environment for your teams and projects. Each team site, by default, is part of a Microsoft 365 group, which includes a mailbox, shared calendar, and other collaboration tools. Team sites may also be part of a team in Microsoft Teams. Permissions for team sites are best managed through the associated Microsoft 365 group or Teams team.\nChannel sites\n- Channel sites are team sites that are associated with a specific channel in a Teams team. Both private and shared channels create separate SharePoint sites just for the channel.\nCommunication sites\n- Communication sites are for broadcasting news and status across the organization. Communication site permissions are managed by using the SharePoint Owners, Members, and Visitors groups for the site.\nHub sites\n-\nHub sites\nare team sites or communication sites that the administrator has configured as the center of a hub. They're designed to provide connection between related sites through shared navigation. Permissions for hub sites can be managed through the Owners, Members, and Visitors groups, or through the associated Microsoft 365 group if there is one. Special permissions are needed to associate sites to a hub.\nTeam site permissions and Microsoft 365 Groups\nBy default, each SharePoint team site is part of an\nMicrosoft 365 group\n. A Microsoft 365 group is a single permissions group that is associated with various Microsoft 365 services. This includes a SharePoint site, an instance of Planner, a mailbox, a shared calendar, and others.\nWhen you add owners or members to the Microsoft 365 group, they're given access to the SharePoint site along with the other group-connected services. Group owners become site owners, and group members become site members.\nIt's possible to manage SharePoint site permissions separately from the Microsoft 365 group by using SharePoint groups, unless it's a channel site. (We recommend against this for the simplest management experience.) In such a case, group members will continue to have access to the site, but users added directly to the site won't have access to any of the group services. Microsoft 365 groups don't have view-only access, so any users you wish to have view permissions on the site must be added directly to the Visitors group on the site.\nUsing team sites with Teams\nMicrosoft Teams provides a hub for collaboration by bringing together various services including a SharePoint team site. Within the Teams experience, users can directly access SharePoint along with the other services. Each team is associated with a Microsoft 365 group and Teams uses that group to manage its permissions.\nFor scenarios where a SharePoint site is used with Teams, we recommend doing all permission management through Teams. As with Microsoft 365 groups, team owners become site owners and team members become site members.\nFor private or shared channel sites, permission management must be done in Teams. Channel owners become sites owners in SharePoint and channel members become site members. Permissions in SharePoint can't be managed separately and will display in read-only mode.\nFor details about how SharePoint and Teams interact, see\nOverview of Teams and SharePoint integration\nand\nManage settings and permissions when SharePoint and Teams are integrated\n.\nCommunication site permissions\nCommunication sites aren't connected to Microsoft 365 groups and use the standard SharePoint permissions groups:\nOwners\nMembers\nVisitors\nNormally with communication sites, you'll have one or more owners, a relatively small number of members who create the content for the site, and a large number of visitors who are the people you're sharing information with.\nYou can give people permissions to the site by adding individual users, security groups, or Microsoft 365 groups to one of the three SharePoint groups. (Nested security groups can cause performance issues and are not recommended.)\nIf a communication site is used by members of a team in Teams, you may want to add the Microsoft 365 group associated with the team to the members group of the communication site. This will allow members of the team to create content in the communication site.\nThe visitors group is a good place to use security groups. In many organizations, this is the easiest way to add large numbers of users to a site.\nFor information about how to share a site, see\nShare a site\n.\nHub site permissions\nManaging the permissions of a hub site is dependent on the underlying type of site. If the site is a group-connected team site, then you should manage permissions through the Microsoft 365 group. If it's a communication site, then you should manage permissions through the SharePoint groups.\nHub site owners define the shared experiences for hub navigation and theme. Hub site members create content on the hub as with any other SharePoint site. Owners and members of the sites associated with the hub create content on their individual sites.\nThe SharePoint Administrator must specify which users can connect other sites to the hub. This is done in the\nSharePoint admin center\nand cannot be changed by site owners.\nShareable links\nGiving people permissions to a site, group, or team gives them access to all site content. If you want to share an individual file or folder, you can do so with shareable links. There are three primary link types:\nAnyone\nlinks give access to the item to anyone who has the link, including people outside your organization. People using an\nAnyone\nlink don't have to authenticate, and their access can't be audited.\nAnyone\nlinks can't be used with files in a Teams shared channel site.\nPeople in your organization\nlinks work for only people inside your Microsoft 365 organization. (They don't work for guests or external participants in Teams shared channels).\nSpecific people\nlinks only work for the people that users specify when they share the item. For files in a Teams shared channel site,\nspecific people\nlinks can't be sent to people outside the organization unless they're in the channel.\nYou can\nchange the type of link that is presented to users by default\nfor each site.\nFor more about the different types of sharing links, see\nSecuring your data\n.\nGuest sharing\nThe external sharing features of SharePoint let users in your organization share content with people outside the organization (such as partners, vendors, clients, or customers). Planning for external sharing should be included as part of your overall permissions planning for SharePoint.\nSharePoint has external sharing settings at both the organization level and the site level (previously called the \"site collection\" level). To allow external sharing on any site, you must allow it at the organization level. You can then restrict external sharing for other sites.\nWhichever option you choose at the organization or site level, the more restrictive functionality is still available. For example, if you choose to allow sharing using\nAnyone\nlinks, users can still share with guests, who sign in, and with internal users.\nExternal sharing is turned on by default for your organization. Default settings for individual sites vary depending on the type of site. See\nSite level settings\nfor more information.\nShared channels in teams\ndo not use guest accounts for sharing with people outside the organization. However, external sharing must be enabled for people outside the organization to be invited to shared channels.\nTo set up guest sharing for a site, see\nCollaborate with guests in a site\n.\nSecurity and privacy\nIf you have confidential information that should never be shared externally, we recommend storing the information in a site that has external sharing turned off. Create additional sites as needed to use for external sharing. This helps you to manage security risk by preventing external access to sensitive information.\nSharePoint and OneDrive integration with Microsoft Entra B2B\nMicrosoft Entra B2B collaboration provides authentication and management of guests. Authentication happens via one-time passcode when they don't already have a work or school account or a Microsoft account (MSA).\nWith\nSharePoint and OneDrive integration with Microsoft Entra B2B\n, the Azure B2B collaboration one-time passcode feature is used for external sharing of files, folders, list items, document libraries, and sites. (Shared channels in Teams don't use Azure B2B collaboration, but rather\nAzure B2B direct connect\n.)\nRelated topics\nExternal sharing overview\nManage sharing settings\nCollaborating with people outside your organization\nShare SharePoint files or folders\nLimit sharing in Microsoft 365\nShared channels in Microsoft Teams\nMicrosoft 365 guest sharing settings reference\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Sharing Permissions",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/external-sharing-overview": {
      "content_hash": "sha256:34ab2da97e4e7ce3bd3b7a8c594c7bb638af5433bd04655d95a6803fb3252ba2",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of external sharing in SharePoint and OneDrive in Microsoft 365\nFeedback\nSummarize this article for me\nNote\nAs of June 2024, invitations sent via the legacy SharePoint Invitation Manager no longer grant access. Users must reshare documents to generate valid invitations.\nExternal sharing in SharePoint and OneDrive allows users to share content with people outside your organization, such as partners, vendors, clients, or customers. You can also use external sharing to share between licensed users on multiple Microsoft 365 subscriptions. External sharing in SharePoint is part of\nsecure collaboration with Microsoft 365\n. Also read\nOverview of external collaboration options in Microsoft 365\n.\nImportant\nTrial tenants can utilize SharePoint's robust collaboration features, but the scope of external sharing will be restricted compared to licensed tenants. This is designed to prevent potential abuse and ensure a safe experience for all users.\nInclude external sharing as part of your overall permissions planning for SharePoint and OneDrive. This article describes what happens when users share, depending on what they're sharing and with whom.\nIf you want to get straight to setting up sharing, choose the scenario you want to enable:\nCollaborate with guests on a document\nCollaborate with guests in a site\nCollaborate with guests in a team\n(If you're trying to share a file or folder, see\nShare OneDrive files and folders\nor\nShare SharePoint files or folders in Microsoft 365\n.)\nNote\nExternal sharing is turned on by default for your entire SharePoint and OneDrive environment. You may want to\nturn it off globally\nbefore people start using sites or until you know exactly how you want to use the feature.\nHow do SharePoint and OneDrive integrate with Microsoft Entra B2B?\nThere are two external sharing models used in SharePoint and OneDrive:\nSharePoint external authentication\nSharePoint and OneDrive integration with Microsoft Entra B2B\nWhen using Microsoft Entra B2B integration, Microsoft Entra external collaboration settings, such as\nguest invite settings and collaboration restrictions\napply.\nThe following table shows the differences between the two sharing models.\nSharing method\nWhat happens when sharing files and folders?\nWhat happens when sharing sites?\nSharePoint external authentication\n(Microsoft Entra B2B integration not enabled)\nNo guest account created*\nMicrosoft Entra settings don't apply\nN/A\n(Microsoft Entra B2B always used)\nMicrosoft Entra B2B integration enabled\nGuest account always created\nMicrosoft Entra settings apply\nGuest account always created\nMicrosoft Entra settings apply\n*A guest account may already exist from another sharing workflow, such as sharing a team, in which case it's used for sharing.\nFor information on how to enable or disable Microsoft Entra B2B integration, see\nSharePoint and OneDrive integration with Microsoft Entra B2B\n.\nHow do external sharing settings work?\nSharePoint has external sharing settings at both the organization level and the site level (previously called the \"site collection\" level). To allow external sharing on any site, you must allow it at the organization level. You can then restrict external sharing for other sites. If a site's external sharing option and the organization-level sharing option don't match, the most restrictive value will always be applied. OneDrive sharing settings can be the same as or more restrictive than the SharePoint settings.\nWhichever option you choose at the organization or site level, the more restrictive functionality is still available. For example, if you choose to allow unauthenticated sharing using \"Anyone\" links, users can still share with guests, who sign in, and with internal users.\nNote\nEven if your organization-level setting allows external sharing, not all new sites allow it by default. See\nDefault site sharing settings\nfor more information.\nWhat are the security and privacy considerations?\nIf you have confidential information that should never be shared externally, we recommend storing the information in a site that has external sharing turned off. Create additional sites as needed to use for external sharing. This helps you to manage security risk by preventing external access to sensitive information.\nNote\nTo limit\ninternal\nsharing of contents on a site, you can prevent site members from sharing, and enable access requests. For info, see\nSet up and manage access requests\n.\nWhen users share a folder with multiple guests, the guests are able to see each other's names in the Manage Access panel for the folder (and any items within it).\nHow do I share Microsoft 365 group-connected team sites?\nWhen you or your users create Microsoft 365 groups (for example in Outlook, or by creating a team in Microsoft Teams), a SharePoint team site is created. Admins and users can also create team sites in SharePoint, which creates a Microsoft 365 group. For group-connected team sites, the group owners are added as site owners, and the group members are added as site members. In most cases, you want to share these sites by adding people to the Microsoft 365 group. However, you can share only the site.\nImportant\nIt's important that all group members have permission to access the team site. If you remove the group's permission, many collaboration tasks (such as sharing files in Teams chats) won't work. Only add guests to the group if you want them to be able to access the site. For info about guest access to Microsoft 365 groups, see\nManage guest access in Groups\n.\nWhat happens when users share content?\nWhen users share with people outside the organization, an invitation is sent to the person in email, which contains a link to the shared item.\nBecause these guests don't have a license in your organization, they're limited to basic collaboration tasks:\nThey can use Office.com for viewing and editing documents. If your plan includes Office Professional Plus, they can't install the desktop version of Office on their own computers unless you assign them a license.\nThey can perform tasks on a site based on the permission level that they've been given. For example, if you add a guest as a site member, they have Edit permissions and they are able to add, edit, and delete lists; they'll also be able to view, add, update, and delete list items and files.\nThey are able to see other types of content on sites, depending on the permissions they've been given. For example, they can navigate to different subsites within a shared site. They'll also be able to do things like view site feeds.\nIf your authenticated guests need greater capability such as OneDrive storage or creating a Power Automate flow, you must assign them an appropriate license.\nHow do I stop sharing?\nYou can stop sharing with guests by removing their permissions from the shared item, or by removing them as a guest in your directory.\nYou can stop sharing with people who have an\nAnyone\nlink by going to the file or folder that you shared and deleting the link or by turning off\nAnyone\nlinks for the site.\nLearn how to stop sharing an item\nNeed more help?\nIf you have technical questions about this topic, you might find it helpful to post them on the\nSharePoint discussion forum\n. It's a great resource for finding others who have worked with similar issues or who have encountered the same situation.\nSee also\nSearching for site content shared externally\nConfigure Teams with three tiers of protection\nCreate a secure guest sharing environment\nSettings interactions between Microsoft 365 Groups, Teams and SharePoint\nPricing - Active Directory External Identities\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "External Sharing",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/turn-external-sharing-on-or-off": {
      "content_hash": "sha256:dfcd1e7d945a55d739b635f3be1ccc2bb1c88c40b869a86bb10caabb16f29ed2",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage sharing settings for SharePoint and OneDrive in Microsoft 365\nFeedback\nSummarize this article for me\nAs a SharePoint Administrator in Microsoft 365, you can change the organization-level sharing settings for SharePoint and OneDrive. These settings control sharing at the organization level, and you can then configure more restrictive settings for specific sites if needed.\nFor end-to-end guidance around how to configure guest sharing in Microsoft 365, see:\nSet up secure collaboration with Microsoft 365\nCollaborate with guests on a document\nCollaborate with guests in a site\nCollaborate with guests in a team\nTo change the sharing settings for a site after you've set the organization-level sharing settings, see\nChange sharing settings for a site\n. To learn how to change the external sharing setting for a specific user's OneDrive, see\nChange the external sharing setting for a user's OneDrive\n.\nTip\nAs a companion to this article, see our\nMicrosoft Sharepoint setup guide\nto review best practices and understand the deployment process from site creation to data migration. Features include protection labels, data loss prevention policies, and file activity auditing. For a customized experience based on your environment, you can access the\nSet up SharePoint in Microsoft 365 guide\nin the Microsoft 365 admin center.\nHow do SharePoint and OneDrive integrate with Microsoft Entra B2B?\nThere are two external sharing models used in SharePoint and OneDrive:\nSharePoint external authentication\nSharePoint and OneDrive integration with Microsoft Entra B2B\nWhen using Microsoft Entra B2B integration, Microsoft Entra external collaboration settings, such as\nguest invite settings and collaboration restrictions\napply.\nThe following table shows the differences between the two sharing models.\nSharing method\nFiles and folders\nSites\nSharePoint external authentication\n(Microsoft Entra B2B integration not enabled)\nNo guest account created*\nMicrosoft Entra settings don't apply\nN/A\n(Microsoft Entra B2B always used)\nMicrosoft Entra B2B integration enabled\nGuest account always created\nMicrosoft Entra settings apply\nGuest account always created\nMicrosoft Entra settings apply\n*A guest account may already exist from another sharing workflow, such as sharing a team, in which case it's used for sharing.\nFor information on how to enable or disable Microsoft Entra B2B integration, see\nSharePoint and OneDrive integration with Microsoft Entra B2B\n.\nVideo demonstration\nThis video shows how the settings on the\nSharing\npage in the SharePoint admin center\naffect the sharing options available to users.\nHow do I change the organization-level external sharing setting?\nGo to\nSharing\nin the SharePoint admin center\n, and sign in with an account that has\nadmin permissions\nfor your organization.\nUnder\nExternal sharing\n, specify your sharing level for SharePoint and OneDrive. The default level for both is\nAnyone\n.\nNote\nThe SharePoint setting applies to all site types, including those connected to Microsoft 365 groups and teams. Groups and Teams guest sharing settings also affect connected SharePoint sites.\nThe OneDrive setting can be more restrictive than the SharePoint setting, but not more permissive.\nThis setting is for your organization overall. Each site has its own sharing setting that you can set independently, though it must be at the same or more restrictive setting as the organization. See\nChange the external sharing setting for a site\nfor more information.\nImportant\nMicrosoft Entra external collaboration settings\ndetermine who can invite guests in your organization for site sharing (always) and file and folder sharing (if Azure B2B collaboration is enabled). Be sure to review Microsoft Entra guest access settings as part of your SharePoint and OneDrive sharing setup.\nWhich sharing option should I select?\nSelect this option:\nIf you want to:\nAnyone\nAllow users to share files and folders by using links that let anyone who has the link access the files or folders without authenticating. This setting also allows users to share sites with new and existing guests who authenticate. If you select this setting, you can restrict the Anyone links so that they must expire within a specific number of days, or so that they can give only View permission.\nFile requests\nrequires that OneDrive be set to\nAnyone\nand edit permissions for\nAnyone\nlinks be enabled. OneDrive settings other than\nAnyone\ndisable file requests.\nSee\nBest practices for sharing files and folders with unauthenticated users\nfor more information.\nNew and existing guests\nRequire people who have received invitations to sign in with their work or school account (if their organization uses Microsoft 365) or a Microsoft account, or to provide a code to verify their identity. Users can share with guests already in your organization's directory, and they can send invitations to people who will be added to the directory if they sign in. For more info about verification codes, see\nSecure external sharing in SharePoint\nExisting guests\nAllow sharing only with guests who are already in your directory. These guests may exist in your directory because they previously accepted sharing invitations or because they were manually added, such as through\nAzure B2B collaboration\n. (To see the guests in your organization, go to the\nGuests page in the Microsoft 365 admin center\n).\nOnly people in your organization\nTurn off external sharing.\nNote\nIf you turn off external sharing for your organization and later turn it back on, guests who previously had access regain it. If you know that external sharing was previously turned on and in use for specific sites and you don't want guests to regain access, first turn off external sharing for those specific sites.\nIf you restrict or turn off external sharing, guests typically lose access within one hour of the change.\nWhat are the additional external sharing settings?\nLimit external sharing by domain\nThis is useful if you want to limit sharing with particular partners, or help prevent sharing with people at certain organizations. The organization-level setting on this page affects all SharePoint sites and each user's OneDrive. To use this setting, list the domains (maximum of 5000) in the box, using the format\ndomain.com\n. To list multiple domains, press Enter after adding each domain.\nYou can also limit external sharing by domain by using the\nSet-SPOTenant\nMicrosoft PowerShell cmdlet with -SharingDomainRestrictionMode and either -SharingAllowedDomainList or -SharingBlockedDomainList. For info about limiting external sharing by domain at the site level, see\nRestricted domains sharing\n.\nAllowed or blocked domains in Microsoft Entra ID\nalso affect SharePoint and OneDrive site sharing (always) and file and folder sharing (if Azure B2B collaboration is enabled). Be sure to review Microsoft Entra collaboration restrictions as part of your SharePoint and OneDrive sharing setup.\nAllow only users in specific security groups to share externally\nFor info about this setting, see\nManage security groups\n.\nAllow guests to share items they don't own\nBy default, guests must have full control permission to share items externally.\nGuest access to a site or OneDrive will expire automatically after this many days\nIf your administrator has set an expiration time for guest access, each guest that you invite to the site or with whom you share individual files and folders will be given access for a certain number of days. For more information visit,\nManage guest expiration for a site\nPeople who use a verification code must reauthenticate after this many days\nIf people who use a verification code have selected to \"stay signed in\" in the browser, they must prove they can still access the account they used to redeem the sharing invitation by entering a code sent to that account. If Azure B2B collaboration is enabled, the\nMicrosoft Entra setting\nis used instead of this setting.\nHow do I manage file and folder links?\nChoose the option you want to show by default when a user creates a sharing link.\nNote\nThis setting specifies the default for your organization, but you can choose a different default link type for a site.\nSpecific people\n- This option is most restrictive and impedes broad internal sharing. If you allow external sharing, this option lets users share with specific people outside the organization.\nOnly people in your organization\n- If links are forwarded, they'll work for anyone in the organization. This option is best if your organization shares broadly internally and rarely shares externally.\nAnyone with the link\n- This option is available only if your external sharing setting is set to\nAnyone\n. Forwarded links work internally or externally, but you can't track who has access to shared items or who has accessed shared items. This is best for friction-free sharing if most files and folders in SharePoint and OneDrive aren't sensitive.\nImportant\nIf you select\nAnyone with the link\n, but the site or OneDrive is set to allow sharing only with guests who sign in or provide a verification code, the default link is\nOnly people in your organization\n. Users need to change the link type to\nSpecific people\nto share files and folders in the site or OneDrive externally.\nWhat are the advanced settings for \"Anyone\" links?\nLink expiration\n- You can require all\nAnyone\nlinks to expire, and specify the maximum number of days allowed. If you change the expiration time, existing links will keep their current expiration time if the new setting is longer, or be updated to the new setting if the new setting is shorter.\nLink permissions\n- You can restrict\nAnyone\nlinks so that they can only provide view permission for files or folders.\nIf you would like to use the\nRequest Files\nfeature, the link permissions must be set to\nView, edit, and upload\nor\nView and Upload\nfor folders.\nWhat other sharing settings are available?\nShow owners the names of people who viewed their files in OneDrive\nThis setting lets you control whether the owner of a shared file can see on the file card the people who only view (and don't edit) the file in OneDrive. The file card appears when users hover over a file name or thumbnail in OneDrive. The info includes the number of views on the file, the number of people who viewed it, and the list of people who viewed it. To learn more about the file card, see\nSee files you shared in OneDrive\n.\nNote\nThis setting is selected by default. If you clear it, file viewer info is still recorded and available to you to audit as an admin. OneDrive owners can also still see people who have viewed their shared Office files by opening the files from Office.com or from the Office desktop apps.\nLet site owners choose to display the names of people who viewed files or pages in SharePoint\nThis setting lets you specify whether site owners can allow users who have access to a file, page, or news post to see on the file card who has viewed the item.\nThis setting is turned on by default at the organization level and off at the site level for existing sites. Viewer information is shown only when the setting is on at both the organization and site level. We recommend that site owners turn on this feature only on team sites that don't have sensitive information.\nLearn how site owners can turn on this feature\n.\nNote\nHistorical data is included when this setting is enabled. Likewise, if the setting is turned off and back on at the organization level or site level, the views during the off period are included in the history.\nUse short links for sharing files and folders\nUses a shorter link format for sharing files and folders. This may be useful if you have integrations that require a shorter URL.\nNeed more help?\nIf you have technical questions about this topic, you might find it helpful to post them on the\nSharePoint discussion forum\n. It's a great resource for finding others who have worked with similar issues or who have encountered the same situation.\nYou can also find help on security and permissions in these\nYouTube videos from SharePoint community experts\n.\nSee also\nLimit accidental exposure to files when sharing with guests\nCreate a secure guest sharing environment\nStop sharing files or folders or change permissions\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Manage Sharing Settings",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/restricted-access-control": {
      "content_hash": "sha256:a6c937c44e8a208a0902ce169b224d9e1b1937a57938ada0d3d3874edabb6952",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRestrict SharePoint site access with Microsoft 365 groups and Microsoft Entra security groups\nFeedback\nSummarize this article for me\nRestricted site access control lets you prevent oversharing by designating access of SharePoint sites and its content to users in a specific group. Users not in the specified group can't access the site or its content, even if they had prior permissions or a shared link. This policy can be applied on Microsoft 365 group-connected, Teams-connected, and nongroup connected sites using Microsoft 365 groups or Microsoft Entra security groups.\nSite access restriction policies are applied when a user attempts to open a site or access a file. Users with direct permissions to the file can still view files in search results. However, they can't access the files if they're not part of the specified group.\nRestricting site access via group membership can minimize the risk of oversharing content. For insights into data sharing, see\nData access governance reports\n.\nWhat do you need to restrict site access?\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need at least one of these licenses:\nMicrosoft 365 Copilot license:\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nMicrosoft SharePoint Advanced Management license:\nAvailable as a standalone purchase.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nAdditional information\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nFor organizations without a Copilot license, you can use SharePoint Advanced Management features\nby purchasing a standalone SharePoint Advanced Management license\n.\nEnable site-level access restriction for your organization\nYou must enable site-level access restriction for your organization before you can configure it for individual sites.\nTo enable site-level access restriction for your organization in SharePoint admin center:\nExpand\nPolicies\nand select\nAccess control\n.\nSelect\nSite-level access restriction\n.\nSelect\nAllow access restriction\nand then select\nSave\n.\nTo enable site-level access restriction for your organization using PowerShell, run the following command:\nSet-SPOTenant -EnableRestrictedAccessControl $true\nIt might take up to one hour for the command to take effect.\nNote\nFor Microsoft 365 Multi-Geo users, run this command separately for each desired geo-location.\nRestrict access to all SharePoint sites using Microsoft 365 group or Microsoft Entra security groups\nYou can restrict access to a SharePoint site by specifying Microsoft Entra security groups or Microsoft 365 groups as the Restricted Access Control group. The control group should have the users who should be allowed access to the site and its content.\nFor a site, you can configure up to 10 Microsoft Entra security groups or Microsoft 365 groups. Once the policy is applied, users in the specified group who have access permission to the content are allowed access.\nImportant\nAdding people to the Restricted Access Control group (Microsoft Entra security group or Microsoft 365 group) doesn't automatically give the users access permission to the site or the content. For a user to be able to access the content protected with this policy, the user would need to have both the site or content access permission AND be a member of the Restricted Access Control group.\nNote\nYou can also use dynamic security groups as a Restricted Access Control group if you want to base group membership on user properties.\nManage site access for a site\nTo manage site access for a site:\nIn SharePoint admin center, expand\nSites\nand select\nActive sites\n.\nSelect the site you want to manage and the site details panel appears.\nIn\nSettings\ntab, select\nEdit\nin the Restricted site access section.\nSelect the\nRestrict SharePoint site access to only users in specified groups\ncheck box.\nAdd or remove your security groups or Microsoft 365 groups and select\nSave\n.\nIn order for site access restriction to be applied to the site, you must add at least one group to the site access restriction policy.\nFor a group connected site, the Microsoft 365 group connected to the site is added as the default Restricted Access Control group. You can choose to keep this group and add more Microsoft 365 or Microsoft Entra Security groups as Restricted Access Control group.\nNote\nThere's a tag labeled as\nDefault group\nmarked against the Microsoft 365 group connected to the site as shown in the previous image.\nTo manage site access restriction for a SharePoint site using PowerShell, use the following commands:\nAction\nPowerShell command\nEnable site access restriction\nSet-SPOSite -Identity <siteurl> -RestrictedAccessControl $true\nAdd group\nSet-SPOSite -Identity <siteurl> -AddRestrictedAccessControlGroups <comma separated group GUIDS>\nEdit group\nSet-SPOSite -Identity <siteurl> -RestrictedAccessControlGroups <comma separated group GUIDS>\nView group\nGet-SPOSite -Identity <siteurl> Select RestrictedAccessControl, RestrictedAccessControlGroups\nRemove group\nSet-SPOSite -Identity <siteurl> -RemoveRestrictedAccessControlGroups <comma separated group GUIDS>\nReset site access restriction\nSet-SPOSite -Identity <siteurl> -ClearRestrictedAccessControl\nSite admin and site owner experience\nOnce you apply the policy to the site, the policy status and all configured control groups are displayed for site owners and site admins on the\nSite access\npanel in addition to the\nSite Information\nand\nPermissions\npanels.\nShared and private channel sites\nShared and private channel sites are separate from the Microsoft 365 group-connected site that standard channels use. Because shared and private channel sites aren't connected to the Microsoft 365 group, site access restriction policies applied to the team don't affect them. You must enable site access restriction for each shared or private channel site separately as nongroup connected sites.\nFor shared channel sites, only internal users in the resource tenant are subject to site access restriction. External channel participants are excluded from site access restriction policy and only evaluated per the site's existing site permissions.\nImportant\nAdding people to the security group or Microsoft 365 group doesn't give users access to the channel in Teams. We recommend adding or removing the same users of the Teams channel in Teams and the security group or Microsoft 365 group, so users have access to both Teams and SharePoint sites.\nAuditing\nAudit events are available in the Microsoft Purview portal to help you monitor site access restriction activities. Audit events are logged for the following activities:\nApplying site access restriction for site\nRemoving site access restriction for site\nChanging site access restriction groups for site\nReporting\nRestricted site access policy insights\nAs an IT administrator, you can view the following reports to gain more insight about SharePoint sites protected with restricted site access policy:\nSites protected by restricted site access policy (RACProtectedSites)\nDetails of access denials due to restricted site access policy (ActionsBlockedByPolicy)\nRestricted site access policy reports are available in non-government cloud environments, as well as GCC, GCC-High, and DoD government cloud environments. The reports are currently unavailable for Gallatin, even if you have the required licenses.\nNote\nIt can take a few hours to generate each report.\nSites protected by restricted site access policy report\nYou can run the following commands in SharePoint PowerShell to generate, view, and download the reports:\nAction\nPowerShell command\nDescription\nGenerate report\nStart-SPORestrictedAccessForSitesInsights -RACProtectedSites\nGenerates a list of sites protected by restricted site access policy\nView report\nGet-SPORestrictedAccessForSitesInsights -RACProtectedSites -ReportId <Report GUID>\nThe report shows the top 100 sites with the highest page views that are protected by the policy.\nDownload report\nGet-SPORestrictedAccessForSitesInsights -RACProtectedSites -ReportId <Report GUID> -Action Download\nThis command must be run as an administrator. The downloaded report is located on the path where the command was run.\nPercentage of site protected with restricted site access report\nGet-SPORestrictedAccessForSitesInsights -RACProtectedSites -ReportId <Report GUID> -InsightsSummary\nThis report shows the percentage of sites that are protected by the policy out of the total number of sites\nAccess denials due to restricted site access policy report\nYou can run the following commands to create, fetch, and view report for access denials due to restricted site access reports:\nAction\nPowerShell command\nDescription\nCreate access denials report\nStart-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy\nCreates a new report for fetching access denial details\nFetch access denials report status\nGet-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy\nFetches the status of the generated report.\nLatest access denials in the past 28 days\nGet-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy -ReportId <Report ID> -Content AllDenials\nGets a list of the most recent 100 access denials that occurred in the past 28 days\nView list of top users who were denied access\nGet-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy -ReportId <Report ID> -Content TopUsers\nGets a list of the top 100 users who received the most access denials\nView list of top sites that received the most access denials\nGet-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy -ReportId <Report ID> -Content TopSites\nGets a list of the top 100 sites that had the most access denials\nDistribution of access denials across different types of sites\nGet-SPORestrictedAccessForSitesInsights -ActionsBlockedByPolicy -ReportId <Report ID> -Content SiteDistribution\nShows the distribution of access denials across different types of sites\nNote\nTo view up to 10,000 denials, you must download the reports. Run the download command as an administrator and the downloaded reports are located on the path from where command was run.\nSharing of site and content with users outside of Restricted Access Control Groups (opt-in capability)\nSharing of SharePoint sites and its content doesn't honor restricted site access policy by default. The SharePoint administrator can choose to restrict sharing of site and its content with users who aren't members of the Restricted Access Control group.\nTo restrict sharing capability with users outside of the Restricted Access Control group, enable it, run the following PowerShell command in SharePoint Online Management Shell as an Administrator:\nSet-SPOTenant -AllowSharingOutsideRestrictedAccessControlGroups $false\nSharing with users\nOnce sharing restriction is applied, sharing is blocked for users who aren't members of the Restricted Access Control group.\nSharing with groups\nSharing is allowed with Microsoft Entra Security or Microsoft 365 groups which are part of the Restricted Access Control groups list. Thus, sharing with all other groups including Everyone except external users or SharePoint groups aren't allowed.\nNote\nSharing of a site and its content isn't allowed for the nested security groups that are part of the Restricted Access Control groups. This support will be added in the next release iteration.\nConfigure the Learn more link for access denial error page (opt-in capability)\nConfigure the\nLearn more\nlink to inform users who were denied access to a SharePoint site due to the restricted site access control policy. With this customizable error link, you can provide more information and guidance to your users.\nNote\nThe\nLearn more\nlink is a tenant-level setting that applies to all sites with Restricted Access Control policy enabled.\nTo configure the link, run the following command in SharePoint PowerShell:\nSet-SPOTenant -RestrictedAccessControlForSitesErrorHelpLink \"<Learn more URL>\"\nTo fetch the value of the link, run the following command:\nGet-SPOTenant | select RestrictedAccessControlForSitesErrorHelpLink\nThe configured learn more link is launched when the user selects the\nKnow more about your organization's policies here\nlink.\nRelated articles\nConditional access policy for SharePoint sites and OneDrive\nData Access Governance reports\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Restricted Access Control",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/restricted-content-discovery": {
      "content_hash": "sha256:26e65f99f63c3a6ce047feacb626b7e6cc479fb27d1466e554cf15c59efc033b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRestrict discovery of SharePoint sites and content\nFeedback\nSummarize this article for me\nFor organizations onboarding to Microsoft 365 Copilot, maintaining strong data governance controls for SharePoint content is critical to deploying Copilot in a safe manner. Sites identified with the highest risk of oversharing can use Restricted Content Discovery to protect content while taking time to ensure that permissions are accurate and well-managed.\nWith Restricted Content Discovery, organizations can limit the ability of end users to search for files from specific SharePoint sites. Enabling Restricted Content Discovery for each site prevents the sites from surfacing in organization-wide search and Microsoft 365 Copilot Business Chat, unless a user had a recent interaction.\nRestricted Content Discovery is a site-level setting that needs to be propagated to the search index, a large number of transactions could lead to a long queue in the ingestion pipeline and higher update latency times.\nWhile child content is hidden by default, users in your organization can still discover files they own or recently interacted with. End users can still find relevant content they need for their day-to-day tasks, even if Restricted Content Discovery is applied to the parent site.\nRestricted Content Discovery doesn't affect searches originating from a site context or other intelligent features such as Microsoft 365 Feed and Recommendations.\nNote\nRestricted Content Discovery doesn't affect existing permissions on sites. Users with access can still open files on sites with Restricted Content Discovery toggled on.\nThis feature can't be applied to OneDrive sites.\nCaution\nOveruse of Restricted Content Discovery can negatively affect performance across search, SharePoint, and Copilot. Removing sites or files from tenant-wide discovery means that there's less content for search and Copilot to ground on, leading to inaccurate or incomplete results.\nUse cases for Restricted Content Discovery\nRestricted Content Discovery can be applied to any SharePoint site in your organization. The key use case for this feature is to prevent accidental discovery of high-risk sites.\nWe recommend using tools such as Data access governance reports and SharePoint admin center's\nActive sites\ntab to first compile a selective list of targeted sites.\nWhat you need to restrict a specific SharePoint access?\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need at least one of these licenses:\nMicrosoft 365 Copilot license:\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nMicrosoft SharePoint Advanced Management license:\nAvailable as a standalone purchase.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nAdditional information\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nFor organizations without a Copilot license, you can use SharePoint Advanced Management features\nby purchasing a standalone SharePoint Advanced Management license\n.\nIn addition to above, you also need the latest version of\nMicrosoft SharePoint Online Management Shell\n.\nConfigure Restricted Content Discovery\nBy default, Restricted Content Discovery is off for all sites. As an IT administrator, you can enable or disable this feature, and check the current state of a given site. You can also delegate Restricted Content Discovery setting to all the site admins of your organization.\nEnable Restricted Content Discovery for a site\nYou can enable Restricted Content Discovery from the SharePoint admin center or via PowerShell.\nTo enable Restricted Content Discovery for a site using SharePoint admin center:\nIn SharePoint admin center, expand\nSites\nand select\nActive sites\n.\nSelect the site you want to restrict the content discovery, and the site details panel appears.\nIn the\nSettings\ntab, toggle on or off in the\nRestrict content from Microsoft 365 Copilot\nsection.\nSelect\nSave\n.\nNote\nChanges can take time to be effective.\nTo enable Restricted Content Discovery for a site using PowerShell, run the following command:\nSet-SPOSite âidentity <site-url> -RestrictContentOrgWideSearch $true\nCheck status of Restricted Content Discovery\nTo check the status of Restricted Content Discovery, run the following command:\nGet-SPOSite âidentity <site-url> | Select RestrictContentOrgWideSearch\nRemove Restricted Content Discovery from a site\nTo remove Restricted Content Discovery on a SharePoint site, run the following command:\nSet-SPOSite âidentity <site-url> -RestrictContentOrgWideSearch $false\nDelegate Management of Restricted Content Discovery to Site Admins\nAs a SharePoint administrator, you can also delegate management of Restricted Content Discovery control to site admin. Upon managing the policy, the site admins would need to provide appropriate justification on why the policy is being updated.\nBy default, the delegation is turned off.  If you decide to enable it, run the following command:\nSet-SPOTenant -DelegateRestrictedContentDiscoverabilityManagement $true\nCheck status of Delegate management of Restricted Content Discovery to site admins\nTo check the delegation status, run the following command:\nGet-SPOTenant | Select-Object DelegateRestrictedContentDiscoverabilityManagement\nOnce the Restricted Content Discovery setting is delegated to all the site admins, they can manage the policy.\nThe site admins would need to provide justification whenever the Restricted Content Discovery setting is updated by them, as shown below:\nOnce the policy is enabled on the site, the\nRestricted\ntag will be visible on theâ¯Homeâ¯tab of the site as shown below:\nAuditing\nAudit events are available in the Microsoft's Unified Audit log to help you monitor activities related to managing of Restricted Content Discovery. Audit events are logged are:\nTurning on the Restricted Content Discovery setting for site\nTurning off the Restricted Content Discovery setting for site\nJustification for updating Restricted Content Discovery setting for site\nRestricted Content Discovery policy insights\nYou can view the following reports to gain insights on the SharePoint sites protected with Restricted Content Discovery:\nGenerate insights report\nTo generate a list of sites with Restricted Content Discovery enabled, run the following command:\nStart-SPORestrictedContentDiscoverabilityReport\nView insights report\nTo view a report displaying the Report GUID, created DateTime stamp, and status of the report generation, run the following command:\nGet-SPORestrictedContentDiscoverabilityReport\nDownload insights report\nTo download a Restricted Content Discovery insights report, you must run the following command as an administrator:\nGet-SPORestrictedContentDiscoverabilityReport âAction Download âReportId <Report GUID>\nThe downloaded report is located on the path where the command was run.\nNext steps\nRestricted Content Discovery gives organizations time to review and/or audit permissions and deploy access controls while onboarding Copilot in a safe manner.\nUltimately for sites that are overshared, the goal is to ensure that proper controls are in place to manage access. SharePoint Advanced Management has a suite of features, such as advanced site content lifecycle management, to help site owners and admins create a robust SharePoint governance framework.\nFrequently Asked Questions\nIs my organization eligible to use Restricted Content Discovery?\nCustomers who are licensed for Copilot and have SharePoint Advanced Management available to them can configure Restricted Content Discovery.\nWhat search scenarios enforce Restricted Content Discovery?\nRestricted Content Discovery only affects tenant-wide search (SharePoint home, Office.com, Bing) and Microsoft 365 Copilot. Only Copilot Discovery scenarios are in scope; Copilot experiences that use data-in-use, such as \"summarize the current document\" in Word aren't impacted.\nDoes Restricted Content Discovery impact other features with dependencies on the search index, such as the Microsoft Purview product suite?\nNo, Restricted Content Discovery doesn't remove content from the tenant search index, which means Microsoft Purview features such as eDiscovery and autolabeling aren't impacted.\nHow soon can I expect Search and Copilot to reflect an update made to the Restricted Content Discovery configuration of a site?\nRestricted Content Discovery is a site-level property. Index update latency is highly dependent on the number of items in the site and the number of sites getting updated at the same time. For sites with more than 500,000 items, the Restricted Content Discovery update could take more than a week to fully process and reflect in search and Copilot.\nHow does Restricted Content Discovery affect the end user experience in Copilot?\nBased on usage of this feature, Copilot has less information available to reference, which could negatively affect its ability to provide accurate and comprehensive responses.\nHow does Restricted Content Discovery fit into an overall approach to prepare SharePoint data for Microsoft 365 Copilot?\nRestricted Content Discovery is designed to limit the ability of end users to search for content from specific SharePoint sites. For a more comprehensive guidance on preparing your data for Copilot, check out this\nblueprint\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Restricted Content Discovery",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/restricted-sharepoint-search": {
      "content_hash": "sha256:4aa630aa53f2a9544310e8f2259972b69083daaef764902d2e62a074626bd3f5",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRestricted SharePoint Search\nFeedback\nSummarize this article for me\nImportant\nRestricted SharePoint Search is designed for customers of Microsoft 365 Copilot.\nWhat is Restricted SharePoint Search?\nRestricted SharePoint Search is a setting that helps you as a\nSharePoint Administrator\nor\nabove\nin Microsoft 365 to maintain a list of SharePoint sites (\"allowed list\") that you have checked the permissions and applied data governance for. The allowed list defines which SharePoint sites can participate in organization-wide search and Copilot experiences. By default, the Restricted SharePoint Search setting is turned off and the allowed list is empty.\nRestricted SharePoint Search allows you to restrict both organization-wide search and Copilot experiences to a curated set of SharePoint sites of your choice. Additionally, whether you have\nenabled Restricted SharePoint Search\n, users in your organization are still able to interact with files and content they own or that they have previously accessed in Copilot.\nWhy should you use Restricted SharePoint Search?\nRestricted SharePoint Search gives you time to review and audit site permissions. We provide Restricted SharePoint Search to help you maintain momentum with your Copilot deployment while you're implementing comprehensive data security with\nSharePoint Advanced Management\n, and\nMicrosoft Purview\n. Combined, these solutions offer a complete solution for data discovery, protection, and governance, ensuring a secure and managed data lifecycle.\nRestricted SharePoint Search addresses oversharing concerns by allowing organizations to:\nPrevent sites from showing up in organization-wide search results and Copilot experiences until your admins or site owners can check the permissions on the site content;\nHonor existing site permissions, and let site owners manage individual site permissions.\nIf Restricted SharePoint Search is enabled, the customer's experience is impacted in the following ways:\nSearch results are limited to sites on the allowed list, usersâ frequently visited sites, sites that users already have permissions to, and usersâ recently accessed files. Turning on this feature impacts the overall search experience, even for non-Copilot users.\nCopilot has less information available to reference, which may impact its ability to provide accurate and comprehensive responses.\nRemember, whether you have enabled Restricted SharePoint Search, users in your organization are always able to interact with files and content they own or that they have previously accessed in Copilot .\nHow does Restricted SharePoint Search work?\nAs a\nSharePoint Administrator\nor\nabove\nin Microsoft 365, you're able to:\nCheck the current status of Restricted SharePoint Search (enabled or disabled)\nEnable or disable Restricted SharePoint Search\nCurate the allowed list\nby identifying the top 100 widely used sites\nAdd or remove sites from the allowed list by providing the site URL\nGet the full list of sites in the allowed list\nRestricted SharePoint Search is off by default. If you decide to enable it, Copilot and non-Copilot users are able to find and use content from:\nAn allowed list of curated SharePoint sites set up by admins (with\nup to 100 SharePoint sites\n), honoring sitesâ existing permissions.\nUsersâ OneDrive files, chats, emails, calendars they have access to.\nFiles from their frequently visited SharePoint sites.\nFiles that were shared directly with the users.\nFiles that the users viewed, edited, or created.\nNote\nThe limit of up to 100 SharePoint sites includes Hub sites, but not their associated sites. When you enable Hub sites, the associated sites of a Hub site are included in the allowed-list but do not count towards the 100-site limit. This approach allows for greater flexibility while still adhering to the existing constraints. When you are picking Hub sites, make sure all the associated sites have proper permissions.\nThe total number of files included from the last three bullet points (frequently visited sites, files shared directly with the user, and files the users viewed, edited, or created) is limited to the last 2,000 entities.\nThe following diagram shows an example of an HR Hub site with eight associated sites:\nAll eight associated sites plus the HR Hub site are counted as one site in the allowed-list.\nLet's consider Alex Wilber, a marketing specialist at Contoso Electronics. Before the organization uses Restricted SharePoint Search, Alex can see not only his own personal contents, like his OneDrive files, chats, emails, contents that he owns or visited, but also content from some sites that haven't undergone access permission review or Access Control Lists (ACL) hygiene, and doesn't have data governance applied. For example, Contoso Electronics has a budgeting site with important business information. Most people don't know about this site, so the site owner hasn't set up proper permissions and hasn't followed correct data governance process. The site might be open to some users who aren't allowed to see it, such as Alex. When Alex asks Copilot for some budgeting information, Copilot gets information from the budgeting site.\nThe IT admin at Contoso Electronics uses Restricted SharePoint Search to limit what sites can be searched through the allowed list. They check SPAC and SPAC DAG reports and decide to exclude this budgeting site from the allowed list. After RSS is turned on, Alex can still access things that he owns or has recently visited, or that are directly shared with him, but he canât access any other sites, unless the site is in the allowed list and he has permission to it. When Alex asks Copilot the same question about budgeting now, Copilot wonât show them any information from that site.\nNote\nSite scoped searches arenât affected by this control. This control impacts\nmodern search\nand copilot experiences.\nFrequently asked questions\nCan I use RSS for creating a \"deny list\" instead?\nNo, this capability isn't part of Restricted SharePoint Search. However, SharePoint Advanced Management offers a similar feature called\nRestricted Access Control for SharePoint sites\n. If your customer isn't ready to use SharePoint Advanced Management, then they can alternatively evaluate to disable the following setting in SharePoint. To learn more information, review\nAllow this site to appear in Search results\n.\nNote\nWhen you turn off âAllow this site to appear in Search resultsâ, you block the site content from showing up in both the organization-wide search and the site specific search.\nDoes Restricted SharePoint Search impact other services that don't depend on SharePoint? For example, Exchange, To-do, Planner, Loop, etc.?\nYes, any product where Enterprise Search is enabled and could have SharePoint content and/or files as search results will be impacted.\nDoes Restricted SharePoint Search impact other features based on the Microsoft Index? For example, Purview or SharePoint Advanced Management features?\nNo, Restricted SharePoint Search won't affect any other features\nbased on the Microsoft Index.\nHow do I enable Restricted SharePoint Search?\nYou can enable Restricted SharePoint Search by using PowerShell scripts. For detailed steps, see\nEnable or disable Restricted Search\n.\nAfter\nenabling RSS\nhow long does it take to take place?\nRSS goes into effect within an hour after it's enabled.\nIf I give the URL of a hub site, will it also include all of the child sites or sites associated hub sites with it? Do these other sites count towards the 100 sites in the allowed lists?\nOnly the hub site (the URL in the Allowed list) is included in the 100. The sub sites under the hub site aren't counted against the 100 limit but RSS is effective on the sub sites.\nWhat to do next?\nAfter setting up Restricted SharePoint Search and enabling Microsoft 365 Copilot for your organization, you should evaluate the SharePoint sites\nactivities\nand\nusage\nto adjust the allowed list. You can use\nMicrosoft SharePoint Admin Center\nand\nMicrosoft Purview\nto gradually increase the scope of search and Copilot experience for your organization. Restricted SharePoint Search honors existing site permissions, so you can work with site owners and admins to add\nadvanced access policies\nand\nadvanced site content lifecycle management\nfor specific users and groups through Microsoft SharePoint Advanced Management. Moreover, Microsoft Purview enhances your organizationâs data security and compliance for Copilot.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Restricted SharePoint Search",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/advanced-management": {
      "content_hash": "sha256:496f15fa574298cf1ad0a71658db9e61501242fb79bee39937c657920d56b6ba",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is SharePoint Advanced Management?\nFeedback\nSummarize this article for me\nSharePoint Advanced Management (SAM) is a comprehensive governance solution for SharePoint and OneDrive. With SAM, you can efficiently manage content growth, secure access, and monitor changes across your organization. These capabilities help you maintain control over your digital workspace and prepare your environment for Microsoft 365 Copilot.\nIn this article, you learn how SAM enables you to:\nPrevent content sprawl\nwith automated policies and insights\nManage the content lifecycle\nthrough reporting and compliance tools\nStreamline permissions and access management\nfor SharePoint and OneDrive sites\nExplore each of the following sections to discover how SAM supports your content governance needs and enhances collaboration in Microsoft 365.\nWhat you need to get started\nBefore you get started, make sure SharePoint Advanced Management (SAM) features are available to your organizations through one of the following two licensing options:\nIf your organization has a Copilot license and at least one user is assigned a Copilot license, SharePoint administrators automatically gain access to the SharePoint Advanced Management features required for Copilot deployment. The only SAM feature not included with Copilot is\nRestricted Site Creation\n.\nOrganizations without a Copilot license can access SharePoint Advanced Management features by\npurchasing a standalone SharePoint Advanced Management license\n.\nSAM features are managed by\nIT administrators\nwith access to the\nSharePoint admin center\n. Some features can also be used by site owners.\nWith the right licensing in place, you can take full advantage of SharePoint Advanced Managementâs three core capabilities: preventing content sprawl, managing the content lifecycle, and streamlining permissions and access management for SharePoint and OneDrive sites. The following sections provide a detailed look at each area, helping you understand how SAM empowers you to govern your organizationâs information effectively and securely.\nWhat is content sprawl and how can you prevent it?\nContent sprawl happens when digital files and information accumulate across your organization without effective oversight. This can make it harder to find what you need, increase storage costs, and create security or compliance risks. To help you prevent content sprawl, SharePoint Advanced Management offers three key features:\nSite ownership policy:\nEnsure every SharePoint site has clear ownership and accountability with automated policies that help you manage site lifecycle and governance.\nAI insights:\nUse AI-powered recommendations to identify patterns, spot potential issues, and take action to keep your content organized and secure.\nManage inactive sites:\nAutomatically detect and address inactive SharePoint sites, reducing clutter and optimizing your storage.\nRequest site attestation:\nRegularly prompt site owners to review and confirm the relevance of their sites, helping you maintain an organized and purposeful digital environment.\nBy using these features together, you can maintain control over your digital workspace and support secure, efficient collaboration.\nSite ownership policy\nSite ownership policies\nare a part of site lifecycle management. These policies help you automatically monitor and enforce site ownership requirements across your organization. You can create these policies to define who should be responsible for each site, set minimum owner or admin counts, and automate notifications when sites don't meet your criteria. By regularly identifying noncompliant sites and prompting users to take action, site ownership policies support effective site management, reduce the risk of ownerless sites, and help maintain security and compliance in your SharePoint environment.\nAI Insights\nThe\nAI insights\nfeature for\nSharePoint Advanced Management\nuses a language model to identify patterns and potential issues from reporting and receive actionable recommendations to solve issues.\nYou can find the\nGet AI insights\nbutton next to various reports in the SharePoint admin center. Once selected, the AI insights feature extracts patterns from the report and offers a list of potential actions.\nInactive sites policy\nYou can run automated, rule-based policies to manage and reduce inactive sites with the\nInactive SharePoint sites policy\nfeature from SharePoint Advanced Management.\nThe inactive sites policy combats content sprawl by automatically identifying and managing inactive SharePoint sites. It operates by defining inactivity criteria, such as lack of updates or user activity over a set period. Once identified, site owners receive email notifications to confirm the active/inactive state of the site.\nRequest site attestation\nRequest site attestation\nis a feature that helps you ensure that SharePoint sites remain relevant and necessary over time. With this feature, you can set up periodic reviews where site owners and site admins are prompted to attest to the continued need for their sites. This process helps identify and clean up unused or unnecessary sites, reducing content sprawl and maintaining an organized digital environment.\nHow can you manage content lifecycle?\nYou can manage the content lifecycle for SharePoint sites by:\nUsing\nsite change history reports\nto track property changes across your sites, helping you monitor updates and maintain compliance.\nReviewing\nrecent site actions\nto see the latest changes you've made, making it easier to audit activity and ensure your governance policies are followed.\nTogether, these features give you visibility into site modifications and support effective lifecycle management.\nSite change history reports\nThe\nSite change history report\nfeature lets you create change history reports in the SharePoint admin center to review SharePoint site property changes made within the last 180 days. Create up to five reports for a given date range and filter by sites and users. You can download the report as a .csv file to view the site property changes.\nRecent site actions\nThe\nRecent SharePoint admin actions\npolicy lets you review and monitor the last 30 changes you've made to a SharePoint site's properties within the last 30 days in the SharePoint admin center. This feature only shows changes made by you and not other administrators.\nHow can you manage permissions and access\nMicrosoft 365 collaboration and AI experiences depend on strong permission and access controls for SharePoint and OneDrive. SharePoint Advanced Management (SAM) provides a suite of features to help you govern access, prevent oversharing, and protect sensitive data:\nAssess content management status:\nEvaluate your organization's content management practices and receive actionable insights to improve governance all in one place.\nBlock download policy:\nRestrict file downloads from SharePoint and OneDrive sites, ensuring browser-only access and preventing offline copies.\nCatalog management:\nProvide a comprehensive view of content distribution across regions, departments, users, information barriers, and custom properties defined by you.\nCompare site policies:\nEvaluate and align site-level policies to maintain consistent governance across your environment.\nConditional access policies:\nUse authentication contexts to connect a Microsoft Entra Conditional Access policy to a SharePoint site.\nData access governance reports:\nIdentify sites with overshared or sensitive content and take action to mitigate risks.\nManage data access governance via PowerShell:\nAutomate and scale your data access governance tasks using PowerShell commands.\nAgent insights:\nGain visibility into agents created in SharePoint and their activities.\nInsights on agents accessing content:\nGet insights on how the agents are accessing content across all SharePoint and OneDrive sites in your organization.\nApp insights:\nMonitor and manage non-Microsoft applications registered in your Microsoft Entra admin center that access your SharePoint content.\nInitiate site access reviews:\nDelegate review of overshared sites to site owners, ensuring regular validation of access permissions.\nRestrict access to all OneDrives by security group:\nLimit OneDrive access to specific security groups, enhancing data protection.\nRestrict access to specific OneDrives:\nControl access to individual OneDrive accounts based on user roles or group memberships.\nRestrict content discovery of SharePoint sites:\nLimit the ability of end users to search for files from specific SharePoint sites.\nRestrict site creation by users:\nEnforce policies to control who can create new SharePoint sites, reducing unnecessary sprawl.\nRestrict site creation by apps:\nControl which non-Microsoft applications can create SharePoint sites, ensuring only trusted apps have this capability.\nRestrict SharePoint access by security groups:\nApply security group-based policies to further refine who can access specific SharePoint sites.\nBy using these features together, you can ensure that only authorized users have access to your organizationâs data, reduce the risk of data leaks, and support secure, efficient collaboration with Microsoft 365 Copilot.\nAssess content management status\nThe\nContent management assessment\nfeature in SharePoint Advanced Management aggregates a comprehensive set of tools all in one place for you to quickly assess and improve your organization's content management practices with actionable insights and recommendations.\nBlock download policy for SharePoint and OneDrive sites\nBlock download policy for SharePoint and OneDrive sites\nYou can block download of files from SharePoint sites or OneDrive without needing to use Microsoft Entra Conditional Access policies. Users have browser-only access with no ability to download, print, or sync files. They also won't be able to access content through apps, including the Microsoft Office desktop apps.\nCatalog management\nCatalog management\nhelps you organize and govern SharePoint sites by grouping them into logical categories based on regions, departments, users, information barriers, and custom properties. This feature uses built-in Microsoft 365 metadata to enable targeted actions like content monitoring, policy enforcement, and Copilot grounding, streamlining governance and reducing administrative overhead.\nCompare site policies\nCompare site policies\nlets you evaluate and align site-level policies to maintain consistent governance across your SharePoint sites. You can compare policies such as sharing settings, sensitivity labels, and access controls between different sites to identify discrepancies and ensure uniform application of your organization's security standards.\nConditional access policies for SharePoint sites\nConditional access policies for SharePoint sites\nlet you enforce stringent access conditions when users access SharePoint sites. Authentication contexts can be directly applied to sites or used with sensitivity labels to connect Microsoft Entra Conditional Access policies to labeled sites. This ensures that only authorized users can access sensitive content based on defined security requirements.\nData access governance reports\nData access governance reports\nlets you view reports that identify sites that contain potentially overshared or sensitive content. You can use these reports to assess and apply appropriate security and compliance policies.\nData Access Governance management via PowerShell\nWhile Data access governance is available in SharePoint admin center portal, large organizations usually look for\nPowerShell support\nin order to manage scale via scripting and automation.\nThis document discusses all appropriate PowerShell commands available via SharePoint Online PowerShell module to manage reports from Data access governance.\nAgent insights\nAgent insights\nis a SharePoint Advanced Management feature that lets you gain visibility into agents created in SharePoint and their activities. This report can help you monitor and manage the agents accessing your SharePoint content.\nInsights on agents' access to content\nInsights on agents' access to content\nis a SharePoint Advanced Management feature that lets you gain insights on how the agents are accessing content across all SharePoint and OneDrive sites in your organization. You can see how agents interact with your content, spot access patterns, and view agent distribution across sites.\nEnterprise app insight reports\nApp insights\nis a SharePoint Advanced Management feature that lets you gain insights on the various non-Microsoft applications registered to your Microsoft Entra admin center and how they access your SharePoint content. This report can help you maintain and protect the integrity of your content.\nSite access reviews\nSite access review\nfeature in the SharePoint admin center lets you delegate the review process of\ndata access governance reports\nto the site owners of overshared sites.\nSite access review involves site owners in the review process so they can address the concern of overshared sites identified in data access governance reports.\nRestricted Access Control for SharePoint\nYou can prevent sites and content from being discovered at the site-level by enabling\nRestricted Access Control for SharePoint sites\n. Site access restriction allows only users in the specified security group or Microsoft 365 group to access content. This policy can be used with Microsoft 365 group-connected, Teams-connected, and nongroup connected sites.\nRestricted Access Control for OneDrive\nYou can limit access to shared content of a specific user's OneDrive to only people in a security group with the\nRestricted Access Control for OneDrive\npolicy. Once the policy is enabled, anyone who isn't in the designated security group won't be able to access content in that OneDrive even if it was previously shared with them.\nTo block users from accessing all OneDrives as a service, you can enable the\nRestrict OneDrive service access\nfeature.\nRestrict site creation by users\nYou can control who can create new SharePoint sites in your organization by enabling the\nRestrict site creation by users\nfeature. This helps reduce unnecessary sprawl and ensures that only authorized users can create sites.\nRestrict site creation by apps\nYou can control which non-Microsoft applications can create SharePoint sites in your organization by enabling the\nRestrict site creation by apps\nfeature. This ensures that only trusted apps have the capability to create sites, enhancing security and governance.\nLicensing\nTo use SharePoint Advanced Management (SAM), your organization must have the appropriate licensing in place. Learn about the main options for accessing SAM features\nhere\n.\nSharePoint Advanced Management features in Microsoft 365 Copilot licenses\nLearn about SharePoint Advanced Management features included in Microsoft 365 Copilot licenses\nhere\n.\nWhich Microsoft 365 Copilot SKUs include SharePoint Advanced Management?\nLearn more about what Microsoft 365 Copilot SKUs include SharePoint Advanced Management features\nhere\n.\nHow does SAM support Microsoft 365 Copilot deployment?\nWhether preparing for\nCopilot deployment\nor managing content post-implementation, SharePoint Advanced Management offers capabilities to help you govern your SharePoint and OneDrive content effectively.\nWe recommend utilizing SharePoint Advanced Management features along with our\nbest practices for Microsoft 365 Copilot\nto reduce the risk of oversharing, control content sprawl, and manage the content lifecycle.\nRelated articles\nMicrosoft 365 Government - how to buy\nGet started with Microsoft 365 Copilot\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Advanced Management",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/data-access-governance-reports": {
      "content_hash": "sha256:016318e5eead188c66236382c10333110e69b3c535104a34a0579829e1f5bcab",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nData access governance reports for SharePoint and OneDrive sites\nFeedback\nSummarize this article for me\nAs sprawl and oversharing of SharePoint sites increase with exponential data growth, organizations need help with governing their data. Data access governance reports can help you govern access to SharePoint data. The reports let you discover sites that contain potentially overshared or sensitive content. You can use these reports to assess and apply the appropriate security and compliance policies.\nWhat you need to create a data access governance report\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need at least one of these licenses:\nMicrosoft 365 Copilot license:\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nMicrosoft SharePoint Advanced Management license:\nAvailable as a standalone purchase.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nAdditional information\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nFor organizations without a Copilot license, you can use SharePoint Advanced Management features\nby purchasing a standalone SharePoint Advanced Management license\n.\nData governance access reports are available in nongovernment cloud environments, as well as GCC, GCC-High, and DoD government cloud environments. The reports are currently unavailable for Gallatin, even if you have the required licenses.\nHow to access the Data access governance reports in the SharePoint admin center\nSign in to the\nSharePoint admin center\nwith the\nSharePoint administrator\ncredentials for your organization.\nIn the left pane, expand\nReports\nand then select\nData access governance\n.\nThe following reports are currently available from the Data access governance landing page:\nSnapshot reports\nSite permissions across your organization\n(Recommended)\nSensitivity label applied to files\nActivity reports\nSharing links\nShared with 'Everyone except external users'\nNote\nIT administrators with Microsoft 365 E5 licensing can access Data access governance reporting, but are unable to view or utilize the other\nSharePoint Advanced Management features\n. No snapshot reports are provided. No remedial actions are provided. Activity reports are available but can return only up to 10,000 sites.\nWhat are snapshot reports?\nSnapshot reports give you a snapshot of your organization's current status based on specific reporting criteria. These reports show data as of the date they were generated.\nCurrently, three types of snapshot reports are available:\nSite permissions report\n: Provides a comprehensive snapshot of permission structure across all SharePoint and OneDrive sites, helping you identify sites with the broadest user access (for example, sites with thousands of users, external guests, or \"Everyone except external users\" permissions).\nSite permissions for users report\n: Lists all sites a specified user can access, allowing admins to determine whether they can access the entire site or specific sections, granted directly to the user or indirectly through groups.\nSensitivity label for files report\n: Identifies SharePoint sites containing files with specific sensitivity labels applied, allowing you to verify that appropriate security policies are in place for your most sensitive content.\nWhat are activity reports?\nActivity reports help you track potential oversharing activities that occurred in the last 28 days. These reports focus on \"recently active\" sites where users created sharing links or shared content with large groups. For all activities tracked in activity reports, you can find corresponding \"baseline\" data in the\nsnapshot reports\n.\nCurrently, two types of activity reports are available to help you identify potential oversharing:\nSharing links reports\n: Identifies sites where users recently created the most sharing links (including \"Anyone,\" \"People in the organization,\" and \"Specific people\" links) to help you catch potential oversharing as it happens.\nShared with 'Everyone except external users' reports\n: Tracks sites where content is shared with all internal users in your organization, helping you identify broad internal exposure that could lead to unintended data access.\nImportant\nFor organizations without SharePoint Advanced Management:\nYou must enable data collection before you can generate activity reports. Here's what you need to know:\nAfter enabling data collection, the system starts collecting audit data\nData is stored for 28 days\nReports become available 24 hours after enabling collection\nReports only contain data from when collection was enabled\nIf no reports are generated for 3 months, data collection pauses and must be re-enabled\nHow to use snapshot and activity reports?\nAs part of your governance strategy, we recommend combining both snapshot and activity reports to get a complete picture of your organization's data access landscape. Here's how to use them together effectively:\nStart with snapshot reports\n: Run site permissions reports first to understand your baseline permission structure and identify sites with the broadest exposure. We recommend running these quarterly to maintain a comprehensive view of your organization's data access.\nFollow up with activity reports\n: Use sharing links and EEEU activity reports to monitor recent oversharing activities and catch emerging risks. We recommend running these monthly to stay on top of ongoing sharing activities.\nThis combination ensures you have both a complete picture of your current state and visibility into ongoing sharing activities that could create new exposure risks.\nWhat is the site permissions for your organization report?\nThe site permissions report for your organization report is the first snapshot report that provides a comprehensive view of your organization's current permission structure across all SharePoint and OneDrive sites. This report analyzes every site to help you understand how broadly your data is exposed and identify potential oversharing risks. This snapshot approach helps you quickly assess your overall security posture and identify sites that need immediate attention.\nLearn create and use the\nsite permissions for your organization report here\n.\nWhat is the site permissions for users report?\nThe site permissions report for users report is the next snapshot report that provides a comprehensive view into permissions of the specified users across all SharePoint and OneDrive sites. This report lists all sites a user can access and allows admins to determine whether they can access the entire site or specific sections, granted directly to the user or indirectly through groups. This approach helps you quickly assess your overall security posture and identify sites that need immediate attention.\nLearn how to create and use the\nsite permissions for users report here\n.\nWhat is the sensitivity labels for files report?\nThe sensitivity labels for files report is the other snapshot report that helps you control access to sensitive content across your organization. This report identifies sites containing\nfiles with sensitivity labels applied\n, allowing you to verify that appropriate security policies are applied.\nLearn how to use the\nsensitivity labels for files report here\n.\nWhat is the sharing links report?\nThe sharing links report is one of the two activity reports that helps you identify sites where users created the most new sharing links in the last 28 days.\nLearn how to create and use\nsharing links report here\n.\nWhat is the 'Everyone except external users' (EEEU) report?\nEEEU is a built-in SharePoint group that automatically includes all internal users but excludes any external guests. The 'Everyone except external users' (EEEU) report is one of the two activity reports that helps you identify sites where content has been shared with your entire organization in the past 28 days. You can run the\nsite permissions for your organization report\nfirst to understand your organization's current EEEU sharing status, then use this activity report to monitor ongoing EEEU sharing activities. Learn how to create and use the Everyone except external users sharing activity report\nhere\n.\nLimitations or known issues\nReports may not work if you have nonpseudonymized report data selected for your organization. To change this setting, you must be a Global Administrator. Go to the\nReports setting in the Microsoft 365 admin center\nand clear\nDisplay concealed user, group, and site names in all reports\n.\nRemedial actions from Data access governance reports\nAfter discovering potential oversharing through Data access governance reports, you can take several actions to address these risks. When deciding which actions to take, consider:\nThe sensitivity of the exposed content\nThe amount of content at risk\nThe potential disruption to users and workflows\nAvailable remediation options\nFor immediate action:\nUse\nRestricted access control (RAC)\nto limit access to a specific group\nReview the\n'Change history' report\nto identify recent permission changes that may have led to oversharing\nFor collaborative remediation:\nUse the\nSite access review feature\nto request that site owners review and update permissions themselves\nThis approach ensures you can balance security needs with minimal disruption to your organization's productivity.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data Access Governance Reports",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/site-lifecycle-management": {
      "content_hash": "sha256:db593c22032d468d2b4299907864e0bfcb2afa7240c5bac7af20bc33e2ebf8af",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage inactive sites by using inactive site policies\nFeedback\nSummarize this article for me\nThe site lifecycle management features from\nMicrosoft SharePoint Advanced Management\nhelp you improve site governance by automating policy configuration in the\nSharePoint admin center\n. Inactive site policies, part of SharePoint's site lifecycle management features, help you automate this process. You can set up an inactive site policy to automatically detect inactive sites and notify site owners by email. Owners can then confirm if the site is still active.\nWhat do you need to create an inactive site policy?\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need at least one of these licenses:\nMicrosoft 365 Copilot license:\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nMicrosoft SharePoint Advanced Management license:\nAvailable as a standalone purchase.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nAdditional information\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nFor organizations without a Copilot license, you can use SharePoint Advanced Management features\nby purchasing a standalone SharePoint Advanced Management license\n.\nHow do inactive site policies work?\nScope of inactive site policies\nYou can configure parameters for an inactive site policy, such as inactive time period, template type, site creation source, sensitivity labels, and exclusion of up to 100 sites.\nIn-scope site activities\nInactive site policies analyze activity across SharePoint and connected platforms like Teams, Viva Engage (formerly Yammer), and Exchange to detect a site's last activity.\nPlatform type\nActivities\nSharePoint\nViewed files, edited files, shared files internally and externally, synced files, viewed pages, visited pages\nViva Engage (formerly Yammer)\nPosted messages, read conversations, liked messages\nTeams\nPosted channel messages in a team across standard channels, posted messages in Teams and standard channels, replied to messages, mentioned in messages, reacted to messages, sent urgent messages, conducted meetings (recurring, ad hoc, one-time)\nExchange\nReceived emails in the Exchange mailbox\nScope of app activities\nInactive site policies don't consider app activity through an app token. They consider app activity through a user token only when a user agent is involved and meets the following criteria.\nActivity source\nCondition when activity is considered\nPnP PowerShell activity via user token\nIs not considered\nSharePoint Online PowerShell activity via user token\nIs considered only when UserAgent parameter value is passed\nCSOM scripting activity via user token\nIs considered when script explicitly sets UserAgent value\nAny other app activity via user token\nIs considered when UserAgent exists, except in the following scenarios when\n- UserAgent starts with \"client-request=id\"/\"ACTIVEMONITORING\"/SPORUNNERS\"\nOR\n- UserAgent ends with \"MSDEMO\"/\"MSDPLATFORM\"/\"SystemUsage\"\nOR\n- UserAgent contains \"GomezAgent\"/\"bingbot.htm\"/\"ms search 6.0 robot\"/\"http://www.monitis.com\"/\"ISV\"\nApp activity via app token\nIs not considered\nIn-scope site templates\nSite lifecycle management reviews the activity of communication sites, classic sites, Teams-connected sites, and group-connected sites with the following site template types:\nSite type\nTemplate type\nCommunication site\nSitePagePublishing#0\nClassic sites\nSTS#0, STS#1, STS#2, WIKI#0, BLOG#0, SGS#0, SPS#0, SPSNEWS#0, ENTERWIKI#0, COMMUNITY#0, DEV#0, EXPRESS#0, EHS#1, EHS#2\nTeams-connected site\nSTS#3 or Group#0\nGroup-connected site\nSTS#3 or Group#0\nOut-of-scope sites\nThe following sites are out of scope and excluded from site activity detection:\nOneDrive sites\nSites created by system users\nApp catalog sites\nRoot sites\nHome sites\nTenant admin sites\nSites associated with Shared and Private Teams channels\nPolicy modes\nWhen setting up a site lifecycle policy, you can choose between a simulation policy and an active policy.\nSimulation mode\nThe simulation policy runs once and generates a report based on the set parameters. If it fails, you need to delete it and create a new one. Once you validate a simulation policy, you can convert it to an active policy.\nNote\nSite lifecycle policies in simulation mode are now available in GCCH and DoD environments as of November 17, 2025.\nActive mode\nThe active policy runs monthly, generating reports and sending notifications to site owners to confirm the site's status. If it fails during a particular month, it will run again on the next schedule. The policy enforces actions on sites that remain uncertified or unattested by the site owner or admin, provided you configured it to take enforcement actions.\nHow to create an inactive site policy\nTo create an inactive site policy, expand\nPolicies\nand select\nSite lifecycle management\nin the\nSharePoint admin center\n:\nSelect\n+ Create policy\nand then select\nNext\n.\nChoose your policy scope option and select\nNext\n.\nIf you select\nUpload a CSV file with a list of up to 10,000 URLs\n, you can upload a list of site URLs of select sites for the policy.\nTip\nYou can export the site list from the SharePoint active sites page.\nEnsure the CSV file use the same format of the sample CSV file and has no duplicate URLs and those URLs are valid and complete.â¯\nEnsure the URLs listed in CSV file belong to your tenant's domain.â¯\nIf you select\nInclude sites with retention policies and retention holds\n, the policy scope includes read-only sites and locked sites. The policy scope automatically includes all inactive ownerless sites.\nDefine the configuration of the policy by selecting the inactivity period, the email recipients, and the enforcement actions. Select\nNext\n. During the configuration step, you can specify the following actions:\nChoose to send emails to site owners or site admins, or both.\nCustomize the email content to provide more context and instructions to the email recipients.\nChoose enforcement actions if there's no response from site owners or admins after three notifications.\nChoose enforcement actions\nFor sites that aren't certified or attested after 3 monthly notifications for any of the site lifecycle management policies, you can take one of the following enforcement actions.\nEnforcement action\nPolicy behavior\nDo nothing\nSite owners or site admins receive monthly notifications for three months. After this period, no notifications are sent for the next three months. If the site remains unattested after six months, monthly notifications resume. The policy execution report lists unattested sites as unactioned by the site owner. You can download this report and filter out sites marked as unactioned.\nRead-only access\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as attested during this period, the site goes into read-only mode.\nArchive sites after mandatory read-only period\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as attested during this period, then the site goes into a read-only mode for a configurable duration (3, 6, 9, or 12 months). After the configured number of months, the site gets archived through\nMicrosoft 365 Archive\n. Archival is subject to the tenant enabling Microsoft 365 Archive on the Microsoft Admin center.\nThe following screenshot shows an example of configuring enforcement actions for a site attestation policy:\nNote\nIf you configure the policy to take an enforcement action:\nThe notifications wonât be sent after policy action is successful.\nThe site and itâs status are included in the monthly report.\nName the policy, add a description (optional), and select a policy mode. Select\nFinish\n. You can now view and manage your policy from the\nSite lifecycle management > Inactive site policy\ndashboard.\nInactive site notifications to site owners or site admins\nNotifications inform SharePoint site owners or site admins when a site is inactive for a specified number of months. To keep the site, the notification recipients should select the\nCertify site\nbutton in the notification email. Once certified, Site lifecycle management doesn't check the site's activity for one year.\nCustomize email notifications\nAdmins can now customize the emails sent by the Site Lifecycle Management policies, to site owners and admins for certification or attestation. Customizing email content helps improve the read-through rate of the emails sent, effectively improving the response efficiency thus contributing towards better governance across the tenant.\nThe option to customize emails is available in the configure step for all site lifecycle management policies.\nSelecting\nCustomize email to be sent\nopens the customization window as following:\nCustomizable section\nDescription\nSender\nConfiguring a custom domain (in MAC) is a prerequisite to using the email customization feature. Select\nhere\nto learn more on how to configure/change this setting.\nSubject\n(up to 100 characters)\nYou can use\n$UserDisplayName\nto insert the user's name and\n$SiteName\nto insert the name of the site.\nMessage\n(up to 500 characters)\nYou can use\n$UserDisplayName\nto insert the user's name,\n$SiteName\nto insert the name of the site and\n$SiteUrl\nto insert URL of the site.\nPolicy guideline URL\nOnly valid HTTP links are allowed\nPolicy guideline description text\nDefault value is the placeholder text\nYou can also customize emails for existing policies. To customize emails, follow these steps:\nSelect an existing policy.\nGo to\nEdit configuration\n.\nFind the email customization option.\nNote\nIf you don't configure email customization for a policy, the system continues to send default emails from\nnoreply@sharepoint.com\n.\nWhen can't you customize emails?\nYou might not be able to customize emails if the custom domain setting isn't configured or is turned off.\nYou must configure the \"Send email notifications from your domain\" setting in Microsoft admin center (MAC) before you can customize emails. If this setting isn't configured, you'll see a warning message on the top of the policy list:\nYou'll also see the warning message during the configuration step:\nIf you previously customized emails in one or more policies but the \"Send email notifications from your domain\" setting in MAC is, then turned off, you'll see the message bar in the policy list, and a warning message in the email customization window.\nNote\nYou need the Global Administrator role to configure this setting in Microsoft admin center (MAC).\nSites managed by multiple site lifecycle management policies\nFor each type of site lifecycle management policy, such as\nsite ownership policy\n,\ninactive site policy\n, and\nsite attestation policy\n, if you create multiple policies under the same type, notification emails aren't repeated. If a notification was sent within the last 30 days from any policy of that type, and the site remains uncertified, no further notifications are sent. The policy execution report shows the site's status as \"Notified by another policy.\"\nFor example, if a site is covered by two different inactive site policies and receives a notification email from the first policy, the second policy doesn't send any additional notifications within the next 30 days if the site remains uncertified.\nIt's recommended to ensure that policies of the same type don't have overlapping scopes. If sites fall under the scope of multiple policies of the same type, the notification schedule and enforcement actions on the site could become unpredictable.\nEnforcement actions\nThe following table summarizes how the inactive site policy behaves based on the selected enforcement action:\nEnforcement action\nPolicy behavior\nDo nothing\nSite owners or site admins receive monthly notifications for three months. After this period, the policy sends no notifications for the next three months. If the site remains inactive after six months, monthly notifications resume. The policy execution report lists inactive sites as unactioned by the site owner. You can download this report and filter out sites marked as unactioned.\nRead-only access\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as certified during this period, the site goes into read-only mode.\nArchive sites after mandatory read-only period\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as certified during this period, then the site goes into a read-only mode for a configurable duration (3, 6, 9, or 12 months). After the configured number of months, the site gets archived through\nMicrosoft 365 Archive\n. Archival is subject to the tenant enabling Microsoft 365 Archive on the Microsoft Admin center.\nImportant\nSite lifecycle policies leverage Outlook Actionable Messages to enable site owners or site admins take necessary actions within email.\nFor notifications to render properly, ensure\nOutlook version requirements\nare met in your organization.\nIf you're a US Government cloud customer, see\nSet up actionable emails for SLM policies in US Government cloud environments\n(in this article).\nTo troubleshoot rendering issues, refer to\nfrequently asked questionnaire\n.\nWhen a site owner or site admin selects the site URL in the notification email, this action does\nnot\ncount as site activity. The site remains inactive. Additionally, any\nread actions\ndone on the site within one hour of visiting from the email aren't considered activity. However, any\nedits\nmade to the site count as activity and reset the inactivity status.\nTip\nBefore creating an inactive site policy, check for any site access restriction policies that could disrupt site attestation by the respective site owner.\nRead-only mode\nAn inactive site policy configured with the read-only enforcement action sends additional notifications to inform site owners or site admins when there's no response.\nA notification is sent when the site goes into read-only mode.\nOnce the site is in read-only mode, the following banner is added to the site:\nRemove site from read-only mode\nTo remove a site from read-only mode in\nSharePoint admin center\n, go to the\nActive sites\npage, select the site, and then select\nUnlock\nfrom the site page panel.\nSite owners can't remove a site from read-only mode and must contact the tenant admin to remove read-only mode.\nUnarchive a site\nTo unarchive a site in\nSharePoint admin center\n, expand\nSites\nand select\nArchived sites\n. Select the site you want to unarchive and select\nReactivate\n.\nNote\nOnly tenant admins can reactivate an archived site.\nReporting\nThe policy execution report lists sites that are inactive for six months. You can download the report as a .csv file and filter out sites that site owners consider unactioned.\nThe following table describes the information included in the policy execution report:\nColumn\nDefinition\nSite name\nName of the site\nURL\nURL of the site\nTemplate\nTemplate of the site\nConnected to Teams\nIs it a Teams-connected site or not\nSensitivity label\nSensitivity label of the site\nRetention policy\nIs any retention policy applied to the site or not\nSite lock state\nState of site access\nbefore\nthe policy runs (Unlock/Read-Only/No access)\nLast activity date (UTC)\nDate of last activity detected by inactive site policy across SharePoint site and connected workloads (Exchange, Viva Engage (formerly Yammer), or Teams)\nSite creation date (UTC)\nDate when the site was created\nStorage used (GB)\nStorage consumed by the site\nNumber of site owners\nTotal count of site owners for the site\nEmail address of site owners\nEmail addresses of all site owners\nNumber of site admins\nTotal count of site admins for the site\nEmail address of site admins\nEmail addresses of all site admins\nAction status\nStatus of the site (First, second, or third notification sent; Site in read-only mode; Site archived; Action taken by another policy: read-only, archive, or notified by another policy)\nTotal notifications count\nTotal notifications sent so far by any policy under the same policy template\nAction taken on (UTC)\nDate on which the enforcement action was taken (date when site was archived or put in read-only mode)\nDuration in read-only\nNumber of days the site is in the enforced read-only state\nSet up actionable emails for SLM policies in US Government cloud environments\nIn US Government Cloud (GCC High and DoD) environments, a tenant administrator must complete an extra, one-time setup for SharePoint site lifecycle management (SLM) policies to use\nactionable messages\n. This step helps ensure that policy notification emails display and function correctly. For example, site admins and site owners can take actions directly from email.\nUnlike other commercial cloud environments, GCC High and DoD tenants require explicit administrator approval of the actionable message provider before it can send interactive email messages. Without this approval, SLM policy emails are delivered, but action buttons don't function as expected.\nImportant\nYou must be a Global Administrator or Exchange Administrator in the tenant to set up actionable messages.\nApprove the SLM actionable message provider\nGo to the\nOutlook Actionable Messages â Connectors admin portal for GCCH or DoD\nand sign in.\nIn the\nProvider Status\nfilter, select\nApproved by Microsoft â Pending Your Approval\n.\nLocate the provider named\nInactiveSiteOAMProviderGCCH\n.\nSelect the provider, and then select\nApprove\n.\nAfter you approve the provider, the SLM policy notifications send actionable messages.\nNote\nThis approval applies only to SLM policy notifications. Other applications or services that use actionable messages might require separate approval.\nEnsure actionable messages are enabled for the tenant\nSite lifecycle management policies use Outlook actionable messages to enable site owners or site administrators to take necessary actions by using links within email messages.\nFor notifications to render properly, make sure your organization meets the\nOutlook version requirements\n.\nTo troubleshoot rendering problems, see\nfrequently asked questions\n.\nTroubleshooting actionable messages\nIf actionable messages don't work as expected, try these steps:\nMake sure that the\nInactiveSiteOAMProviderGCCH\nprovider is in an approved state.\nAllow sufficient time. It can take up to 24 hours for changes to propagate.\nRelated articles\nMicrosoft 365 group expiration policy\nRestore deleted sites\nOverview of Microsoft 365 Archive\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Site Lifecycle Management",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/request-site-attestations": {
      "content_hash": "sha256:5c996860f03881385162e7210a15f5baec320076a2b0595d799e04d17f93f086",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRequest recurring site attestations for SharePoint sites\nFeedback\nSummarize this article for me\nThe site lifecycle management features from\nMicrosoft SharePoint Advanced Management\nhelp you improve site governance by automating policy configuration in the\nSharePoint admin center\n. Site attestation policies, part of SharePoint's site lifecycle management features, help you manage periodic attestation of sites at scale. This attestation involves regular reviews by site owners or admins to check and confirm the accuracy of site information, including the site's necessity, its owners, members, permissions, and sharing settings. For sites that remain unattested, you can choose to automate enforcement actions to prevent risks of content overexposure. This approach ensures ongoing site compliance and actively reduces risks such as information oversharing.\nWhat do you need to create a site attestation policy\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need at least one of these licenses:\nMicrosoft 365 Copilot license:\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nMicrosoft SharePoint Advanced Management license:\nAvailable as a standalone purchase.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nAdditional information\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nFor organizations without a Copilot license, you can use SharePoint Advanced Management features\nby purchasing a standalone SharePoint Advanced Management license\n.\nHow does a site attestation policy work?\nScope of site attestation policies\nYou can create site lifecycle policies with different scopes based on your organization's requirements. Choose the sites to include in the policy based on:\nSite templates\nCreation sources\nSensitivity labels\nWhether to include sites under retention policies and retention holds\nTo exclude specific sites, add the site URLs of up to 100 sites in the\nExclude sites\nsection while configuring the policy.\nPolicy modes\nWhen setting up a site lifecycle policy, you can choose between a simulation policy and an active policy.\nSimulation mode\nThe simulation policy runs once and generates a report based on the set parameters. If it fails, you need to delete it and create a new one. Once you validate a simulation policy, you can convert it to an active policy.\nNote\nSite lifecycle policies in simulation mode are now available in GCCH and DoD environments as of November 17, 2025.\nActive mode\nThe active policy runs monthly, generating reports and sending notifications to site owners to confirm the site's status. If it fails during a particular month, it will run again on the next schedule. The policy enforces actions on sites that remain uncertified or unattested by the site owner or admin, provided you configured it to take enforcement actions.\nCreate site attestation policies\nTo create a site attestation policy, follow these steps:\nSign in to the\nSharePoint admin center\nby using the\nSharePoint administrator\ncredentials for your organization.\nIn the navigation pane, expand\nPolicies\nand select\nSite lifecycle management\n.\nUnder\nSite attestation policies\n, select\nOpen\n.\nSelect\nCreate a policy\n.\nOn the\nOverview\npage of\nManage site attestation\n, select\nNext\n.\nOn the next page, you define the scope of the policy.\nDefine the scope of the site attestation policy\nTo define the scope of the site attestation policy, on the\nSelect policy scope\npage, start by selecting the sites for the policy by using one of the following approaches:\nUpload a CSV file with a list of up to 10,000 URLs\nSelect sites at scale\nUpload a CSV file with the list of sites\nIf you select\nUpload a CSV file with a list of up to 10,000 URLs\n, you can upload a list of site URLs for the policy.\nTip\nYou can export the site list from the SharePoint active sites page.\nEnsure the CSV file uses the same format as the sample CSV file and has no duplicate URLs. Also, make sure the URLs are valid and complete.â¯\nEnsure the URLs listed in the CSV file belong to your tenant's domain.â¯\nSelect sites at scale\nIf you choose\nSelect sites at scale\n, you can select site templates to include in this policy, and filter them by:\nSensitivity label\nSite creation source\nYou can also choose whether to:\nInclude sites with retention policies and retention holds\nExclude specific sites from this policy\nSelect site template types\nSelect site template types from the following list:\nAll sites\nClassic sites\nCommunication sites\nGroup connected sites without teams\nTeam sites without Microsoft 365 group\nTeams-connected sites\nFilter sites by sensitivity labels\nSet policy scope by filtering sites by their sensitivity labels.\nNote\nIf your tenant doesn't set up sensitivity labels, this option is unavailable.\nFilter sites by creation source\nFilter sites for the policy scope by site creation source:\nSharePoint Home\nSharePoint admin center\nPowerShell\nPnP\nTeams\nInclude sites with retention policies and retention holds\nBy default, the box for\nInclude sites with retention policies and retention holds, read-only sites and locked sites\nis selected. This selection means sites in a read-only state or locked states are included in the scope of the policy, with whatever other filters applied.\nExclude specific sites from the policy\nEnter up to 100 sites that you want to exclude from the policy. Be sure to separate each URL by new lines.\nAfter setting the policy's scope, select\nNext\n. You then configure the site attestation policy settings.\nConfigure site attestation policy settings\nOn\nConfigure policy\n, you can:\nChoose how often you want the sites to be attested (3 months, 6 months, and 12 months).\nIdentify who is responsible for attesting the site (site owners, site admins, or both).\nExclude site owners or admins from receiving requests.\nSpecify what action the policy should take after three notifications.\nExclude site owners or admins from receiving requests\nYou can exclude up to 100 users or Microsoft 365 or security groups from receiving attestation requests, even if they're the site owners or site admins for the sites included in the policy.\nActions to take on unattested sites after three notifications\nFor sites that are unattested after three monthly notifications, you can choose to either do nothing or take one of the following enforcement actions. The following table summarizes how the inactive site policy behaves for each selected enforcement action:\nEnforcement action\nPolicy behavior\nDo nothing\nSite owners or site admins receive monthly notifications for three months. After this period, no notifications are sent for the next three months. If the site remains unattested after six months, monthly notifications resume. The policy execution report lists unattested sites as unactioned by the site owner. You can download this report and filter out sites marked as unactioned.\nRead-only access\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as attested during this period, the site goes into read-only mode.\nArchive sites after mandatory read-only period\nSite owners or site admins receive monthly notifications for three months. If the notification recipients don't mark the site as attested during this period, then the site goes into a read-only mode for a configurable duration (3, 6, 9, or 12 months). After the configured number of months, the site gets archived through\nMicrosoft 365 Archive\n. Archival is subject to the tenant enabling Microsoft 365 Archive on the Microsoft Admin center.\nNote\nIf you configure the policy to take an enforcement action:\nThe notifications stop after the policy action succeeds.\nThe site and its status are included in the monthly report.\nCustomize email notifications\nAdmins can now customize the emails sent by the Site Lifecycle Management policies, to site owners and admins for certification or attestation. Customizing email content helps improve the read-through rate of the emails sent, effectively improving the response efficiency thus contributing towards better governance across the tenant.\nThe option to customize emails is available in the configure step for all site lifecycle management policies.\nSelecting\nCustomize email to be sent\nopens the customization window as following:\nCustomizable section\nDescription\nSender\nConfiguring a custom domain (in MAC) is a prerequisite to using the email customization feature. Select\nhere\nto learn more on how to configure/change this setting.\nSubject\n(up to 100 characters)\nYou can use\n$UserDisplayName\nto insert the user's name and\n$SiteName\nto insert the name of the site.\nMessage\n(up to 500 characters)\nYou can use\n$UserDisplayName\nto insert the user's name,\n$SiteName\nto insert the name of the site and\n$SiteUrl\nto insert URL of the site.\nPolicy guideline URL\nOnly valid HTTP links are allowed\nPolicy guideline description text\nDefault value is the placeholder text\nYou can also customize emails for existing policies. To customize emails, follow these steps:\nSelect an existing policy.\nGo to\nEdit configuration\n.\nFind the email customization option.\nNote\nIf you don't configure email customization for a policy, the system continues to send default emails from\nnoreply@sharepoint.com\n.\nWhen can't you customize emails?\nYou might not be able to customize emails if the custom domain setting isn't configured or is turned off.\nYou must configure the \"Send email notifications from your domain\" setting in Microsoft admin center (MAC) before you can customize emails. If this setting isn't configured, you'll see a warning message on the top of the policy list:\nYou'll also see the warning message during the configuration step:\nIf you previously customized emails in one or more policies but the \"Send email notifications from your domain\" setting in MAC is, then turned off, you'll see the message bar in the policy list, and a warning message in the email customization window.\nNote\nYou need the Global Administrator role to configure this setting in Microsoft admin center (MAC).\nAfter configuring the policy settings, select\nNext\nto finish your policy. Name the policy, add a description (optional), and select a policy mode.\nSelect\nFinish\n. You can now view and manage your policy from the\nSite lifecycle management\n>\nSite attestation policy\ndashboard.\nSite set as read-only mode\nWhen you configure an unattested site policy with the read-only enforcement action, it sends extra notifications to inform site owners or site admins that the site goes into read-only mode.\nWhen the site is in read-only mode, the following banner appears on the site:\nRemove site from read-only mode\nTo remove a site from read-only mode in\nSharePoint admin center\n, go to the\nActive sites\npage, select the site, and then select\nUnlock\nfrom the site page panel.\nSite owners can't remove a site from read-only mode. They must contact the tenant admin to remove read-only mode.\nUnarchive a site\nTo unarchive a site in\nSharePoint admin center\n, expand\nSites\nand select\nArchived sites\n. Select the site you want to unarchive and select\nReactivate\n.\nNote\nOnly tenant admins can reactivate an archived site.\nSites managed by multiple site attestation policies\nFor each type of site lifecycle management policy, such as\nsite ownership policy\n,\ninactive site policy\n, and\nsite attestation policy\n, if you create multiple policies, notification emails aren't repeated. If a notification was sent within the last 30 days from any policy of that type, and the site remains unattested or uncertified, no further notifications are sent. The policy execution report shows the site's status as \"Notified by another policy.\"\nFor example, if a site is covered by two different site attestation policies and receives a notification email from the first policy, the second policy doesn't send any extra notifications within the next 30 days if the site remains unattested.\nMake sure that policies of the same type don't have overlapping scopes. If sites fall under the scope of multiple policies of the same type, the notification schedule and enforcement actions on the site could become unpredictable.\nReporting\nAfter each run of the configured policy, you can view a detailed report about the sites it identifies.\nIn the\nSite attestation policies\npage, select the desired policy from the list.\nThe panel outlines the numbers of:\nSites to attest\nSites that didn't have anyone to notify\nSites attested\nSites set to read-only\nArchived sites\nYou can also view the policy's scope, configuration, and general information on the report.\nYou can also view the policy's scope, configuration, and general information on the panel. Select the\nDownload detailed report\noption to download the report in CSV containing the following details for each of the sites identified due for attestation:\nColumn\nDefinition\nSite name\nName of the site\nURL\nURL of the site\nTemplate\nTemplate of the site\nConnected to Teams\nIndicates if it's a Teams-connected site\nSensitivity label\nSensitivity label assigned to the site\nRetention policy\nIndicates if any retention policy is applied to the site\nSite lock state\nState of site access\nbefore\nthe policy runs (Unlock/Read-Only/No access)\nNotified site admins\nEmail addresses of site admins receiving attestation notifications\nNotified site owners\nEmail addresses of site owners receiving attestation notifications\nLast attested by\nEmail address of the person who last attested the site\nLast attestation date (UTC)\nDate when the site was last attested\nNumber of site owners\nTotal count of site owners for the site\nEmail address of site owners\nEmail addresses of all site owners\nNumber of site admins\nTotal count of site admins for the site\nEmail address of site admins\nEmail addresses of all site admins\nTotal notifications count\nTotal notifications sent so far by any policy under the same policy template\nAction status of policy\nStatus of the site (First, second, or third notification sent, Site in read-only mode, Site archived, Action taken by another policy such as read-only, archive, or notified by another policy)\nAction taken on (UTC)\nDate on which the enforcement action was taken (date when site was archived or put in read-only mode)\nLast activity date (UTC)\nDate of last activity detected across SharePoint site and connected workloads\nSite creation date (UTC)\nDate when the site was created\nStorage used (GB)\nStorage consumed by the site\nDuration in read-only (days)\nNumber of days the site is in the enforced read-only state\nConfigure actionable emails for US Government Cloud (GCC High or DoD) environments\nIn US Government Cloud (GCC High and DoD) environments, a tenant administrator must complete an extra, one-time setup for SharePoint site lifecycle management (SLM) policies to use\nactionable messages\n. This step helps ensure that policy notification emails display and function correctly. For example, site admins and site owners can take actions directly from email.\nUnlike other commercial cloud environments, GCC High and DoD tenants require explicit administrator approval of the actionable message provider before it can send interactive email messages. Without this approval, SLM policy emails are delivered, but action buttons don't function as expected.\nImportant\nYou must be a Global Administrator or Exchange Administrator in the tenant to set up actionable messages.\nApprove the SLM actionable message provider\nGo to the\nOutlook Actionable Messages â Connectors admin portal for GCCH or DoD\nand sign in.\nIn the\nProvider Status\nfilter, select\nApproved by Microsoft â Pending Your Approval\n.\nLocate the provider named\nInactiveSiteOAMProviderGCCH\n.\nSelect the provider, and then select\nApprove\n.\nAfter you approve the provider, the SLM policy notifications send actionable messages.\nNote\nThis approval applies only to SLM policy notifications. Other applications or services that use actionable messages might require separate approval.\nEnsure actionable messages are enabled for the tenant\nSite lifecycle management policies use Outlook actionable messages to enable site owners or site administrators to take necessary actions by using links within email messages.\nFor notifications to render properly, make sure your organization meets the\nOutlook version requirements\n.\nTo troubleshoot rendering problems, see\nfrequently asked questions\n.\nTroubleshooting actionable messages\nIf actionable messages don't work as expected, try these steps:\nMake sure that the\nInactiveSiteOAMProviderGCCH\nprovider is in an approved state.\nAllow sufficient time. It can take up to 24 hours for changes to propagate.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Site Attestation",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/information-barriers": {
      "content_hash": "sha256:7a40414efafcd28a59ffae6a17ab541c3a2c853050116db6dfd33d3681721b80",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nUse Information Barriers with SharePoint\nFeedback\nSummarize this article for me\nMicrosoft Purview Information Barriers\nare policies in Microsoft 365 that a compliance admin can configure to prevent users from communicating and collaborating with each other. This solution is useful if, for example, one division is handling information that shouldn't be shared with specific other divisions, or a division needs to be prevented, or isolated, from collaborating with all users outside of the division. Information Barriers are often used in highly regulated industries and those organizations with compliance requirements, such as finance, legal, and government.\nFor SharePoint, Information Barriers can determine and prevent the following kinds of unauthorized collaborations:\nAdding a user to a site\nUser access to a site or site content\nSharing a site or site content with other users\nInformation Barriers modes and SharePoint sites\nInformation Barriers modes\nhelp strengthen access, sharing, and membership of a site based on its IB mode and segments associated with the site.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nWhen you use Information Barriers with SharePoint, you can use the following IB modes:\nMode\nDescription\nExamples\nOpen\nWhen a SharePoint site doesn't have segments, the site's IB mode is automatically set as\nOpen\n. See\nthis section\nfor details on managing segments with the\nOpen\nmode configuration.\nA Team site created for picnic event for your organization.\nOwner Moderated\nWhen a SharePoint site is created for collaboration between incompatible segments moderated by the site owner, the site's IB mode should be set as\nOwner Moderated\n. See\nthis section\nfor details on managing\nOwner Moderated\nsite.\nA site is created for collaboration between VP of Sales and Research in the presence of VP of HR (site owner).\nImplicit\nWhen a site is provisioned by Microsoft Teams, the site's IB mode is set as\nImplicit\nby default. A SharePoint Administrator or Global Administrator can't manage segments with the\nImplicit\nmode configuration.\nA Team is created for all Sales segment users to collaborate with each other.\nExplicit\nWhen segment is added to a SharePoint site either via end-user site creation experience or by a SharePoint Administrator adding segment to a site, the site's IB mode is set as\nExplicit\n. See\nthis section\nfor details on managing segments with the\nExplicit\nmode configuration.\nA research site is created for Research segment users.\nSharing sites for IB modes\nSharing of sites with users is based on the IB mode of the site.\nOpen\nWhen a site has no segments and you set the site's Information Barriers mode to\nOpen\n:\nThe site and its contents can be shared based on the information barrier policy applied to the user. For example, if a user in HR is allowed to communicate with users in Research, the user can share the site with those users.\nTip\nIf you want to allow sharing of\nOpen\nmode sites with mail-enabled security groups, see the\nAllow sharing of Open mode sites with mail-enabled security groups\nsection in this article.\nOwner Moderated\nWhen you set a site's Information Barriers mode to\nOwner Moderated\n:\nThe option to share with\nAnyone with the link\nis disabled.\nThe option to share with\nCompany-wide link\nis disabled.\n(For group connected sites) The site and its content can be shared with existing members.\n(For non-group connected sites) The site and its content can be shared only by the site owner per their IB policy.\nImplicit\nWhen you set a site's Information Barriers mode to\nImplicit\n:\nThe option to share with\nAnyone with the link\nis disabled.\nThe option to share with\nCompany-wide link\nis disabled.\nThe site and its content can be shared with existing members via a sharing link.\nNew users can't be added to the site directly. The Team owner should add users to the Team's group using Microsoft Teams.\nNote\nIf you enabled Information Barriers for SharePoint in your organization before March 15, 2022, see the\nEnable SharePoint and OneDrive Information Barriers\nsection in this article.\nExplicit\nWhen you associate a site with segments and set the site's Information Barriers mode to\nExplicit\n:\nThe option to share with\nAnyone with the link\nis disabled.\nThe option to share with\nCompany-wide link\nis disabled.\nYou can share the site and its content only with users whose segment matches that of the site. For example, if you associate a site with the HR segment, you can share the site with just HR users (even though HR is compatible with both Sales and Research segments).\nYou can add new users as site members only if their segment matches the segment of the site.\nAccess control for IB modes\nThe IB policy is enforced when opening the SharePoint site or content in the SharePoint site. This enforcement is based on the IB mode of the site.\nOpen mode\nFor a user to access a SharePoint site that has no segment and the site's Information Barriers mode is set to\nOpen\n:\nThe user has site access permissions.\nOwner Moderated mode\nFor a user to access a SharePoint site with the site's Information Barriers mode set to\nOwner Moderated\n:\n(For non-group connected sites) The user has site access permissions.\n(For group connected sites) The user must be a member of the Microsoft 365 group connected to the site.\nImplicit mode\nTo access SharePoint sites that use Information Barriers mode set to\nImplicit\n:\nYou're a member of the Microsoft 365 group connected to the site.\nIf you're not a member of the Microsoft 365 group connected to the site, you can't access the site.\nThe Information Barriers compliance assistant ensures the group membership is IB compliant.\nNote\nIf you enabled Information Barriers for SharePoint in your organization before March 15, 2022, see the\nEnable SharePoint and OneDrive Information Barriers\nsection in this article.\nExplicit mode\nTo access SharePoint sites that use segments and site's Information Barriers mode is\nExplicit\n:\nYour segment matches a segment that's associated with the site.\nAND\nYou have access permission to the site.\nNon-segment users can't access a site associated with segments. They see an error message.\nAllow apps running in app-only mode to access IB sites\nMany organizations use applications running in an app-only context in their organization. To allow these apps running in app-only mode to access IB protected sites, SharePoint admins can enable opt-in capability.\nImportant\nInformation Barriers policies might impact the applications accessing sites in app-only mode. We recommend you enable the policy and then test the experience for the apps used in your organization.\nTo enable applications running in app-only mode to access IB sites, run the following command:\nSet-SPOTenant -AppBypassInformationBarriers $true\nIf you enable Teams Meeting Recording or EDU Assignment application in your organization, run the following command to allow these applications to interact with IB protected sites:\nSet-SPOTenant -AppOnlyBypassPeoplePickerPolicies $true\nExample scenario\nThe following example illustrates three segments in an organization: HR, Sales, and Research. An information barrier policy blocks communication and collaboration between the Sales and Research segments. These segments are incompatible.\nWith SharePoint Information Barriers, a SharePoint Administrator or Global Administrator can associate segments to a site to prevent the site from being shared with or accessed by users outside the segments. You can associate up to 100 compatible segments with a site. You associate the segments at the site level (previously called site collection level). The Microsoft 365 group connected to the site is also associated with the site's segment.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nIn the previous example, the HR segment is compatible with both Sales and Research. However, because the Sales and Research segments are incompatible, you can't associate them with the same site.\nPrerequisites\nMake sure you meet the\nlicensing requirements for Information Barriers\n.\nCreate information barrier policies\nthat allow or block communication between the segments, and then set them to active. Create segments and define the users in each.\nWait 24 hours after configuring and activating your information barrier policies for the changes to propagate through your organization.\nComplete the steps in the following sections to enable and manage SharePoint and OneDrive Information Barriers in your organization.\nEnable SharePoint and OneDrive Information Barriers in your organization\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nSharePoint Administrators or Global Administrators can enable Information Barriers in SharePoint and OneDrive in your organization. Complete the following steps to enable Information Barriers for your organization:\nDownload\nand install the latest version of SharePoint Online Management Shell.\nConnect to SharePoint Online as a Global Administrator or\nSharePoint Administrator\nin Microsoft 365. To learn how, see\nGetting started with SharePoint Online Management Shell\n.\nRun the following command to enable Information Barriers in SharePoint and OneDrive:\nSet-SPOTenant -InformationBarriersSuspension $false\nWait for approximately 1 hour for the changes to take effect after you enable Information Barriers for SharePoint and OneDrive in your organization.\nNote\nIf you enabled Information Barriers for SharePoint in your organization before March 15, 2022, the default access and sharing control for Implicit mode for Microsoft Teams-connected sites are based on the segments associated with the site.\nTo enable Microsoft 365 group-membership based access and sharing control for all Implicit mode Teams-connected sites in your tenant, run the following command:\nSet-SPOTenant -IBImplicitGroupBased $true\nIf you installed a previous version of the SharePoint Online Management Shell, complete the following steps:\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nGo to\nAdd or remove programs\nand uninstall\nSharePoint Online Management Shell\n.\nNavigate to the Microsoft Download Center for the\nSharePoint Online Management Shell\n), select your language, and then select\nDownload\n.\nYou might be asked to choose between downloading a x64 and x86 .msi file. Download the x64 file if you're running the 64-bit version of Windows or the x86 file if you're running the 32-bit version of Windows. If you don't know which version you're running on your computer, see\nWhich version of Windows operating system am I running?\n.\nAfter the download is complete, run the installer file and follow the configuration steps in the setup workflow.\nConnect to SharePoint Online as a Global Administrator or\nSharePoint Administrator\nin Microsoft 365. To learn how, see\nGetting started with SharePoint Online Management Shell\n.\nRun the following command to enable Information Barriers in SharePoint and OneDrive:\nSet-SPOTenant -InformationBarriersSuspension $false\nWait for approximately 1 hour for the changes to take effect after you configure Information Barriers in SharePoint and OneDrive in your organization.\nNote\nIf you enabled Information Barriers for SharePoint in your organization before March 15, 2022, the default access and sharing control for Implicit mode for Microsoft Teams-connected sites are based on the segments associated with the site.\nTo enable Microsoft 365 group-membership based access and sharing control for all Implicit mode sites in your organization, run the following command:\nSet-SPOTenant -IBImplicitGroupBased $true\nNote\nIf you have Microsoft 365 Multi-Geo, run this command for each of your geo-locations.\nView and manage segments as an administrator\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nSharePoint Administrators or Global Administrators can view and manage segments on a SharePoint site. Your organization can have up to 5,000 segments, and users can be assigned to multiple segments.\nImportant\nSupport for 5,000 segments and assigning users to multiple segments is only available when your organization isn't in\nLegacy\nmode. Assigning users to multiple segments requires extra steps to change the Information Barriers mode for your organization. For more information, see\nUse multi-segment support in Information Barriers)\n.\nFor organizations in\nLegacy\nmode, the maximum number of segments supported is 250, and users are restricted to being assigned to only one segment. Organizations in\nLegacy\nmode are eligible to upgrade to the newest version of Information Barriers in the future. For more information, see the\nInformation Barriers roadmap\n.\nView and manage Information Barriers segments as follows:\n1. Use the SharePoint admin center to view and manage information segments\nTo view, edit, or remove information segments for a site, use\nActive sites\nin the SharePoint admin center\n.\nThe Segments column lists the first segment associated with the site and shows whether the site has other segments associated.\nLearn how to show or move this column\nTo view the complete list of segments associated with a site, select the site name to open the details panel, then select the\nSettings\ntab.\nTo edit the segments associated with the site, select\nEdit\n, add or remove segments, then select\nSave\n.\n2. Use SharePoint PowerShell to view and manage information segments on a site\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. Minimizing the number of users with the Global Administrator role helps improve security for your organization. Learn more about Microsoft Purview\nroles and permissions\n.\nConnect to the\nSecurity & Compliance Center PowerShell\nas a Global Administrator.\nRun the following command to get the list of segments and their GUIDs.\nGet-OrganizationSegment | ft Name, EXOSegmentID\nSave the list of segments.\nName\nEXOSegmentId\nSales\na9592060-c856-4301-b60f-bf9a04990d4d\nResearch\n27d20a85-1c1b-4af2-bf45-a41093b5d111\nHR\na17efb47-e3c9-4d85-a188-1cd59c83de32\nIf you didn't previously complete this step,\ndownload\nand install the latest SharePoint Online Management Shell. If you installed a previous version of the SharePoint Online Management Shell, follow the instructions in the\nEnable SharePoint and OneDrive Information Barriers in your organization\nsection in this article.\nConnect to SharePoint Online as a\nGlobal Administrator or SharePoint Administrator\nin Microsoft 365. To learn how, see\nGetting started with SharePoint Online Management Shell\n.\nRun the following command:\nSet-SPOSite -Identity <site URL> -AddInformationSegment <segment GUID>\nFor example:\nSet-SPOSite -Identity https://contoso.sharepoint.com/sites/ResearchTeamSite -AddInformationSegment 27d20a85-1c1b-4af2-bf45-a41093b5d111\nYou see an error message if you attempt to associate a segment that isn't compatible with the site's existing segments.\nNote\nWhen you add a segment to a site, the site's IB mode is automatically updated as\nExplicit\n.\nTo remove a segment from a site, run the following command:\nSet-SPOSite -Identity <site URL> -RemoveInformationSegment <segment GUID>\nFor example:\nSet-SPOSite -Identity https://contoso.sharepoint.com/sites/ResearchTeamSite -RemoveInformationSegment 27d20a85-1c1b-4af2-bf45-a41093b5d111\nNote\nWhen you remove all segments from a site, the site's IB mode is automatically updated to\nOpen\n.\nTo view the segments of a site, run the following command to return the GUIDs of any segments associated with the site.\nGet-SPOSite -Identity <site URL> | Select InformationSegment\n3. Use the SharePoint REST API to view and manage information segments on a site\nSharePoint includes a Representational State Transfer (REST) service that you can use to manage segments on a site. To access SharePoint resources and manage site segments by using REST, construct a RESTful HTTP request by using the OData standard. This request corresponds to the desired client object model application programming interface (API).\nFor more information about the SharePoint REST service, see\nGet to know the SharePoint REST service\n.\nView and manage IB modes as an administrator with SharePoint PowerShell\nTo view the IB mode of a site, run the following command:\nGet-SPOSite -Identity <site URL> | Select InformationBarriersMode\nOwner Moderated mode scenario\nYou want to allow a Sales and Research user to collaborate on a SharePoint site in the presence of HR user.\nOwner Moderated\nis a mode applicable to site (Teams-connected site, non-group connected sites) which allows incompatible segment users access to site. Only the site owner has the capability to invite incompatible segment users on this same site.\nTo update a site's mode to\nOwner Moderated\n, run the following PowerShell command:\nSet-SPOSite -Identity <siteurl> -InformationBarriersMode OwnerModerated\nYou can't set the Owner Moderated IB mode on a site with segments. Remove the segments first before setting IB mode as Owner Moderated. Users who have site access permissions can access an Owner Moderated site. Only the site owner can share an Owner Moderated site and its contents per their IB policy.\nAuditing\nYou can view audit events in the\nMicrosoft Purview portal\nto monitor information barrier activities. The system logs audit events for the following activities:\nEnabling Information Barriers for SharePoint and OneDrive\nApplying a segment to a site\nChanging the segment of a site\nRemoving the segment of a site\nApplying Information Barriers mode to a site\nChanging Information Barriers mode of a site\nDisabling Information Barriers for SharePoint and OneDrive\nFor more information about SharePoint segment auditing in Office 365, see\nSearch the audit log in the Microsoft Purview portal\n.\nSite creation and management by site owners\nWhen a segmented user creates a SharePoint site, the site associates with the user's segment and the site's Information Barriers mode automatically sets to\nExplicit\n.\nSite owners can add more segments to a SharePoint site that already has segments with the site's mode set as\nExplicit\n. Site owners can't remove added segments from sites. SharePoint Administrators need to remove added segments in your organization if needed.\nWhen a non-segmented user creates a SharePoint site, the site doesn't associate with any segment and the site's Information Barriers mode automatically sets to\nOpen\n.\nWhen a SharePoint Administrator creates a SharePoint site from the\nSharePoint admin center\n, the site doesn't associate with any segment and the site's IB mode sets to\nOpen\n.\nTo help site owners add a segment to a site, share the\nAssociate information segments with SharePoint sites\narticle with your SharePoint site owners.\nMicrosoft Teams sites\nWhen you create a team in Microsoft Teams, you also automatically create a SharePoint site for the team's files. To protect the Microsoft Teams sites with Information Barriers control, you can enable Information Barriers in SharePoint for your tenant.\nWithin 24 hours, the site's Information Barriers mode is automatically set as\nImplicit\nand segments associated with the team's members are associated with the site.\nMicrosoft Teams sites with the information barrier mode as\nImplicit\nhave site access and sharing based on Microsoft 365 group membership.\nFor example, users have access to the Microsoft Teams site if they're members of the Microsoft 365 group connected to the site. The Microsoft 365 group connected to the Team is IB compliant.\nNote\nIf you enabled Information Barriers for SharePoint in your organization before March 15, 2022, the Teams-connected site's access and sharing is based on the segments of the site. For example:\nThe site and its content can be shared with user whose segment matches that of the site.\nThe site and its content can be accessed by a user if they have same segment as that of the site and have site access permissions.\nTo enable Microsoft 365 group membership-based access and sharing control for all\nImplicit\nmode sites in your organization, run the following command as a SharePoint Administrator:\nSet-SPOTenant -IBImplicitGroupBased $true\nPrivate channel and Information Barriers\nWhen you enable SharePoint Information Barriers in your organization, any new private channel site automatically inherits its parent Microsoft Team's IB mode within 24 hours. The mode for a private channel is assigned as follows:\nParent Team's IB mode\nPrivate channel site's IB mode\nOpen\nOpen\nImplicit or Owner Moderated\nImplicit\nPrivate channel site access and sharing is governed by its IB mode:\nPrivate channel site with\nOpen\nInformation Barriers mode\nAccess is allowed to anyone who has site access permissions\nSharing links are allowed per the site's existing sharing policy\nPeople picker allows discoverability of user per the sharer's IB policy\nPrivate channel site with\nImplicit\nInformation Barriers mode\nAccess is allowed to user who is currently a member of the private channel\nSharing is allowed using\nPeople with existing access link\nPrivate channel sites already configured in your organization have their Information Barriers mode set as\nOpen\n. To configure existing private channel sites to\nImplicit\nmode, run the following cmdlet in SharePoint PowerShell module:\nSet-Sposite -Identity <site URL> -InformationBarriersMode Implicit\nLearn more about managing\nMicrosoft Teams connected teams sites\n.\nSearch\nUsers see search results from:\nSegment associated sites\n: When the site's segment matches the user's segment and the user has site access permission. For example, a site with\nExplicit\nmode.\nNon-segmented sites\n: When the user has existing access to the content or site. For example, sites with\nOpen\n,\nOwner Moderated\nor\nImplicit\nmode. When the user selects the search result to open the content in the site, the user is denied access if they don't match the site's IB policy.\nTenant wide search and Copilot experience\nUsers experience is as follows:\nSegment associated sites\n: When the site's segment matches the user's segment and the user has site access permission. For example, a site with\nExplicit\nmode.\nOpen mode sites:\nWhen the user has existing access to the content or site.\nImplicit and Owner moderated mode sites:\nWhen the user has existing access to the content or site.\nIf the user had access to the site and content prior to the policy application, they would continue to see the site and its contents in search and Copilot results. However, when attempting to open the content, they will be denied access if they do not comply with the site's IB policy.\nEffects of changes to user segments\nIf a SharePoint site owner or site member's segment changes, they continue to have access to the site or content per the site's IB mode:\nOpen mode\n: User can access the site if they have existing site access permissions.\nOwner Moderated\n: User can access the site if they have existing site access permissions.\nImplicit Mode\n: If the user is a member of the Microsoft 365 group, they continue to have access to the site.\nExplicit Mode\n: If the user's new segment matches the site's segment and user has site access permissions, they continue to have access to the site.\nEffects of changes to existing information barrier policies\nIf a compliance administrator changes an existing IB policy, the change might impact the compatibility of the segments associated with a site (in\nExplicit\nor\nImplicit\nmode*).\nFor example, segments that were once compatible might no longer be compatible.\nWith Information Barriers policy compliance report, the SharePoint Administrator can view the list of sites where segments are no longer compatible. For more information, see\nLearn how to create an Information Barriers policy compliance report in PowerShell\n.\nTo manage out of compliance sites:\nIn\nExplicit\nmode, a SharePoint Administrator must change the associated segments to bring them in to IB compliance.\nIn\nImplicit\nmode, a SharePoint Administrator can't manage segments directly. We recommend the Teams admin to manage the Team's membership to bring the Teams membership roster and segments in to IB compliance.\nHow to suspend SharePoint and OneDrive Information Barriers in your organization\nIf your organization wants to temporarily suspend Information Barriers on SharePoint, use SharePoint Online Management Shell and the\nSet-Spotenant\ncmdlet.\nTo suspend Information Barriers, run the following command:\nSet-SPOTenant -InformationBarriersSuspension $true\nNote\nIf you have Microsoft 365 Multi-Geo, run this command for each of your geo-locations.\nAllow sharing of Open mode sites with mail-enabled security groups\nIB supports an opt-in capability available in the\nSharePoint PowerShell module\nfor sites in\nOpen\nmode to be shared with\nmail-enabled security groups\nfor site permissions, sharing, and audience targeting. This capability is only supported in\nOpen\nmode sites. SharePoint admins can enable this support in your organization. We recommend you ensure the security group membership is IB compliant.\nBefore enabling group support, verify that you meet the following prerequisites:\nYour organization has only IB\nBlock\npolicies\nYour organization is enabled for SharePoint IB (see\nthis section\nin this article).\nTo configure mail-enabled security group support in\nOpen\nmode sites, run the following command:\nSet-SPOTenant -ShowPeoplePickerGroupSuggestionsForIB $true\nResources\nInformation Barriers in Microsoft Teams\nInformation Barriers in OneDrive\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Information Barriers",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/insights-on-sharepoint-agents": {
      "content_hash": "sha256:d6e1ac5ec2c02e9d57e387e90502d8a509aa6016b666864667dc1e079b692398",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nInsights report on agents in SharePoint\nFeedback\nSummarize this article for me\nInsights report on agents in SharePoint provides SharePoint Administrators with rich information on the recently created agents across all SharePoint sites and OneDrive sites within their organization. This report provides admins with the ability to learn about the sites with the highest number of agents created. Using this report, SharePoint admins can further govern and maintain the integrity of the content used by agents as grounding data.\nThe insights report is based on the Microsoft audit data logged for the agents, created in SharePoint, through the FileCreated and FileRenamed events.\nYou can generate and manage agent Insights report in SharePoint Admin Center or with SharePoint Online Management Shell.\nWhat do you need to access agent Insights report\nWhat are the license requirements?\nYour organization needs to have the right license and meet certain administrative permissions or roles to use the feature described in this article.\nFirst, your organization must have one of the following base licenses:\nOffice 365 E3, E5, or A5\nMicrosoft 365 E1, E3, E5, or A5\nAdditionally, you need to have\nMicrosoft 365 Copilot license\n.\nNote\nAt least one user in your organization must be assigned a Copilot license (this user doesn't need to be a SharePoint administrator).\nIf your organization has a Copilot license and at least one person in your organization is assigned a Copilot license, SharePoint administrators automatically gain access to the\nSharePoint Advanced Management features needed for Copilot deployment\n.\nAdministrator requirements\nYou must be a\nSharePoint administrator\nor have equivalent permissions.\nImportant\nIf you don't have a Microsoft SharePoint Advanced Management license, you are asked to enable data collection, so that the product starts to collect the relevant audit data to build this report. Once enabled, the reports can be generated 24 hours later and contain data from the point of collection. Data is stored for 28 days. If no reports are generated at least once in three months, data collection is paused and should be enabled again. To enable data collection for these reports, refer to\nthe Data collection for Insights report on agents created in SharePoint section in this article\n.\nHow to access agent Insights report in SharePoint Admin Center\nSign in to the\nSharePoint admin center\nwith the\nSharePoint administrator\ncredentials for your organization.\nIn the left pane, expand\nReports\nand then select\nAgent Insights\n.\nHow to create reports in SharePoint Admin Center\nWith permissions of a SharePoint Administrator, you can create the report by selecting\nCreate a report\n.\nProvide the Report name and under Report duration, specify the time frame for the report.\nSelect\nCreate and run\n.\nNote\nYou can create a report for the past 1, 7, 14, or 28 days.\nView report status in SharePoint Admin Center\nTo check if a report is ready or when it was last updated, see theâ¯\nStatus\nâ¯column.\nView report in SharePoint Admin Center\nWhen a report is ready, select it to view the data. You can view the top 100 records hosting the highest number of agents. You can search for sites or filter on the site template, and governance policies.\nApply Content governance policies in SharePoint Admin Center\nYou can apply content governance policies on the sites from the insights report. The policies available are\nRestrict site access policy\nand\nRestrict Content Discovery policy\n.\nNote\nAfter a policy is applied to the site from the insights report, the policy status on the existing report won't be updated. To view the updated status of the policy on the site, select the policy to view the latest status or access the Active site panel and review the site settings.\nAgent Insights reports in SharePoint Online Management Shell\nYou can generate and manage agent Insights reports using SharePoint Online Management Shell.\nIf you haven't,\ndownload\nand install the latest version of SharePoint Online Management Shell.\nConnect to SharePoint Online as at least aâ¯\nSharePoint administrator\nin Microsoft 365. For more information, see\nGetting started with SharePoint Online Management Shell\n.\nTo generate and view these reports, ensure the organization has the SharePoint Advanced Management add-on SKU or Microsoft 365 Copilot license.\nWith permissions of at least a SharePoint administrator, you can generate and view the insights report using the following commands:\nTo generate report for a one-day default report duration, run the command:\nStart-SPOCopilotAgentInsightsReport\nTo generate a report for any other duration (7, 14 or 28 days), run the command:\nStart-SPOCopilotAgentInsightsReport -ReportPeriodInDays\nFor example, to generate report for the past 28 days, run the command:\nStart-SPOCopilotAgentInsightsReport -ReportPeriodInDays <28>\nTo check the status of all active and available reports, run the command:\nGet-SPOCopilotAgentInsightsReport\nTo check the status of a specific report, run the command:\nGet-SPOCopilotAgentInsightsReport âReportId\nTo download and view the report, run the command:\nGet-SPOCopilotAgentInsightsReport âReportId -Action Download\nNote\nPowerShell displays up to 100 records, but downloaded reports can contain up to 1 million records.\nGet-SPOCopilotAgentInsightsReport âReportId -Action View\nTo view further detailed reports, the following options are available:\na. CopilotAgentsOnSites: Provides the name of all the agents currently available on all sites. This report contains up to 1,000,000 records.\nNote\nThe default value for the\n-Content\nparameter is\nCopilotAgentsOnSites\n.\nGet-SPOCopilotAgentInsightsReport âReportId -Content CopilotAgentsOnSites\nb. TopSites: Provides a list of 100 sites with the number of agents available on each site.\nGet-SPOCopilotAgentInsightsReport âReportId -Content TopSites\nc. SiteDistribution: Provides the summarized view of agents across all types of sites like Communication sites, Microsoft 365 group connected sites, OneDrive site, etc.\nGet-SPOCopilotAgentInsightsReport âReportId -Content SiteDistribution\nData collection for insights report on agents in SharePoint\nIf you don't have a Microsoft SharePoint Advanced Management license, you are asked to enable data collection. This section explains how to enable and check status for data collection for the Insights report on agents in SharePoint.\nEnable data collection\nThis PowerShell command starts collecting audit data for reports on activities from the last 28 days.\nStart-SPOAuditDataCollectionForActivityInsights\nDisabling data collection\nThis PowerShell command stops collecting audit data for reports on activities from the last 28 days.\nStop-SPOAuditDataCollectionForActivityInsights\nChecking the data collection status\nOnce data collection is enabled, the reports can be generated after 24 hours. To check whether reports can be generated, use the PowerShell commandâ¯Get-SPOAuditDataCollectionStatusForActivityInsights. The command returns the current data collection status, which can be \"NotInitiated\", \"InProgress\", \"Paused\". Reports can be generated when the status is \"InProgress\".\nGet-SPOAuditDataCollectionStatusForActivityInsights\nKnown experiences with agent Insights reports in SharePoint\nThe following are some known experiences with agent Insights reports generated in SharePoint Admin Center or using SharePoint Online Management Shell:\nA report can be rerun only after 24 hours since the last report generated.\nIn large tenants, it might take up to 48 hours for the data to be available.\nOnly one report can exist for each report range value (1, 7, 14, or 28 days). This means you can see a maximum of four reports at a given point.\nThe newly generated report replaces the previously created report with the same date range. To preserve the previously created report, download the report first before creating a new report for the same date range.\nThese reports are generated using Microsoft 365 unified audit data and might not cover all audit events.\nRelated articles\nRestrict SharePoint site access with Microsoft 365 groups and Microsoft Entra security groups\nRestrict discovery of SharePoint sites and content\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Agent Insights",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/control-lists": {
      "content_hash": "sha256:c200bb5bded136382404d0fa4601bb90ce83fee0cad761248e6606014e1e9d17",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nControl settings for Microsoft Lists\nFeedback\nSummarize this article for me\nAs at least a\nSharePoint Administrator\nin Microsoft 365, you can control settings for Microsoft Lists. You can:\nDisable the creation of personal lists (prevent users from saving new lists to \"My lists\").\nDisable built-in list templates that aren't relevant for your organization.\nYou control both of these settings by using Microsoft PowerShell.\nDisable creation of personal lists\nIf you change this setting, when users create a list, they must select a SharePoint site for saving the list. The \"Save to\" setting doesn't include the \"My lists\" option.\nDefault\nPersonal list creation disabled\nDownload the latest SharePoint Online Management Shell\n.\nNote\nIf you installed a previous version of the SharePoint Online Management Shell, go to Add or remove programs and uninstall \"SharePoint Online Management Shell.\"\nConnect to SharePoint as at least a\nSharePoint Administrator\nin Microsoft 365. To learn how, see\nGetting started with SharePoint Online Management Shell\n.\nRun the following command:\nSet-SPOTenant -DisablePersonalListCreation $true\nTo re-enable the creation of personal lists, set the parameter to\n$false\n.\nDisable built-in list templates\nDisabling these templates removes them from all places users create lists (the Lists app, Microsoft Teams, and SharePoint sites).\nDefault\nBuilt-in list templates disabled\nSome templates disabled\nAll templates disabled\nDownload the latest SharePoint Online Management Shell\n.\nNote\nIf you installed a previous version of the SharePoint Online Management Shell, go to Add or remove programs and uninstall \"SharePoint Online Management Shell.\"\nConnect to SharePoint as at least a\nSharePoint Administrator\nin Microsoft 365. To learn how, see\nGetting started with SharePoint Online Management Shell\n.\nRun the following command:\nSet-SPOTenant -DisableModernListTemplateIds '<template ID>'\nWhere the template ID is:\nIssue tracker: 'C147E310-FFB3-0CDF-B9A3-F427EE0FF1CE'\nEmployee onboarding: 'D4C4DAA7-1A90-00C6-8D20-242ACB0FF1CE'\nEvent itinerary: '3465A758-99E6-048B-AB94-7E24CA0FF1CE'\nAsset manager: 'D2EDA86E-6F3C-0700-BE3B-A408F10FF1CE'\nRecruitment tracker: '3A7C53BE-A128-0FF9-9F97-7B6F700FF1CE'\nTravel requests: 'C51CF376-87CF-0E8F-97FF-546BC60FF1CE'\nWork progress tracker: 'B117A022-9F8B-002D-BDA8-FA266F0FF1CE'\nContent scheduler: '9A429811-2AB5-07BC-B5A0-2DE9590FF1CE'\nIncidents: 'E3BEEF0B-B3B5-0698-ABB2-6A8E910FF1CE'\nPatient care coordination: '0134C13D-E537-065B-97D1-6BC46D0FF1CE'\nLoans: '7C920B56-2D7A-02DA-94B2-57B46E0FF1CE'\nGift ideas: '008F8143-9644-0238-B4B5-C03E4F0FF1CE'\nRecipe tracker: 'A1755E7D-8E3A-4141-89FC-6C77EB0FF1CE'\nExpense tracker: '96D6DBE5-D7C3-030A-867A-0B72EB0FF1CE'\nTravel requests with approvals: '4EB20749-6360-417C-83DD-06135C0FF1CE'\nContent scheduler with approvals: 'C381BD64-C1A1-4D9E-BE9C-0571900FF1CE'\nPlaylist: '3A867B4A-7429-0E1A-B02E-BF4B240FF1CE'\nResume repository: 'F6AEF3EE-EC97-433C-A662-E9170B0FF1CE'\nTo re-enable a built-in template, use the parameter\nEnableModernListTemplateIds\n.\nDisable extra features on a built-in template\nSome built-in list templates include extra features such as automations and custom formatting. If you wish to keep only the base schema of a built-in list template but not the rest of its features included in that template:\nCreate a list from the built-in list template.\nCreate a custom list template\nbased off of that list. The custom list template doesn't include any extra features by default.\nDisable the original built-in list template\n.\nNote\nUsers in your organization see the custom list template on the\nFrom your organization\ntab rather than on the\nFrom Microsoft\ntab.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "List Management",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/create-training-site": {
      "content_hash": "sha256:912a0784a2796adae94435efdc3180b0a21e69ebcc1de16919d06bcf57f0ef49",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGuided walkthrough: Creating a Training site for your organization\nFeedback\nSummarize this article for me\nIn this article, we show you elements of an example Training site to inspire you, and help you learn how to create similar sites for your own organization. This example site provides info about a specific event and guides the user toward learning and registration. It relies on visuals to engage and motivate the visitor.\nFirst, if you haven't already created a Communication site, check out the\nCreate your site\nsection in this article. If you need to learn how to edit and publish the page on your site, check out the section\nEdit, work with sections and web parts, and publish\nin this article.\nOnce you have your created your site and know how to edit pages, you can use the following guidance to add the elements shown.\nExample Training site\nImage of the homepage\nCustomization instructions\n1. Logo and site classification\nCustomize your logo and classify your site.\nLearn how\n2. Create impact\nUse the hero web part to visually communicate your value.\nLearn how\n3. Guide users to key action\nLead visitors to register or discover more.\nLearn how\n4. Describe the event\nUse text to describe the \"what\" and \"why\" of the event.\nLearn how\n5. Use images with links\nIncrease visibility and link to detailed agenda pages.\nLearn how\n6. Highlight detailed information\nImages can define areas of important information.\nLearn how\n7. Show event dates\nProvide an event calendar so users can plan their schedules.\nLearn how\n8. Add a map\nUse a map to help users get to where they need to be.\nLearn how\n9. Provide on-page registration\nAdd a form for easy registration.\nLearn how\nCreate your site\nTo make a site like the one shown here, you create a\nCommunication site\n. To do this, select\nCreate site\nfrom the SharePoint start page (or, if you're going to associate this site with a Hub site, navigate to the hub site and select\nCreate site\nthere so that the communication site is automatically associated with that hub site).\nNext, choose\nCommunication site\n, and then the\nTopic\nlayout. Fill out your site name, description, and other information, and select\nFinish\n. Then you get a template with the same type of layout as the example in this article.\nFor more information, see\nCreate a communication site in SharePoint Online\n.\nBack to top\nLogo and site classification\nIn this example, the header area doesn't contain any navigation because it's a \"stand-alone\" page. However, the header area does contain a custom logo, and shows a label indicating that the site is classified as \"Internal Only.\" Site classification uses values such as internal, confidential, high business impact, low business impact, and so on. These values can pertain to sensitivity of information or to the life cycle of information.\nTo learn how to change the logo and classify your site, see\nManage your SharePoint site settings\n.\nBack to top\nManage sections and web parts\nStart editing by clicking\nEdit\non the top right of the page.\nWhile editing, on the left, below the header your drafts can be saved for later or discarded.\nThe + symbol before or after a section will add a section using one of several layouts.\nSections make up your page, and are you place one or more web parts. When you edit the page, each section shows controls to edit the layout, move, or delete the sections. For information on working with sections, see\nAdd or remove sections and columns on a page\n.\nSelect the plus symbol\nin a section, which may appear before or after a web part in a section, to see the many types of web parts available. For more information on all web parts, see\nUsing web parts on SharePoint pages\n.\nWeb parts may be edited, moved, or deleted within sections. The\nEdit web part\nicon opens detailed controls unique to each web part type.\nWhen your page updates are ready, select\nPublish\nto make them visible to your entire organization.\nTip\nTo manage all of your pages on the site, select\nPages\non the top menu.\nFor more information on using pages, see\nCreate and use modern pages on a SharePoint site\n.\nBack to top\nCreate impact with the Hero web part\nLet your visitors know the focus of your Workshop with the Hero web part. The layout used in this example is\nTwo tiles\n.\nHero layout: Tiles or Layers\n:\nEditing the web part presents layout options. The\nTiles\noption presents layouts for between one and five tiles. The\nLayers\noption sets each image as a layer with the image next to the title. Up to five layers are possible allowing one web part to create an entire page.\nEach tile can be edited\n:\nUse the\nMove item\ncontrol on the left to rearrange the tiles within the Hero web part. Controls on the right allow you to\nEdit details\nadjusting the text and image used,\nSet focal point\nfor the hover animation, plus\nZoom in\nand\nZoom out\nof the image.\nIn this example, the Hero web part is in a full-width section.\nFor more information on using the Hero web part, see Use the\nHero web part\n.\nBack to top\nShow event dates\nThe Events web part automatically displays event information. The events shown are controlled by filters for\nSource\n,\nEvent list\n,\nCategory\n, and\nDate range\n. Events can be shown with detailed summaries in\nFilmstrip\nview or in a\nCompact\nview.\nIn this Workshop site example, this web part uses the\nFilmstrip\nlayout.\nFor more information on using the Events web part, see\nUse the Events web part\n.\nBack to top\nDescribe the event with the Text web part\nThe leadership drop quote and the Monthly Q&A descriptions use the Text web part. This web part allows basic text formatting for creating fixed sections of formatted text.\nWhen editing text, this web part offers basic formatting tools to set styles and add enhancements like\nbold\nand\nitalics\n. Selecting the ... control at the right end of the formatting toolbar offers more options to the right of the web part.\nIn this Workshop site example shown before, the web part is in a one-column section.\nFor more information on using the Text web part, see\nAdd text and tables to your page with the Text web part\n.\nBack to top\nGuide users to key actions with Quick links\nThe Quick links web part offers several easy to use menu formats for listing links to other pages or sites.\nIn this site example, the web part uses the\nButton\nlayout for quick and easy reference.\nFor more information on using the Quick Links web part, see\nUse the Quick Links web part\n.\nBack to top\nUse images with links\nThe Image web part places a fixed image on the page. Images can be photographs, diagrams, or even used to bring emphasis to text. Captions and alt-text keep images accessible.\nFor more information on using the Image web part, see\nUse the Image web part\n.\nBack to top\nAdd maps with the Bing Maps web part\nThe Bing Maps web part offers an easy visual map reference and quick link to allow visitors to plan their route to your workshop.\nFor more information on using the Bing Maps web part, see\nUse the Bing Maps web part\n.\nBack to top\nAdd forms for registration\nIf you created a form for registration using\nMicrosoft Forms\n, you can place that form directly on the page with the Microsoft Forms web part. It's an easy way for attendees to fill out their information, and an easy way for you to collect it.\nFor more information on using the Microsoft Forms web part, see\nUse the Microsoft Forms web part\n.\nBack to top\nWant more?\nGet inspired with more examples in the\nSharePoint Look Book\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Training Sites",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/sharepoint/governance/versioning-content-approval-and-check-out-planning": {
      "content_hash": "sha256:e389bce8ecfa4b6af035e14c12ce0d1f95083844137db7d3238ca085fd57be3f",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nPlan document versioning, content approval, and check-out controls in SharePointServer\nFeedback\nSummarize this article for me\nAPPLIES TO:\n2013\n2016\n2019\nSubscription Edition\nSharePoint in Microsoft 365\nThis article describes how to plan to use versioning, content approval, and check-out in SharePoint Server to control document versions throughout their life cycle.\nAbout versioning, content approval, and check-outs\nSharePoint Server includes the following features that can help you control documents in a document library:\nVersioning is the method by which successive iterations of a document are numbered and saved.\nContent approval is the method by which site members who have approver permissions control the publication of content.\nCheck-out and Check-in are the methods by which users can better control when a new version of a document is created and also comment on changes that they made when they check a document in.\nYou configure settings for the content governance features discussed in this article in document libraries. To share these settings across libraries in your solution, you can create document library templates that include your content governance settings. This makes sure that new libraries will reflect your content governance decisions.\nFor more information about versioning, see\nEnable and configure versioning for a list or library\n.\nPlan versioning\nThe default versioning control for a document library depends on the site collection template. However, you can configure versioning control for a document library depending on your particular requirements. Each document library can have a different versioning control that best suits the kind of documents in the library. SharePoint Server has three versioning options:\nNo versioning\nSpecifies that no earlier versions of documents are saved. When versioning is not being used, earlier versions of documents are not retrievable, and document history is also not retained because comments that accompany each iteration of a document are not saved. Use this option on document libraries that contain unimportant content or content that will never change.\nCreate major versions\nSpecifies that numbered versions of documents are retained by using a simple versioning scheme (such as 1, 2, 3). To control the effect on storage space, you can specify how many earlier versions to keep, counting back from the current version.\nIn major versioning, every time that a new version of a document is saved, all users who have permissions to the document library will be able to view the content. Use this option when you do not want to differentiate between draft versions of documents and published versions. For example, in a document library that is used by a workgroup in an organization, major versioning is a good choice if everyone on the team must be able to view all iterations of each document.\nCreate major and minor (draft) versions\nSpecifies that numbered versions of documents are retained by using a major and minor versioning scheme (such as 1.0, 1.1, 1.2, 2.0, 2.1). Versions ending in\n.0\nare major versions and versions ending with non-zero extensions are minor versions. Previous major and minor versions of documents are saved together with current versions. To control the effect on storage space, you can specify how many previous major versions to keep, counting back from the current version. You can also specify how many major versions being kept should include their respective minor versions. For example, if you specify that minor versions should be kept for two major versions and the current major version is 4.0, then all minor versions starting at 3.1 will be kept.\nIn major and minor versioning, any user who has read permissions can view major versions of documents. You can specify which users can also view minor versions. Typically, we recommend that you grant permissions to view and work with minor versions to the users who can edit items, and restrict users who have read permissions to viewing only major versions.\nUse major and minor versioning when you want to differentiate between published content that can be viewed by an audience and draft content that is not yet ready for publication. For example, on a human resources Web site that describes organizational benefits, use major and minor versioning to restrict employees' access to benefits descriptions while the descriptions are being revised.\nPlan content approval\nUse content approval to formalize and control making content available to an audience. For example, an enterprise that publishes content as one of its products or services might require a legal review and approval before publishing the content.\nA document draft awaiting content approval is in the Pending status. When an approver reviews the document and approves the content, it becomes available for viewing by users who have read permissions. A document library owner can enable content approval for a document library and, optionally, can associate a workflow with the library to run the approval process.\nThe way that documents are submitted for approval varies depending on the versioning settings in the document library:\nNo versioning\nIf versioning is not being used and changes to a document are saved, the document's status becomes Pending. SharePoint Server keeps the earlier version of the document so that users who have read permissions can still view it. After the pending changes are approved, the new version of the document is made available for viewing by users who have read permissions and the earlier version is not retained.\nIf versioning is not being used and a new document is uploaded to the document library, it is added to the library in the Pending status and is not viewable by users who have read permissions until it is approved.\nCreate major versions\nIf major versioning is being used and changes to a document are saved, the document's status becomes Pending and the previous major version of the document is made available for viewing by users who have read permissions. After changes to the document are approved, a new major version of the document is created and made available to users who have read permissions, and the previous major version is saved to the document's history list.\nIf major versioning is being used and a new document is uploaded to the document library, it is added to the library in the Pending status and is not viewable by users who have read permissions until it is approved as version 1.\nCreate major and minor (draft) versions\nIf major and minor versioning is being used and changes to a document are saved, the author has the choice of saving a new minor version of the document as a draft or creating a new major version, which changes the document's status to Pending. After the changes to the document are approved, a new major version of the document is created and made available to users who have read permissions. In major and minor versioning, both major and minor versions of documents are kept in a document's history list.\nIf major and minor versioning is being used and a new document is uploaded to the document library, it can be added to the library either in the Draft status as version 0.1 or the author can immediately request approval. In this case, the document's status becomes Pending.\nPlan check-out and check-in\nYou can require users to check out documents from a document library before they edit the documents. The benefits of requiring check-out and check-in include the following:\nBetter control of when document versions are created. When a document is checked out, the author can save the document without checking it in. Other users of the document library will be unable to see these changes, and a new version is not created. A new version (visible to other users) is only created when an author checks in a document. This gives the author more flexibility and control.\nBetter capture of metadata. When a document is checked in, the author can write comments that describe the changes that were made to the document. This creates an ongoing historical record of the changes that were made to the document.\nIf your solution requires users to check in and check out documents to edit them, you can use features in Office client applications that support these actions. Users can check out documents, undo check-outs, and check in documents from Office client applications.\nWhen a document is checked out, it is locked for exclusive editing by the user. When the user saves edits to this file, the changes are uploaded and saved to the server. The changes are private to the user and not visible to others. When the user is ready to check in the document, the latest changes are made visible to others and published.\nFrom Office client applications, users can also choose to leave checked-out documents on the server by changing content editing options.\nNote\nYou should not check out a document when you use the co-authoring functionality.\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Versioning",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/create-retention-policies#retaining-content-thats-in-sharepoint-sites": {
      "content_hash": "sha256:7d5500d7789e4372f72cbeb649a3c4c1c6f9772fc675aac3a3cff4f655ccf1ad",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate and configure retention policies\nFeedback\nSummarize this article for me\nMicrosoft 365 licensing guidance for security & compliance\n.\nUse a retention policy to manage the data for your organization by deciding proactively whether to retain content, delete content, or retain and then delete the content.\nA retention policy lets you do this very efficiently by assigning the same retention settings at the container level to be automatically inherited by content in that container. For example, all items in SharePoint sites, all email messages in users' Exchange mailboxes, all channel messages for teams that are used with Microsoft Teams. If you're not sure whether to use a retention policy at the container level or a retention label at the item level, see\nRetention policies and retention labels\n.\nFor more information about retention policies and how retention works in Microsoft 365, see\nLearn about retention policies and retention labels\n.\nNote\nThe information on this page is for compliance administrators. If you are not an administrator and want to understand how retention policies have been configured for the apps that you use, contact your help desk, IT department, or administrator. If you're seeing messages about retention policies in Teams chats and channel messages, you might find it helpful to review\nTeams messages about retention policies\n.\nBefore you begin\nTo make sure you have permissions to create and edit retention policies, see the\npermissions information for data lifecycle management\n.\nDecide before you create your retention policy whether it will be\nadaptive\nor\nstatic\n. For more information, see\nAdaptive or static policy scopes for retention\n. If you decide to use an adaptive policy, you must create one or more adaptive scopes before you create your retention policy, and then select them during the create retention policy process. For instructions, see\nConfiguration information for adaptive scopes\n.\nTo retain prompts and responses for AI apps other than Microsoft 365 Copilot and Copilot Studio, you must first have a collection policy for these AI apps, and that policy includes the setting to capture content. For more information, see\nCollection Policies solution overview\n.\nIf you're creating a retention policy for Teams and use\nprivate channels\n, make sure you're aware of the\nmigration of private channel messages in 2025\nso you know whether to select\nTeams private channel messages\nor\nTeams channel messages\nas the location.\nCreate and configure a retention policy\nAlthough a retention policy can support multiple services that are identified as \"locations\" in the retention policy, you can't create a single retention policy that includes all the supported locations:\nExchange mailboxes\nSharePoint sites\nor\nSharePoint classic and communication sites\nOneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nExchange public folders\nTeams channel messages\nTeams chats\nTeams private channel messages\n(applicable\npre-migration\nonly)\nMicrosoft Copilot experiences\nEnterprise AI apps\nOther AI apps\nViva Engage community messages\nViva Engage user messages\nIf you select the Teams or Viva Engage locations when you create a retention policy, the other locations are automatically excluded. This means that the instructions to follow depend on whether you need to include the Teams or Viva Engage locations.\nNote\nWhen you use adaptive policies instead of static policies, you can configure a single retention policy to include both Teams and Viva Engage locations. This isn't the case for static policies where Teams and Viva Engage locations require their own retention policy.\nWhen you've more than one retention policy, and when you also use retention labels, see\nThe principles of retention, or what takes precedence?\nto understand the outcome when multiple retention settings apply to the same content.\nSelect the tab for instructions to create a retention policy for Teams, Copilots, AI apps, Viva Engage, or the other supported services (Exchange, SharePoint, OneDrive, Microsoft 365 Groups, Skype for Business):\nRetention policy for Teams & AI apps\nRetention policy for Viva Engage\nRetention policy for all other services\nNote\nFor AI apps other than Microsoft 365 Copilot and Copilot Studio, see\nBefore you begin\nabout the prerequisite of collection policies.\nRetention policies for Teams support\nshared channels\n. When you configure retention settings for the\nTeams channel message\nlocation, if a team has any shared channels, they inherit retention settings from their parent team.\nRetention policies also support newly created call data records, which are system-generated messages that contain\nmetadata for meetings and calls\n. All call data records are always included with the\nTeams chats\nlocation, even call data records for Teams channel messages and Teams private channel messages.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto start the\nCreate retention policy\nconfiguration, and name your new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nTeams chats\nbut not\nTeams channel messages\n.\nIf you chose\nStatic\n: On the\nChoose locations to apply the policy\npage, select one or more locations:\nTeams channel message\n: Messages from standard and shared channel chats, and standard and shared channel meetings. Includes messages from private channel chats and private channel meetings\npost-migration\nonly.\nTeams chats\n: For Teams, messages from private 1:1 chats, group chats, meeting chats, and chat with yourself.\nTeams private channel messages\n: Applicable\npre-migration\nonly. Messages from private channel chats and private channel meetings. If you select this option, you can't select the other Teams locations in the same retention policy.\nMicrosoft Copilot experiences\n: For built-in and custom Copilot experiences, all user prompts responses. Includes Microsoft 365 Copilot, Security Copilot, Copilot in Fabric, Copilot Studio.\nEnterprise AI apps\n: For non-Copilot Enterprise AI apps onboarded or connected to your org using methods like Entra registration or data connectors, all user prompts and responses. Includes Entra-registered AI apps, ChatGPT Enterprise, Microsoft Foundry.\nOther AI Apps\n: For other supported AI apps, all user prompts and responses. includes ChatGPT, Google Gemini, Microsoft Bing, DeepSeek.\nBy default,\nall teams and all users are selected\n, but you can refine this by selecting the\nChoose\nand\nExclude\noptions\n.\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\n.\nComplete the configuration and save your settings.\nFor guidance when to use retention policies for Teams and understand the end user experience, see\nManage retention policies for Microsoft Teams\nfrom the Teams documentation.\nFor technical details about how retention works for Teams and Copilot data, including what elements of messages are supported for retention and timing information with example walkthroughs, see\nLearn about retention for Microsoft Teams\nand\nLearn about retention for Copilot\n.\nKnown configuration issues for Teams retention policies\nAlthough you can select the option to start the retention period when items were last modified, the value of\nWhen items were created\nis always used. For messages that are edited, a copy of the original message is saved with its original timestamp to identify when this pre-edited message was created, and the post-edited message has a newer timestamp.\nWhen you select\nEdit\nfor the Teams chats location, you might see guests and non-mailbox users. Retention policies aren't designed for these users, so don't select them.\nTo include newly created call data records for Teams channel messages and Teams private channel messages, you must select the\nTeams chats\nlocation, instead of the\nTeams channel messages\nand\nTeams private channel messages\nlocations.\nAdditional retention policy needed to support Teams\nTeams is more than just chats and channel messages. If you have teams that were created from a Microsoft 365 group (formerly Office 365 group), you should additionally configure a retention policy that includes that Microsoft 365 group by using the\nMicrosoft 365 Group mailboxes & sites\nlocation. This retention policy applies to content in the group's mailbox, site, and files. Files include\nTeams meeting recordings\nand\ntranscripts\nfrom channel meetings.\nTo retain or delete Teams meeting recordings with their transcripts from user chats, you'll need a retention policy that includes the organizer's OneDrive account as the location.\nIf you have team sites that aren't connected to a Microsoft 365 group, which includes sites for Teams shared channels and Teams private channels, you need a retention policy that includes the\nSharePoint classic and communication sites\nor\nOneDrive accounts\nlocations to retain and delete files in Teams:\nFiles that are shared in chat are stored in the OneDrive account of the user who shared the file.\nFiles that are uploaded to channels are stored in the SharePoint site for the team.\nTip\nYou can apply a retention policy to the files of just a specific team when it's not connected to a Microsoft 365 group by selecting the SharePoint site for the team, and the OneDrive accounts of users in the Team.\nIt's possible that a retention policy that's applied to Microsoft 365 groups, SharePoint sites, or OneDrive accounts could delete a file that's referenced in a Teams chat or channel message before those messages get deleted. In this scenario, the file still displays in the Teams message, but when users select the file, they get a \"File not found\" error. This behavior isn't specific to retention policies and could also happen if a user manually deletes a file from SharePoint or OneDrive.\nNote\nRetention policies for Viva Engage do not inform users when messages are deleted as a result of a retention policy.\nTo use this feature, your Viva Engage network must be\nNative Mode\n, not Hybrid Mode.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto create a new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nViva Engage user messages\nbut not\nViva Engage community messages\n.\nIf you chose\nStatic\n: On the\nChoose locations to apply the policy\npage, toggle on one or both of the locations for Viva Engage:\nViva Engage community message\nand\nViva Engage user messages\n.\nBy default, all communities and users are selected, but you can refine this by specifying communities and users to be included or excluded.\nFor Viva Engage user messages:\nIf you leave the default at\nAll users\n, Azure B2B guest users are not included.\nIf you select\nEdit\nfor\nAll users\n, you can apply a retention policy to external users if you know their account.\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\n.\nComplete the configuration and save your settings.\nFor technical details about how retention works for Viva Engage, including what elements of messages are supported for retention and timing information with example walkthroughs, see\nLearn about retention for Viva Engage\n.\nKnown configuration issues for Viva Engage retention policies\nAlthough you can select the option to start the retention period when items were last modified, the value of\nWhen items were created\nis always used. For messages that are edited, a copy of the original message is saved with its original timestamp to identify when this pre-edited message was created, and the post-edited message has a newer timestamp.\nWhen you select\nEdit\nfor the Viva Engage user messages location, you might see guests and non-mailbox users. Retention policies aren't designed for these users, so don't select them.\nAdditional retention policies needed to support Viva Engage\nViva Engage is more than just community messages and private messages. To retain and delete email messages for your Viva Engage network, configure an additional retention policy that includes any Microsoft 365 groups that are used for Viva Engage, by using the\nMicrosoft 365 Group mailboxes & sites\nlocation.\nThis location will also include files that are uploaded to Viva Engage communities. These files are stored in the group-connected SharePoint site for the Viva Engage community.\nIt's possible that a retention policy that's applied to SharePoint sites could delete a file that's referenced in a Viva Engage message before those messages get deleted. In this scenario, the file still displays in the Viva Engage message, but when users select the file, they get a \"File not found\" error. This behavior isn't specific to retention policies and could also happen if a user manually deletes a file from SharePoint.\nUse the following instructions for retention policies that apply to any of these services:\nExchange: Email and public folders\nSharePoint: Sites and SharePoint Embedded containers\nOneDrive: Accounts\nMicrosoft 365 groups\nSkype for Business\nNote\nIf your organization is using\nadministrative units\nand you're a restricted administrator assigned one or more adminsitrative units, you won't be able to configure a retention policy that includes SharePoint sites or Exchange public folders. For these locations, you must be an unrestricted administrator.\nSign in to the Microsoft Purview portal\n>\nSolutions\n>\nData Lifecycle Management\n>\nPolicies\n>\nRetention policies\n.\nSelect\nNew retention policy\nto start the\nCreate retention policy\nconfiguration, and name your new retention policy.\nFor the\nAssign admin units\npage, keep the default of\nFull directory\n. Currently, admin units aren't supported for this policy.\nFor the\nChoose the type of retention policy to create\npage, select\nAdaptive\nor\nStatic\n, depending on the choice you made from the\nBefore you begin\ninstructions. If you haven't already created adaptive scopes, you can select\nAdaptive\nbut because there won't be any adaptive scopes to select, you won't be able to finish the configuration with this option. Adaptive policies don't support the locations for Exchange public folders or Skype for Business.\nDepending on your selected scope:\nIf you chose\nAdaptive\n: On the\nChoose adaptive policy scopes and locations\npage, select\nAdd scopes\nand select one or more adaptive scopes that have been created. Then, select one or more locations. The locations that you can select depend on the\nscope types\nadded. For example, if you only added a scope type of\nUser\n, you'll be able to select\nExchange mailboxes\nbut not\nSharePoint sites\n.\nIf you chose\nStatic\n: On the\nChoose locations\npage, toggle on or off any of the locations except the locations for Teams and Viva Engage. For each location, you can leave it at the default to\napply the policy to the entire location\n, or\nspecify includes and excludes\n.\nInformation specific to locations:\nExchange mailboxes and Exchange public folders\nSharePoint sites and OneDrive accounts\nMicrosoft 365 Group mailboxes & sites\nSkype for Business\nFor\nDecide if you want to retain content, delete it, or both\npage, specify the configuration options for retaining and deleting content.\nYou can create a retention policy that just retains content without deleting, retains and then deletes after a specified period of time, or just deletes content after a specified period of time. For more information, see\nSettings for retaining and deleting content\non this page.\nComplete the configuration and save your settings.\nSeparate an existing 'Teams chats and Copilot interactions' policy\nPreviously, retention policies used the location\nTeams chats and Copilot interactions\nthat combined Teams chat and Copilot interactions. There are now separate retention locations for Teams chat and Copilot interactions.\nYou can separate Teams chats from Copilot interactions from an existing retention policy.\nYou can create new retention policies for just Teams chats, or for just Copilot interactions.\nUse the following PowerShell commands to separate an existing retention policy for\nTeams chats and Copilot interactions\n:\nTo make your existing retention policy for the\nolder locations\na Teams chat only policy:\nSet-RetentionCompliancePolicy -Identity \"<policy name>\" -Applications \"User:TeamsChatUserInteractions\"\nOr, if you have an existing retention policy for\nnewer locations\n, such as Teams private channel messages and Viva Engage, you can add Teams chat to it:\nSet-AppRetentionCompliancePolicy -Identity \"<policy name>\" -Applications \"User:TeamsChatUserInteractions\"\nTo add Microsoft 365 Copilot interactions to an existing retention policy for\nnewer locations\n, such as Teams private channel messages and Viva Engage:\nSet-AppRetentionCompliancePolicy -Identity â<policy name>â -Applications \"User:M365Copilot\"\nFor new retention policies, select the new locations, such as\nTeams chat\nor\nMicrosoft Copilot Experiences\n.\nNote\nIf you have existing retention policies for\nTeams chats and Copilot interactions\n, they continue to be supported, although they can't be edited when your tenant supports the separate locations. At this point, any new retention policies must use the new locations.\nHow long it takes for retention policies to take effect\nWhen you create and submit a retention policy, it can take up to seven days for the retention policy to be applied:\nFirst, the retention policy needs to be distributed to the locations that you selected, and then applied to content. You can always check the distribution status of the retention policy by selecting it from the\nRetention policies\npage in the Microsoft Purview portal. From the flyout pane, if you see\n(Error)\nincluded in the status, and in the details for the locations see a message that it's taking longer than expected to deploy the policy or to try redeploying the policy, try running the\nSet-AppRetentionCompliancePolicy\nor\nSet-RetentionCompliancePolicy\nPowerShell command to retry the policy distribution:\nConnect to Security & Compliance PowerShell\n.\nRun one of the following commands:\nFor the policy locations\nTeams private channel messages\n,\nViva Engage user messages\nand\nViva Engage community messages\n:\nSet-AppRetentionCompliancePolicy -Identity <policy name> -RetryDistribution\nFor all other policy locations, such as\nExchange mailboxes\n,\nSharePoint classic and communication sites\n, and\nTeams channel messages\n:\nSet-RetentionCompliancePolicy -Identity <policy name> -RetryDistribution\nUpdating retention policies\nWhen settings from the retention policy are already applied to content, a change in configuration to the policy will be automatically applied to this content in addition to content that's newly identified.\nSome settings can't be changed after the policy is created and saved, which include the name of the retention policy, the scope type (adaptive or static), and the retention settings except the retention period.\nIf you no longer need the retention settings that you've configured, see\nReleasing a policy for retention\n.\nTroubleshooting retention policies\nIf your retention policies aren't working as expected or you see errors related to your retention policies, use the following troubleshooting resources:\nIdentify errors in Microsoft 365 retention and retention label policies\nResolve errors in Microsoft 365 retention and retention label policies\nNext steps\nIf some items for Exchange, SharePoint, OneDrive, or Microsoft 365 Groups need different retention settings from the retention policy settings you've configured,\ncreate retention labels for these exceptions\n.\nHowever, if you're looking to manage high-value items for business, legal, or regulatory record-keeping requirements,\nuse file plan to create and manage retention labels\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Retention for SharePoint",
      "section": "SharePoint Administration"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/admin/manage/manage-addins-in-the-admin-center": {
      "content_hash": "sha256:dc572fc11be76a59b672b07541237b6fdc22f5665025a48cfe1a44d819135d23",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nManage add-ins in the Microsoft 365 admin center\nFeedback\nSummarize this article for me\nNote\nThe\nintegrated apps portal\nis the recommended and most feature-rich way for most customers to centrally deploy Office add-ins to users and groups within your organization.\nOffice Add-ins help users personalize your documents and streamline the way you access information on the web. See\nStart using your Office Add-in\n.\nAfter a Global or Exchange admin deploys add-ins for users in an organization, they can turn add-ins off or on, edit, delete, and manage access to the add-ins.\nFor more information about installing add-ins from the admin center, see\nDeploy add-ins in the admin center\n.\nAdd-in states\nAn add-in can be in either the\nOn\nor\nOff\nstate.\nState\nHow the state occurs\nEffect\nActive\nAdmin uploaded the add-in and assigned it to users or groups.\nUsers and groups assigned to the add-in see it in the relevant clients.\nTurned off\nAdmin turned off the add-in.\nUsers and groups assigned to the add-in no longer have access to it.\nIf the add-in state is changed to Active, the users and groups will have access to it again.\nDeleted\nAdmin deleted the add-in.\nUsers and groups assigned the add-in no longer have access to it.\nConsider deleting an add-in if no one is using it anymore. For example, turning off an add-in might make sense if an add-in is used only during specific times of the year.\nDelete an add-in\nYou can also delete an add-in that was deployed.\nIn the admin center, go to the\nSettings\n>\nIntegrated apps\npage.\nSelect the deployed add-in and then select the\nConfiguration\ntab.\nIn the\nConfiguration\npane, go to\nAdvanced Settings\n>\nAdd-ins\n.\nSelect the add-in from the list again.\nChoose\nRemove Add-In\n. Remove the Add-in button on the bottom right corner.\nValidate your selections, and choose\nRemove\n.\nEdit add-in access\nPost deployment, admins can also manage user access to add-ins.\nIn the admin center, go to the\nSettings\n>\nIntegrated apps\npage.\nSelect the deployed add-in.\nClick on\nEdit\nunder\nWho has Access\n.\nSave the changes.\nManage add-in downloads by turning on/off Microsoft Marketplace across all apps (except Outlook)\nImportant\nIn the UI of the Microsoft 365 Admin Center, Microsoft Marketplace is still sometimes referred to as \"Office Store\".\nNote\nOutlook add-in installation is managed by a\ndifferent process\n.\nAs an organization you may wish to manage the download of Office add-ins from Microsoft Marketplace. This could be used to ensure that users within your organization can get the benefits from all the Office add-ins, or only the organization-approved add-ins can be deployed with centralized deployment.\nTo turn on/off add-in acquisition\nIn the admin center, go to the\nSettings\n>\nOrg settings\npage.\nSelect\nUser owned apps and services\n.\nCheck or clear the option to allow or prevent users to access the Office Store (which refers to Microsoft Marketplace).\nOptions available in non-educational tenants:\nOptions available in educational tenants:\nThe userâs license information is used to define whether a user is a faculty/staff or a student along with the Age Group property to check whether the student is an adult or not. A user who does not have an educational license is included in the\nFaculty, staff and other non-student users\nuser group.â¯\nNote\nFor more information see:\nLearn how to review the user's license type and assign or unassign licenses as required\nUnderstand how to configure the Age Group property in the Microsoft Encarta admin center\nThis will control all users' ability to acquire the following add-ins from Microsoft Marketplace.\nAdd-ins for non-subscription Word, Excel, and PowerPoint on Windows and Mac\nAdd-ins for subscription Microsoft 365\nWhen you disable the access to Microsoft Marketplace, a user who tries to access it will see the following message:\nOffice store not available. Unfortunately, your organization has disabled access to the Office Store. Please contact your administrator to get access to the store.\nNote\nAcquisitions may still be possible from Microsoft Markeplace, but the user will not be able to launch or use the add-in in the client. This does not prevent an administrator from using centralized deployment to assign an add-in from Microsoft Marketplace.\nSupport for turning on/off the Microsoft Marketplace is available in the following versions:\nOffice on Windows: 16.0.9001 - Currently available.\nOffice on Mac: 16.10.18011401 - Currently available.\nOffice on iOS: 2.9.18010804 - Currently available.\nOffice on the web - Currently available.\nTo prevent a user from signing in with a Microsoft account, you can restrict logon to use only the organizational account. For more information, see\nIdentity, authentication, and authorization in Office 2016\n.\nNote\nPreventing users from accessing Microsoft Markeplace will also prevent them from\nSideloading Office Add-ins for testing from a network share\n.\nMore about the end-user experience with add-ins\nAfter you deploy an add-in, your end users can start using it in their Office applications. The add-in appears on all platforms that the add-in supports. See\nStart using your Office Add-in\n.\nIf the add-in supports add-in commands, the commands appear in the ribbon. In the following example, the command\nSearch Citation\nappears for the\nCitations\nadd-in.\nIf the deployed add-in doesn't support add-in commands or if a user wants to view all deployed add-ins, the user can view them via\nMy Add-ins\n.\nIn Word, Excel, or PowerPoint\non the\nHome\nribbon, select\nAdd-ins\n, and then select\nMore Add-ins\non the callout.\nOn the\nApps\npane, select\nManage your apps\nto see a list of all deployed apps, agents, and add-ins.\nDouble-click the add-in you deployed earlier (in this example,\nCitations\n).\nIn Outlook\nOn the\nApp Bar\non the left of the window, select the\nMore Apps\nbutton. Or on the\nHome\nribbon, select\nAll Apps\nand then select\nAdd apps\non the callout.\nOn the\nApps\npane, select\nManage your apps\nto see a list of all deployed apps, agents, and add-ins.\nRelated content\nMinors and acquiring add-ins from the Microsoft Store\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Integrated Apps",
      "section": "Microsoft 365 Administration"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/enterprise/view-service-health": {
      "content_hash": "sha256:501af130ae6e052810076e00d9c3ef9b9693126ae7d45ec75cb381437edaf01c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nHow to check Microsoft 365 service health\nFeedback\nSummarize this article for me\nYou can view the health of your Microsoft services, including Office on the web, Microsoft Teams, Exchange Online, and Microsoft Dynamics 365 on the\nService health\npage in the\nMicrosoft 365 admin center\n. If you're experiencing problems with a cloud service, you can check the service health to determine whether this is a known issue with a resolution in progress before you call support or spend time troubleshooting.\nIf you're unable to sign in to the admin center, you can use the\nservice status page\nto check for known issues preventing you from logging into your tenant. Also, sign up to follow us at\n@MSFT365status\non\nX\n(Twitter) to see information on certain events.\nHow to check service health\nGo to the Microsoft 365 admin center at\nhttps://admin.microsoft.com\n, and sign in with an admin account.\nNote\nPeople who are assigned the Service Support admin and Helpdesk admin role can view service health. For more information about roles that can view service health, see\nAbout admin roles\n.\nTo view service health, in the left-hand navigation of the admin center, go to\nHealth\n>\nService health\n, or select the\nService health\ncard on the\nHome dashboard\n. The dashboard card indicates whether there's an active service issue and links to the detailed\nService health\npage.\nOn the\nService health\npage, the health state of each cloud service is shown in a table format.\nThe\nOverview\ntab (the default view) shows all services, their current health state, and any active incidents or advisories. An icon and status in the\nHealth\ncolumn indicate the state of each service.\nThe\nIssues for your organization to act on\nsection lists any issues detected in your environment that require your action. If there are no issues in your environment that need action, this section won't be visible.\nThe\nActive issues Microsoft is working on\nsection lists active incidents and advisories that Microsoft is working to resolve.\nThe\nIssue history\ntab shows all incidents and advisories that have been resolved within the last 7 or 30 days.\nIf you're experiencing an issue with a Microsoft 365 service and you don't see it listed on the Service health page, tell us about it by selecting\nReport an issue\n, and completing the short form. We'll look at related data and reports from other organizations to see how widespread the issue is, and if it originated with our service. If it did, we'll add it as a new incident or advisory on the\nService health\npage, where you can track its resolution. The\nReported issues\ntab will show all issues your tenant has reported from this form and the status.\nTo customize your view of which services show up on the dashboard, select\nCustomize > Custom view\n, and clear the checkboxes for the services you want to filter out of your Service health dashboard view. Make sure that the checkbox is selected for each service that you want to monitor.\nTo sign up for email notifications of new incidents that affect your tenant and status changes for an active incident, select\nCustomize > Email\n, select\nSend me email notifications about service health\n, and then specify:\nUp to two email addresses.\nWhether you want notifications for incidents or advisories\nThe services for which you want notification\nYou can also subscribe to email notifications for individual events instead of every event for a service. To do so, select the active issue you want to receive email notification updates for, select\nManage notifications for this issue\n, and then specify:\nUp to two email addresses.\nNote\nEach admin can have their Preferences set and the above limit of two email address is per admin account.\nTip\nYou can also use the\nMicrosoft 365 Admin app\non your mobile device to view Service health, which is a great way to stay current with push notifications.\nView details of posted service health issue\nIn the\nActive issues Microsoft is working on\nsection, select the issue title to see the issue detail page. This page shows more information about the issue, including a feed of all the messages posted while we work on a solution.\nThe advisory or incident summary provides the following information:\nTitle\n- A summary of the problem.\nID\n- A numeric identifier for the problem.\nLast updated\n- The last time that the service health message was updated.\nEstimated start time\n- The estimated time when the issue started.\nAffected services\n- The names of the affected services.\nIssue type\n- The severity of the issue (incident or advisory).\nIssue origin\n- An indication of whether the issue was found at Microsoft or in your environment.\nStatus\n- The current state of the issue.\nUser Impact\n- A brief description of the impact this issue has on the end user.\nAll Updates\n- We post frequent messages to let you know the progress that we're making in applying a solution.\nTranslate service health details\nWe use machine translation to automatically display messages in your preferred language. Read\nLanguage translation for the Service health page\nfor more information on how to set your language.\nDefinitions\nMost of the time, services will appear as healthy with no further information. When a service is having a problem, the issue is identified as either an advisory or an incident and shows a current status.\nTip\nPlanned maintenance events aren't shown in service health. You can track planned maintenance events by staying up to date with the\nMessage center\n. Filter to messages categorized as Plan for change to find out when the change is going to happen, its effect, and how to prepare for it. See\nMessage center in Microsoft 365\nfor more details.\nIncidents and advisories\nIcon\nDescription\nIf a service has an advisory shown, we're aware of a problem that is affecting some users, but the service is still available. In an advisory, there's often a workaround to the problem and the problem might be intermittent or is limited in scope and user impact.\nIf a service has an active incident shown, it's a critical issue and the service or a major function of the service is unavailable. For example, users might be unable to send and receive email or unable to sign-in. Incidents will have noticeable impact to users. When there's an incident in progress, we'll provide updates regarding the investigation, mitigation efforts, and confirmation of resolution in the Service health dashboard.\nStatus definitions\nStatus\nDefinition\nInvestigating\nWe're aware of a potential issue and are gathering more information about what's going on and the scope of impact.\nService degradation\nWe've confirmed that there's an issue that might affect use of a service or feature. You might see this status if a service is performing more slowly than usual, there are intermittent interruptions, or if a feature isn't working, for example.\nService interruption\nYou'll see this status if we determine that an issue affects the ability for users to access the service. In this case, the issue is significant and can be reproduced consistently.\nRestoring service\nThe cause of the issue has been identified, we know what corrective action to take, and are in the process of bringing the service back to a healthy state.\nExtended recovery\nThis status indicates that corrective action is in progress to restore service to most users but will take some time to reach all the affected systems. You might also see this status if we've made a temporary fix to reduce impact while we wait to apply a permanent fix.\nInvestigation suspended\nIf our detailed investigation of a potential issue results in a request for additional information from customers to allow us to investigate further, you'll see this status. If we need you to act, we'll let you know what data or logs we need.\nService restored\nWe've confirmed that corrective action has resolved the underlying problem and the service has been restored to a healthy state. To find out what went wrong, view the issue details.\nFalse positive\nAfter a detailed investigation, we've confirmed the service is healthy and operating as designed. No impact to the service was observed or the cause of the incident originated outside of the service. Incidents and advisories with this status appear in the history view until they expire (after the period of time stated in the final post for that event).\nPost-incident report published\nWe've published a Post Incident Report for a specific issue that includes root cause information and next steps to ensure a similar issue doesn't reoccur.\nMessage Post Types\nType\nDefinition\nQuick Update\nShort and frequent incremental updates for broadly impacting incidents, available to all customers.\nAdditional Details\nThese additional posts will provide richer technical and resolution details to offer deeper visibility into the handling of incidents. This is available for tenants that meet the same requirements outlined for\nExchange Online monitoring\n,\nHistory\nService health lets you look at your current health status and view the history of any service advisories and incidents that have affected your tenant in the past 30 days. To view the past health of all services, select\nHistory\nview.\nFor more information about our commitment to uptime, see\nTransparent operations from Microsoft 365\n.\nLanguage translation for the Service health page\nService health posts are written in English due to the timeliness of the information we're posting but can be automatically displayed in the language specified by your personal language settings for Microsoft 365. If you set your preferred language to anything other than English, you'll see an option in the Service health page to automatically translate posts. The messages are machine translated to your preferred language, meaning that a computer did the translation.\nBefore you can choose your language settings, you have to set your preferred language. No translation options are shown when your language is set to English. You can't specify a preferred language for others; each person has to change this setting for themselves.\nBefore you can choose your language settings, you have to set your preferred language. No translation options are shown when your language is set to English. You can't specify a preferred language for others; each person has to change this setting for themselves.\nSet your preferred language\nGo to the Microsoft 365 admin center\nhttps://admin.microsoft.com\n, or home page, select the settings icon in the upper-right corner of the page.\nUnder\nLanguage and time zone\n, select\nView all\nto show the available options. Select your desired language from the drop-down menu, and then select\nSave\n. Microsoft 365 will try to refresh and display the new language. If that doesn't happen immediately or if it seems that it's taking too long, you can either refresh your browser or sign out and then sign back in.\nMachine translation in Service health dashboard\nWhen your preferred language isn't set to English, the option to translate the post into your language is available.\nTo set Service health posts to automatically machine-translate and display in your preferred language, go to\nHealth > Service health\ndashboard. You'll see a button to toggle automatic translation on or off. When this setting is off, posts are shown in English. When this setting is on, messages display in your preferred language. The setting you choose will persist for each visit.\nYou also can toggle between seeing details for a specific issue in English and your preferred language in the issue details page that appears after you click the title of an issue.\nRelated articles\nMessage center Preferences\nHow to check Windows release health on admin center\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Service Health",
      "section": "Microsoft 365 Administration"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/admin/manage/message-center": {
      "content_hash": "sha256:4bf5a71acaf459ce183d2da04173726e5ecd56a14379bdbb1ed51eb7f1527c59",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nTrack new and changed features in the Microsoft 365 Message center\nFeedback\nSummarize this article for me\nTo keep track of upcoming changes, including new and changed features, planned maintenance, or other important announcements, go to\nMessage center\n.\nTo open Message center:\nIn the admin center, go to\nHealth\n>\nMessage center\n.\nIn the\nadmin center\n, go to\nHealth\n>\nMessage center\n.\nYou can also use the\nMicrosoft 365 Admin app\non your mobile device to view Message center, which is a great way to stay current with push notifications.\nTo unsubscribe from Message center emails, see\nUnsubscribe from Message center emails\nin this article.\nFrequently asked questions\nQuestion\nAnswer\nWho can view posts in Message center?\nMost users who have been assigned any admin role in Microsoft 365 can view Message center posts.\nHere's a list\nof admin roles that don't have access to the Message center. You can also assign the Message center reader role to users who should be able to read and share Message center posts without having any other admin privileges.\nIs this the only way Microsoft communicates changes about Microsoft 365?\nNo, but Message center is the primary way we communicate the timing of individual changes in Microsoft 365. See\nStay on top of Microsoft 365 changes\nfor more information.\nHow can I see posts in my language?\nMessage center posts are written in English. You can control whether, by default, posts are shown in English or are automatically machine-translated to your preferred language. You can also select to machine-translate posts to any language we support. See\nLanguage translation for Message center posts\nfor more details.\nCan I preview changes or features before they are rolled-out to my organization?\nSome changes and new features can be previewed by opting in to the Targeted release program. To opt in, in the admin center, go to\nSettings\n>\nOrg settings\n>\nOrganization profile\n>\nRelease preferences\n. (In the admin center, you may need to select\nShow all\nat the bottom of the left navigation pane to see\nSettings\n.) You can choose Targeted release for your entire organization, or just for selected users. See\nStandard or Targeted release options in Microsoft 365\nfor more information about the program.\nCan I find out the exact date a change is available in my organization?\nUnfortunately, we can't tell you the exact date a change is made to your organization. In our Message center post, we give as much information as we can on the timing of the release, based on our confidence level. We're working on improvements to get better with that level of detail.\nAre these messages specific to my organization?\nWe do our best to make sure that you only see Message center posts that affect your organization. The Microsoft 365 Roadmap includes all of the features we are currently working on and rolling out, but not all of these features apply to every organization.\nCan I get message center posts emailed instead?\nYes! You can select to have a weekly digest emailed to you and up to two other email addresses. The emailed weekly digest is turned on by default. If you aren't getting your weekly digests, check your spam folder. See the\nPreferences\nsection of this article for more information on how to set up the weekly digest.\nHow do I stop getting the Message center digest?\nGo to Message center in the admin center and select\nPreferences\n. In the\nEmail\ntab, turn off the option to\nSend me email notifications from message center\n.\nHow can I ensure data privacy notifications are received by the right contacts in my organization?\nAs a global admin you receive data privacy messages for your organization. Additionally, you can assign the Message Center Privacy reader role to people who should see data privacy messages. Other admin roles with access to Message Center cannot view data privacy messages.\nFor more info, see\nPreferences\nin this article.\nWhy canât I see a message that was previously there?\nTo manage the number of messages within Message center, each message will expire and be removed after a period of time. Generally, messages expire 30 days post the time period outlined in the message body.\nFeature release status for your organization in Message Center\nFor each new and updated feature announcement in Message center, the\nStatus for your org\nfield provides a release status to help you track when a feature is available in your tenant.\nThese three release statuses are updated on each applicable message over the lifecycle of the feature release\nScheduled\n: The feature is planned to release to your tenant, and is not available to any users in your organization\nRolling out\n: The feature is beginning to roll out to some applicable users in your organization.\nLaunched\n: The feature is generally available to all the applicable users in your organization.\nUpdates to feature release status are provided on the original Message center post. Filtering capability on\nâStatus for your orgâ\nallows easier visibility on the updated release status.\nThe release status is\nONLY\navailable for new and updated features that are also announced on Microsoft 365 Public Roadmap and have reached general availability status (production ready). If you do not see release status on a message, it means the release status is not available for that feature.\nNote\nThe release status will initially be available for a limited number of Microsoft Teams, Outlook on the web and Microsoft 365 admin center feature announcements.\nRelevance Recommendation\nFor each new Message center post, we provide a recommendation for how relevant the change is for your organization. This recommendation is based on multiple factors such as:\nApps and service usage.\nChanges meant to prevent or fix issues for subscription.\nChanges meant to help you plan ahead or stay informed.\nImpact changes, such as data privacy and app and service retirements.\nThere are three levels of relevance:\nHigh\n- These are posts about changes in your organization, which need immediate action to avoid service disruption. These can also include feature releases with high potential impact to your organization, for example, an app or service being heavily used by people in your organization.\nMedium\n- These are posts about changes in your organization, which don't need immediate action. Examples are nonbreaking changes or new features for a service, which is being used by your organization, an early announcement for an upcoming breaking feature change, retirement\nLow\n- These are posts about changes that need monitoring. They are related to low impact apps and services in your organization. Examples would be a feature update for an app or service, which isn't actively used in your organization.\nThe relevance recommendations are\nONLY\nbe available for the newer MC posts. This means the MC posts you already received will see a \"blank\" for relevance recommendation.\nIf you see\nProcessing\nfor a Message center post, it means that the score is being computed for this post and should be available soon. You should try to refresh after a few minutes.\nOnce you start receiving this, please tell us if a Message center post is\nnot relevant\nto you through the\nextended feedback.\nThis feedback is important for us to improve the accuracy of the relevance recommendations.\nFilter messages\nMessage center presents a view of all active messages in a table format. By default, it shows the most recent message at the top of the list. You can select\nService\nto see messages for various services, such as Microsoft 365 Apps, SharePoint Online, etc. Under\nTag\nyou can select\nAdmin impact\n,\nData privacy\n,\nFeature update\n,\nMajor update\n,\nNew feature\n,\nRetirement\n, or\nUser impact\nmessages. Under\nMessage state\nyou can select\nFavorites\n,\nUnread\n, or\nUpdated\nmessages.\nThe Archive tab shows the messages you have archived. To archive a message, in the message pane, Select\nArchive\n.\nUse the\nService\n,\nTag\n, and\nMessage state\ndrop-down menus to select a filtered view of messages. For example, in this diagram, the messages are tagged with the\nAdmin impact\ntag.\nYou can select any column heading, except\nService\nand\nTag\n, to sort messages in ascending or descending order.\nUse the\nService\n,\nTag\n, and\nMessage state\ndrop-down menus to select a filtered view of messages. For example, in this diagram, the messages are tagged with the\nAdmin impact\n.\nYou can select any column heading, except\nService\nand\nTags\n, to sort messages in ascending or descending order.\nMajor updates\nMajor updates can be reviewed by selecting the\nMajor update\nfrom the\nTags\ndrop-down.\nMajor updates are communicated at least 30 days in advance when an action is required and might include:\nUser impacting changes to daily productivity such as changing a userâs inbox, meetings, delegations, sharing and access that may result in help desk calls, or organizational conformance concerns.\nChanges to the themes, web parts, deployed Copilot agents and other components that may impact customer customizations.\nIncreases or decreases to visible capacity such as storage, number of rules, Copilot agents and prompts, items, or durations.\nRebranding that may cause end-user confusion or result in help desk changes, collateral changes, or URL changes if the new URL is not *.cloud.microsoft\nA new service or application deployed with default settings turned on.\nChanges to where data is stored or accessed.\nPreferences\nIf administration is distributed across your organization, you may not want or need to see posts about all Microsoft 365 services. Each admin can:\nSet preferences that control which messages are displayed in Message center.\nFilter messages.\nSet email preferences to receive a weekly digest of all messages, emails for major updates only, and emails for data privacy messages.\nSelect\nPreferences\nat the top of Message center.\nIn the\nCustom View\ntab, make sure that the check box is selected for each service that you want to monitor. Clear the check boxes for the services you want to filter out of your Message center view.\nDigest emails are turned on by default and are sent to your primary email address. To stop receiving the weekly digest, clear the\nSend me email notifications from message center\ncheck box in the\nEmail tab\n.\nYou can also enter up to two email addresses, separated by a semicolon.\nYou can also choose the emails you want to get, and a weekly digest of services you select.\nSelect\nSave\nto keep your changes.\nSelect\nPreferences\nat the top of Message center.\nIn the\nCustom View\ntab, make sure that the check box is selected for each service that you want to monitor. Clear the check boxes for the services you want to filter out of your Message center view.\nDigest emails are turned on by default and are sent to your primary email address. To stop receiving the weekly digest, clear the\nSend me email notifications from message center\ncheck box in he\nEmail tab\n.\nYou can also enter up to two email addresses, separated by a semicolon.\nYou can also choose the emails you want to get, as well as a weekly digest of services you select.\nSelect\nSave\nto keep your changes.\nDisplay messages in your preferred language\nWe use machine translation to automatically display messages in your preferred language. Read\nLanguage translation for Message center posts\nfor more information on how to set your language.\nNote\nThe weekly digest and any posts that are emailed are sent in English-only. Recipients can use\nTranslator for Outlook\nto read the message in their preferred language.\nMonthly active users\nWhen you open a message center post, we'll tell you the number of users who've been using that Microsoft 365 app or service in the\nService & monthly active users\nsection. The numbers are for the last 28 days. This info can help you prioritize which changes you should work on.\nThe number of monthly users applies to all users who've used that Microsoft 365 app or service on any device.\nNote\nThis feature isn't available for all Microsoft 365 productivity apps and services yet. We'll let you know when the feature isn't available.\nChoose columns\nTo choose columns, on the\nMessage center\npage, on the far right, select\nChoose columns\n, and in the\nChoose columns\npane, select the ones you want displayed.\nHere's a quick overview of the information in each column.\nColumn information\nColumn\nDescription\nCheck mark\nSelecting the check mark in the column heading row selects all messages currently displayed. Selecting the check mark next to one or more messages lets you take action on those messages.\nMessage title\nMessage titles are brief descriptions of upcoming changes. If the full title doesn't display, hover your cursor over it and the entire title will appear in a pop-up box.\nService\nIcons indicate the application to which the message applies.\nMore options\nMore options let you dismiss a message, mark it as read or unread, or share it with another admin. To restore an archived message, select the\nArchive\ntab, select the check mark next to the message, and select\nRestore\n.\nTags\nYou can choose tags from the Tag drop-down to filter messages.\nData Privacy\n: Data privacy notification (limited to global administrator and Message center Privacy reader roles).\nMajor update\n: Changes communicated at least 30 days in advance (\nMajor updates\n).\nRetirement\n: Retirement of a service or feature.\nNew feature\n: New feature or service.\nFeature update\n: Update to an existing feature.\nAdmin impact\n: When the change clearly impacts the admin in the following ways - UI change, workflow change, control available and Specific/Potential Action.\nUser impact\n: When the change to the service clearly impacts the user - UI Change and workflow change.\nUpdated message\n: When a message is updated.\nCategory\nThis is not shown by default, but can be specified in the\nChoose columns\npanel. Messages are identified by one of the following three categories:\nPrevent or fix issues\n: Informs you of known issues affecting your organization and may require that you take action to avoid disruptions in service. Prevent or fix issues are different than Service health messages because they prompt you to be proactive to avoid issues.\nPlan for change\n: Informs you of changes to Microsoft 365 that may require you to act to avoid disruptions in service. For example, we let you know about changes to system requirements or about features that are being removed. We try to provide at least 30 days' notice of any change that requires an admin to act to keep the service running normally.\nStay informed\n: Tells you about new or updated features we are turning on in your organization. announced first in the\nMicrosoft 365 Roadmap\n.\nMay also let you know about planned maintenance in accordance with our Service Level Agreement. Planned maintenance may result in down time, where you or your users can't access Microsoft 365, a specific feature, or a service such as email or OneDrive for Business.\nAct by\nWe'll only have dates here if we're making a change that requires you to take an action by a certain deadline. Since we rarely use the\nAct by\ncolumn, if you see something here, you should pay extra attention to it.\nLast updated\nDate that the message was published or last updated.\nMessage ID\nMicrosoft tracks our Message center posts by message ID. You can refer to this ID if you want to give feedback or if you call Support about a particular message.\nImportant\nMicrosoft recommends that you use roles with the fewest permissions. This helps improve security for your organization. Global Administrator is a highly privileged role that should be limited to emergency scenarios when you can't use an existing role.\nAdmin roles that don't have access to the Message center\nCompliance administrator\nConditional access administrator\nCustomer Lockbox access approver\nDevice administrators\nDirectory readers\nDirectory synchronization accounts\nDirectory writers\nIntune service administrator\nPrivileged role administrator\nReports reader\nGive feedback on a post\nIn the Message center, you can select a message to see details.\nIf a Message Center post is not relevant for your organization, please provide us with feedback. Select thumbs up or thumbs down on the MC post and select\nThis change isn't relevant to my org\n.\nNote\nIf you're using Microsoft 365 for Government - GCC High and Office 365 Government - DoD, you won't be able to provide feedback on a post.\nShare a message\nSee a message that someone else needs to act on? You can share the contents of the message with any user by email:\nSelect the message to open it, and then select\nShare\n.\nTo share the message, enter up to two email addresses separated by a colon. You can send to individual and to group email addresses. Optionally, you can choose to receive a copy of the message in email (the message goes to your primary email address) or add a personal message to provide recipients with more context.\nSelect\nShare\nto send the email.\nGet a link\nNeed to follow up with another admin to make sure they're aware of a change and taking action? You can generate a link to share in email or instant messaging. The person you share the link with has to have access to Message center. See\nadmin roles that don't have access to the Message center\nfor more information.\nSelect the message center post.\nSelect\nCopy link\n.\nUse Ctrl+V or right-click and select\nPaste\nto insert the link to whatever document you wish.\nRead and unread states\nAny message in Message center that is unread will appear in bold. Opening a message marks it as read. You can mark a message as unread.\nOn the main page of the message center, select the\nMore options\nellipses next to a message, and then select\nMark as unread\n.\nYou can also open a message and mark it as unread in the details panel.\nArchive and restore\nIf you see a message that doesn't pertain to you, or maybe you've already acted on it, you can archive the message. Archiving a message removes it from the Inbox. The view that you see in the Message center is specific to your user account, so archiving it from your view doesn't affect other admins. There are two ways to archive a message.\nOn the main page of the Message center, select a message, and then select\nArchive\nabove the list of messages.\nOpen the message, and then select\nArchive\non the top of the message pane.\nNeed to get an archived message back? No problem.\nSelect the\nArchive\ntab at the top of the Message center. A list of archived messages appears.\nSelect the message, select\nRestore\n, and the message is restored to Inbox.\nFavorite messages\nTo mark a message as a favorite, hover over the message title and you will see a\nFavorite\nstar you can select right after the\nMore options\nellipses. Once you have marked messages as favorite, you can also sort and filter them.\nScroll messages in the message pane\nWhen you open a message in a reading pane, you can use the\nUp\nand\nDown\narrows on the top of the pane to move to the next, or the previous message in the list.\nTrack your message center tasks in Planner\nA lot of actionable information about changes to Microsoft 365 services arrives in the Microsoft 365 message center. It can be difficult to keep track of which changes require tasks to be done, when, and by whom, and to track each task to completion. You also might want to make a note of something and tag it to check on later. You can do all this and more when you sync your messages from the Microsoft 365 admin center to Microsoft Planner. For more information, see\nTrack your message center tasks in Planner\n.\nSet language translation for Message center posts\nTo learn how to set your language preferences to enable machine translation for Message center posts, see\nLanguage translation for Message center posts\n.\nWork with service communications API in Microsoft Graph\nIf you'd like to program an alternative way to get real-time service health information and Message center communications, see\nWorking with service communications API in Microsoft Graph\n.\nUnsubscribe from Message center emails\nDigest emails are turned on by default and are sent to your primary email address. To stop receiving the weekly digest, select\nPreferences\nand then\nEmail\n.\nDe-select the\nSend a weekly digest of my messages\ncheckbox.\nEmail notification for major updates is a separate control. If you don't want to receive email notices about major updates, verify that\nSend me emails for major updates\ncheckbox is not selected.\nTo stop receiving email notices about data privacy messages, verify that\nSend me emails for data privacy messages\ncheckbox is not selected. (Data privacy messages are not included in the weekly digest.)\nSelect\nSave\nto keep your changes.\nRelated content\nSet up the Standard or Targeted release options\n(article)\nBusiness subscriptions and billing documentation\n(link page)\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Message Center",
      "section": "Microsoft 365 Administration"
    },
    "https://learn.microsoft.com/en-us/azure/sentinel/overview": {
      "content_hash": "sha256:a5cd0d11a906ba0a1924f564b90f17966bab8fc2e56d87c9bc141d1962800c8a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Microsoft Sentinel security information and event management (SIEM)?\nFeedback\nSummarize this article for me\nMicrosoft Sentinel is a cloud-native SIEM solution that delivers scalable, cost-efficient security across multicloud and multiplatform environments. It combines AI, automation, and threat intelligence to support threat detection, investigation, response, and proactive hunting.\nMicrosoft Sentinel SIEM empowers analysts to anticipate and stop attacks across clouds and platforms, faster and with greater precision.\nThis article highlights the key capabilities in Microsoft Sentinel.\nMicrosoft Sentinel inherits the Azure Monitor\ntamper-proofing and immutability\npractices. While Azure Monitor is an append-only data platform, it includes provisions to delete data for compliance purposes.\nThis service supports\nAzure Lighthouse\n, which lets service providers sign in to their own tenant to manage subscriptions and resource groups that customers have delegated.\nEnable out of the box security content\nMicrosoft Sentinel provides security content packaged in SIEM solutions that enable you to ingest data, monitor, alert, hunt, investigate, respond, and connect with different products, platforms, and services.\nDefender portal\nAzure portal\nFor more information, see\nAbout Microsoft Sentinel content and solutions\n.\nCollect data at scale\nCollect data across all users, devices, applications, and infrastructure, both on-premises and in multiple clouds.\nDefender portal\nAzure portal\nThis table highlights the key capabilities in Microsoft Sentinel for data collection.\nCapability\nDescription\nGet started\nOut of the box data connectors\nMany connectors are packaged with SIEM solutions for Microsoft Sentinel and provide real-time integration. These connectors include Microsoft sources and Azure sources like Microsoft Entra ID, Azure Activity, Azure Storage, and more.\nOut of the box connectors are also available for the broader security and applications ecosystems for non-Microsoft solutions. You can also use common event format, Syslog, or REST-API to connect your data sources with Microsoft Sentinel.\nMicrosoft Sentinel data connectors\nCustom connectors\nMicrosoft Sentinel supports ingesting data from some sources without a dedicated connector. If you're unable to connect your data source to Microsoft Sentinel using an existing solution, create your own data source connector.\nResources for creating Microsoft Sentinel custom connectors\n.\nData normalization\nMicrosoft Sentinel uses both query time and ingestion time normalization to translate various sources into a uniform, normalized view.\nNormalization and the Advanced Security Information Model (ASIM)\nDetect threats\nDetect previously undetected threats and minimize false positives using Microsoft's analytics and unparalleled threat intelligence.\nDefender portal\nAzure portal\nThis table highlights the key capabilities in Microsoft Sentinel for threat detection.\nCapacity\nDescription\nGet started\nAnalytics\nHelps you reduce noise and minimize the number of alerts you have to review and investigate. Microsoft Sentinel uses analytics to group alerts into incidents. Use the out of the box analytic rules as-is, or as a starting point to build your own rules. Microsoft Sentinel also provides rules to map your network behavior and then look for anomalies across your resources. These analytics connect the dots, by combining low fidelity alerts about different entities into potential high-fidelity security incidents.\nDetect threats out-of-the-box\nMITRE ATT&CK coverage\nMicrosoft Sentinel analyzes ingested data, not only to detect threats and help you investigate, but also to visualize the nature and coverage of your organization's security status based on the tactics and techniques from the MITRE ATT&CKÂ® framework.\nUnderstand security coverage by the MITRE ATT&CKÂ® framework\nThreat intelligence\nIntegrate numerous sources of threat intelligence into Microsoft Sentinel to detect malicious activity in your environment and provide context to security investigators for informed response decisions.\nThreat intelligence in Microsoft Sentinel\nWatchlists\nCorrelate data from a data source you provide, a watchlist, with the events in your Microsoft Sentinel environment. For example, you might create a watchlist with a list of high-value assets, terminated employees, or service accounts in your environment. Use watchlists in your search, detection rules, threat hunting, and response playbooks.\nWatchlists in Microsoft Sentinel\nWorkbooks\nCreate interactive visual reports by using workbooks. Microsoft Sentinel comes with built-in workbook templates that allow you to quickly gain insights across your data as soon as you connect a data source. Or, create your own custom workbooks.\nVisualize collected data\n.\nInvestigate threats\nInvestigate threats with artificial intelligence, and hunt for suspicious activities at scale, tapping into years of cyber security work at Microsoft.\nThis table highlights the key capabilities in Microsoft Sentinel for threat investigation.\nFeature\nDescription\nGet started\nIncidents\nMicrosoft Sentinel deep investigation tools help you to understand the scope and find the root cause of a potential security threat. You can choose an entity on the interactive graph to ask interesting questions for a specific entity, and drill down into that entity and its connections to get to the root cause of the threat.\nNavigate and investigate incidents in Microsoft Sentinel\nHunts\nMicrosoft Sentinel's powerful hunting search-and-query tools, based on the MITRE framework, enable you to proactively hunt for security threats across your organizationâs data sources, before an alert is triggered. Create custom detection rules based on your hunting query. Then, surface those insights as alerts to your security incident responders.\nThreat hunting in Microsoft Sentinel\nNotebooks\nMicrosoft Sentinel supports Jupyter notebooks in Azure Machine Learning workspaces, including full libraries for machine learning, visualization, and data analysis.\nUse notebooks in Microsoft Sentinel to extend the scope of what you can do with Microsoft Sentinel data. For example:\n- Perform analytics that aren't built in to Microsoft Sentinel, such as some Python machine learning features.\n- Create data visualizations that aren't built in to Microsoft Sentinel, such as custom timelines and process trees.\n- Integrate data sources outside of Microsoft Sentinel, such as an on-premises data set.\nJupyter notebooks with Microsoft Sentinel hunting capabilities\nRespond to incidents rapidly\nAutomate your common tasks and simplify security orchestration with playbooks that integrate with Azure services and your existing tools. Microsoft Sentinel's automation and orchestration provides a highly extensible architecture that enables scalable automation as new technologies and threats emerge.\nPlaybooks in Microsoft Sentinel are based on workflows built in Azure Logic Apps. For example, if you use the ServiceNow ticketing system, use Azure Logic Apps to automate your workflows and open a ticket in ServiceNow each time a particular alert or incident is generated.\nThis table highlights the key capabilities in Microsoft Sentinel for threat response.\nFeature\nDescription\nGet started\nAutomation rules\nCentrally manage the automation of incident handling in Microsoft Sentinel by defining and coordinating a small set of rules that cover different scenarios.\nAutomate threat response in Microsoft Sentinel with automation rules\nPlaybooks\nAutomate and orchestrate your threat response by using playbooks, which are a collection of remediation actions. Run a playbook on-demand or automatically in response to specific alerts or incidents, when triggered by an automation rule.\nTo build playbooks with Azure Logic Apps, choose from a constantly expanding gallery of connectors for various services and systems like ServiceNow, Jira, and more. These connectors allow you to apply any custom logic in your workflow.\nAutomate threat response with playbooks in Microsoft Sentinel\nList of all Logic App connectors\nMicrosoft Sentinel in the Azure portal retirement timeline\nMicrosoft Sentinel is\ngenerally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license. This means that you can use Microsoft Sentinel in the Defender portal even if you aren't using other Microsoft Defender services.\nStarting in\nJuly 2026\n, Microsoft Sentinel will be supported in the Defender portal only, and any remaining customers using the Azure portal will be automatically redirected.\nIf you're currently using Microsoft Sentinel in the Azure portal, we recommend that you start planning your transition to the Defender portal now to ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n.\nFor more information, see:\nMicrosoft Sentinel in the Microsoft Defender portal\nTransition your Microsoft Sentinel environment to the Defender portal\nPlanning your move to Microsoft Defender portal for all Microsoft Sentinel customers\n(blog)\nChanges for new customers starting July 2025\nFor the sake of the changes described in this section, new Microsoft Sentinel customers are customers who are\nonboarding the first workspace in their tenant to Microsoft Sentinel\n.\nStarting\nJuly, 2025\n, such new customers who also have the permissions of a subscription\nOwner\nor a\nUser access administrator\n, and are not Azure Lighthouse-delegated users, have their workspaces automatically onboarded to the Defender portal together with onboarding to Microsoft Sentinel.\nUsers of such workspaces, who also aren't Azure Lighthouse-delegated users, see links in Microsoft Sentinel in the Azure portal that redirect them to the Defender portal.\nFor example:\nSuch users use Microsoft Sentinel in the Defender portal only.\nNew customers who don't have relevant permissions aren't automatically onboarded to the Defender portal, but they do still see redirection links in the Azure portal, together with prompts to have a user with relevant permissions manually onboard the workspace to the Defender portal.\nThis table summarizes these experiences:\nCustomer type\nExperience\nExisting customers\ncreating new workspaces in a tenant where there is already a workspace enabled for Microsoft Sentinel\nWorkspaces are not automatically onboarded, and users don't see redirection links\nAzure Lighthouse-delegated users\ncreating new workspaces in any tenant\nWorkspaces are not automatically onboarded, and users don't see redirection links\nNew customers\nonboarding the first workspace in their tenant to Microsoft Sentinel\n-\nUsers who have the required permissions\nhave their workspace automatically onboarded. Other users of such workspaces see redirection links in the Azure portal.\n-\nUsers who don't have the required permissions\ndon't have their workspace automatically onboarded. All users of such workspaces see redirection links in the Azure portal, and a user with the required permissions must onboard the workspace to the Defender portal.\nRelated content\nOnboard Microsoft Sentinel\nDeployment guide for Microsoft Sentinel\nPlan costs and understand Microsoft Sentinel pricing and billing\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Microsoft Sentinel",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/sentinel/connect-data-sources": {
      "content_hash": "sha256:7fe24b6babbc887fddb514d182393bdb3a35d22499270e3cbb92323f836b76e1",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Sentinel data connectors\nFeedback\nSummarize this article for me\nAfter you onboard Microsoft Sentinel into your workspace, use data connectors to start ingesting your data into Microsoft Sentinel. Microsoft Sentinel comes with many out of the box connectors for Microsoft services, which integrate in real time. For example, the Microsoft Defender XDR connector is a service-to-service connector that integrates data from Office 365, Microsoft Entra ID, Microsoft Defender for Identity, and Microsoft Defender for Cloud Apps.\nBuilt-in connectors enable connection to the broader security ecosystem for non-Microsoft products. For example, use Syslog, Common Event Format (CEF), or REST APIs to connect your data sources with Microsoft Sentinel.\nNote\nFor information about feature availability in US Government clouds, see the Microsoft Sentinel tables in\nCloud feature availability for US Government customers\n.\nData management considerations for Microsoft Sentinel data lake\nThe following considerations must be factored into your compliance and data management planning:\nGDPR and Data Retention\nTenant admins can exercise GDPR rights using the Purge feature for the analytics tier. This doesn't affect the data lake tier.\nSpecific records can't be purged from the Sentinel data lake. The data lake retains ingested data for the defined retention period, even if the data is deleted at the source or in the analytics tier.\nPurview Integration\n. Changes to Purview settings don't have any effect on data stored in the Sentinel data lake.\nStorage Location\nSentinel data lake storage locations are selected by the tenant admin and may differ from the primary storage location of the source services.\nImportant\nMicrosoft Sentinel is generally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license.\nStarting in\nJuly 2026\n, all customers using Microsoft Sentinel in the Azure portal will be\nredirected to the Defender portal and will use Microsoft Sentinel in the Defender portal only\n. Starting in\nJuly 2025\n, many new customers are\nautomatically onboarded and redirected to the Defender portal\n.\nIf you're still using Microsoft Sentinel in the Azure portal, we recommend that you start planning your\ntransition to the Defender portal\nto ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n. For more information, see\nItâs Time to Move: Retiring Microsoft Sentinelâs Azure portal for greater security\n.\nData connectors provided with solutions\nMicrosoft Sentinel solutions provide packaged security content, including data connectors, workbooks, analytics rules, playbooks, and more. When you deploy a solution with a data connector, you get the data connector together with related content in the same deployment.\nThe Microsoft Sentinel\nData connectors\npage lists the installed or in-use data connectors.\nDefender portal\nAzure portal\nTo add more data connectors, install the solution associated with the data connector from the\nContent Hub\n. For more information, see the following articles:\nFind your Microsoft Sentinel data connector\nAbout Microsoft Sentinel content and solutions\nDiscover and manage Microsoft Sentinel out-of-the-box content\nMicrosoft Sentinel content hub catalog\nAdvanced Security Information Model (ASIM) based domain solutions for Microsoft Sentinel\nCreate custom connectors\nIf you're unable to connect your data source to Microsoft Sentinel using any of the existing solutions available, consider creating your own data source connector. For example, many security solutions provide a set of APIs for retrieving log files and other security data from their product or service. Those APIs connect to Microsoft Sentinel with one of the following methods:\nThe data source APIs are configured with the\nCodeless Connector Framework\n.\nThe data connector uses the Log Ingestion API for Azure Monitor as part of an\nAzure Function\nor\nLogic App\n.\nYou can also use Azure Monitor Agent directly or Logstash to create your custom connector. For more information, see\nResources for creating Microsoft Sentinel custom connectors\n.\nAgent-based integration for data connectors\nMicrosoft Sentinel can use agents provided by the Azure Monitor service (on which Microsoft Sentinel is based) to collect data from any data source that can perform real-time log streaming. For example, most on-premises data sources connect by using agent-based integration.\nThe following sections describe the different types of Microsoft Sentinel agent-based data connectors. To configure connections using agent-based mechanisms, follow the steps in each Microsoft Sentinel data connector page.\nSyslog and Common Event Format (CEF)\nYou can stream events from Linux-based, Syslog-supporting devices into Microsoft Sentinel by using the Azure Monitor Agent (AMA). Log formats vary, but many sources support CEF-based formatting. Depending on the device type, the agent is installed either directly on the device, or on a dedicated Linux-based log forwarder. The AMA receives plain Syslog or CEF event messages from the Syslog daemon over UDP. The Syslog daemon forwards events to the agent internally, communicating over TCP or UDS (Unix Domain Sockets), depending on the version. The AMA then transmits these events to the Microsoft Sentinel workspace.\nHere's a simple flow that shows how Microsoft Sentinel streams Syslog data.\nThe device's built-in Syslog daemon collects local events of the specified types, and forwards the events locally to the agent.\nThe agent streams the events to your Log Analytics workspace.\nAfter successful configuration, Syslog messages appear in the Log Analytics\nSyslog\ntable, and CEF messages in the\nCommonSecurityLog\ntable.\nFor more information, see\nSyslog and Common Event Format (CEF) via AMA connectors for Microsoft Sentinel\n.\nCustom logs\nFor some data sources, you can collect logs as files on Windows or Linux computers using the Log Analytics custom log collection agent.\nTo connect using the Log Analytics custom log collection agent, follow the steps in each Microsoft Sentinel data connector page. After successful configuration, the data appears in custom tables.\nFor more information, see\nCustom Logs via AMA data connector - Configure data ingestion to Microsoft Sentinel from specific applications\n.\nService-to-service integration for data connectors\nMicrosoft Sentinel uses the Azure foundation to provide out-of-the-box service-to-service support for Microsoft services and Amazon Web Services.\nFor more information, see the following articles:\nConnect Microsoft Sentinel to Azure, Windows, Microsoft, and Amazon services\nFind your Microsoft Sentinel data connector\nData connector support\nBoth Microsoft and other organizations author Microsoft Sentinel data connectors. Each data connector has one of the following support types listed on the data connector page in Microsoft Sentinel.\nSupport type\nDescription\nMicrosoft-supported\nApplies to:\nData connectors for data sources where Microsoft is the data provider and author.\nSome Microsoft-authored data connectors for non-Microsoft data sources.\nMicrosoft supports and maintains data connectors in this category according to the\nMicrosoft Azure Support Plans\n.\nPartners or the Community support data connectors authored by any party other than Microsoft.\nPartner-supported\nApplies to data connectors authored by parties other than Microsoft.\nThe partner company provides support or maintenance for these data connectors. The partner company can be an Independent Software Vendor, a Managed Service Provider (MSP/MSSP), a Systems Integrator (SI), or any organization whose contact information is provided on the Microsoft Sentinel page for that data connector.\nFor any issues with a partner-supported data connector, contact the specified data connector support contact.\nCommunity-supported\nApplies to data connectors authored by Microsoft or partner developers that don't have listed contacts for data connector support and maintenance on the data connector page in Microsoft Sentinel.\nFor questions or issues with these data connectors, you can\nfile an issue\nin the\nMicrosoft Sentinel GitHub community\n.\nFor more information, see\nFind support for a data connector\n.\nNext steps\nFor more information about data connectors, see the following articles.\nConnect your data sources to Microsoft Sentinel by using data connectors\nFind your Microsoft Sentinel data connector\nResources for creating Microsoft Sentinel custom connectors\nFor a basic Infrastructure as Code (IaC) reference of Bicep, Azure Resource Manager, and Terraform to deploy data connectors in Microsoft Sentinel, see\nMicrosoft Sentinel data connector IaC reference\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Data Connectors",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/sentinel/detect-threats-custom": {
      "content_hash": "sha256:fcdd05ca0198ae524e93de607eabe785b8191b6172966f9feb55642cf467e7da",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nCreate a scheduled analytics rule from scratch\nFeedback\nSummarize this article for me\nYouâve set up\nconnectors and other means of collecting activity data\nacross your digital estate. Now you need to dig through all that data to detect patterns of activity and discover activities that donât fit those patterns and that could represent a security threat.\nMicrosoft Sentinel and its many\nsolutions provided in the Content hub\noffer templates for the most commonly used types of analytics rules, and youâre strongly encouraged to make use of those templates, customizing them to fit your specific scenarios. But itâs possible you might need something completely different, so in that case you can create a rule from scratch, using the analytics rule wizard.\nNote\nIf you're reviewing the details of a SOC optimization recommendation in the\nSOC optimization\npage and followed the\nLearn more\nlink to this page, you might be looking for the list of suggested analytics rules. In this case, scroll to the bottom of the optimization details tab and select\nGo to Content hub\nto find and install the recommended rules specific to that recommendation. For more information, see\nSOC optimization usage flow\n.\nThis article describes the process of creating an analytics rule from scratch, including using the\nAnalytics rule wizard\n. It includes screenshots and directions to access the wizard in both the Azure portal and the Defender portal.\nImportant\nMicrosoft Sentinel is generally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license.\nStarting in\nJuly 2026\n, all customers using Microsoft Sentinel in the Azure portal will be\nredirected to the Defender portal and will use Microsoft Sentinel in the Defender portal only\n. Starting in\nJuly 2025\n, many new customers are\nautomatically onboarded and redirected to the Defender portal\n.\nIf you're still using Microsoft Sentinel in the Azure portal, we recommend that you start planning your\ntransition to the Defender portal\nto ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n. For more information, see\nItâs Time to Move: Retiring Microsoft Sentinelâs Azure portal for greater security\n.\nPrerequisites\nYou must have the Microsoft Sentinel Contributor role, or any other role or set of permissions that includes write permissions on your Log Analytics workspace and its resource group.\nYou should have at least a basic familiarity with data science and analysis and the Kusto Query Language.\nYou should familiarize yourself with the analytics rule wizard and all the configuration options that are available. For more information, see\nScheduled analytics rules in Microsoft Sentinel\n.\nDesign and build your query\nBefore you do anything else, you should design and build a query in Kusto Query Language (KQL) that your rule will use to query one or more tables in your Log Analytics workspace.\nDetermine a data source, or a set of data sources, that you want to search to detect unusual or suspicious activity. Find the name of the Log Analytics table into which data from those sources is ingested. You can find the table name on the page of the data connector for that source. Use this table name (or a function based on it) as the basis for your query.\nDecide what kind of analysis you want this query to perform on the table. This decision determines which commands and functions you should use in the query.\nDecide which data elements (fields, columns) you want from the query results. This decision determines how you structure the output of the query.\nImportant\nMake sure that your query returns the\nTimeGenerated\ncolumn, as scheduled analytics rules use it as the reference for the lookback period. This means that the rule only evaluates records where the\nTimeGenerated\nvalue falls within the specified lookback window.\nBuild and test your queries in the\nLogs\nscreen. When you're satisfied, save the query for use in your rule.\nFor more information, see:\nBest practices for analytics rule queries\n.\nKusto Query Language in Microsoft Sentinel\nBest practices for Kusto Query Language queries\nCreate your analytics rule\nThis section describes how to create a rule by using the Azure or Defender portals.\nGet started creating a scheduled query rule\nTo get started, go to the\nAnalytics\npage in Microsoft Sentinel to create a scheduled analytics rule.\nFor Microsoft Sentinel in the\nDefender portal\n, select\nMicrosoft Sentinel\n>\nConfiguration\n>\nAnalytics\n. For Microsoft Sentinel in the\nAzure portal\n, under\nConfiguration\n, select\nAnalytics\n.\nSelect\n+Create\nand select\nScheduled query rule\n.\nDefender portal\nAzure portal\nName the rule and define general information\nIn the Azure portal, stages appear as tabs. In the Defender portal, they appear as milestones on a timeline.\nEnter the following information for your rule.\nField\nDescription\nName\nA unique name for your rule. This field supports plain text only. Any URLs included in the name should follow the\npercent-encoding format\nfor them to display properly.\nDescription\nA free-text description for your rule.\nIf Microsoft Sentinel is onboarded to the Defender portal, this field supports plain text only. Any URLs included in the description should follow the percent-encoding format for them to display properly.\nSeverity\nMatch the impact the activity triggering the rule might have on the target environment, if the rule is a true positive.\nInformational\n: No impact on your system, but the information might be indicative of future steps planned by a threat actor.\nLow\n: The immediate impact is minimal. A threat actor would likely need to conduct multiple steps before achieving an impact on an environment.\nMedium\n: The threat actor could have some impact on the environment with this activity, but it would be limited in scope or require additional activity.\nHigh\n: The activity identified provides the threat actor with wide ranging access to conduct actions on the environment or is triggered by impact on the environment.\nMITRE ATT&CK\nChoose those threat activities that apply to your rule. Select from among the\nMITRE ATT&CK\ntactics and techniques presented in the drop-down list. You can make multiple selections.\nFor more information on maximizing your coverage of the MITRE ATT&CK threat landscape, see\nUnderstand security coverage by the MITRE ATT&CKÂ® framework\n.\nStatus\nEnabled\n: The rule runs immediately upon creation, or at the\nspecific date and time you choose to schedule it (currently in PREVIEW)\n.\nDisabled\n: The rule is created but doesn't run. Enable it later from your\nActive rules\ntab when you need it.\nSelect\nNext: Set rule logic\n.\nDefender portal\nAzure portal\nDefine the rule logic\nThe next step is to set the rule logic, which includes adding the Kusto query that you created.\nEnter the rule query and alert enhancement configuration.\nSetting\nDescription\nRule query\nPaste the query you designed, built, and tested into the\nRule query\nwindow. Every change you make in this window is instantly validated, so if there are any mistakes, you see an indication right below the window.\nMap entities\nExpand\nEntity mapping\nand define up to 10 entity types recognized by Microsoft Sentinel onto fields in your query results. This mapping integrates the identified entities into the\nEntities\nfield in your alert schema\n.\nFor complete instructions on mapping entities, see\nMap data fields to entities in Microsoft Sentinel\n.\nSurface custom details in your alerts\nExpand\nCustom details\nand define any fields in your query results you want to surface in your alerts as custom details. These fields appear in any incidents that result as well.\nFor complete instructions on surfacing custom details, see\nSurface custom event details in alerts in Microsoft Sentinel\n.\nCustomize alert details\nExpand\nAlert details\nand customize otherwise-standard alert properties according to the content of various fields in each individual alert. For example, customize the alert name or description to include a username or IP address featured in the alert.\nFor complete instructions on customizing alert details, see\nCustomize alert details in Microsoft Sentinel\n.\nSchedule and scope the query.\nSet the following parameters in the\nQuery scheduling\nsection:\nSetting\nDescription / Options\nRun query every\nControls the\nquery interval\n: how often the query runs.\nAllowed range:\n5 minutes\nto\n14 days\n.\nLookup data from the last\nDetermines the\nlookback period\n: the time period covered by the query.\nAllowed range:\n5 minutes\nto\n14 days\n.\nMust be longer than or equal to the query interval.\nStart running\nAutomatically\n: The rule runs for the first time immediately upon being created, and after that at the query interval.\nAt specific time\n(Preview): Set a date and time for the rule to first run, after which it runs at the query interval.\nAllowed range:\n10 minutes\nto\n30 days\nafter the rule creation (or enablement) time.\nSet the threshold for creating alerts.\nUse the\nAlert threshold\nsection to define the sensitivity level of the rule. For example, set a minimum threshold of 100:\nSetting\nDescription\nGenerate alert when number of query results\nIs greater than\nNumber of events\n100\nIf you don't want to set a threshold, enter\n0\nin the number field.\nSet event grouping settings.\nUnder\nEvent grouping\n, choose one of two ways to handle the grouping of\nevents\ninto\nalerts\n:\nSetting\nBehavior\nGroup all events into a single alert\n(default)\nThe rule generates a single alert every time it runs, as long as the query returns more results than the specified\nalert threshold\nabove. This single alert summarizes all the events returned in the query results.\nTrigger an alert for each event\nThe rule generates a unique alert for each event returned by the query. This option is useful if you want events to be displayed individually, or if you want to group them by certain parametersâby user, hostname, or something else. You can define these parameters in the query.\nTemporarily suppress rule after an alert is generated.\nTo suppress a rule beyond its next run time if an alert is generated, turn the\nStop running query after alert is generated\nsetting\nOn\n. If you turn this on, set\nStop running query for\nto the amount of time the query should stop running, up to 24 hours.\nSimulate the results of the query and logic settings.\nIn the\nResults simulation\narea, select\nTest with current data\nto see what your rule results would look like if it had been running on your current data. Microsoft Sentinel simulates running the rule 50 times on the current data, using the defined schedule, and shows you a graph of the results (log events). If you modify the query, select\nTest with current data\nagain to update the graph. The graph shows the number of results over the time period defined by the settings in the\nQuery scheduling\nsection.\nSelect\nNext: Incident settings\n.\nDefender portal\nAzure portal\nConfigure the incident creation settings\nIn the\nIncident settings\ntab, choose whether Microsoft Sentinel turns alerts into actionable incidents, and whether and how alerts are grouped together in incidents.\nEnable incident creation.\nIn the\nIncident settings\nsection,\nCreate incidents from alerts triggered by this analytics rule\nis set by default to\nEnabled\n, meaning that Microsoft Sentinel creates a single, separate incident from each alert triggered by the rule.\nIf you don't want this rule to create any incidents (for example, if this rule is just to collect information for subsequent analysis), set this option to\nDisabled\n.\nImportant\nIf you onboarded Microsoft Sentinel to the Microsoft Defender portal, leave this setting\nEnabled\n.\nIn this scenario, Microsoft Defender XDR creates incidents, not Microsoft Sentinel.\nThese incidents appear in the incidents queue in both the Azure and Defender portals.\nIn the Azure portal, new incidents are displayed with \"Microsoft XDR\" as the\nincident provider name\n.\nIf you want a single incident to be created from a group of alerts, instead of one for every single alert, see the next step.\nSet alert grouping settings.\nIn the\nAlert grouping\nsection, if you want a single incident to be generated from a group of up to 150 similar or recurring alerts (see note), set\nGroup related alerts, triggered by this analytics rule, into incidents\nto\nEnabled\n, and set the following parameters.\nLimit the group to alerts created within the selected time frame\n: Set the time frame within which the similar or recurring alerts are grouped together. Alerts outside this time frame generate a separate incident or set of incidents.\nGroup alerts triggered by this analytics rule into a single incident by\n: Choose how alerts are grouped together:\nOption\nDescription\nGroup alerts into a single incident if all the entities match\nAlerts are grouped together if they share identical values for each of the mapped entities (defined in the\nSet rule logic\ntab above). This is the recommended setting.\nGroup all alerts triggered by this rule into a single incident\nAll the alerts generated by this rule are grouped together even if they share no identical values.\nGroup alerts into a single incident if the selected entities and details match\nAlerts are grouped together if they share identical values for all of the mapped entities, alert details, and custom details selected from the respective drop-down lists.\nRe-open closed matching incidents\n: If an incident is resolved and closed, and later on another alert is generated that should belong to that incident, set this setting to\nEnabled\nif you want the closed incident re-opened, and leave as\nDisabled\nif you want the alert to create a new incident.\nThis option isn't available when Microsoft Sentinel is onboarded to the Microsoft Defender portal.\nImportant\nIf you onboarded Microsoft Sentinel to the Microsoft Defender portal, the\nalert grouping\nsettings take effect only at the moment that the incident is created.\nBecause the Defender portal's correlation engine is responsible for alert correlation in this scenario, it accepts these settings as initial instructions, but it also might make decisions about alert correlation that don't take these settings into account.\nTherefore, the way alerts are grouped into incidents might often be different than you would expect based on these settings.\nNote\nUp to 150 alerts\ncan be grouped into a single incident.\nThe incident is only created after all the alerts are generated. All of the alerts are added to the incident immediately upon its creation.\nIf more than 150 alerts are generated by a rule that groups them into a single incident, a new incident is generated with the same incident details as the original, and the excess alerts are grouped into the new incident.\nSelect\nNext: Automated response\n.\nDefender portal\nAzure portal\nReview or add automated responses\nIn the\nAutomated responses\ntab, see the automation rules displayed in the list. If you want to add any responses that aren't already covered by existing rules, you have two choices:\nEdit an existing rule if you want the added response to apply to many or all rules.\nSelect\nAdd new\nto\ncreate a new automation rule\nthat applies only to this analytics rule.\nTo learn more about what you can use automation rules for, see\nAutomate threat response in Microsoft Sentinel with automation rules\n.\nUnder\nAlert automation (classic)\nat the bottom of the screen, you see any playbooks you configured to run automatically when an alert is generated by using the old method.\nAs of June 2023\n, you can't add playbooks to this list. Playbooks already listed here continue to run until this method is\ndeprecated, effective March 2026\n.\nIf you still have any playbooks listed here, create an automation rule based on the\nalert created trigger\nand invoke the playbook from the automation rule. After you complete that step, select the ellipsis at the end of the line of the playbook listed here, and select\nRemove\n. See\nMigrate your Microsoft Sentinel alert-trigger playbooks to automation rules\nfor full instructions.\nDefender portal\nAzure portal\nSelect\nNext: Review and create\nto review all the settings for your new analytics rule.\nValidate configuration and create the rule\nWhen the \"Validation passed\" message appears, select\nCreate\n.\nIf an error appears instead, find and select the red X on the tab in the wizard where the error occurred.\nCorrect the error and go back to the\nReview and create\ntab to run the validation again.\nDefender portal\nAzure portal\nView the rule and its output\nView the rule definition\nYou can find your newly created custom rule (of type \"Scheduled\") in the table under the\nActive rules\ntab on the main\nAnalytics\nscreen. From this list, you can enable, disable, or delete each rule.\nView the results of the rule\nDefender portal\nAzure portal\nTo view the results of the analytics rules you create in the Defender portal, expand\nInvestigation & response\nin the navigation menu, then\nIncidents & alerts\n. View incidents on the\nIncidents\npage, where you can triage incidents,\ninvestigate them\n, and\nremediate the threats\n. View individual alerts on the\nAlerts\npage.\nTo view the results of the analytics rules you create in the Azure portal, go to the\nIncidents\npage, where you can triage incidents,\ninvestigate them\n, and\nremediate the threats\n.\nTune the rule\nYou can update the rule query to exclude false positives. For more information, see\nHandle false positives in Microsoft Sentinel\n.\nNote\nAlerts generated in Microsoft Sentinel are available through\nMicrosoft Graph Security\n. For more information, see the\nMicrosoft Graph Security alerts documentation\n.\nExport the rule to an ARM template\nIf you want to package your rule to be managed and deployed as code, you can easily\nexport the rule to an Azure Resource Manager (ARM) template\n. You can also import rules from template files in order to view and edit them in the user interface.\nNext steps\nWhen using analytics rules to detect threats from Microsoft Sentinel, make sure you enable all rules associated with your connected data sources to ensure full security coverage for your environment.\nTo automate rule enablement, push rules to Microsoft Sentinel via\nAPI\nand\nPowerShell\n, although doing so requires extra effort. When using API or PowerShell, you must first export the rules to JSON before enabling the rules. API or PowerShell might be helpful when enabling rules in multiple instances of Microsoft Sentinel with identical settings in each instance.\nFor more information, see:\nTroubleshooting analytics rules in Microsoft Sentinel\nNavigate and investigate incidents in Microsoft Sentinel\nEntities in Microsoft Sentinel\nTutorial: Use playbooks with automation rules in Microsoft Sentinel\nAlso, learn from an example of using custom analytics rules when\nmonitoring Zoom\nwith a\ncustom connector\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Custom Analytics Rules",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/sentinel/detect-threats-built-in": {
      "content_hash": "sha256:35749b5e89f47fb087d35133b7e223ec656243f9631e0878f046de44bc2dec3a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nThreat detection in Microsoft Sentinel\nFeedback\nSummarize this article for me\nImportant\nCustom detections\nis now the best way to create new rules across Microsoft Sentinel SIEM Microsoft Defender XDR. With custom detections, you can reduce ingestion costs, get unlimited real-time detections, and benefit from seamless integration with Defender XDR data, functions, and remediation actions with automatic entity mapping. For more information, read\nthis blog\n.\nAfter\nsetting up Microsoft Sentinel to collect data from all over your organization\n, you need to constantly dig through all that data to detect security threats to your environment. To accomplish this task, Microsoft Sentinel provides threat detection rules that run regularly, querying the collected data and analyzing it to discover threats. These rules come in a few different flavors and are collectively known as\nanalytics rules\n.\nThese rules generate\nalerts\nwhen they find what theyâre looking for. Alerts contain information about the events detected, such as the\nentities\n(users, devices, addresses, and other items) involved. Alerts are aggregated and correlated into\nincidents\nâcase filesâthat you can\nassign and investigate\nto learn the full extent of the detected threat and respond accordingly. You can also build predetermined, automated responses into the rules' own configuration.\nYou can create these rules from scratch, using the\nbuilt-in analytics rule wizard\n. However, Microsoft strongly encourages you to make use of the vast array of\nanalytics rule templates\navailable to you through the many\nsolutions for Microsoft Sentinel\nprovided in the content hub. These templates are pre-built rule prototypes, designed by teams of security experts and analysts based on their knowledge of known threats, common attack vectors, and suspicious activity escalation chains. You activate rules from these templates to automatically search across your environment for any activity that looks suspicious. Many of the templates can be customized to search for specific types of events, or filter them out, according to your needs.\nThis article helps you understand how Microsoft Sentinel detects threats, and what happens next.\nImportant\nMicrosoft Sentinel is generally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license.\nStarting in\nJuly 2026\n, all customers using Microsoft Sentinel in the Azure portal will be\nredirected to the Defender portal and will use Microsoft Sentinel in the Defender portal only\n. Starting in\nJuly 2025\n, many new customers are\nautomatically onboarded and redirected to the Defender portal\n.\nIf you're still using Microsoft Sentinel in the Azure portal, we recommend that you start planning your\ntransition to the Defender portal\nto ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n. For more information, see\nItâs Time to Move: Retiring Microsoft Sentinelâs Azure portal for greater security\n.\nTypes of analytics rules\nYou can view the analytics rules and templates available for you to use on the\nAnalytics\npage of the\nConfiguration\nmenu in Microsoft Sentinel. The currently\nactive rules\nare visible in one tab, and\ntemplates\nto create new rules in another tab. A third tab displays\nAnomalies\n, a special rule type described later in this article.\nTo find more rule templates than are currently displayed, go to the\nContent hub\nin Microsoft Sentinel to install the related product solutions or standalone content. Analytics rule templates are available with nearly every product solution in the content hub.\nThe following types of analytics rules and rule templates are available in Microsoft Sentinel:\nScheduled rules\nNear-real-time (NRT) rules\nAnomaly rules\nMicrosoft security rules\nBesides the preceding rule types, there are some other specialized template types that can each create one instance of a rule, with limited configuration options:\nThreat intelligence\nAdvanced multistage attack detection (\"Fusion\")\nMachine learning (ML) behavior analytics\nScheduled rules\nBy far the most common type of analytics rule,\nScheduled\nrules are based on\nKusto queries\nthat are configured to run at regular intervals and examine raw data from a defined \"lookback\" period. If the number of results captured by the query passes the threshold configured in the rule, the rule produces an alert.\nThe queries in\nscheduled rule templates\nwere written by security and data science experts, either from Microsoft or from the vendor of the solution providing the template. Queries can perform complex statistical operations on their target data, revealing baselines and outliers in groups of events.\nThe query logic is displayed in the rule configuration. You can use the query logic and the scheduling and lookback settings as defined in the template, or customize them to create new rules. Alternatively, you can create\nentirely new rules from scratch\n.\nLearn more about\nScheduled analytics rules in Microsoft Sentinel\n.\nNear-real-time (NRT) rules\nNRT rules are a limited subset of\nscheduled rules\n. They are designed to run once every minute, in order to supply you with information as up-to-the-minute as possible.\nThey function mostly like scheduled rules and are configured similarly, with some limitations.\nLearn more about\nQuick threat detection with near-real-time (NRT) analytics rules in Microsoft Sentinel\n.\nAnomaly rules\nAnomaly rules use machine learning to observe specific types of behaviors over a period of time to determine a baseline. Each rule has its own unique parameters and thresholds, appropriate to the behavior being analyzed. After the observation period is completed, the baseline is set. When the rule observes behaviors that exceed the boundaries set in the baseline, it flags those occurrences as anomalous.\nWhile the configurations of out-of-the-box rules can't be changed or fine-tuned, you can duplicate a rule, and then change and fine-tune the duplicate. In such cases, run the duplicate in\nFlighting\nmode and the original concurrently in\nProduction\nmode. Then compare results, and switch the duplicate to\nProduction\nif and when its fine-tuning is to your liking.\nAnomalies don't necessarily indicate malicious or even suspicious behavior by themselves. Therefore, anomaly rules don't generate their own alerts. Rather, they record the results of their analysisâthe detected anomaliesâin the\nAnomalies\ntable. You can query this table to provide context that improves your detections, investigations, and threat hunting.\nFor more information, see\nUse customizable anomalies to detect threats in Microsoft Sentinel\nand\nWork with anomaly detection analytics rules in Microsoft Sentinel\n.\nMicrosoft security rules\nWhile scheduled and NRT rules automatically create incidents for the alerts they generate, alerts generated in external services and ingested to Microsoft Sentinel don't create their own incidents. Microsoft security rules automatically create Microsoft Sentinel incidents from the alerts generated in other Microsoft security solutions, in real time. You can use Microsoft security templates to create new rules with similar logic.\nImportant\nMicrosoft security rules are\nnot available\nif you have:\nEnabled\nMicrosoft Defender XDR incident integration\n, or\nOnboarded Microsoft Sentinel to the\nDefender portal\n.\nIn these scenarios, Microsoft Defender XDR creates the incidents instead.\nAny such rules you had defined beforehand are automatically disabled.\nFor more information about\nMicrosoft security\nincident creation rules, see\nAutomatically create incidents from Microsoft security alerts\n.\nThreat intelligence\nTake advantage of threat intelligence produced by Microsoft to generate high fidelity alerts and incidents with the\nMicrosoft Threat Intelligence Analytics\nrule. This unique rule isn't customizable, but when enabled, automatically matches Common Event Format (CEF) logs, Syslog data or Windows DNS events with domain, IP and URL threat indicators from Microsoft Threat Intelligence. Certain indicators contain more context information through MDTI (\nMicrosoft Defender Threat Intelligence\n).\nFor more information on how to enable this rule, see\nUse matching analytics to detect threats\n.\nFor more information on MDTI, see\nWhat is Microsoft Defender Threat Intelligence\n.\nAdvanced multistage attack detection (Fusion)\nMicrosoft Sentinel uses the\nFusion correlation engine\n, with its scalable machine learning algorithms, to detect advanced multistage attacks by correlating many low-fidelity alerts and events across multiple products into high-fidelity and actionable incidents. The\nAdvanced multistage attack detection\nrule is enabled by default. Because the logic is hidden and therefore not customizable, there can be only one rule with this template.\nThe Fusion engine can also correlate alerts produced by\nscheduled analytics rules\nwith alerts from other systems, producing high-fidelity incidents as a result.\nImportant\nThe\nAdvanced multistage attack detection\nrule type is\nnot available\nif you have:\nEnabled\nMicrosoft Defender XDR incident integration\n, or\nOnboarded Microsoft Sentinel to the\nDefender portal\n.\nIn these scenarios, Microsoft Defender XDR creates the incidents instead.\nAlso, some of the\nFusion\ndetection templates are currently in\nPREVIEW\n(see\nAdvanced multistage attack detection in Microsoft Sentinel\nto see which ones). See the\nSupplemental Terms of Use for Microsoft Azure Previews\nfor additional legal terms that apply to Azure features that are in beta, preview, or otherwise not yet released into general availability.\nMachine learning (ML) behavior analytics\nTake advantage of Microsoft's proprietary machine learning algorithms to generate high fidelity alerts and incidents with the\nML Behavior Analytics\nrules. These unique rules (currently in\nPreview\n) aren't customizable, but when enabled, detect specific anomalous SSH and RDP login behaviors based on IP and geolocation and user history information.\nAccess permissions for analytics rules\nWhen you create an analytics rule, an access permissions token is applied to the rule and saved along with it. This token ensures that the rule can access the workspace that contains the data queried by the rule, and that this access is maintained even if the rule's creator loses access to that workspace.\nThere is one exception to this access, however: when a rule is created to access workspaces in other subscriptions or tenants, such as what happens in the case of an MSSP, Microsoft Sentinel takes extra security measures to prevent unauthorized access to customer data. For these kinds of rules, the credentials of the user that created the rule are applied to the rule instead of an independent access token, so that when the user no longer has access to the other subscription or tenant, the rule stops working.\nIf you operate Microsoft Sentinel in a cross-subscription or cross-tenant scenario, when one of your analysts or engineers loses access to a particular workspace, any rules created by that user stops working. In this situation, you get a health monitoring message regarding \"insufficient access to resource\", and the rule is\nauto-disabled\nafter having failed a certain number of times.\nExport rules to an ARM template\nYou can easily\nexport your rule to an Azure Resource Manager (ARM) template\nif you want to manage and deploy your rules as code. You can also import rules from template files in order to view and edit them in the user interface.\nNext steps\nLearn more about\nScheduled analytics rules in Microsoft Sentinel\nand\nQuick threat detection with near-real-time (NRT) analytics rules in Microsoft Sentinel\n.\nTo find more rule templates, see\nDiscover and manage Microsoft Sentinel out-of-the-box content\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Built-in Analytics",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/sentinel/monitor-your-data": {
      "content_hash": "sha256:767383d40f5774e24a33a6cc907f8d7205eb1a16069b3e0f188366650e6e6182",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nVisualize and monitor your data by using workbooks in Microsoft Sentinel\nFeedback\nSummarize this article for me\nAfter you connect your data sources to Microsoft Sentinel, visualize and monitor the data using workbooks in Microsoft Sentinel. Microsoft Sentinel workbooks are based on Azure Monitor workbooks, and add tables and charts with analytics for your logs and queries to the tools already available in Azure.\nMicrosoft Sentinel allows you to create custom workbooks across your data or use existing workbook templates available with packaged solutions or as standalone content from the content hub. Each workbook is an Azure resource like any other, and you can assign it with Azure role-based access control (RBAC) to define and limit who can access.\nThis article describes how to visualize your data in Microsoft Sentinel by using workbooks. Editing workbooks directly in the Defender portal is as Preview.\nImportant\nMicrosoft Sentinel is generally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license.\nStarting in\nJuly 2026\n, all customers using Microsoft Sentinel in the Azure portal will be\nredirected to the Defender portal and will use Microsoft Sentinel in the Defender portal only\n. Starting in\nJuly 2025\n, many new customers are\nautomatically onboarded and redirected to the Defender portal\n.\nIf you're still using Microsoft Sentinel in the Azure portal, we recommend that you start planning your\ntransition to the Defender portal\nto ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n. For more information, see\nItâs Time to Move: Retiring Microsoft Sentinelâs Azure portal for greater security\n.\nPrerequisites\nYou must have at least\nWorkbook reader\nor\nWorkbook contributor\npermissions on the resource group of the Microsoft Sentinel workspace.\nThe workbooks that you see in Microsoft Sentinel are saved within the Microsoft Sentinel workspace's resource group and are tagged by the workspace in which they were created.\nTo use a workbook template, install the solution that contains the workbook or install the workbook as a standalone item from the\nContent Hub\n. For more information, see\nDiscover and manage Microsoft Sentinel out-of-the-box content\n.\nIf you're working in the Defender portal with an Azure Data Explorer data source, make sure to configure and authenticate to Azure Data Explorer from the Defender portal.\nCreate a workbook from a template\nUse a template installed from the content hub to create a workbook.\nIn Microsoft Sentinel, select\nThreat management > Workbooks\n.\nOn the\nWorkbooks\npage, select the\nTemplates\ntab to see the list of workbook templates installed. Select a template to view its details.\nSome workbooks require specific data connections to function. Before saving a workbook, check for a\nRequired data types\nfield ensure that you have that type of data ingested.\nFor example:\nDefender portal\nAzure portal\nFrom the details pane, select\nSave\n, and then select the location where you want to save the workbook. This action creates an Azure resource in the selected location based on the relevant template. Only the workbook's JSON file is saved in this location, and no data.\nFrom the details pane, select\nView saved workbook\nto open it for editing.\nWith the workbook open, select\nEdit\nto customize the workbook according to your needs.\nDefender portal\nAzure portal\nWhen working in the Defender portal, some visualizations can only be viewed in the Azure portal. In such cases, select\nOpen in Azure\nto open the workbook in the Azure portal.\nFor example, select the\nTimeRange\nfilter to view data for a different time range than the current selection. To edit a specific workbook area, either select\nEdit\nor select the ellipsis (\n...\n) to add elements, or move, clone, or remove the area.\nTo clone your workbook, select\nSave as\n. Save the clone with another name, under the same subscription and resource group. Cloned workbooks are also displayed under the\nMy workbooks\ntab in the\nMicrosoft Sentinel > Threat management > Workbooks\npage.\nWhen you're done, select\nDone Editing\nto save your changes.\nFor more information, see:\nCreate interactive reports with Azure Monitor Workbooks\nTutorial: Visual data in Log Analytics\nCreate new workbook\nCreate a workbook from scratch in Microsoft Sentinel.\nIn Microsoft Sentinel, select\nThreat management > Workbooks\n, and then select\nAdd workbook\n.\nTo edit the workbook, select\nEdit\n, and then add text, queries, and parameters as necessary.\nFor more information on how to customize the workbook, see how to\nCreate interactive reports with Azure Monitor Workbooks\n.\nWhen building a query, set the\nData source\nto\nLogs\nand\nResource type\nto\nLog Analytics\n, and then choose one or more workspaces.\nWe recommend that your query uses an\nAdvanced Security Information Model (ASIM) parser\nand not a built-in table. The query will then support any current or future relevant data source rather than a single data source.\nWhen you're done with your edits, select\nDone editing\nand then\nSave\n. In the side pane, enter a meaningful name for your workbook, and select the subscription and resource group for your workspace.\nWhen working in the Azure portal, switch between workbooks in your workspace by selecting\nOpen\nin the toolbar of any workbook. The screen switches to a list of other workbooks you can switch to.\nSelect the workbook you want to open:\nCreate new tiles for your workbooks\nTo add a custom tile to a Microsoft Sentinel workbook, first create the tile in Log Analytics. For more information, see\nVisual data in Log Analytics\n.\nOnce you create a tile, select\nPin\nand then select the workbook where you want the tile to appear.\nRefresh your workbook data\nRefresh your workbook to display updated data. In the toolbar, select one of the following options:\nRefresh\n, to manually refresh your workbook data.\nAuto refresh\n, to set your workbook to automatically refresh at a configured interval.\nSupported auto refresh intervals range from\n5 minutes\nto\n1 day\n.\nAuto refresh is paused while you're editing a workbook, and intervals are restarted each time you switch back to view mode from edit mode.\nAuto refresh intervals are also restarted if you manually refresh your data.\nBy default, auto refresh is turned off. If you've turned auto-refresh on, it's turned off again each time you close the notebook to optimize perforamnce and prevent it from running in the background. Turn auto refresh back on as needed the next time you open the workbook.\nPrint a workbook or save as PDF (Azure portal only)\nTo print a workbook, or save it as a PDF, use the options menu to the right of the workbook title. These options are available only in the Azure portal. If you're working in the Defender portal, select\nOpen in Azure\nto open the workbook in the Azure portal.\nSelect options >\nPrint content\n.\nIn the print screen, adjust your print settings as needed or select\nSave as PDF\nto save it locally.\nFor example:\nDelete one or more workbooks\nYou can delete both saved templates and customized workbooks from the\nMy workbooks\ntab. Templates themselves can't be deleted.\nTo delete a workbook, select the workbook in the\nMy workbooks\ntab, and then select\nDelete\n. This action removes the workbook resource and any changes you made to the template. The original template remains available.\nWorkbook recommendations\nThis section reviews basic recommendations we have for using workbooks with Microsoft Sentinel.\nAdd Microsoft Entra ID workbooks\nIf you use Microsoft Entra ID with Microsoft Sentinel, we recommend that you install the Microsoft Entra solution for Microsoft Sentinel and use the following workbooks:\nMicrosoft Entra sign-ins\nanalyzes sign-ins over time to see if there are anomalies. This workbook provides failed sign-ins by applications, devices, and locations so that you can notice, at a glance if something unusual happens. Pay attention to multiple failed sign-ins.\nMicrosoft Entra audit logs\nanalyzes admin activities, such as changes in users (add, remove, etc.), group creation, and modifications.\nAdd firewall workbooks\nWe recommend that you install the appropriate solution from the\nContent hub\nto add a workbook for your firewall.\nFor example, install the Palo Alto firewall solution for Microsoft Sentinel to add the Palo Alto workbooks. The workbooks analyze your firewall traffic, providing you with correlations between your firewall data and threat events, and highlight suspicious events across entities.\nCreate different workbooks for different uses\nWe recommend creating different visualizations for each type of persona that uses workbooks, based on the persona's role and what they're looking for. For example, create a workbook for your network admin that includes the firewall data.\nAlternately, create workbooks based on how frequently you want to look at them, whether there are things you want to review daily, and others items you want to check once an hour. For example, you might want to look at your Microsoft Entra sign-ins every hour to search for anomalies.\nSample query for comparing traffic trends across weeks\nUse the following query to create a visualization that compares traffic trends across weeks. Switch the device vendor and data source you run the query on, depending on your environment.\nThe following sample query uses the\nSecurityEvent\ntable from Windows. You might want to switch it to run on the\nAzureActivity\nor\nCommonSecurityLog\ntable, on any other firewall.\n// week over week query\nSecurityEvent\n| where TimeGenerated > ago(14d)\n| summarize count() by bin(TimeGenerated, 1d)\n| extend Week = iff(TimeGenerated>ago(7d), \"This Week\", \"Last Week\"), TimeGenerated = iff(TimeGenerated>ago(7d), TimeGenerated, TimeGenerated + 7d)\nSample query with data from multiple sources\nYou might want to create a query that incorporates data from multiples sources. For example, create a query that looks at Microsoft Entra audit logs for new users that were created, and then checks your Azure logs to see if the user started making role assignment changes within 24 hours of creation. That suspicious activity would show up in a visualization with the following query:\nAuditLogs\n| where OperationName == \"Add user\"\n| project AddedTime = TimeGenerated, user = tostring(TargetResources[0].userPrincipalName)\n| join (AzureActivity\n| where OperationName == \"Create role assignment\"\n| project OperationName, RoleAssignmentTime = TimeGenerated, user = Caller) on user\n| project-away user1\nSee more information on the following items used in the preceding examples, in the Kusto documentation:\nwhere\noperator\nextend\noperator\nproject\noperator\nproject-away\noperator\njoin\noperator\nsummarize\noperator\nago()\nfunction\nbin()\nfunction\niff()\nfunction\ntostring()\nfunction\ncount()\naggregation function\nFor more information on KQL, see\nKusto Query Language (KQL) overview\n.\nOther resources:\nKQL quick reference\nKusto Query Language learning resources\nKnown issues for editing workbooks in the Defender portal (Preview)\nEditing workbooks directly in the Defender portal is currently in Preview, and currently includes the following known issues:\nThe advanced editor might show up in light mode, even if your portal is set to dark mode.\nCustom endpoint data isn't supported for editing workbooks in the Defender portal.\nWorkbooks within workbooks aren't supported for editing in the Defender portal.\nRead-only sharing isn't supported for workbooks in the Defender portal.\nMermaid diagrams aren't supported for editing workbooks in the Defender portal.\nRelated articles\nFor more information, see:\nCommonly used Microsoft Sentinel workbooks\nAzure Monitor workbooks\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Workbooks",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/sentinel/automate-incident-handling-with-automation-rules": {
      "content_hash": "sha256:96538528884348e863ee76c4620a2c9bf8618c35feb8d1ad1028c5850a2d119d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAutomate threat response in Microsoft Sentinel with automation rules\nFeedback\nSummarize this article for me\nThis article explains what Microsoft Sentinel automation rules are, and how to use them to implement your Security Orchestration, Automation and Response (SOAR) operations. Automation rules increase your SOC's effectiveness and save you time and resources.\nImportant\nMicrosoft Sentinel is generally available in the Microsoft Defender portal\n, including for customers without Microsoft Defender XDR or an E5 license.\nStarting in\nJuly 2026\n, all customers using Microsoft Sentinel in the Azure portal will be\nredirected to the Defender portal and will use Microsoft Sentinel in the Defender portal only\n. Starting in\nJuly 2025\n, many new customers are\nautomatically onboarded and redirected to the Defender portal\n.\nIf you're still using Microsoft Sentinel in the Azure portal, we recommend that you start planning your\ntransition to the Defender portal\nto ensure a smooth transition and take full advantage of the\nunified security operations experience offered by Microsoft Defender\n. For more information, see\nItâs Time to Move: Retiring Microsoft Sentinelâs Azure portal for greater security\n.\nWhat are automation rules?\nAutomation rules are a way to centrally manage automation in Microsoft Sentinel, by allowing you to define and coordinate a small set of rules that can apply across different scenarios.\nAutomation rules apply to the following categories of use cases:\nPerform basic automation tasks for incident handling without using playbooks. For example:\nAdd incident tasks\nfor analysts to follow.\nSuppress noisy incidents.\nTriage new incidents by changing their status from New to Active and assigning an owner.\nTag incidents to classify them.\nEscalate an incident by assigning a new owner.\nClose resolved incidents, specifying a reason and adding comments.\nAutomate responses for multiple analytics rules at once.\nControl the order of actions that are executed.\nInspect the contents of an incident (alerts, entities, and other properties) and take further action by calling a playbook.\nAutomation rules can also be the mechanism by which you run a playbook in response to an\nalert\nnot associated with an incident\n.\nIn short, automation rules streamline the use of automation in Microsoft Sentinel, enabling you to simplify complex workflows for your threat response orchestration processes.\nComponents\nAutomation rules are made up of several components:\nTriggers\nthat define what kind of incident event causes the rule to run, subject to\nconditions\n.\nConditions\nthat determine the exact circumstances under which the rule runs and performs\nactions\n.\nActions\nto change the incident in some way or call a\nplaybook\n, which performs more complex actions and interacts with other services.\nTriggers\nAutomation rules are triggered\nwhen an incident is created or updated\nor\nwhen an alert is created\n. Recall that incidents include alerts, and that both alerts and incidents can be created by analytics rules, as explained in\nThreat detection in Microsoft Sentinel\n.\nThe following table shows the different possible scenarios that cause an automation rule to run.\nTrigger type\nEvents that cause the rule to run\nWhen incident is created\nMicrosoft Defender portal:\nA new incident is created in the Microsoft Defender portal.\nMicrosoft Sentinel not onboarded to the Defender portal:\nA new incident is created by an analytics rule.\nAn incident is ingested from Microsoft Defender XDR.\nA new incident is created manually.\nWhen incident is updated\nAn incident's status is changed (closed/reopened/triaged).\nAn incident's owner is assigned or changed.\nAn incident's severity is raised or lowered.\nAlerts are added to an incident.\nComments, tags, or tactics are added to an incident.\nWhen alert is created\nAn alert is created by a Microsoft Sentinel\nScheduled\nor\nNRT\nanalytics rule.\nIncident-based or alert-based automation?\nWith automation rules centrally handling the response to both incidents and alerts, how should you choose which to automate, and in which circumstances?\nFor most use cases,\nincident-triggered automation\nis the preferable approach. In Microsoft Sentinel, an\nincident\nis a âcase fileâ â an aggregation of all the relevant evidence for a specific investigation. Itâs a container for alerts, entities, comments, collaboration, and other artifacts. Unlike\nalerts\nwhich are single pieces of evidence, incidents are modifiable, have the most updated status, and can be enriched with comments, tags, and bookmarks. The incident allows you to track the attack story that keeps evolving with the addition of new alerts.\nFor these reasons, it makes more sense to build your automation around incidents. So the most appropriate way to create playbooks is to base them on the Microsoft Sentinel incident trigger in Azure Logic Apps.\nThe main reason to use\nalert-triggered automation\nis for responding to alerts generated by analytics rules that\ndo not create incidents\n(that is, where incident creation is\ndisabled\nin the\nIncident settings\ntab of the\nanalytics rule wizard\n).\nThis reason is especially relevant when your Microsoft Sentinel workspace is onboarded to the Defender portal. In this scenario, all incident creation happens in the Defender portal, and therefore the incident creation rules in Microsoft Sentinel\nmust be disabled\n.\nEven without being onboarded to the unified portal, you might anyway decide to use alert-triggered automation if you want to use other external logic to decide if and when to create incidents from alerts, and how alerts are grouped together. For example:\nA playbook, triggered by an alert that doesnât have an associated incident, can enrich the alert with information from other sources, and based on some external logic decide whether to create an incident or not.\nA playbook, triggered by an alert, can, instead of creating an incident, look for an appropriate existing incident to add the alert to. Learn more about\nincident expansion\n.\nA playbook, triggered by an alert, can notify SOC personnel of the alert so the team can decide whether or not to create an incident.\nA playbook, triggered by an alert, can send the alert to an external ticketing system for incident creation and management, and that system creates a new ticket for each alert.\nNote\nAlert-triggered automation is available only for alerts created by\nScheduled\n,\nNRT\n, and\nMicrosoft security\nanalytics rules\n.\nAlert-triggered automation for alerts created by Microsoft Defender XDR is not available in the Defender portal. For more information, see\nAutomation in the Defender portal\n.\nConditions\nComplex sets of conditions can be defined to govern when actions (see below) should run. These conditions include the event that triggers the rule (incident created or updated, or alert created), the states or values of the incident's properties and\nentity properties\n(for incident trigger only), and also the analytics rule or rules that generated the incident or alert.\nWhen an automation rule is triggered, it checks the triggering incident or alert against the conditions defined in the rule. For incidents, the property-based conditions are evaluated according to\nthe current state\nof the property at the moment the evaluation occurs, or according to\nchanges in the state\nof the property (see below for details). Since a single incident creation or update event could trigger several automation rules, the\norder\nin which they run (see below) makes a difference in determining the outcome of the conditions' evaluation. The\nactions\ndefined in the rule are executed only if all the conditions are satisfied.\nIncident create trigger\nFor rules defined using the trigger\nWhen an incident is created\n, you can define conditions that check the\ncurrent state\nof the values of a given list of incident properties, using one or more of the following operators:\nequals\nor\ndoes not equal\nthe value defined in the condition.\ncontains\nor\ndoes not contain\nthe value defined in the condition.\nstarts with\nor\ndoes not start with\nthe value defined in the condition.\nends with\nor\ndoes not end with\nthe value defined in the condition.\nFor example, if you define\nAnalytic rule name\nas\nContains == Brute force attack against a Cloud PC\n, an analytic rule with the\nBrute force attack against Azure portal\ndoesn't meet the condition. However, if you define\nAnalytic rule name\nas\nDoes not contain == User credentials\n, then both the\nBrute force attack against a Cloud PC\nand\nBrute force against Azure portal\nanalytics rules meet the condition.\nNote\nThe\ncurrent state\nin this context refers to the moment the condition is evaluated - that is, the moment the automation rule runs. If more than one automation rule is defined to run in response to the creation of this incident, then changes made to the incident by an earlier-run automation rule are considered the current state for later-run rules.\nIncident update trigger\nThe conditions evaluated in rules defined using the trigger\nWhen an incident is updated\ninclude all of those listed for the incident creation trigger. But the update trigger includes more properties that can be evaluated.\nOne of these properties is\nUpdated by\n. This property lets you track the type of source that made the change in the incident. You can create a condition evaluating whether the incident was updated by one of the following values, depending on whether you onboarded your workspace to the Defender portal:\nOnboarded workspaces\nWorkspaces not onboarded\nAn application, including applications in both the Azure and Defender portals.\nA user, including changes made by users in both the Azure and Defender portals.\nAIR\n, for updates by\nautomated investigation and response in Microsoft Defender for Office 365\nAn alert grouping (that added alerts to the incident), including alert groupings that were done both by analytics rules and built-in Microsoft Defender XDR correlation logic\nA playbook\nAn automation rule\nOther, if none of the above values apply\nAn application\nA Microsoft Sentinel user\nAn alert grouping done by analytics rules (that added alerts to the incident).\nA playbook\nAn automation rule\nMicrosoft Defender XDR\nUsing this condition, for example, you can instruct this automation rule to run on any change made to an incident, except if it was made by another automation rule.\nMore to the point, the update trigger also uses other operators that check\nstate changes\nin the values of incident properties as well as their current state. A\nstate change\ncondition would be satisfied if:\nAn incident property's value was\nchanged\n(regardless of the actual value before or after).\nchanged from\nthe value defined in the condition.\nchanged to\nthe value defined in the condition.\nadded\nto (this applies to properties with a list of values).\nTag\nproperty: individual vs. collection\nThe incident property\nTag\nis a collection of individual itemsâa single incident can have multiple tags applied to it. You can define conditions that check\neach tag in the collection individually\n, and conditions that check\nthe collection of tags as a unit\n.\nAny individual tag\noperators check the condition against every tag in the collection. The evaluation is\ntrue\nwhen\nat least one tag\nsatisfies the condition.\nCollection of all tags\noperators check the condition against the collection of tags as a single unit. The evaluation is\ntrue\nonly if\nthe collection as a whole\nsatisfies the condition.\nThis distinction matters when your condition is a negative (does not contain), and some tags in the collection satisfy the condition and others don't.\nLet's look at an example where your condition is,\nTag does not contain \"2024\"\n, and you have two incidents, each with two tags:\n\\ Incidents â¶\nCondition â¼ \\\nIncident 1\nTag 1: 2024\nTag 2: 2023\nIncident 2\nTag 1: 2023\nTag 2: 2022\nAny individual tag\ndoes not contain \"2024\"\nTRUE\nTRUE\nCollection of all tags\ndoes not contain \"2024\"\nFALSE\nTRUE\nIn this example, in\nIncident 1\n:\nIf the condition checks each tag individually, then since there's at least one tag that\nsatisfies the condition\n(that\ndoesn't\ncontain \"2024\"), the overall condition is\ntrue\n.\nIf the condition checks all the tags in the incident as a single unit, then since there's at least one tag that\ndoesn't satisfy the condition\n(that\ndoes\ncontain \"2024\"), the overall condition is\nfalse\n.\nIn\nIncident 2\n, the outcome is the same, regardless of which type of condition is defined.\nSupported entity properties\nFor the list of entity properties supported as conditions for automation rules, see\nMicrosoft Sentinel automation rules reference\n.\nAlert create trigger\nCurrently the only condition that can be configured for the alert creation trigger is the set of analytics rules for which the automation rule is run.\nActions\nActions can be defined to run when the conditions (see above) are met. You can define many actions in a rule, and you can choose the order in which they run (see below). The following actions can be defined using automation rules, without the need for the\nadvanced functionality of a playbook\n:\nAdding a task to an incident â you can create a\nchecklist of tasks for analysts to follow\nthroughout the processes of triage, investigation, and remediation of the incident, to ensure that no critical steps are missed.\nChanging the status of an incident, keeping your workflow up to date.\nWhen changing to âclosed,â specifying the\nclosing reason\nand adding a comment. This helps you keep track of your performance and effectiveness, and fine-tune to reduce\nfalse positives\n.\nChanging the severity of an incident â you can reevaluate and reprioritize based on the presence, absence, values, or attributes of entities involved in the incident.\nAssigning an incident to an owner â this helps you direct types of incidents to the personnel best suited to deal with them, or to the most available personnel.\nAdding a tag to an incident â this is useful for classifying incidents by subject, by attacker, or by any other common denominator.\nAlso, you can define an action to\nrun a playbook\n, in order to take more complex response actions, including any that involve external systems. The playbooks available to be used in an automation rule depend on the\ntrigger\non which the playbooks\nand\nthe automation rule are based: Only incident-trigger playbooks can be run from incident-trigger automation rules, and only alert-trigger playbooks can be run from alert-trigger automation rules. You can define multiple actions that call playbooks, or combinations of playbooks and other actions. Actions are executed in the order in which they are listed in the rule.\nPlaybooks using\neither version of Azure Logic Apps (Standard or Consumption)\nare available to run from automation rules.\nExpiration date\nYou can define an expiration date on an automation rule. The rule is disabled after that date passes. This is useful for handling (that is, closing) \"noise\" incidents caused by planned, time-limited activities such as penetration testing.\nOrder\nYou can define the order in which automation rules are run. Later automation rules evaluate the conditions of the incident according to its state after being acted on by previous automation rules.\nFor example, if \"First Automation Rule\" changed an incident's severity from Medium to Low, and \"Second Automation Rule\" is defined to run only on incidents with Medium or higher severity, it doesn't run on that incident.\nThe order of automation rules that add\nincident tasks\ndetermines the order in which the tasks appear in a given incident.\nRules based on the update trigger have their own separate order queue. If such rules are triggered to run on a just-created incident (by a change made by another automation rule), they run only after all the applicable rules based on the create trigger are finished running.\nNotes on execution order and priority\nSetting the\norder\nnumber in automation rules determines their order of execution.\nEach trigger type maintains its own queue.\nFor rules created in the Azure portal, the\norder\nfield is automatically populated with the number following the highest number used by existing rules of the same trigger type.\nHowever, for rules created in other ways (command line, API, etc.), the\norder\nnumber must be assigned manually.\nThere is no validation mechanism that prevents multiple rules from having the same order number, even within the same trigger type.\nYou can allow two or more rules of the same trigger type to have the same order number, if you don't care which order they run in.\nFor rules of the same trigger type with the same order number, the execution engine randomly selects which rules run in which order.\nFor rules of different\nincident trigger\ntypes, all applicable rules with the\nincident creation\ntrigger type run first (according to their order numbers), and only then the rules with the\nincident update\ntrigger type (according to\ntheir\norder numbers).\nRules always run sequentially, never in parallel.\nNote\nAfter onboarding to the Defender portal, if multiple changes are made to the same incident in a five to ten minute period, a single update is sent to Microsoft Sentinel, with only the most recent change.\nCommon use cases and scenarios\nIncident tasks\nAutomation rules allow you to standardize and formalize the steps required for the triaging, investigation, and remediation of incidents, by\ncreating tasks\nthat can be applied to a single incident, across groups of incidents, or to all incidents, according to the conditions you set in the automation rule and the threat detection logic in the underlying analytics rules. Tasks applied to an incident appear in the incident's page, so your analysts have the entire list of actions they need to take, right in front of them, and don't miss any critical steps.\nIncident- and alert-triggered automation\nAutomation rules can be triggered by the creation or updating of incidents and also by the creation of alerts. These occurrences can all trigger automated response chains, which can include playbooks (\nspecial permissions are required\n).\nTrigger playbooks for Microsoft providers\nAutomation rules provide a way to automate the handling of Microsoft security alerts by applying these rules to incidents created from the alerts. The automation rules can call playbooks (\nspecial permissions are required\n) and pass the incidents to them with all their details, including alerts and entities. In general, Microsoft Sentinel best practices dictate using the incidents queue as the focal point of security operations.\nMicrosoft security alerts include the following:\nMicrosoft Entra ID Protection\nMicrosoft Defender for Cloud\nMicrosoft Defender for Cloud Apps\nMicrosoft Defender for Office 365\nMicrosoft Defender for Endpoint\nMicrosoft Defender for Identity\nMicrosoft Defender for IoT\nMultiple sequenced playbooks/actions in a single rule\nYou can now have near-complete control over the order of execution of actions and playbooks in a single automation rule. You also control the order of execution of the automation rules themselves. This allows you to greatly simplify your playbooks, reducing them to a single task or a small, straightforward sequence of tasks, and combine these small playbooks in different combinations in different automation rules.\nAssign one playbook to multiple analytics rules at once\nIf you have a task you want to automate on all your analytics rules â say, the creation of a support ticket in an external ticketing system â you can apply a single playbook to any or all of your analytics rules â including any future rules â in one shot. This makes simple but repetitive maintenance and housekeeping tasks a lot less of a chore.\nAutomatic assignment of incidents\nYou can assign incidents to the right owner automatically. If your SOC has an analyst who specializes in a particular platform, any incidents relating to that platform can be automatically assigned to that analyst.\nIncident suppression\nYou can use rules to automatically resolve incidents that are known false/benign positives without the use of playbooks. For example, when running penetration tests, doing scheduled maintenance or upgrades, or testing automation procedures, many false-positive incidents might be created that the SOC wants to ignore. A time-limited automation rule can automatically close these incidents as they are created, while tagging them with a descriptor of the cause of their generation.\nTime-limited automation\nYou can add expiration dates for your automation rules. There might be cases other than incident suppression that warrant time-limited automation. You might want to assign a particular type of incident to a particular user (say, an intern or a consultant) for a specific time frame. If the time frame is known in advance, you can effectively cause the rule to be disabled at the end of its relevancy, without having to remember to do so.\nAutomatically tag incidents\nYou can automatically add free-text tags to incidents to group or classify them according to any criteria of your choosing.\nUse cases added by update trigger\nNow that changes made to incidents can trigger automation rules, more scenarios are open to automation.\nExtend automation when incident evolves\nYou can use the update trigger to apply many of the above use cases to incidents as their investigation progresses and analysts add alerts, comments, and tags. Control alert grouping in incidents.\nUpdate orchestration and notification\nNotify your various teams and other personnel when changes are made to incidents, so they don't miss any critical updates. Escalate incidents by assigning them to new owners and informing the new owners of their assignments. Control when and how incidents are reopened.\nMaintain synchronization with external systems\nIf you used playbooks to create tickets in external systems when incidents are created, you can use an update-trigger automation rule to call a playbook that updates those tickets.\nAutomation rules execution\nAutomation rules are run sequentially, according to the\norder\nyou\ndetermine\n. Each automation rule is executed after the previous one has finished its run. Within an automation rule, all actions are run sequentially in the order in which they are defined.\nPlaybook actions within an automation rule might be treated differently under some circumstances, according to the following criteria:\nPlaybook run time\nAutomation rule advances to the next action...\nLess than a second\nImmediately after playbook is completed\nLess than two minutes\nUp to two minutes after playbook began running,\nbut no more than 10 seconds after the playbook is completed\nMore than two minutes\nTwo minutes after playbook began running,\nregardless of whether or not it was completed\nPermissions for automation rules to run playbooks\nWhen a Microsoft Sentinel automation rule runs a playbook, it uses a special Microsoft Sentinel service account specifically authorized for this action. The use of this account (as opposed to your user account) increases the security level of the service.\nIn order for an automation rule to run a playbook, this account must be granted explicit permissions to the resource group where the playbook resides. At that point, any automation rule can run any playbook in that resource group.\nWhen you're configuring an automation rule and adding a\nrun playbook\naction, a drop-down list of playbooks appears. Playbooks to which Microsoft Sentinel does not have permissions display as unavailable (\"grayed out\"). You can grant Microsoft Sentinel permission to the playbooks' resource groups on the spot by selecting the\nManage playbook permissions\nlink. To grant those permissions, you need\nOwner\npermissions on those resource groups.\nSee the full permissions requirements\n.\nPermissions in a multitenant architecture\nAutomation rules fully support cross-workspace and\nmultitenant deployments\n(in the case of multitenant, using\nAzure Lighthouse\n).\nTherefore, if your Microsoft Sentinel deployment uses a multitenant architecture, you can have an automation rule in one tenant run a playbook that lives in a different tenant, but permissions for Sentinel to run the playbooks must be defined in the tenant where the playbooks reside, not in the tenant where the automation rules are defined.\nIn the specific case of a Managed Security Service Provider (MSSP), where a service provider tenant manages a Microsoft Sentinel workspace in a customer tenant, there are two particular scenarios that warrant your attention:\nAn automation rule created in the customer tenant is configured to run a playbook located in the service provider tenant.\nThis approach is normally used to protect intellectual property in the playbook. Nothing special is required for this scenario to work. When defining a playbook action in your automation rule, and you get to the stage where you grant Microsoft Sentinel permissions on the relevant resource group where the playbook is located (using the\nManage playbook permissions\npanel), you can see the resource groups belonging to the service provider tenant among those you can choose from.\nSee the whole process outlined here\n.\nAn automation rule created in the customer workspace (while signed into the service provider tenant) is configured to run a playbook located in the customer tenant\n.\nThis configuration is used when there is no need to protect intellectual property. For this scenario to work, permissions to execute the playbook need to be granted to Microsoft Sentinel in\nboth tenants\n. In the customer tenant, you grant them in the\nManage playbook permissions\npanel, just like in the scenario above. To grant the relevant permissions in the service provider tenant, you need to add an additional Azure Lighthouse delegation that grants access rights to the\nAzure Security Insights\napp, with the\nMicrosoft Sentinel Automation Contributor\nrole, on the resource group where the playbook resides.\nThe scenario looks like this:\nSee\nour instructions\nfor setting this up.\nCreating and managing automation rules\nYou can\ncreate and manage automation rules\nfrom different areas in Microsoft Sentinel or the Defender portal, depending on your particular need and use case.\nAutomation page\nAutomation rules can be centrally managed in the\nAutomation\npage, under the\nAutomation rules\ntab. From there, you can create new automation rules and edit the existing ones. You can also drag automation rules to change the order of execution, and enable or disable them.\nIn the\nAutomation\npage, you see all the rules that are defined on the workspace, along with their status (Enabled/Disabled) and which analytics rules they are applied to.\nWhen you need an automation rule that applies to incidents from Microsoft Defender XDR, or from many analytics rules in Microsoft Sentinel, create it directly in the\nAutomation\npage.\nAnalytics rule wizard\nIn the\nAutomated response\ntab of the Microsoft Sentinel analytics rule wizard, under\nAutomation rules\n, you can view, edit, and create automation rules that apply to the particular analytics rule being created or edited in the wizard.\nWhen you create an automation rule from here, the\nCreate new automation rule\npanel shows the\nanalytics rule\ncondition as unavailable, because this rule is already set to apply only to the analytics rule you're editing in the wizard. All the other configuration options are still available to you.\nIncidents page\nYou can also create an automation rule from the\nIncidents\npage, in order to respond to a single, recurring incident. This is useful when creating a\nsuppression rule\nfor\nautomatically closing \"noisy\" incidents\n.\nWhen you create an automation rule from here, the\nCreate new automation rule\npanel populates all the fields with values from the incident. It names the rule the same name as the incident, applies it to the analytics rule that generated the incident, and uses all the available entities in the incident as conditions of the rule. It also suggests a suppression (closing) action by default, and suggests an expiration date for the rule. You can add or remove conditions and actions, and change the expiration date, as you wish.\nExport and import automation rules\nExport your automation rules to Azure Resource Manager (ARM) template files, and import rules from these files, as part of managing and controlling your Microsoft Sentinel deployments as code. The export action creates a JSON file in your browser's downloads location, that you can then rename, move, and otherwise handle like any other file.\nThe exported JSON file is workspace-independent, so it can be imported to other workspaces and even other tenants. As code, it can also be version-controlled, updated, and deployed in a managed CI/CD framework.\nThe file includes all the parameters defined in the automation rule. Rules of any trigger type can be exported to a JSON file.\nFor instructions on exporting and importing automation rules, see\nExport and import Microsoft Sentinel automation rules\n.\nNext steps\nIn this document, you learned about how automation rules can help you to centrally manage response automation for Microsoft Sentinel incidents and alerts.\nCreate and use Microsoft Sentinel automation rules to manage incidents\n.\nUse automation rules to create lists of tasks for analysts\n.\nTo learn more about advanced automation options, see\nAutomate threat response with playbooks in Microsoft Sentinel\n.\nFor help with implementing playbooks, see\nTutorial: Use playbooks to automate threat responses in Microsoft Sentinel\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Automation Rules",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/sentinel/investigate-cases": {
      "content_hash": "sha256:a3cb34f3d0f5e2e80e449bd0802dcf8629b0ccb0b85703d85d3e9c3a3dfa7613",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nInvestigate incidents with Microsoft Sentinel (legacy)\nFeedback\nSummarize this article for me\nThis article helps you use Microsoft Sentinel's legacy incident investigation experience. If you're using the newer version of the interface, use the newer set of instructions to match. For more information, see\nNavigate and investigate incidents in Microsoft Sentinel\n.\nAfter connecting your data sources to Microsoft Sentinel, you want to be notified when something suspicious happens. To enable you to do this, Microsoft Sentinel lets you create advanced analytics rules that generate incidents that you can assign and investigate.\nAn incident can include multiple alerts. It's an aggregation of all the relevant evidence for a specific investigation. An incident is created based on analytics rules that you created in the\nAnalytics\npage. The properties related to the alerts, such as severity and status, are set at the incident level. After you let Microsoft Sentinel know what kinds of threats you're looking for and how to find them, you can monitor detected threats by investigating incidents.\nImportant\nNoted features are currently in PREVIEW. The\nAzure Preview Supplemental Terms\ninclude additional legal terms that apply to Azure features that are in beta, preview, or otherwise not yet released into general availability.\nPrerequisites\nYou'll only be able to investigate the incident if you used the entity mapping fields when you set up your analytics rule. The investigation graph requires that your original incident includes entities.\nIf you have a guest user that needs to assign incidents, the user must be assigned the\nDirectory Reader\nrole in your Microsoft Entra tenant. Regular (nonguest) users have this role assigned by default.\nHow to investigate incidents\nSelect\nIncidents\n. The\nIncidents\npage lets you know how many incidents you have and whether they're new,\nActive\n, or closed. For each incident, you can see the time it occurred and the status of the incident. Look at the severity to decide which incidents to handle first.\nYou can filter the incidents as needed, for example by status or severity. For more information, see\nSearch for incidents\n.\nTo begin an investigation, select a specific incident. On the right, you can see detailed information for the incident including its severity, summary of the number of entities involved, the raw events that triggered this incident, the incidentâs unique ID, and any mapped MITRE ATT&CK tactics or techniques.\nTo view more details about the alerts and entities in the incident, select\nView full details\nin the incident page and review the relevant tabs that summarize the incident information.\nIf you're currently using the new experience, toggle it off at the top right of the incident details page to use the legacy experience instead.\nIn the\nTimeline\ntab, review the timeline of alerts and bookmarks in the incident, which can help you reconstruct the timeline of attacker activity.\nIn the\nSimilar incidents (Preview)\ntab, you see a collection of up to 20 other incidents that most closely resemble the current incident. This allows you to view the incident in a larger context and helps direct your investigation.\nLearn more about similar incidents below\n.\nIn the\nAlerts\ntab, review the alerts included in this incident. You see all relevant information about the alerts â the analytics rules that produced them, the number of results returned per alert, and the ability to run playbooks on the alerts. To drill down even further into the incident, select the number of\nEvents\n. This opens the query that generated the results and the events that triggered the alert in Log Analytics.\nIn the\nBookmarks\ntab, you see any bookmarks you or other investigators have linked to this incident.\nLearn more about bookmarks\n.\nIn the\nEntities\ntab, you can see all the\nentities\nthat you\nmapped\nas part of the alert rule definition. These are the objects that played a role in the incident, whether they be users, devices, addresses, files, or\nany other types\n.\nFinally, in the\nComments\ntab, you can add your comments on the investigation and view any comments made by other analysts and investigators.\nLearn more about comments\n.\nIf you're actively investigating an incident, it's a good idea to set the incident's status to\nActive\nuntil you close it.\nIncidents can be assigned to a specific user or to a group. For each incident you can assign an owner, by setting the\nOwner\nfield. All incidents start as unassigned. You can also add comments so that other analysts are able to understand what you investigated and what your concerns are around the incident.\nRecently selected users and groups appear at the top of the pictured drop-down list.\nSelect\nInvestigate\nto view the investigation map.\nUse the investigation graph to deep dive\nThe investigation graph enables analysts to ask the right questions for each investigation. The investigation graph helps you understand the scope, and identify the root cause, of a potential security threat by correlating relevant data with any involved entity. You can dive deeper and investigate any entity presented in the graph by selecting it and choosing between different expansion options.\nThe investigation graph provides you with:\nVisual context from raw data\n: The live, visual graph displays entity relationships extracted automatically from the raw data. This enables you to easily see connections across different data sources.\nFull investigation scope discovery\n: Expand your investigation scope using built-in exploration queries to surface the full scope of a breach.\nBuilt-in investigation steps\n: Use predefined exploration options to make sure you're asking the right questions in the face of a threat.\nTo use the investigation graph:\nSelect an incident, then select\nInvestigate\n. This takes you to the investigation graph. The graph provides an illustrative map of the entities directly connected to the alert and each resource connected further.\nImportant\nYou'll only be able to investigate the incident if you used the entity mapping fields when you set up your analytics rule. The investigation graph requires that your original incident includes entities.\nMicrosoft Sentinel currently supports investigation of\nincidents up to 30 days old\n.\nSelect an entity to open the\nEntities\npane so you can review information on that entity.\nExpand your investigation by hovering over each entity to reveal a list of questions that was designed by our security experts and analysts per entity type to deepen your investigation. We call these options\nexploration queries\n.\nFor example, you can request related alerts. If you select an exploration query, the resulting entitles are added back to the graph. In this example, selecting\nRelated alerts\nreturned the following alerts into the graph:\nSee that the related alerts appear connected to the entity by dotted lines.\nFor each exploration query, you can select the option to open the raw event results and the query used in Log Analytics, by selecting\nEvents>\n.\nIn order to understand the incident, the graph gives you a parallel timeline.\nHover over the timeline to see which things on the graph occurred at what point in time.\nFocus your investigation\nLearn how you can broaden or narrow the scope of your investigation by either\nadding alerts to your incidents or removing alerts from incidents\n.\nSimilar incidents (preview)\nAs a security operations analyst, when investigating an incident you want to pay attention to its larger context. For example, you'll want to see if other incidents like this have happened before or are happening now.\nYou might want to identify concurrent incidents that might be part of the same larger attack strategy.\nYou might want to identify similar incidents in the past, to use them as reference points for your current investigation.\nYou might want to identify the owners of past similar incidents, to find the people in your SOC who can provide more context, or to whom you can escalate the investigation.\nThe\nsimilar incidents\ntab in the incident details page, now in preview, presents up to 20 other incidents that are the most similar to the current one. Similarity is calculated by internal Microsoft Sentinel algorithms, and the incidents are sorted and displayed in descending order of similarity.\nSimilarity calculation\nThere are three criteria by which similarity is determined:\nSimilar entities:\nAn incident is considered similar to another incident if they both include the same\nentities\n. The more entities two incidents have in common, the more similar they're considered to be.\nSimilar rule:\nAn incident is considered similar to another incident if they were both created by the same\nanalytics rule\n.\nSimilar alert details:\nAn incident is considered similar to another incident if they share the same title, product name, and/or\ncustom details\n.\nThe reasons an incident appears in the similar incidents list are displayed in the\nSimilarity reason\ncolumn. Hover over the info icon to show the common items (entities, rule name, or details).\nSimilarity time frame\nIncident similarity is calculated based on data from the 14 days prior to the last activity in the incident, that being the end time of the most recent alert in the incident.\nIncident similarity is recalculated every time you enter the incident details page, so the results might vary between sessions if new incidents were created or updated.\nComment on incidents\nAs a security operations analyst, when investigating an incident you'll want to thoroughly document the steps you take, both to ensure accurate reporting to management and to enable seamless cooperation and collaboration among coworkers. Microsoft Sentinel gives you a rich commenting environment to help you accomplish this.\nAnother important thing that you can do with comments is enrich your incidents automatically. When you run a playbook on an incident that fetches relevant information from external sources (say, checking a file for malware at VirusTotal), you can have the playbook place the external source's response - along with any other information you define - in the incident's comments.\nComments are simple to use. You access them through the\nComments\ntab on the incident details page.\nFrequently asked questions about incident comments\nThere are several considerations to take into account when using incident comments. The following list of questions points to these considerations.\nWhat kinds of input are supported?\nText:\nComments in Microsoft Sentinel support text inputs in plain text, basic HTML, and Markdown. You can also paste copied text, HTML, and Markdown into the comment window.\nImages:\nYou can insert links to images in comments and the images are displayed inline, but the images must already be hosted in a publicly accessible location such as Dropbox, OneDrive, Google Drive and the like. Images can't be uploaded directly to comments.\nIs there a size limit on comments?\nPer comment:\nA single comment can contain up to\n30,000 characters\n.\nPer incident:\nA single incident can contain up to\n100 comments\n.\nNote\nThe size limit of a single incident record in the\nSecurityIncident\ntable in Log Analytics is 64 KB. If this limit is exceeded, comments (starting with the earliest) will be truncated, which may affect the comments that will appear in\nadvanced search\nresults.\nThe actual incident records in the incidents database will not be affected.\nWho can edit or delete comments?\nEditing:\nOnly the author of a comment has permission to edit it.\nDeleting:\nOnly users with the\nMicrosoft Sentinel Contributor\nrole have permission to delete comments. Even the comment's author must have this role in order to delete it.\nClose an incident\nOnce you resolve a particular incident (for example, when your investigation has reached its conclusion), you should set the incidentâs status to\nClosed\n. When you do so, you'll be asked to classify the incident by specifying the reason you're closing it. This step is mandatory. Select\nSelect classification\nand choose one of the following from the drop-down list:\nTrue Positive - suspicious activity\nBenign Positive - suspicious but expected\nFalse Positive - incorrect alert logic\nFalse Positive - incorrect data\nUndetermined\nFor more information about false positives and benign positives, see\nHandle false positives in Microsoft Sentinel\n.\nAfter choosing the appropriate classification, add some descriptive text in the\nComment\nfield. This is useful in the event you need to refer back to this incident. Select\nApply\nwhen youâre done, and the incident is closed.\nSearch for incidents\nTo find a specific incident quickly, enter a search string in the search box above the incidents grid and press\nEnter\nto modify the list of incidents shown accordingly. If your incident isn't included in the results, you might want to narrow your search by using\nAdvanced search\noptions.\nTo modify the search parameters, select the\nSearch\nbutton and then select the parameters where you want to run your search.\nFor example:\nBy default, incident searches run across the\nIncident ID\n,\nTitle\n,\nTags\n,\nOwner\n, and\nProduct name\nvalues only. In the search pane, scroll down the list to select one or more other parameters to search, and select\nApply\nto update the search parameters. Select\nSet to default\nreset the selected parameters to the default option.\nNote\nSearches in the\nOwner\nfield support both names and email addresses.\nUsing advanced search options changes the search behavior as follows:\nSearch behavior\nDescription\nSearch button color\nThe color of the search button changes, depending on the types of parameters currently being used in the search.\nAs long as only the default parameters are selected, the button is grey.\nAs soon as different parameters are selected, such as advanced search parameters, the button turns blue.\nAuto-refresh\nUsing advanced search parameters prevents you from selecting to automatically refresh your results.\nEntity parameters\nAll entity parameters are supported for advanced searches. When searching in any entity parameter, the search runs in all entity parameters.\nSearch strings\nSearching for a string of words includes all of the words in the search query. Search strings are case sensitive.\nCross workspace support\nAdvanced searches aren't supported for cross-workspace views.\nNumber of search results displayed\nWhen you're using advanced search parameters, only 50 results are shown at a time.\nTip\nIf you're unable to find the incident you're looking for, remove search parameters to expand your search. If your search results in too many items, add more filters to narrow down your results.\nRelated content\nIn this article, you learned how to get started investigating incidents using Microsoft Sentinel. For more information, see:\nInvestigate incidents with UEBA data\nAutomation in Microsoft Sentinel: Security orchestration, automation, and response (SOAR)\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Investigate Incidents",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/key-vault/general/overview": {
      "content_hash": "sha256:9546c1cc48a790e91d31084a96eab752e2092d0dee8f40d3351997249bf6a5ec",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nAbout Azure Key Vault\nFeedback\nSummarize this article for me\nAzure Key Vault is one of several\nkey management solutions in Azure\n, and helps solve the following problems:\nSecrets Management\n- Azure Key Vault can be used to Securely store and tightly control access to tokens, passwords, certificates, API keys, and other secrets\nKey Management\n- Azure Key Vault can be used as a Key Management solution. Azure Key Vault makes it easy to create and control the encryption keys used to encrypt your data.\nCertificate Management\n- Azure Key Vault lets you easily provision, manage, and deploy public and private Transport Layer Security/Secure Sockets Layer (TLS/SSL) certificates for use with Azure and your internal connected resources.\nAzure Key Vault offers two service tiers to meet different security and compliance requirements:\nStandard tier\n- Encrypts data using software libraries validated to FIPS 140 Level 1\nPremium tier\n- Offers HSM-protected keys, generated and protected by FIPS 140-3 Level 3 validated Marvell LiquidSecurity HSMs, for the highest level of cryptographic protection\nFor detailed pricing and feature comparisons between tiers, see the\nAzure Key Vault pricing page\n.\nNote\nZero Trust\nis a security strategy comprising three principles: \"Verify explicitly\", \"Use least privilege access\", and \"Assume breach\". Data protection, including key management, supports the \"use least privilege access\" principle. For more information, see\nWhat is Zero Trust?\nWhy use Azure Key Vault?\nCentralize application secrets\nCentralizing storage of application secrets in Azure Key Vault allows you to control their distribution. Key Vault greatly reduces the chances that secrets may be accidentally leaked. When application developers use Key Vault, they no longer need to store security information in their application. Not having to store security information in applications eliminates the need to make this information part of the code. For example, an application may need to connect to a database. Instead of storing the connection string in the app's code, you can store it securely in Key Vault.\nYour applications can securely access the information they need by using URIs. These URIs allow the applications to retrieve specific versions of a secret. There's no need to write custom code to protect any of the secret information stored in Key Vault.\nSecurely store secrets and keys\nAccess to a key vault requires proper authentication and authorization before a caller (user or application) can get access. Authentication establishes the identity of the caller, while authorization determines the operations that they're allowed to perform.\nAuthentication is done via Microsoft Entra ID. Authorization may be done via Azure role-based access control (Azure RBAC) or Key Vault access policy. Azure RBAC can be used for both management of the vaults and to access data stored in a vault, while key vault access policy can only be used when attempting to access data stored in a vault.\nAzure Key Vault provides multiple layers of security to protect your data. All key vaults are encrypted at rest using keys stored in hardware security modules (HSMs), and Azure safeguards your keys, secrets, and certificates using industry-standard algorithms, key lengths, and cryptographic protection.\nFor organizations requiring the highest level of security, the Premium tier offers HSM-protected keys (RSA-HSM, EC-HSM, or OCT-HSM) that never leave the HSM boundary. These Premium tier HSMs utilize Marvell LiquidSecurity hardware with FIPS 140-3 Level 3 validation, ensuring the most stringent cryptographic protection available.\nBoth Standard and Premium tiers use\nFederal Information Processing Standard 140 validated software cryptographic modules and HSMs\nto meet rigorous security and compliance standards.\nFinally, Azure Key Vault is designed so that Microsoft doesn't see or extract your data.\nMonitor access and use\nOnce you've created a couple of Key Vaults, you'll want to monitor how and when your keys and secrets are being accessed. You can monitor activity by enabling logging for your vaults. You can configure Azure Key Vault to:\nArchive to a storage account.\nStream to an event hub.\nSend the logs to Azure Monitor logs.\nYou have control over your logs and you may secure them by restricting access and you may also delete logs that you no longer need.\nSimplified administration of application secrets\nWhen storing valuable data, you must take several steps. Security information must be secured, it must follow a life cycle, and it must be highly available. Azure Key Vault simplifies the process of meeting these requirements by:\nRemoving the need for in-house knowledge of Hardware Security Modules.\nScaling up on short notice to meet your organization's usage spikes.\nReplicating the contents of your Key Vault within a region and to a secondary region. Data replication ensures high availability and takes away the need of any action from the administrator to trigger the failover.\nProviding standard Azure administration options via the portal, Azure CLI and PowerShell.\nAutomating certain tasks on certificates that you purchase from Public CAs, such as enrollment and renewal.\nIn addition, Azure Key Vaults allow you to segregate application secrets. Applications may access only the vault that they're allowed to access, and they can be limited to only perform specific operations. You can create an Azure Key Vault per application and restrict the secrets stored in a Key Vault to a specific application and team of developers.\nIntegrate with other Azure services\nAs a secure store in Azure, Key Vault has been used to simplify scenarios like:\nAzure Disk Encryption\nThe\nalways encrypted\nand\nTransparent Data Encryption\nfunctionality in SQL server and Azure SQL Database\nAzure App Service\n.\nKey Vault itself can integrate with storage accounts, event hubs, and log analytics.\nNext steps\nKey management in Azure\nLearn more about\nkeys, secrets, and certificates\nQuickstart: Create an Azure Key Vault using the CLI\nAuthentication, requests, and responses\nWhat is Zero Trust?\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Key Vault",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/key-vault/general/private-link-service": {
      "content_hash": "sha256:8d17055b11096255650299b2cffe608a21583b9700f6207c884c19aa61f90a3e",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nIntegrate Key Vault with Azure Private Link\nFeedback\nSummarize this article for me\nAzure Private Link Service enables you to access Azure Services (for example, Azure Key Vault, Azure Storage, and Azure Cosmos DB) and Azure hosted customer/partner services over a Private Endpoint in your virtual network.\nAn Azure Private Endpoint is a network interface that connects you privately and securely to a service powered by Azure Private Link. The private endpoint uses a private IP address from your VNet, effectively bringing the service into your VNet. All traffic to the service can be routed through the private endpoint, so no gateways, NAT devices, ExpressRoute or VPN connections, or public IP addresses are needed. Traffic between your virtual network and the service traverses over the Microsoft backbone network, eliminating exposure from the public Internet. You can connect to an instance of an Azure resource, giving you the highest level of granularity in access control.\nFor more information, see\nWhat is Azure Private Link?\nPrerequisites\nTo integrate a key vault with Azure Private Link, you'll need:\nA key vault.\nAn Azure virtual network.\nA subnet in the virtual network.\nOwner or contributor permissions for both the key vault and the virtual network.\nYour private endpoint and virtual network must be in the same region. When you select a region for the private endpoint using the portal, it will automatically filter only virtual networks that are in that region. Your key vault can be in a different region.\nYour private endpoint uses a private IP address in your virtual network.\nAzure portal\nAzure CLI\nEstablish a private link connection to Key Vault using the Azure portal\nFirst, create a virtual network by following the steps in\nCreate a virtual network using the Azure portal\nYou can then either create a new key vault, or establish a private link connection to an existing key vault.\nCreate a new key vault and establish a private link connection\nYou can create a new key vault with the\nAzure portal\n,\nAzure CLI\n, or\nAzure PowerShell\n.\nAfter configuring the key vault basics, select the Networking tab and follow these steps:\nDisable public access by toggling off the radio button.\nSelect the \"+ Create a private endpoint\" Button to add a private endpoint.\nIn the \"Location\" field of the Create Private Endpoint Blade, select the region in which your virtual network is located.\nIn the \"Name\" field, create a descriptive name that will allow you to identify this private endpoint.\nSelect the virtual network and subnet you want this private endpoint to be created in from the dropdown menu.\nLeave the \"integrate with the private zone DNS\" option unchanged.\nSelect \"Ok\".\nYou'll now be able to see the configured private endpoint. You can now delete and edit this private endpoint.\nSelect the \"Review + Create\" button and create the key vault. It will take 5-10 minutes for the deployment to complete.\nEstablish a private link connection to an existing key vault\nIf you already have a key vault, you can create a private link connection by following these steps:\nSign in to the Azure portal.\nIn the search bar, type in \"key vaults\".\nSelect the key vault from the list to which you want to add a private endpoint.\nSelect the \"Networking\" tab under Settings.\nSelect the \"Private endpoint connections\" tab at the top of the page.\nSelect the \"+ Create\" button at the top of the page.\nUnder \"Project Details\", select the Resource Group that contains the virtual network that you created as a prerequisite for this tutorial. Under \"Instance details\", enter \"myPrivateEndpoint\" as the Name, and select the same location as the virtual network that you created as a prerequisite for this tutorial.\nYou can choose to create a private endpoint for any Azure resource in using this blade. You can either use the dropdown menus to select a resource type and select a resource in your directory, or you can connect to any Azure resource using a resource ID. Leave the \"integrate with the private zone DNS\" option unchanged.\nAdvance to the \"Resources\" blade. For \"Resource type\", select \"Microsoft.KeyVault/vaults\"; for \"Resource\", select the key vault you created as a prerequisite for this tutorial. \"Target sub-resource\" will auto-populate with \"vault\".\nAdvance to the \"Virtual Network\". Select the virtual network and subnet that you created as a prerequisite for this tutorial.\nAdvance through the \"DNS\" and \"Tags\" blades, accepting the defaults.\nOn the \"Review + Create\" blade, select \"Create\".\nWhen you create a private endpoint, the connection must be approved. If the resource for which you're creating a private endpoint is in your directory, you'll be able to approve the connection request provided you have sufficient permissions; if you're connecting to an Azure resource in another directory, you must wait for the owner of that resource to approve your connection request.\nThere are four provisioning states:\nService action\nService consumer private endpoint state\nDescription\nNone\nPending\nConnection is created manually and is pending approval from the Private Link resource owner.\nApprove\nApproved\nConnection was automatically or manually approved and is ready to be used.\nReject\nRejected\nConnection was rejected by the private link resource owner.\nRemove\nDisconnected\nConnection was removed by the private link resource owner, the private endpoint becomes informative and should be deleted for cleanup.\nHow to manage a private endpoint connection to Key Vault using the Azure portal\nLog in to the Azure portal.\nIn the search bar, type in \"key vaults\"\nSelect the key vault that you want to manage.\nSelect the \"Networking\" tab.\nIf there are any connections that are pending, you'll see a connection listed with \"Pending\" in the provisioning state.\nSelect the private endpoint you wish to approve\nSelect the approve button.\nIf there are any private endpoint connections you want to reject, whether it's a pending request or existing connection, select the connection and select the \"Reject\" button.\nEstablish a private link connection to Key Vault using CLI (Initial Setup)\naz login # Login to Azure CLI\naz account set --subscription {SUBSCRIPTION ID} # Select your Azure Subscription\naz group create -n {RESOURCE GROUP} -l {REGION} # Create a new Resource Group\naz provider register -n Microsoft.KeyVault # Register KeyVault as a provider\naz keyvault create -n {VAULT NAME} -g {RG} -l {REGION} # Create a Key Vault\naz keyvault update -n {VAULT NAME} -g {RG} --default-action deny # Turn on Key Vault Firewall\naz network vnet create -g {RG} -n {vNet NAME} -location {REGION} # Create a Virtual Network\n\n # Create a Subnet\naz network vnet subnet create -g {RG} --vnet-name {vNet NAME} --name {subnet NAME} --address-prefixes {addressPrefix}\n\n # Disable Virtual Network Policies\naz network vnet subnet update --name {subnet NAME} --resource-group {RG} --vnet-name {vNet NAME} --disable-private-endpoint-network-policies true\n\n # Create a Private DNS Zone\naz network private-dns zone create --resource-group {RG} --name privatelink.vaultcore.azure.net\n\n # Link the Private DNS Zone to the Virtual Network\naz network private-dns link vnet create --resource-group {RG} --virtual-network {vNet NAME} --zone-name privatelink.vaultcore.azure.net --name {dnsZoneLinkName} --registration-enabled true\nCreate a Private Endpoint (Automatically Approve)\naz network private-endpoint create --resource-group {RG} --vnet-name {vNet NAME} --subnet {subnet NAME} --name {Private Endpoint Name} --private-connection-resource-id \"/subscriptions/{AZURE SUBSCRIPTION ID}/resourceGroups/{RG}/providers/Microsoft.KeyVault/vaults/{KEY VAULT NAME}\" --group-ids vault --connection-name {Private Link Connection Name} --location {AZURE REGION}\nCreate a Private Endpoint (Manually Request Approval)\naz network private-endpoint create --resource-group {RG} --vnet-name {vNet NAME} --subnet {subnet NAME} --name {Private Endpoint Name} --private-connection-resource-id \"/subscriptions/{AZURE SUBSCRIPTION ID}/resourceGroups/{RG}/providers/Microsoft.KeyVault/vaults/{KEY VAULT NAME}\" --group-ids vault --connection-name {Private Link Connection Name} --location {AZURE REGION} --manual-request\nManage Private Link Connections\n# Show Connection Status\naz network private-endpoint show --resource-group {RG} --name {Private Endpoint Name}\n\n# Approve a Private Link Connection Request\naz keyvault private-endpoint-connection approve --approval-description {\"OPTIONAL DESCRIPTION\"} --resource-group {RG} --vault-name {KEY VAULT NAME} âname {PRIVATE LINK CONNECTION NAME}\n\n# Deny a Private Link Connection Request\naz keyvault private-endpoint-connection reject --rejection-description {\"OPTIONAL DESCRIPTION\"} --resource-group {RG} --vault-name {KEY VAULT NAME} âname {PRIVATE LINK CONNECTION NAME}\n\n# Delete a Private Link Connection Request\naz keyvault private-endpoint-connection delete --resource-group {RG} --vault-name {KEY VAULT NAME} --name {PRIVATE LINK CONNECTION NAME}\nAdd Private DNS Records\n# Determine the Private Endpoint IP address\naz network private-endpoint show -g {RG} -n {PE NAME} # look for the property networkInterfaces then id; the value must be placed on {PE NIC} below.\naz network nic show --ids {PE NIC} # look for the property ipConfigurations then privateIpAddress; the value must be placed on {NIC IP} below.\n\n# https://learn.microsoft.com/azure/dns/private-dns-getstarted-cli#create-an-additional-dns-record\naz network private-dns zone list -g {RG}\naz network private-dns record-set a add-record -g {RG} -z \"privatelink.vaultcore.azure.net\" -n {KEY VAULT NAME} -a {NIC IP}\naz network private-dns record-set list -g {RG} -z \"privatelink.vaultcore.azure.net\"\n\n# From home/public network, you wil get a public IP. If inside a vnet with private zone, nslookup will resolve to the private ip.\nnslookup {KEY VAULT NAME}.vault.azure.net\nnslookup {KEY VAULT NAME}.privatelink.vaultcore.azure.net\nValidate that the private link connection works\nYou should validate that the resources within the same subnet of the private endpoint resource are connecting to your key vault over a private IP address, and that they have the correct private DNS zone integration.\nFirst, create a virtual machine by following the steps in\nCreate a Windows virtual machine in the Azure portal\nIn the \"Networking\" tab:\nSpecify Virtual network and Subnet. You can create a new virtual network or select an existing one. If selecting an existing one, make sure the region matches.\nSpecify a Public IP resource.\nIn the \"NIC network security group\", select \"None\".\nIn the \"Load balancing\", select \"No\".\nOpen the command line and run the following command:\nnslookup <your-key-vault-name>.vault.azure.net\nIf you run the ns lookup command to resolve the IP address of a key vault over a public endpoint, you'll see a result that looks like this:\nc:\\ >nslookup <your-key-vault-name>.vault.azure.net\n\nNon-authoritative answer:\nName: \nAddress: (public IP address)\nAliases: <your-key-vault-name>.vault.azure.net\nIf you run the ns lookup command to resolve the IP address of a key vault over a private endpoint, you'll see a result that looks like this:\nc:\\ >nslookup your_vault_name.vault.azure.net\n\nNon-authoritative answer:\nName: \nAddress: 10.1.0.5 (private IP address)\nAliases: <your-key-vault-name>.vault.azure.net\n <your-key-vault-name>.privatelink.vaultcore.azure.net\nTroubleshooting Guide\nCheck to make sure the private endpoint is in the approved state.\nYou can check and fix this in Azure portal. Open the Key Vault resource, and select the Networking option.\nThen select the Private endpoint connections tab.\nMake sure connection state is Approved and provisioning state is Succeeded.\nYou may also navigate to the private endpoint resource and review same properties there, and double-check that the virtual network matches the one you're using.\nCheck to make sure you have a Private DNS Zone resource.\nYou must have a Private DNS Zone resource with the exact name: privatelink.vaultcore.azure.net.\nTo learn how to set this up please see the following link.\nPrivate DNS Zones\nCheck to make sure the Private DNS Zone is linked to the Virtual Network. This may be the issue if you're still getting the public IP address returned.\nIf the Private Zone DNS isn't linked to the virtual network, the DNS query originating from the virtual network will return the public IP address of the key vault.\nNavigate to the Private DNS Zone resource in the Azure portal and select the virtual network links option.\nThe virtual network that will perform calls to the key vault must be listed.\nIf it's not there, add it.\nFor detailed steps, see the following document\nLink Virtual Network to Private DNS Zone\nCheck to make sure the Private DNS Zone isn't missing an A record for the key vault.\nNavigate to the Private DNS Zone page.\nSelect Overview and check if there's an A record with the simple name of your key vault (i.e. fabrikam). Don't specify any suffix.\nMake sure you check the spelling, and either create or fix the A record. You can use a TTL of 600 (10 mins).\nMake sure you specify the correct private IP address.\nCheck to make sure the A record has the correct IP Address.\nYou can confirm the IP address by opening the Private Endpoint resource in Azure portal.\nNavigate to the Microsoft.Network/privateEndpoints resource, in the Azure portal (not the Key Vault resource)\nIn the overview page look for Network interface and select that link.\nThe link will show the Overview of the NIC resource, which contains the property Private IP address.\nVerify that this is the correct IP address that is specified in the A record.\nIf you're connecting from an on-premises resource to a Key Vault, ensure you have all required conditional forwarders in the on-premises environment enabled.\nReview\nAzure Private Endpoint DNS configuration\nfor the zones needed, and make sure you have conditional forwarders for both\nvault.azure.net\nand\nvaultcore.azure.net\non your on-premises DNS.\nEnsure that you have conditional forwarders for those zones that route to an\nAzure Private DNS Resolver\nor some other DNS platform with access to Azure resolution.\nLimitations and Design Considerations\nLimits\n: See\nAzure Private Link limits\nPricing\n: See\nAzure Private Link pricing\n.\nLimitations\n: See\nAzure Private Link service: Limitations\nNext Steps\nLearn more about\nAzure Private Link\nLearn more about\nAzure Key Vault\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Key Vault Private Endpoints",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/private-link/private-link-overview": {
      "content_hash": "sha256:ba5d63f9dc389d82e5535fb480ce10e5f164d17ac0a7f90268008297078dee77",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Azure Private Link?\nFeedback\nSummarize this article for me\nAzure Private Link enables you to access Azure PaaS Services (for example, Azure Storage and SQL Database) and Azure hosted customer-owned/partner services over a\nprivate endpoint\nin your virtual network.\nTraffic between your virtual network and the service travels the Microsoft backbone network. Exposing your service to the public internet is no longer necessary. You can create your own\nprivate link service\nin your virtual network and deliver it to your customers. Setup and consumption using Azure Private Link is consistent across Azure PaaS, customer-owned, and shared partner services.\nImportant\nAzure Private Link is now generally available. Both Private Endpoint and Private Link service (service behind standard load balancer) are generally available. Different Azure PaaS will onboard to Azure Private Link at different schedules. See\nPrivate Link availability\nfor an accurate status of Azure PaaS on Private Link. For known limitations, see\nPrivate Endpoint\nand\nPrivate Link Service\n.\nNote\nThe feature Private Link Service Direct Connect, which allows you to connect to any privately routable destination IP address, is now in public preview. For more information and known limitations, see\nPrivate Link Service Direct Connect\nNote\nAzure Private Link is one of the services that make up the Network Foundations category in Azure. Other services in this category include\nAzure DNS\nand\nAzure Virtual Networks\n. Each service has its own unique features and use cases. For more information on this service category, see\nNetwork Foundations\n.\nFor scenarios that involve public internet PaaS traffic, configure\nnetwork security perimeter\nto set up a secure logical boundary. Network security perimeter restricts communication to services within its perimeter, and it allows nonperimeter public traffic through inbound and outbound access rules.\nImportant\nNetwork security perimeter is now generally available in all Azure public cloud regions. For information on supported services, see\nOnboarded private link resources\nfor supported PaaS services.\"\nKey benefits\nAzure Private Link provides the following benefits:\nPrivately access services on the Azure platform\n: Connect your virtual network using private endpoints to all services that can be used as application components in Azure. Service providers can render their services in their own virtual network and consumers can access those services in their local virtual network. The Private Link platform handles the connectivity between the consumer and services over the Azure backbone network.\nOn-premises and peered networks\n: Access services running in Azure from on-premises over ExpressRoute private peering, VPN tunnels, and peered virtual networks using private endpoints. There's no need to configure ExpressRoute Microsoft peering or traverse the internet to reach the service. Private Link provides a secure way to migrate workloads to Azure.\nProtection against data leakage\n: A private endpoint is mapped to an instance of a PaaS resource instead of the entire service. Consumers can only connect to the specific resource. Access to any other resource in the service is blocked. This mechanism provides protection against data leakage risks.\nGlobal reach\n: Connect privately to services running in other regions. The consumer's virtual network could be in region A and it can connect to services behind Private Link in region B.\nExtend to your own services\n: Enable the same experience and functionality to render your service privately to consumers in Azure. By placing your service behind a standard Azure Load Balancer, you can enable it for Private Link. The consumer can then connect directly to your service using a private endpoint in their own virtual network. You can manage the connection requests using an approval call flow. Azure Private Link works for consumers and services belonging to different Microsoft Entra tenants.\nNote\nAzure Private Link, along with Azure Virtual Network, span across\nAzure Availability Zones\nand are therefore zone resilient. To provide high availability for the Azure resource using a private endpoint, ensure that resource is zone resilient.\nAvailability\nFor information on Azure services that support Private Link, see\nAzure Private Link availability\n.\nFor the most up-to-date notifications, check the\nAzure Private Link updates page\n.\nLogging and monitoring\nAzure Private Link has integration with Azure Monitor. This combination allows:\nArchival of logs to a storage account.\nStreaming of events to your Event Hubs.\nAzure Monitor logging.\nYou can access the following information on Azure Monitor:\nPrivate endpoint\n:\nData processed by the Private Endpoint â¯(IN/OUT)\nPrivate Link service\n:\nData processed by the Private Link service (IN/OUT)\nNAT port availability\nPricing\nFor pricing details, see\nAzure Private Link pricing\n.\nFAQs\nFor FAQs, see\nAzure Private Link FAQs\n.\nLimits\nFor limits, see\nAzure Private Link limits\n.\nService Level Agreement\nFor service level agreement, see\nSLA for Azure Private Link\n.\nNext steps\nQuickstart: Create a Private Endpoint using Azure portal\nQuickstart: Create a Private Link service by using the Azure portal\nLearn module: Introduction to Azure Private Link\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Private Link",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-storage-overview": {
      "content_hash": "sha256:9ee9b9fac74ca69426dd714819bc68f05d41ad95290b65a3105c076464109b19",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nStore business-critical blob data with immutable storage in a write once, read many (WORM) state\nFeedback\nSummarize this article for me\nImmutable storage for Azure Blob Storage enables users to store business-critical data in a WORM (Write Once, Read Many) state. While in a WORM state, data can't be modified or deleted for a user-specified interval. By configuring immutability policies for blob data, you can protect your data from overwrites and deletes.\nImmutable storage for Azure Blob Storage supports two types of immutability policies:\nTime-based retention policies\n: With a time-based retention policy, users can set policies to store data for a specified interval. When a time-based retention policy is set, objects can be created and read, but not modified or deleted. After the retention period has expired, objects can be deleted but not overwritten.\nLegal hold policies\n: A legal hold stores immutable data until the legal hold is explicitly cleared. When a legal hold is set, objects can be created and read, but not modified or deleted.\nThese policies can be set at the same time as one another. For example, a user can have both a time-based retention policy and a legal hold set at the same level and at the same time. In order for a write to succeed, you must either have versioning enabled or have neither a legal hold or time-based retention policy on the data. In order for a delete to succeed, there must not be a legal hold or time-based retention policy on the data as well.\nThe following diagram shows how time-based retention policies and legal holds prevent write and delete operations while they are in effect.\nThere are two features under the immutable storage umbrella:\ncontainer-level WORM\nand\nversion-level WORM\n. Container-level WORM allows policies to be set at the container level only, while version-level WORM allows policies to be set at the account, container, or version level.\nAbout immutable storage for blobs\nImmutable storage helps healthcare organizations, financial institutions, and related industriesâparticularly broker-dealer organizationsâto store data securely. Immutable storage can be used in any scenario to protect critical data against modification or deletion.\nTypical applications include:\nRegulatory compliance\n: Immutable storage for Azure Blob Storage helps organizations address SEC 17a-4(f), CFTC 1.31(d), FINRA, and other regulations.\nSecure document retention\n: Immutable storage for blobs ensures that data can't be modified or deleted by any user, not even by users with account administrative privileges.\nLegal hold\n: Immutable storage for blobs enables users to store sensitive information that is critical to litigation or business use in a tamper-proof state for the desired duration until the hold is removed. This feature isn't limited only to legal use cases but can also be thought of as an event-based hold or an enterprise lock, where the need to protect data based on event triggers or corporate policy is required.\nRegulatory compliance\nMicrosoft retained a leading independent assessment firm that specializes in records management and information governance, Cohasset Associates, to evaluate immutable storage for blobs and its compliance with requirements specific to the financial services industry. Cohasset validated that immutable storage, when used to retain blobs in a WORM state, meets the relevant storage requirements of CFTC Rule 1.31(c)-(d), FINRA Rule 4511, and SEC Rule 17a-4(f). Microsoft targeted this set of rules because they represent the most prescriptive guidance globally for records retention for financial institutions.\nThe Cohasset report is available in the\nMicrosoft Service Trust Center\n. The\nAzure Trust Center\ncontains detailed information about Microsoft's compliance certifications. To request a letter of attestation from Microsoft regarding WORM immutability compliance, please contact\nAzure Support\n.\nTime-based retention policies\nA time-based retention policy stores blob data in a WORM format for a specified interval. When a time-based retention policy is set, clients can create and read blobs, but can't modify or delete them. After the retention interval has expired, blobs can be deleted but not overwritten.\nScope\nA time-based retention policy can be configured at the following scopes:\nVersion-level WORM policy: A time-based retention policy can be configured at the account, container, or version level. If it's configured at the account or container level, it will be inherited by all blobs in the respective account or container. If there is a legal hold on a container, Version-level WORM cannot be created for the same container. This is because the versions can't generated due to the legal hold.\nContainer-level WORM policy: A time-based retention policy configured at the container level applies to all blobs in that container. Individual blobs can't be configured with their own immutability policies.\nRetention interval for a time-based policy\nThe minimum retention interval for a time-based retention policy is one day, and the maximum is 146,000 days (400 years).\nWhen you configure a time-based retention policy, the affected objects stay in the immutable state during the effective retention period. The effective retention period for objects is equal to the difference between the blob's creation time and the user-specified retention interval. Because a policy's retention interval can be extended, immutable storage uses the most recent value of the user-specified retention interval to calculate the effective retention period.\nFor example, suppose that a user creates a time-based retention policy with a retention interval of five years. An existing blob in that container, testblob1, was created one year ago, so the effective retention period for testblob1 is four years. When a new blob, testblob2, is uploaded to the container, the effective retention period for testblob2 is five years from the time of its creation.\nLocked versus unlocked policies\nWhen you first configure a time-based retention policy, the policy is unlocked for testing purposes. When you finish testing, you can lock the policy so that it's fully compliant with SEC 17a-4(f) and other regulatory compliance.\nBoth locked and unlocked policies protect against deletes and overwrites. However, you can modify an unlocked policy by shortening or extending the retention period. You can also delete an unlocked policy.\nYou can't delete a locked time-based retention policy. You can extend the retention period, but you can't decrease it. A maximum of five increases to the effective retention period is allowed over the lifetime of a locked policy that is defined at the container level. For a policy configured for a blob version, there's no limit to the number of increases to the effective period.\nImportant\nA time-based retention policy must be locked for the blob to be in a compliant immutable (write and delete protected) state for SEC 17a-4(f) and other regulatory compliance. Microsoft recommends that you lock the policy in a reasonable amount of time, typically less than 24 hours. While the unlocked state provides immutability protection, using the unlocked state for any purpose other than short-term testing is not recommended.\nRetention policy audit logging\nEach container with a time-based retention policy enabled provides a policy audit log. The audit log includes up to seven time-based retention commands for locked time-based retention policies. Logging typically starts once you have locked the policy. Log entries include the user ID, command type, time stamps, and retention interval. The audit log is retained for the policy's lifetime in accordance with the SEC 17a-4(f) regulatory guidelines.\nThe Azure Activity log provides a more comprehensive log of all management service activities. Azure resource logs retain information about data operations. It's the user's responsibility to store those logs persistently, as might be required for regulatory or other purposes.\nChanges to time-based retention policies at the version level aren't audited.\nLegal holds\nA legal hold is a temporary immutability policy that can be applied for legal investigation purposes or general protection policies. A legal hold stores blob data in a Write-Once, Read-Many (WORM) format until the hold is explicitly cleared. When a legal hold is in effect, blobs can be created and read, but not modified or deleted. Use a legal hold when the period of time that the data must be kept in a WORM state is unknown.\nScope\nA legal hold policy can be configured at either of the following scopes:\nVersion-level WORM policy: A legal hold can be configured on an individual blob version level for granular management of sensitive data.\nContainer-level WORM policy: A legal hold that is configured at the container level applies to all blobs in that container. Individual blobs can't be configured with their own immutability policies.\nTags\nA container-level legal hold must be associated with one or more user-defined alphanumeric tags that serve as identifier strings. For example, a tag may include a case ID or event name.\nAudit logging\nEach container with a legal hold in effect provides a policy audit log. The log contains the user ID, command type, time stamps, and legal hold tags. The audit log is retained for the policy's lifetime in accordance with the SEC 17a-4(f) regulatory guidelines.\nThe Azure Activity log provides a more comprehensive log of all management service activities. Azure resource logs retain information about data operations. It's the user's responsibility to store those logs persistently, as might be required for regulatory or other purposes.\nChanges to legal holds at the version level aren't audited.\nImmutable storage feature options\nThe following table shows a breakdown of the differences between container-level WORM and version-level WORM:\nCategory\nContainer-level WORM\nVersion-level WORM\nPolicy granularity level\nPolicies can be configured only at the container level. Each object that is uploaded into the container inherits the immutable policy set.\nPolicies can be configured at the account, container, or blob level. If a policy is set at the account level, all blobs that are uploaded into that account inherits the policy. The same logic follows with containers. If a policy is set at multiple levels, the order of precedence is always Blob -> Container -> Account.\nTypes of policies available\nTwo different types of policies can be set at the container level: Time-based retention policies and legal holds.\nAt the account and container level, only time-based retention policies can be set. At the blob level, both time-based retention policies and legal holds can be set.\nFeature dependencies\nNo other features are a prerequisite or requirement for this feature to function.\nVersioning is a prerequisite for this feature to be used.\nEnablement for existing accounts/container\nThis feature can be enabled at any time for existing containers.\nDepending on the level of granularity, this feature might not be enabled for all existing accounts/containers.\nAccount/container deletion\nOnce a time-based retention policy is locked on a container, containers may only be deleted if they're empty.\nOnce version-level WORM is enabled on an account or container level, they may only be deleted if they're empty.\nSupport for Azure Data Lake Storage (storage accounts that have a hierarchical namespace enabled)\nContainer-level WORM policies are supported in accounts that have a hierarchical namespace.\nVersion-level WORM policies are not yet supported in accounts that have a hierarchical namespace.\nTo learn more about container-level WORM, see\nContainer-Level WORM policies\n. To learn more about version-level WORM, please visit\nversion-Level WORM policies\n.\nContainer-level vs version-level WORM\nThe following table helps you decide which type of WORM policy to use.\nCriteria\nContainer-level WORM Usage\nVersion-level WORM Usage\nOrganization of data\nYou want to set policies for specific data sets, which can be categorized by container. All the data in that container needs to be kept in a WORM state for the same amount of time.\nYou can't group objects by retention periods. All blobs must be stored with an individual retention time based on that blobâs scenarios, or user has a mixed workload so that some groups of data can be clustered into containers while other blobs can't. You might also want to set container-level policies and blob-level policies within the same account.\nAmount of data that requires an immutable policy\nYou don't need to set policies on more than 10,000 containers per account.\nYou want to set policies on all data or large amounts of data that can be delineated by account. You know that if you use container-level WORM, you'll have to exceed the 10,000-container limit.\nInterest in enabling versioning\nYou don't want to deal with enabling versioning either because of the cost, or because the workload would create numerous extra versions to deal with.\nYou either want to use versioning, or don't mind using it. You know that if they donât enable versioning, you can't keep edits or overwrites to immutable blobs as separate versions.\nStorage location (Blob Storage vs Data Lake Storage)\nYour workload is entirely focused on Azure Data Lake Storage. You have no immediate interest or plan to switch to using an account that doesn't have the hierarchical namespace feature enabled.\nYour workload is either on Blob Storage in an account that doesn't have the hierarchical namespace feature enabled, and can use version-level WORM now, or you're willing to wait for versioning to be available for accounts that do have a hierarchical namespace enabled (Azure Data Lake Storage).\nAccess tiers\nAll blob access tiers support immutable storage. You can change the access tier of a blob with the Set Blob Tier operation. For more information, see\nAccess tiers for blob data\n.\nRedundancy configurations\nAll redundancy configurations support immutable storage. For more information about redundancy configurations, see\nAzure Storage redundancy\n.\nRecommended blob types\nMicrosoft recommends that you configure immutability policies mainly for block blobs and append blobs. Configuring an immutability policy for a page blob that stores a VHD disk for an active virtual machine is discouraged as writes to the disk will be blocked, or if versioning is enabled, each write is stored as a new version. Microsoft recommends that you thoroughly review the documentation and test your scenarios before locking any time-based policies.\nImmutable storage with blob soft delete\nWhen blob soft delete is configured for a storage account, it applies to all blobs within the account regardless of whether a legal hold or time-based retention policy is in effect. Microsoft recommends enabling soft delete for extra protection before any immutability policies are applied.\nIf you enable blob soft delete and then configure an immutability policy, any blobs that have already been soft deleted are permanently deleted once the soft delete retention policy is expired. Soft-deleted blobs can be restored during the soft delete retention period. A blob or version that hasn't yet been soft deleted is protected by the immutability policy and can't be soft deleted until after the time-based retention policy is expired or the legal hold is removed.\nUse blob inventory to track immutability policies\nAzure Storage blob inventory provides an overview of the containers in your storage accounts and the blobs, snapshots, and blob versions within them. You can use the blob inventory report to understand the attributes of blobs and containers, including whether a resource has an immutability policy configured.\nWhen you enable blob inventory, Azure Storage generates an inventory report daily. The report provides an overview of your data for business and compliance requirements.\nFor more information about blob inventory, see\nAzure Storage blob inventory\n.\nNote\nYou can't configure an inventory policy in an account if support for version-level immutability is enabled on that account, or if support for version-level immutability is enabled on the destination container that is defined in the inventory policy.\nConfiguring policies at scale\nYou can use a\nstorage task\nto configure a immutability policies at scale across multiple storage accounts based on a set of conditions that you define. A storage task is a resource available in\nAzure Storage Actions\n; a serverless framework that you can use to perform common data operations on millions of objects across multiple storage accounts. To learn more, see\nWhat is Azure Storage Actions?\n.\nPricing\nThere's no extra capacity charge for using immutable storage. Immutable data is priced in the same way as mutable data. If you're using version-level WORM, the bill might be higher because you've enabled versioning, and there's a cost associated with extra versions being stored. Review the versioning pricing policy for more information. For pricing details on Azure Blob Storage, see the\nAzure Storage pricing page\n.\nCreating or deleting a time-based retention policy or legal hold on a blob version results in a write transaction charge. Modifying a time-based retention policy (either locking it or extending it) results in an other operation charge. If you are interested in learning more about transaction charges, please see\nOperations and Data Transfer\nhere.\nIf you fail to pay your bill and your account has an active time-based retention policy in effect, normal data retention policies apply as stipulated in the terms and conditions of your contract with Microsoft. For general information, see\nData management at Microsoft\n.\nFeature support\nImportant\nThis feature is\nincompatible\nwith point-in-time restore and last access tracking.\nThis feature is compatible with customer-managed unplanned failover, however, any changes that are made to the immutable policy after the last sync time (such as locking a time based retention policy, extending it, etc.) will not be synced to the secondary region. Once failover is completed, you can redo the changes to the secondary region to ensure it is up-to-date with your immutability requirements.\nImmutability policies aren't supported in accounts that have Network File System (NFS) 3.0 protocol or the SSH File Transfer Protocol (SFTP) enabled on them.\nSome workloads, such as SQL Backup to URL, create a blob and then add to it. If a container has an active time-based retention policy or legal hold in place, this pattern won't succeed. For more information, see\nAllow protected append blob writes\n.\nFor more information, see\nBlob Storage feature support in Azure Storage accounts\n.\nNext steps\nData protection overview\nContainer-level WORM policies for immutable blob data\nVersion-level WORM policies for immutable blob data\nConfigure immutability policies for blob versions\nConfigure immutability policies for containers\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Immutable Blob Storage",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/azure-monitor/alerts/alerts-overview": {
      "content_hash": "sha256:dffe2557a463ae5f04e6fd012e06b3c1cc08d4c038492873a6b2c06ee0b08fd8",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat are Azure Monitor alerts?\nFeedback\nSummarize this article for me\nAlerts help you detect and address issues before users notice them by proactively notifying you when Azure Monitor data indicates there might be a problem with your infrastructure or application.\nYou can alert on any metric or log data source in the Azure Monitor data platform.\nThis diagram shows you how alerts work.\nAn\nalert rule\nmonitors your data and captures a signal that indicates something is happening on the specified resource. The alert rule captures the signal and checks to see if the signal meets the criteria of the condition.\nAn alert rule combines:\nThe resources to be monitored.\nThe signal or data from the resource.\nConditions.\nAn\nalert\nis triggered if the conditions of the alert rule are met. The alert initiates the associated action group and updates the state of the alert. If you're monitoring more than one resource, the alert rule condition is evaluated separately for each of the resources, and alerts are fired for each resource separately.\nAlerts are stored for 30 days and are deleted after the 30-day retention period. You can see all alert instances for all of your Azure resources on the\nAlerts page\nin the Azure portal.\nAlerts consist of:\nAction groups\n: These groups can trigger notifications to let users know that an alert has been triggered or start automated workflows. Action groups can include:\nNotification methods, such as email, SMS, and push notifications.\nAutomation runbooks.\nAzure functions.\nITSM incidents.\nLogic apps.\nSecure webhooks.\nWebhooks.\nEvent hubs.\nAlert conditions\n: These conditions are set by the system. When an alert fires, the alert condition is set to\nfired\n. After the underlying condition that caused the alert to fire clears, the alert condition is set to\nresolved\n.\nUser response\n: The response is set by the user and doesn't change until the user changes it. The User response can be\nNew\n,\nAcknowledged\n, or\nClosed\n.\nAlert processing rules\n: You can use alert processing rules to make modifications to triggered alerts as they're being fired. You can use alert processing rules to add or suppress action groups, apply filters, or have the rule processed on a predefined schedule.\nTypes of alerts\nThis table provides a brief description of each alert type. For more information about each alert type and how to choose which alert type best suits your needs, see\nTypes of Azure Monitor alerts\n.\nAlert type\nDescription\nMetric alerts\nMetric alerts evaluate resource metrics at regular intervals. Metrics can be platform metrics, custom metrics, logs from Azure Monitor converted to metrics, or Application Insights metrics. Metric alerts can also apply multiple conditions and use dynamic thresholds.\nLog search alerts\nLog search alerts allow users to use a Log Analytics query to evaluate resource logs at a predefined frequency. Log search can use dynamic thresholds (preview).\nSimple log search alerts - preview\nSimple Log alerts allow users to use a Log Analytics query to evaluate each row individually.\nActivity log alerts\nActivity log alerts are triggered when a new activity log event occurs that matches defined conditions. Resource Health alerts and Service Health alerts are activity log alerts that report on your service and resource health.\nSmart detection alerts\nSmart detection on an Application Insights resource automatically warns you of potential performance problems and failure anomalies in your web application. You can migrate smart detection on your Application Insights resource to create alert rules for the different smart detection modules.\nPrometheus alerts\nPrometheus alerts are used for alerting on Prometheus metrics stored in\nAzure Monitor managed services for Prometheus\n. The alert rules are based on the PromQL open-source query language.\nNote\nQuery-based metric alerts are now in public preview for alerting based on Prometheus and OpenTelemetry metrics. See\nQuery-based metric alerts overview (preview)\nAlerts and state\nAlerts can be stateful or stateless.\nStateless alerts fire each time the condition is met, even if fired previously.\nStateful alerts fire when the rule conditions are met, and will not fire again or trigger any more actions until the conditions are resolved.\nEach alert rule is evaluated individually. There is no validation to check if there is another alert configured for the same conditions. If there is more than one alert rule configured for the same conditions, each of those alerts will fire when the conditions are met.\nAlerts are stored for 30 days and are deleted after the 30-day retention period.\nStateless alerts\nStateless alerts fire each time the condition is met. The alert condition for all stateless alerts is always\nfired\n.\nAll activity log alerts are stateless.\nThe frequency of notifications for stateless metric alerts differs based on the alert rule's configured frequency:\nAlert frequency of less than 5 minutes\n: While the condition continues to be met, a notification is sent sometime between one and six minutes.\nAlert frequency of equal to or more than 5 minutes\n: While the condition continues to be met, a notification is sent between the configured frequency and double the frequency. For example, for an alert rule with a frequency of 15 minutes, a notification is sent sometime between 15 to 30 minutes.\nStateful alerts\nStateful alerts fire when the rule conditions are met, and will not fire again or trigger any more actions until the conditions are resolved.\nThe alert condition for stateful alerts is\nfired\n, until it is considered resolved. When an alert is considered resolved, the alert rule sends out a resolved notification by using webhooks or email, and the alert condition is set to\nresolved\n.\nFor stateful alerts, while the alert itself is deleted after 30 days, the alert condition is stored until the alert is resolved, to prevent firing another alert, and so that notifications can be sent when the alert is resolved.\nSee\nservice limits\nfor alerts limitations, including limitations for stateful log alerts.\nThis table describes when a stateful alert is considered resolved:\nAlert type\nThe alert is resolved when\nMetric alerts\nThe alert condition isn't met for three consecutive checks.\nLog search alerts\nThe alert condition isn't met for a specific time range. The time range differs based on the frequency of the alert:\n1 minute\n: The alert condition isn't met for 10 minutes.\n5 to 15 minutes\n: The alert condition isn't met for three frequency periods.\n15 minutes to 11 hours\n: The alert condition isn't met for two frequency periods.\n11 to 12 hours\n: The alert condition isn't met for one frequency period.\nRecommended alert rules\nYou can\nenable recommended out-of-the-box alert rules in the Azure portal\n.\nThe system compiles a list of recommended alert rules based on:\nThe resource provider's knowledge of important signals and thresholds for monitoring the resource.\nData that tells us what customers commonly alert on for this resource.\nNote\nRecommended alert rules are enabled for:\nVirtual machines\nAKS resources\nLog Analytics workspaces\nAlerting at-scale\nYou can use any of the following methods for creating alert rules at-scale. Each choice has advantages and disadvantages that could have an effect on cost and on maintenance of the alert rules.\nMetric alerts\nYou can use\none metric alert rule to monitor multiple resources\nof the same type that exist in the same Azure region. Individual notifications are sent for each monitored resource.\nFor metric alert rules for Azure services that don't support multiple resources, use automation tools such as the Azure CLI, PowerShell, or Azure Resource Manager templates to create the same alert rule for multiple resources. For sample ARM templates, see\nResource Manager template samples for metric alert rules in Azure Monitor\n.\nEach metric alert rule is charged based on the number of time series that are monitored.\nLog search alerts\nUse\nlog search alert rules\nto monitor all resources that send data to the Log Analytics workspace. These resources can be from any subscription or region. Use data collection rules when setting up your Log Analytics workspace to collect the required data for your log search alert rule.\nYou can also create resource-centric alerts instead of workspace-centric alerts by using\nSplit by dimensions\n. When you split on the resourceId column, you will get one alert per resource that meets the condition.\nLog search alert rules that use splitting by dimensions are charged based on the number of time series created by the dimensions resulting from your query. If the data is already collected to a Log Analytics workspace, there is no additional cost.\nIf you use metric data at scale in the Log Analytics workspace, pricing will change based on the data ingestion.\nSimple log search alerts - Preview\nSimple log search alerts are designed to provide a simpler and faster alternative to traditional log search alerts. Unlike traditional log search alerts that aggregate rows over a defined period, simple log alerts evaluate each row individually. Search based alerts support the analytics and basic logs.\nSimple log search alerts use the Kusto Query Language (KQL) but the feature is designed to simplify the query process, making it easier for you to create alerts without extensive KQL knowledge.\nSimple search alerts provide faster alerting compared to traditional log search alerts By evaluating each row individually. Alerts are triggered almost in real-time, allowing for quicker incident response.\nCreate a simple log search alert\n.\nUsing Azure policies for alerting at scale\nYou can use\nAzure policies\nto set up alerts at-scale. This has the advantage of easily implementing alerts at-scale. You can see how this is implemented with\nAzure Monitor baseline alerts\n.\nKeep in mind that if you use policies to create alert rules, you may have the increased overhead of maintaining a large alert rule set.\nAzure role-based access control for alerts\nYou can only access, create, or manage alerts for resources for which you have permissions.\nTo create an alert rule, you must have:\nRead permission on the target resource of the alert rule.\nWrite permission on the resource group in which the alert rule is created. If you're creating the alert rule from the Azure portal, the alert rule is created by default in the same resource group in which the target resource resides.\nRead permission on any action group associated with the alert rule, if applicable.\nThese built-in Azure roles, supported at all Azure Resource Manager scopes, have permissions to and can access alerts information and create alert rules:\nMonitoring contributor\n: A contributor can create alerts and use resources within their scope.\nMonitoring reader\n: A reader can view alerts and read resources within their scope.\nIf the target action group or rule location is in a different scope than the two built-in roles, create a user with the appropriate permissions.\nPricing\nFor information about pricing, see\nAzure Monitor pricing\n.\nNext steps\nSee your alert instances\nCreate a new alert rule\nLearn about action groups\nLearn about alert processing rules\nManage your alerts programmatically\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Monitor Alerts",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/service-health/service-health-overview": {
      "content_hash": "sha256:570d3b9962debee701a60e604372c7acc65c9db6c1747584942728f444514ba9",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nService Health portal classic experience overview\nFeedback\nSummarize this article for me\nThe\nService Health portal\nis part of the\nService Health service\n. The portal provides you with a customizable dashboard that tracks the health of your Azure services in the regions where you use them. In this dashboard, you can track active events like ongoing service issues, upcoming planned maintenance, or relevant health advisories. You can use the Service Health dashboard to create and manage Service Health alerts, which proactively notify you when service issues are affecting you.\nNote\nThis article describes the older \"classic\" portal experience, which is no longer available. We recommend using the new\nService Health\nportal instead.\nFor more information, see\nAzure Service Health\n.\nService Health events\nThe\nService Health portal\ntracks four types of health events that might affect your resources:\nService issues\n: Problems with the Azure services that affect you right now.\nPlanned maintenance\n: Upcoming maintenance that can affect the availability of your services in the future.\nHealth advisories\n: Changes in Azure services that require your attention. Examples include deprecation of Azure features or upgrade requirements (like needing to upgrade to a supported PHP framework).\nSecurity advisories\n: Security-related notifications or violations that might affect the availability of your Azure services.\nWhen events become inactive, they get placed in your health history for up to 90 days.\nNote\nTo view Service Health events, users must be\ngranted the Reader role\non a subscription.\nGet started with the Service Health portal\nTo open your Service Health dashboard, select\nService Health\nunder\nAzure services\nin the Azure portal. If you're using a custom dashboard, select\nMore services\nand search for Service Health.\nSee current issues that are affecting your services\nSelect\nService issues\non the left menu to see ongoing problems in Azure services that are affecting your resources. You learn when the issue began, and what services and regions are affected. You can also read the most recent update to understand what Azure is doing to resolve the issue.\nFrom the\nService issues\npane, select the\nPotential impact\ntab to see a list of the specific resources you own that might be affected by the issue. You can download a CSV file of these resources to share with your team.\nSee emerging issues that might affect your services\nIn certain situations, widespread service issues might be posted to the\nAzure status page\nbefore targeted communications can be sent to affected customers. To ensure that Azure Service Health provides a comprehensive view of issues that might affect you, active Azure status page issues appear in Service Health as\nemerging issues\n. When an event is active on the Azure status page, an\nEmerging issues\nbanner is present in Service Health. Select the banner to see the full details of the issue.\nGet links and explanations that you can download\nYou can get a link for the issue to use in your problem management system. You can download PDF (and sometimes CSV) files to share with people who don't have access to the Azure portal.\nGet support from Microsoft\nContact support if your resource remains in an unhealthy or unusable state even after the issue is marked as resolved. Use the support links on the right of the page.\nPin a personalized health map to your dashboard\nYou can use filters in Service Health to show your business-critical subscriptions, regions, and resource types. You can save a filter and pin a personalized health world map to your portal dashboard.\nConfigure Service Health alerts\nWhen your business-critical resources are affected, Service Health integrates with Azure Monitor to alert you via emails, text messages, and webhook notifications. Set up an activity log alert for the appropriate Service Health event. You can route that alert to the appropriate people in your organization by using action groups. For more information, see\nConfigure alerts for Service Health\n.\nRelated content\nSet up alerts so you're notified of health issues.\nLearn about\nbest practices for setting up Azure Service Health alerts\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Service Health",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/information-protection/what-is-information-protection": {
      "content_hash": "sha256:8d600d35d2a6cdb84cda0a9ebb159a0c2c7b7b7ba5958b9abbee68ff9e4db22c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Azure Information Protection?\nFeedback\nSummarize this article for me\nNote\nAre you looking for\nMicrosoft Purview Information Protection\n, formerly Microsoft Information Protection (MIP)?\nThe Azure Information Protection add-in is\nretired\nand replaced with labels that are\nbuilt in to your Microsoft 365 apps and services\n. Learn more about the\nsupport status of other Azure Information Protection components\n.\nThe\nMicrosoft Purview Information Protection client\n(without the add-in) is\ngenerally available\n.\nAzure Information Protection (AIP) provides the encryption service,\nAzure Rights Management\n, that's used by Microsoft Purview Information Protection and the following capabilities:\nSensitivity labels\nMicrosoft Purview Information Protection client\nMicrosoft Purview Information Protection scanner\nMicrosoft Information Protection SDK\nFor a comprehensive list of capabilities from Microsoft Purview Information Protection, see\nProtect your sensitive data with Microsoft Purview\n.\nMicrosoft Information Protection SDK\nThe Microsoft Information Protection SDK extends sensitivity labels to third-party apps and services. Developers can use the SDK to build built-in support for applying labels and protection to files.\nFor example, you might use the MIP SDK for:\nA line-of-business application that applies sensitivity labels to files on export.\nA CAD/CAM design application that provides support for built-in labeling.\nA cloud access security broker or data loss prevention solution that reasons over data encrypted with Azure Information Protection.\nFor more information, see the\nMicrosoft Information Protection SDK overview\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Information Protection",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/information-protection/rms-client/track-and-revoke-admin": {
      "content_hash": "sha256:7c7564e17da50b0e1483b10fd4b33b2b688f8b1198ef0477a1f920f2c6c26a56",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nTrack and revoke document access\nFeedback\nSummarize this article for me\nDocument tracking provides information for administrators about when a protected document was accessed. If necessary, both admins and users can revoke document access for tracked documents.\nA document must be registered for tracking before an admin can track access details, including successful access events and denied attempts, and revoke access if needed. See the next section for minimum versions of Office apps for built-in labeling that support file registration the next time they're opened.\nNote\nTrack and revoke features are supported for Office file types only.\nRequirements\nUse the\ncapabilities table\nand the row\nDocument tracking and revocation\nto identify the minimum versions of Word, Excel, and PowerPoint that automatically register label-protected local Office documents (if not already registered) the next time they're opened.\nPowerShell cmdlets in this article use the\nAIPService\nPowerShell module, which you can install from the\nPowerShell Gallery\n. You must run\nConnect-AipService\nto connect to your tenant before you run any of the documented cmdlets.\nLimitations\nPassword-protected documents aren't supported by track and revoke features.\nIf you attach multiple documents to an email, and then protect the email and send it, each of the attachments gets the same ContentID value. This ContentID value will be returned only with the first file that had been opened. Searching for the other attachments won't return the ContentID value required to get tracking data.\nAdditionally, revoking access for one of the attachments also revokes access for the other attachments in the same protected email.\nDocuments protected with admin-defined permissions that are uploaded to SharePoint or OneDrive lose their\nContentID\nvalue, and access can't be tracked or revoked.\nIf a user downloads a file protected with admin-defined permissions from SharePoint or OneDrive, a new\nContentID\nis applied to the document. Using the original\nContentID\nvalue to track data won't include any access performed for the user's downloaded file. Additionally, revoking access based on the original\nContentID\nvalue won't revoke access for any of the downloaded files.\nIf administrators have access to the downloaded files, they can use PowerShell to identify a document's\nContentID\nfor track and revoke actions.\nTrack document access\nAdmins can track access for protected documents via PowerShell using the\nContentID\ngenerated for the protected document during registration.\nTo view document access details\n:\nUse the following cmdlets to find details for the document you want to track:\nFind the\nContentID\nvalue for the document you want to track.\nUse the\nGet-AipServiceDocumentLog\nto search for a document using the filename or the email address of the user who applied protection.\nFor example;\nGet-AipServiceDocumentLog -ContentName \"test.docx\" -Owner âalice@contoso.comâ -FromTime \"[DATE] 00:00:00\" -ToTime \"[DATE] 23:59:59\"\nThis command returns the\nContentID\nfor all matching, protected documents that are registered for tracking.\nNote\nProtected documents are registered for tracking when they're first opened in an Office app that supports file registration. If this command does not return the ContentID for your protected file, open it in an Office app that\nsupports file registration\n.\nUse the\nGet-AipServiceTrackingLog\ncmdlet with your document's\nContentID\nto return your tracking data.\nFor example:\nGet-AipServiceTrackingLog -ContentId c03bf90c-6e40-4f3f-9ba0-2bcd77524b87\nTracking data is returned, including emails of users who attempted access, whether access was granted or denied, the time and date of the attempt, and the domain and location where the access attempt originated.\nRevoke document access from PowerShell\nAdmins can revoke access for any protected document stored in their local content shares, using the\nSet-AIPServiceDocumentRevoked\ncmdlet.\nNote\nIf\noffline access\nis allowed, users will continue to be able to access the documents that have been revoked until the offline policy period expires.\nFind the\nContentID\nvalue for the document you want to revoke access for.\nUse the\nGet-AipServiceDocumentLog\nto search for a document using the filename or the email address of the user who applied protection.\nFor example:\nGet-AipServiceDocumentLog -ContentName \"test.docx\" -Owner âalice@contoso.comâ -FromTime \"[DATE] 00:00:00\" -ToTime \"[DATE] 23:59:59\"\nThe data returned includes the ContentID value for your document.\nTip\nOnly documents that have been protected and registered for tracking have a\nContentID\nvalue. If your document has no\nContentID\n, open it in an Office app that\nsupports file registration\n.\nUse the\nSet-AIPServiceDocumentRevoked\nwith your document's ContentID to revoke access.\nFor example:\nSet-AipServiceDocumentRevoked -ContentId 0e421e6d-ea17-4fdb-8f01-93a3e71333b8 -IssuerName testIssuer\nBy using the\nSensitivity\nmenu in their Office apps, users can also revoke access for any documents that they protected.\nRestore access\nIf you've accidentally revoked access to a specific document, use the same\nContentID\nvalue with the\nClear-AipServiceDocumentRevoked\ncmdlet to restore the access.\nFor example:\nClear-AipServiceDocumentRevoked -ContentId 0e421e6d-ea17-4fdb-8f01-93a3e71333b8 -IssuerName testIssuer\nDocument access is granted to the user you defined in the\nIssuerName\nparameter.\nTurn off track and revoke features for your tenant\nIf you need to turn off track and revoke features for your tenant, such as for privacy requirements in your organization or region, run the\nDisable-AipServiceDocumentTrackingFeature\ncmdlet.\nDocument tracking and options to revoke access are turned off for your tenant:\nOpening protected documents no longer registers the documents for track and revoke.\nAccess logs aren't stored when protected documents that are already registered are opened. Access logs that were stored before turning off these features are still available.\nAdmins won't be able to track or revoke access via PowerShell, and although end-users still see the\nRevoke\nmenu option in their Office apps, the site displays a message that tracking and revocation has been disabled by their administrator.\nIf you need to turn track and revoke back on, run the\nEnable-AipServiceDocumentTrackingFeature\ncmdlet.\nRemove the track and revoke options from the sensitivity menu\nIf you need to remove the Track & Revoke button from the sensitivity menu on Office clients, use PowerShell advanced settings with the\nSet-LabelPolicy\ncmdlet.\nExample PowerShell command:\nSet-LabelPolicy -Identity Global -AdvancedSettings @{EnableRevokeGuiSupport=\"False\"}\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Track and Revoke Documents",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/compliance/apply-irm-to-a-list-or-library": {
      "content_hash": "sha256:91732fa2a45dc4b608118c53d408667404afa0b4b5845c82e6d659d28bc37505",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nApply Information Rights Management (IRM) to a list or library\nFeedback\nSummarize this article for me\nYou can use Information Rights Management (IRM) to help control and protect files that are downloaded from lists or libraries. This feature is only supported in the Microsoft global cloud. IRM isn't supported for SharePoint lists and libraries in national cloud deployments.\nAdministrator preparations before applying IRM\nThe Azure Rights Management service (Azure RMS) from Microsoft Purview Information Protection, and the on-premises equivalent, Active Directory Rights Management Services (AD RMS), support Information Rights Management for sites. No other installations are required.\nBefore you apply IRM to a list or library, you need to enable IRM for your site. You need administrator permissions for the site to enable IRM. In addition, to apply IRM to a list or library, you must have administrator permissions for that list or library.\nIf you're using SharePoint, your users might experience timeouts when downloading larger IRM-protected files. To avoid timeouts, use your Office apps to apply IRM protection, and store larger files in a SharePoint library that doesn't use IRM.\nNote\nIf you're using SharePoint Server 2013, a server administrator must install protectors on all front-end Web servers for every file type that the users in your organization want to protect by using IRM.\nApply IRM to a list or library\nGo to the list or library for which you want to configure IRM.\nOn the ribbon, select the\nLibrary\ntab, and then select\nLibrary Settings\n. (If you're working in a list, select the\nList\ntab, and then select\nList Settings\n).\nUnder\nPermissions and Management\n, select\nInformation Rights Management\n. If the Information Rights Management link doesn't appear, IRM might not be enabled for your site. Contact your server administrator to see if you can enable IRM for your site. The\nInformation Rights Management\nlink doesn't appear for picture libraries.\nOn the\nInformation Rights Management Settings\npage, select the\nRestrict permission to documents in this library on download\ncheck box to apply restricted permissions to documents that users download from this list or library.\nIn the\nCreate a permission policy title\nbox, enter a descriptive name for the policy. Use a name that helps you identify this policy from other policies. For example, use\nCompany Confidential\nto apply restricted permissions to a list or library that contains confidential company documents.\nIn the\nAdd a permission policy description\nbox, type a description that appears to users who use this list or library that explains how they should handle the documents in this list or library. For example, you can type\nDiscuss the contents of this document only with other employees\nif you want to restrict access to the information in these documents to internal users.\nTo apply another restriction to the documents in this list or library, select\nShow Options\n, and do any of the following:\nTo do this:\nDo this:\nAllow users to print documents from this list or library\nSelect the\nAllow viewers to print\ncheck box.\nAllow users with at least the View Items permission to run embedded code or macros on a document.\nSelect the\nAllow viewers to run script and screen reader to function on downloaded documents\ncheck box. If you select this option, users could run code to extract the contents of a document.\nSelect this option if you want to restrict access to content to a specified period of time. If you select this option, user issuance licenses to access the content will expire after the specified number of days Users need to return to the server to verify their credentials and download a new copy.\nSelect the\nAfter download, document access rights will expire after these number of days (1-365)\ncheck box, and then specify the number of days for which you want the document to be viewable.\nPrevent users from uploading documents that don't support IRM to this list or library. If you select this option, users can't upload these file types: File types that don't have corresponding IRM protectors installed on all of the front-end web servers. File types that SharePoint Server 2010 can't decrypt. File types that are IRM protected in another program.\nSelect the\nDo not allow users to upload documents that do not support IRM\ncheck box.\nRemove restricted permissions from this list or library on a specific date.\nSelect the\nStop restricting access to the library at\ncheck box, and then select the date that you want.\nControl the interval that Azure RMS credentials are cached for the program that is licensed to open the document.\nSelect the\nUsers must verify their credentials using this interval (days)\ncheck box, then enter the interval for caching credentials in number of days.\nAllow group protection so that users can share with members of the same group.\nSelect\nAllow group protection\n, and enter the group's name for sharing.\nPrevent opening documents in the browser for this Document Library.\nSelect this option if you want to restrict users from opening Office files in the browser. Note that this setting applies only to Office files and will not affect other file types, such as Loop or PDF.\nAfter you finish selecting the options you want, select\nOK\n.\nWhat is Information Rights Management?\nInformation Rights Management (IRM) enables you to limit the actions that users can take on files that downloaded from lists or libraries. IRM encrypts the downloaded files and limits the set of users and programs that are allowed to decrypt these files. IRM can also limit the rights of the users who are allowed to read files, so that they can't take actions such as print copies of the files or copy text from them.\nYou can use IRM on lists or libraries to limit the dissemination of sensitive content. For example, create a document library to share information about upcoming products with selected marketing representatives. Then use IRM to prevent these individuals from sharing this content with other users in the company.\nOn a site, you apply IRM to an entire list or library, rather than to individual files. This application makes it easier to ensure a consistent level of protection for an entire set of documents or files. IRM can thus help your organization to enforce corporate policies that govern the use and dissemination of confidential or proprietary information.\nNote\nThe information in this article regarding Information Rights Management supersedes any terms that reference 'Information Rights Management' in any Microsoft SharePoint Server 2013 and SharePoint Server 2016 license term agreements.\nHow IRM can help protect content\nIRM helps to protect restricted content in the following ways:\nHelps to prevent an authorized viewer from copying, modifying, printing, faxing, or copying and pasting the content for unauthorized use\nHelps to prevent an authorized viewer from copying the content by using the Print Screen feature in Microsoft Windows\nHelps to prevent an unauthorized viewer from viewing the content if it was sent in e-mail after it was downloaded from the server\nRestricts access to content to a specified period of time, after which users must confirm their credentials and download the content again\nHelps to enforce corporate policies that govern the use and dissemination of content within your organization\nHow IRM can't help protect content\nIRM can't protect restricted content from:\nErasure, theft, capture, or transmission by malicious programs such as Trojan horses, keystroke loggers, and certain types of spyware\nLoss or corruption because of the actions of computer viruses\nManual copying or retyping of content from the display on a screen\nDigital or film photography of content that is displayed on a screen\nCopying by non-Microsoft screen-capture programs\nCopying of content metadata (column values) by non-Microsoft screen-capture programs or copy-and-paste action\nHow IRM works for lists and libraries\nIRM protection is applied to files at the list or library level. When IRM is enabled for a library, rights management applies to all of the files in that library. When IRM is enabled for a list, rights management applies only to files that are attached to list items, not the actual list items.\nWhen users download files in an IRM-enabled list or library, the files are encrypted so that only authorized users can view them. Each rights-managed file also contains an issuance license that imposes restrictions on the users who view the file. Typical restrictions include:\nMaking a file read-only\nDisabling the copying of text\nPreventing users from saving a local copy\nPreventing users from printing the file\nClient programs that can read IRM-supported file types use the issuance license within the rights-managed file to enforce these restrictions. In this way, a rights-managed file retains its protection even after being downloaded from the server.\nThe types of restrictions applied to a file that is downloaded from a list or library are based on the user's site permissions. The following table explains how the permissions on sites correspond to IRM permissions.\nPermissions\nIRM Permissions\nManage Permissions, Manage Web Site\nFull control\n(as defined by the client program): This permission generally allows a user to read, edit, copy, save, and modify permissions of rights-managed content.\nEdit Items, Manage Lists, Add, and Customize Pages\nEdit\n,\nCopy\n, and\nSave\n: A user can print a file only if the\nAllow users to print documents\ncheck box is selected on the Information Rights Management Settings page for the list or library.\nView Items\nRead\n: A user can read the document, but can't copy or modify its content. A user can print only if the\nAllow users to print documents\ncheck box is selected on the Information Rights Management Settings page for the list or library.\nOther\nNo other permissions correspond directly to IRM permissions.\nWhen you enable IRM for a list or library in SharePoint Server 2013, you can only protect file types in that list or library for which a protector is installed on all front-end web servers. A protector is a program that controls the encryption and decryption of rights-managed files of a specific file format. SharePoint includes protectors for the following file types:\nMicrosoft Office InfoPath forms\nThe 97-2003 file formats for the following Microsoft Office programs: Word, Excel, and PowerPoint\nThe Office Open XML Formats for the following Microsoft Office programs: Word, Excel, and PowerPoint\nThe XML Paper Specification (XPS) format\nIf your organization plans to use IRM to protect any other file types in addition to the formats listed in this article, your server administrator must install protectors for these other file formats.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Apply IRM to SharePoint",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai": {
      "content_hash": "sha256:66c621255f414f4049c683582da445ed1ff12c71def47b755b48a90cbf0469f5",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Responsible AI?\nFeedback\nSummarize this article for me\nAPPLIES TO:\nAzure CLI ml extension v2 (current)\nPython SDK azure-ai-ml v2 (current)\nResponsible Artificial Intelligence (Responsible AI) is an approach to developing, assessing, and deploying AI systems safely, ethically, and with trust. AI systems result from many decisions made by their creators. Responsible AI helps guide these decisionsâfrom defining system purpose to user interactionâtoward more beneficial and equitable outcomes. It keeps people and their goals at the center of design and respects values like fairness, reliability, and transparency.\nMicrosoft created a\nResponsible AI Standard\n, a framework for building AI systems based on six principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. These principles are the foundation of a responsible and trustworthy approach to AI, especially as intelligent technology becomes more common in everyday products and services.\nThis article explains how Azure Machine Learning provides tools to help developers and data scientists implement and operationalize these six principles.\nFairness and inclusiveness\nAI systems should treat everyone fairly and avoid affecting similar groups differently. For example, when AI systems provide guidance on medical treatment, loan applications, or employment, they should make the same recommendations to people with similar symptoms, financial circumstances, or qualifications.\nFairness and inclusiveness in Azure Machine Learning\n: The\nfairness assessment\ncomponent of the\nResponsible AI dashboard\nhelps assess model fairness across sensitive groups, such as gender, ethnicity, age, and other characteristics.\nReliability and safety\nTo build trust, AI systems must operate reliably, safely, and consistently. They should function as designed, respond safely to unexpected conditions, and resist harmful manipulation. Their behavior and ability to handle different conditions reflect the range of situations developers anticipated during design and testing.\nReliability and safety in Azure Machine Learning\n: The\nerror analysis\ncomponent of the\nResponsible AI dashboard\nhelps you:\nGet a deep understanding of how failure is distributed for a model.\nIdentify cohorts (subsets) of data with a higher error rate than the overall benchmark.\nThese discrepancies can occur when the system or model underperforms for specific demographic groups or for rarely observed input conditions in the training data.\nTransparency\nWhen AI systems inform decisions that impact people's lives, it's critical that people understand how those decisions are made. For example, a bank might use an AI system to decide if a person is creditworthy, or a company might use one to select job candidates.\nA crucial part of transparency is\ninterpretability\n: providing useful explanations of AI system behavior. Improving interpretability helps stakeholders understand how and why AI systems work, so they can identify performance issues, fairness concerns, exclusionary practices, or unintended outcomes.\nTransparency in Azure Machine Learning\n: The\nmodel interpretability\nand\ncounterfactual what-if\ncomponents of the\nResponsible AI dashboard\nhelp generate human-understandable descriptions of model predictions.\nThe model interpretability component provides several views into a model's behavior:\nGlobal explanations\n. For example, what features affect the overall behavior of a loan allocation model?\nLocal explanations\n. For example, why was a customer's loan application approved or rejected?\nModel explanations for a selected cohort of data points\n. For example, what features affect the overall behavior of a loan allocation model for low-income applicants?\nThe counterfactual what-if component helps you understand and debug a machine learning model by showing how it reacts to feature changes and perturbations.\nAzure Machine Learning also supports a\nResponsible AI scorecard\n. The scorecard is a customizable PDF report that developers can configure, generate, download, and share with technical and non-technical stakeholders. It helps educate stakeholders about dataset and model health, achieve compliance, and build trust. The scorecard can also support audit reviews by revealing machine learning model characteristics.\nPrivacy and security\nAs AI becomes more common, protecting privacy and securing personal and business information is more important and complex. Privacy and data security require close attention because AI systems need data to make accurate predictions and decisions. AI systems must comply with privacy laws that:\nRequire transparency about the collection, use, and storage of data.\nMandate that consumers have appropriate controls to choose how their data is used.\nPrivacy and security in Azure Machine Learning\n: Azure Machine Learning enables administrators and developers to\ncreate secure configurations\nthat comply with company policies. With Azure Machine Learning and the Azure platform, you can:\nRestrict access to resources and operations by user account or group.\nRestrict incoming and outgoing network communications.\nEncrypt data in transit and at rest.\nScan for vulnerabilities.\nApply and audit configuration policies.\nMicrosoft also created two open-source packages to help implement privacy and security principles:\nSmartNoise\n: Differential privacy is a set of systems and practices that help keep the data of individuals safe and private. In machine learning solutions, differential privacy might be required for regulatory compliance. SmartNoise is an open-source project (co-developed by Microsoft) that contains components for building differentially private systems that are global.\nCounterfit\n: Counterfit is an open-source project that comprises a command-line tool and generic automation layer to allow developers to simulate cyberattacks against AI systems. Anyone can download the tool and deploy it through Azure Cloud Shell to run in a browser, or deploy it locally in an Anaconda Python environment. It can assess AI models hosted in various cloud environments, on-premises, or in the edge. The tool is agnostic to AI models and supports various data types, including text, images, or generic input.\nAccountability\nPeople who design and deploy AI systems must be accountable for how those systems operate. Organizations should use industry standards to develop accountability norms. These norms help ensure that AI systems are not the final authority on decisions that affect people's lives and that humans maintain meaningful control over highly autonomous systems.\nAccountability in Azure Machine Learning\n:\nMachine learning operations (MLOps)\nis based on DevOps principles and practices that improve AI workflow efficiency. Azure Machine Learning provides these MLOps capabilities for better accountability:\nRegister, package, and deploy models from anywhere. You can also track the associated metadata that's required to use the model.\nCapture the governance data for the end-to-end machine learning lifecycle. The logged lineage information can include who is publishing models, why changes were made, and when models were deployed or used in production.\nNotify and alert on events in the machine learning lifecycle. Examples include experiment completion, model registration, model deployment, and data drift detection.\nMonitor applications for operational issues and issues related to machine learning. Compare model inputs between training and inference, explore model-specific metrics, and provide monitoring and alerts on your machine learning infrastructure.\nIn addition, the\nResponsible AI scorecard\nin Azure Machine Learning creates accountability by enabling cross-stakeholder communication. The scorecard empowers developers to configure, download, and share model health insights with both technical and non-technical stakeholders. Sharing these insights helps build trust.\nAzure Machine Learning also supports decision-making by informing business decisions through:\nData-driven insights, which help stakeholders understand causal treatment effects on outcomes using historical data only. For example, \"How would a medicine affect a patient's blood pressure?\" These insights come from the\ncausal inference\ncomponent of the\nResponsible AI dashboard\n.\nModel-driven insights, which answer user questions (such as \"What can I do to get a different outcome from your AI next time?\") so they can take action. These insights are provided through the\ncounterfactual what-if\ncomponent of the\nResponsible AI dashboard\n.\nNext steps\nFor more information on how to implement Responsible AI in Azure Machine Learning, see\nResponsible AI dashboard\n.\nLearn how to generate the Responsible AI dashboard via\nCLI and SDK\nor\nAzure Machine Learning studio UI\n.\nLearn how to generate a\nResponsible AI scorecard\nbased on the insights observed in your Responsible AI dashboard.\nLearn about the\nResponsible AI Standard\nfor building AI systems according to six key principles.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Responsible AI",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview": {
      "content_hash": "sha256:b1443e2bacc49fd15e07b1ba2c21db567a5651841e5880967fe6ad7caa16c9ee",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Azure AI Content Safety?\nFeedback\nSummarize this article for me\nAzure AI Content Safety is an AI service that detects harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes text and image APIs that allow you to detect material that is harmful. The interactive Content Safety Studio allows you to view, explore, and try out sample code for detecting harmful content across different modalities.\nContent filtering software can help your app comply with regulations or maintain the intended environment for your users.\nThis documentation contains the following article types:\nConcepts\nprovide in-depth explanations of the service functionality and features.\nQuickstarts\nare getting-started instructions to guide you through making requests to the service.\nHow-to guides\ncontain instructions for using the service in more specific or customized ways.\nWhere it's used\nThe following are a few scenarios in which a software developer or team would require a content moderation service:\nUser prompts submitted to a generative AI service.\nContent produced by generative AI models.\nOnline marketplaces that moderate product catalogs and other user-generated content.\nGaming companies that moderate user-generated game artifacts and chat rooms.\nSocial messaging platforms that moderate images and text added by their users.\nEnterprise media companies that implement centralized moderation for their content.\nK-12 education solution providers filtering out content that is inappropriate for students and educators.\nImportant\nYou cannot use Azure AI Content Safety to detect illegal child exploitation images.\nProduct features\nThis service makes several different types of analysis available. The following table describes the currently available APIs.\nFeature\nFunctionality\nConcepts guide\nGet started\nPrompt Shields\nScans text for the risk of a User input attack on a Large Language Model.\nPrompt Shields concepts\nQuickstart\nGroundedness detection\n(preview)\nDetects whether the text responses of large language models (LLMs) are grounded in the source materials provided by the users.\nGroundedness detection concepts\nQuickstart\nProtected material text detection\nScans AI-generated text for known text content (for example, song lyrics, articles, recipes, selected web content).\nProtected material concepts\nQuickstart\nCustom categories (standard) API (preview)\nLets you create and train your own custom content categories and scan text for matches.\nCustom categories concepts\nQuickstart\nCustom categories (rapid) API (preview)\nLets you define emerging harmful content patterns and scan text and images for matches.\nCustom categories concepts\nHow-to guide\nAnalyze text\nAPI\nScans text for sexual content, violence, hate, and self harm with multi-severity levels.\nHarm categories\nQuickstart\nAnalyze image\nAPI\nScans images for sexual content, violence, hate, and self harm with multi-severity levels.\nHarm categories\nQuickstart\nTask adherence API\nDetects when tool use by AI agents is misaligned, unintended, or premature in the context of a user interaction.\nTask adherence concepts\nQuickstart\nContent Safety Studio\nAzure AI Content Safety Studio\nis an online tool designed to handle potentially offensive, risky, or undesirable content using cutting-edge content moderation ML models. It provides templates and customized workflows, enabling users to choose and build their own content moderation system. Users can upload their own content or try it out with provided sample content.\nContent Safety Studio not only contains out-of-the-box AI models but also includes\nMicrosoft's built-in terms blocklists\nto flag profanities and stay up to date with new content trends. You can also upload your own blocklists to enhance the coverage of harmful content that's specific to your use case.\nStudio also lets you set up a\nmoderation workflow\n, where you can continuously monitor and improve content moderation performance. It can help you meet content requirements from all kinds of industries like gaming, media, education, E-commerce, and more. Businesses can easily connect their services to the Studio and have their content moderated in real-time, whether user-generated or AI-generated.\nAll of these capabilities are handled by the Studio and its backend; customers donât need to worry about model development. You can onboard your data for quick validation and monitor your KPIs accordingly, like technical metrics (latency, accuracy, recall), or business metrics (block rate, block volume, category proportions, language proportions, and more). With simple operations and configurations, customers can test different solutions quickly and find the best fit, instead of spending time experimenting with custom models or doing moderation manually.\nTry Content Safety Studio\nContent Safety Studio features\nIn Content Safety Studio, the following Azure AI Content Safety features are available:\nModerate Text Content\n: With the text moderation tool, you can easily run tests on text content. Whether you want to test a single sentence or an entire dataset, our tool offers a user-friendly interface that lets you assess the test results directly in the portal. You can experiment with different sensitivity levels to configure your content filters and blocklist management, ensuring that your content is always moderated to your exact specifications. Plus, with the ability to export the code, you can implement the tool directly in your application, streamlining your workflow and saving time.\nModerate Image Content\n: With the image moderation tool, you can easily run tests on images to ensure that they meet your content standards. Our user-friendly interface allows you to evaluate the test results directly in the portal, and you can experiment with different sensitivity levels to configure your content filters. Once you've customized your settings, you can easily export the code to implement the tool in your application.\nMonitor Online Activity\n: The powerful monitoring page allows you to easily track your moderation API usage and trends across different modalities. With this feature, you can access detailed response information, including category and severity distribution, latency, error, and blocklist detection. This information provides you with a complete overview of your content moderation performance, enabling you to optimize your workflow and ensure that your content is always moderated to your exact specifications. With our user-friendly interface, you can quickly and easily navigate the monitoring page to access the information you need to make informed decisions about your content moderation strategy. You have the tools you need to stay on top of your content moderation performance and achieve your content goals.\nSecurity\nMicrosoft Entra ID or Managed Identity\nFor enhanced security, you can use Microsoft Entra ID or Managed Identity (MI) to manage access to your resources.\nManaged Identity is automatically enabled when you create a Content Safety resource.\nMicrosoft Entra ID is supported in both API and SDK scenarios. Refer to the general AI services guideline of\nAuthenticating with Microsoft Entra ID\n. You can also grant access to other users within your organization by assigning them the roles of\nCognitive Services Users\nand\nReader\n. To learn more about granting user access to Azure resources using the Azure portal, refer to the\nRole-based access control guide\n.\nEncryption of data at rest\nLearn how Azure AI Content Safety handles the\nencryption and decryption of your data\n. Customer-managed keys (CMK), also known as Bring Your Own Key (BYOK), offer greater flexibility to create, rotate, disable, and revoke access controls. You can also audit the encryption keys used to protect your data.\nPricing\nAzure AI Content Safety has an\nF0\nand\nS0\npricing tier. See the Azure\npricing page\nfor more information.\nService limits\nImportant\nDeprecation Notice\nAs part of Content Safety versioning and lifecycle management, we are announcing the deprecation of certain Public Preview and GA versions of our service APIs. Following our deprecation policy:\nPublic Preview versions\n: Each new Public Preview version will trigger the deprecation of the previous preview version after a 90-day period, provided no breaking changes are introduced.\nGA versions\n: When a new GA version is released, the prior GA version will be deprecated after a 90-day period if compatibility is maintained.\nSee the\nWhat's new\npage for upcoming deprecations.\nInput requirements\nSee the following list for the input requirements for each feature.\nAnalyze text API\n:\nDefault maximum length: 10K characters (split longer texts as needed).\nAnalyze image API\n:\nMaximum image file size: 4 MB\nDimensions between 50 x 50 and 7200 x 7200 pixels.\nImages can be in JPEG, PNG, GIF, BMP, TIFF, or WEBP formats.\nAnalyze multimodal API (preview)\n:\nDefault maximum text length: 1K characters.\nMaximum image file size: 4 MB\nDimensions between 50 x 50 and 7200 x 7200 pixels.\nImages can be in JPEG, PNG, GIF, BMP, TIFF, or WEBP formats.\nPrompt Shields API\n:\nMaximum prompt length: 10K characters.\nUp to five documents with a total of 10K characters.\nGroundedness detection API (preview)\n:\nMaximum length for grounding sources: 55,000 characters (per API call).\nMaximum text and query length: 7,500 characters.\nMinimum query length: 3 words.\nProtected material detection APIs\n:\nDefault maximum length: 10K characters.\nDefault minimum length: 110 characters (for scanning LLM completions, not user prompts).\nCustom categories (standard) API (preview)\n:\nMaximum inference input length: 1K characters.\nTask adherence (preview)\n:\nMaximum input length: 100K characters.\nLanguage support\nThe Azure AI Content Safety models for protected material, groundedness detection, and custom categories (standard) work with English only.\nOther Azure AI Content Safety models have been specifically trained and tested on the following languages: Chinese, English, French, German, Spanish, Italian, Japanese, Portuguese. However, these features can work in many other languages, but the quality might vary. In all cases, you should do your own testing to ensure that it works for your application.\nFor more information, see\nLanguage support\n.\nRegion availability\nTo use the Content Safety APIs, you must create your Azure AI Content Safety resource in a supported region. Currently, the Content Safety features are available in the following Azure regions with different API versions:\nRegion\nCustom Category (standard)\nGroundedness\nImage\nMultimodal(Image with Tex)\nCustom Category (rapid)\nPrompt Shield\nProtected Material (Text)\nProtected Material (Code)\nText\nAustralia East\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nCanada East\nâ\nâ\nâ\nâ\nâ\nâ\nCentral US\nâ\nâ\nâ\nâ\nâ\nâ\nEast US\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nEast US 2\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nFrance Central\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nGermany West Central\nâ\nâ\nâ\nâ\nItaly North\nâ\nâ\nâ\nâ\nJapan East\nâ\nâ\nâ\nâ\nâ\nâ\nKorea Central\nâ\nâ\nâ\nâ\nNorth Central US\nâ\nâ\nâ\nâ\nâ\nâ\nPoland Central\nâ\nâ\nâ\nâ\nâ\nSouth Central US\nâ\nâ\nâ\nâ\nâ\nâ\nSouth India\nâ\nâ\nâ\nâ\nâ\nâ\nSweden Central\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nSwitzerland North\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nSwitzerland West\nâ\nâ\nâ\nâ\nâ\nâ\nUAE North\nâ\nâ\nâ\nâ\nâ\nâ\nUK South\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nWest Europe\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nWest US\nâ\nâ\nâ\nâ\nâ\nâ\nâ\nWest US 2\nâ\nâ\nâ\nâ\nâ\nâ\nWest US 3\nâ\nâ\nâ\nâ\nâ\nâ\nFairFax - USGovArizona\nâ\nâ\nâ\nâ\nâ\nFairFax - USGovVirginia\nâ\nâ\nâ\nâ\nFeel free to\ncontact us\nif your business needs other regions to be available.\nQuery rates\nContent Safety features have query rate limits in requests-per-second (RPS) or requests-per-10-seconds (RP10S) . See the following table for the rate limits for each feature.\nPricing tier\nModeration APIs\n(text and image)\nPrompt Shields\nProtected material\ndetection\nGroundedness\ndetection (preview)\nCustom categories\n(rapid) (preview)\nCustom categories\n(standard) (preview)\nMultimodal\nF0\n5 RPS\n5 RPS\n5 RPS\nN/A\n5 RPS\n5 RPS\n5 RPS\nS0\n1000 RP10S\n1000 RP10S\n1000 RP10S\n50 RPS\n1000 RP10S\n5 RPS\n10 RPS\nIf you need a faster rate, please\ncontact us\nto request it.\nContact us\nIf you get stuck,\nemail us\nor use the feedback widget at the bottom of any Microsoft Learn page.\nNext steps\nFollow a quickstart to get started using Azure AI Content Safety in your application.\nContent Safety quickstart\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "AI Content Safety",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/cost-management-billing/costs/overview-cost-management": {
      "content_hash": "sha256:56039a237df110bbd03e5594188ef6898c1dfe5d643a1d89a0987088e7d70603",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Microsoft Cost Management\nFeedback\nSummarize this article for me\nMicrosoft Cost Management is a suite of FinOps tools that help organizations analyze, monitor, and optimize their Microsoft Cloud costs. Cost Management is available to anyone with access to a billing account, subscription, resource group, or management group. You can access Cost Management within the billing and resource management experiences or separately as a standalone tool optimized for FinOps teams who manage cost across multiple scopes. You can also automate and extend native capabilities or enrich your own tools and processes with cost to maximize organizational visibility and accountability with all stakeholders and realize your optimization and efficiency goals faster.\nA few examples of what you can do in Cost Management include:\nReport on and analyze costs in the Azure portal, Microsoft 365 admin center, or Power BI.\nMonitor costs proactively with budget, anomaly, reservation utilization, and scheduled alerts.\nEnable tag inheritance and split shared costs with cost allocation rules.\nAutomate business processes or integrate cost into external tools by exporting data.\nHow charges are processed\nTo understand how Cost Management works, you should first understand the Commerce system. At its core, Microsoft Commerce is a data pipeline that underpins all Microsoft commercial transactions, whether consumer or commercial. While there are many inputs and connections to this pipeline, like the sign-up and Marketplace purchase experiences, this article focuses on the components that help you monitor, allocate, and optimize your costs.\nFrom the left, your Azure, Microsoft 365, Dynamics 365, and Power Platform services measure the products and services you use and purchase at the most granular level. Each service pushes the measured usage and purchase quantities into the Commerce data pipeline on a different cadence. In general, if data for one service is slower than another, it's due to how frequently those services are publishing their usage and charges.\nAs data makes its way through the pipeline, the rating system applies discounts based on your specific price sheet and generates ârated usage,â which includes a price and quantity for each cost record. It's important to note that measured usage and purchase quantities and pricing quantities may differ due to different pricing models, like block pricing which rates usage in \"blocks\" of units (e.g., \"100 hours\"). Usage and purchase quantities are often provided in the lower-level measurement unit while pricing quantities can be in a higher-level pricing unit. Cost Management shows quantity in the measurement unit while the price sheet and invoices show quantity in the pricing unit. At the end of the month, credits are applied and the invoice is published. This process starts 72 hours after your billing period ends, which is usually the last day of the calendar month for most accounts. For example, if your billing period ends on March 31, charges will be finalized on April 4 at midnight.\nImportant\nCredits are applied like a gift card or other payment instrument before the invoice is generated. While credit status is tracked as new charges flow into the data pipeline, credits arenât explicitly applied to these charges until the end of the month.\nEverything up to this point makes up the billing process where charges are finalized, discounts are applied, and invoices are published. Billing account and billing profile owners may be familiar with this process as part of the Billing experience within the Azure portal or Microsoft 365 admin center. The Billing experience allows you to review credits, manage your billing address and payment methods, pay invoices, and more â everything related to managing your billing relationship with Microsoft.\nThe\nanomaly detection\nmodel identifies anomalies daily based on normalized usage (not rated usage).\nThe cost allocation engine applies tag inheritance and\nsplits shared costs\n.\nAzure Advisor cost recommendations are pulled in to enable cost savings insights for subscriptions and resource groups.\nCost alerts are sent out for\nbudgets\n,\nanomalies\n,\nscheduled alerts\n, and more based on the configured settings.\nLastly, cost details are made available from\nCost Analysis\nin the Azure portal and published to your storage account via\nscheduled exports\n.\nHow Cost Management and Billing relate\nCost Management\nis a set of FinOps tools that enable you to analyze, manage, and optimize your costs.\nBilling\nprovides all the tools you need to manage your billing account and pay invoices.\nWhile Cost Management is available from within the Billing experience, Cost Management is also available from every subscription, resource group, and management group in the Azure portal to ensure everyone has full visibility into the costs theyâre responsible for and can optimize their workloads to maximize efficiency. Cost Management is also available independently to streamline the process for managing cost across multiple billing accounts, subscriptions, resource groups, and/or management groups.\nWhat data is included in Cost Management and Billing?\nWithin the Billing experience, you can manage all the products, subscriptions, and recurring purchases you use; review your credits and commitments; and view and pay your invoices. Invoices are available online or as PDFs and include all billed charges and any applicable taxes. Credits are applied to the total invoice amount when invoices are generated. This invoicing process happens in parallel to Cost Management data processing, which means Cost Management doesn't include credits, taxes, and some purchases, like support charges in non-MCA accounts.\nClassic Cloud Solution Provider (CSP) and sponsorship subscriptions aren't supported in Cost Management. These subscriptions will be supported after they transition to Microsoft Customer Agreement.\nFor more information about supported offers, what data is included, or how data is refreshed and retained in Cost Management, see\nUnderstand Cost Management data\n.\nEstimate your cloud costs\nDuring your cloud journey, there are many tools available to help you understand pricing:\nAzure Migrate\nis a free tool that helps you analyze your on-premises workloads and plan your cloud migration.\nThe\nAzure pricing calculator\nis a free cost management tool that allows users to understand and estimate costs of Azure Services and products. It serves as the only unauthenticated experience that allows you to configure and budget the expected cost of deploying solutions in Azure. For customers that want to view their negotiated estimate prices, there is an authenticated version. The Azure pricing calculator allows organizations to plan and forecast cloud expenses, evaluate different configurations and pricing models, and make informed decisions about service selection and deployment options.\nReport on and analyze costs\nCost Management and Billing include several tools to help you understand, report on, and analyze your invoiced Microsoft Cloud costs.\nCost Analysis\nis a tool for ad-hoc cost exploration. Get quick answers with lightweight insights and analytics.\nPower BI\nis an advanced solution to build more extensive dashboards and complex reports or combine costs with other data. Power BI is available for billing accounts and billing profiles.\nExports and the Cost Details API\nenable you to integrate cost details into external systems or business processes.\nFor more information, see\nGet started with reporting\n.\nOrganize and allocate costs\nOrganizing and allocating costs are critical to ensuring invoices are routed to the correct business units and can be further split for internal billing, also known as\nchargeback\n. The first step to allocating cloud costs is organizing subscriptions and resources in a way that facilitates natural reporting and chargeback. Microsoft offers the following options to organize resources and subscriptions:\nMCA\nbilling profiles\nand\ninvoice sections\nare used to\ngroup subscriptions into invoices\n. Each billing profile represents a separate invoice that can be billed to a different business unit and each invoice section is segmented separately within those invoices. You can also view costs by billing profile or invoice section in Cost Analysis.\nEA\ndepartments\nand\nenrollment accounts\nare conceptually like invoice sections, as groups of subscriptions, but they aren't represented within the invoice PDF. They're included within the cost details backing each invoice, however. You can also view costs by department or enrollment account in Cost Analysis.\nManagement groups\nalso allow grouping subscriptions together, but offer a few key differences:\nManagement group access is inherited down to the subscriptions and resources.\nManagement groups can be layered into multiple levels and subscriptions can be placed at any level.\nManagement groups aren't included in cost details.\nAll historical costs are returned for management groups based on the subscriptions currently within that hierarchy. When a subscription moves, all historical cost moves.\nAzure Policy supports management groups, and they can have rules assigned to automate compliance reporting for your cost governance strategy.\nSubscriptions\nand\nresource groups\nare the lowest level at which you can organize your cloud solutions. At Microsoft, every product â sometimes even limited to a single region â is managed within its own subscription. It simplifies cost governance but requires more overhead for subscription management. Most organizations use subscriptions for business units and separating dev/test from production or other environments, then use resource groups for the products. It complicates cost management because resource group owners don't have a way to manage cost across resource groups. On the other hand, it's a straightforward way to understand who's responsible for most resource-based charges. Keep in mind that not all charges come from resources and some don't have resource groups or subscriptions associated with them. It is important to understand that the subscriptions and resource groups linked to the purchase transaction of an entitlement offer may differ from those associated with the usage benefiting from the commitment. For instance, when you purchase a reservation, the transaction is tied to a billing subscription. Subsequently, the reservation benefit is applied to actual usage, which may be recorded in a different subscription and resource group, if choosing a shared scope. It also changes as you move to MCA billing accounts.\nResource tags\nare the only way to add your own business context to cost details and are perhaps the most flexible way to map resources to applications, business units, environments, owners, etc. For more information, see\nHow tags are used in cost and usage data\nfor limitations and important considerations.\nOnce your resources and subscriptions are organized using the subscription hierarchy and have the necessary metadata (tags) to facilitate further allocation, use the following tools in Cost Management to streamline cost reporting:\nTag inheritance\nsimplifies the application of tags by copying subscription and resource group tags down to the resources in cost data. These tags aren't saved on the resources themselves. The change only happens within Cost Management and isn't available to other services, like Azure Policy.\nCost allocation\noffers the ability to âmoveâ or split shared costs from one subscription, resource group, or tag to another subscription, resource group, or tag. Cost allocation doesn't change the invoice. The goal of cost allocation is to reduce overhead and more accurately report on where charges are ultimately coming from (albeit indirectly), which should drive more complete accountability.\nHow you organize and allocate costs plays a huge role in how people within your organization can manage and optimize costs. Be sure to plan ahead and revisit your allocation strategy yearly.\nMonitor costs with alerts\nCost Management and Billing offer many different types of emails and alerts to keep you informed and help you proactively manage your account and incurred costs.\nBudget alerts\nnotify recipients when cost exceeds a predefined cost or forecast amount. Budgets can be visualized in Cost Analysis and are available on every scope supported by Cost Management. Subscription and resource group budgets can also be configured to notify an action group to take automated actions to reduce or even stop further charges.\nAnomaly alerts\nnotify recipients when an unexpected change in daily usage has been detected. It can be a spike or a dip. Anomaly detection is only available for subscriptions and can be viewed within Cost Analysis smart views. Anomaly alerts can be configured from the cost alerts page.\nScheduled alerts\nnotify recipients about the latest costs on a daily, weekly, or monthly schedule based on a saved cost view in Cost Analysis. Alert emails include a visual chart representation of the view and can optionally include a CSV file. Although views are configured in Cost Analysis, recipients don't require access to the Azure portal or to Cost Management to view the email, chart, or linked CSV when sent to them.\nEA commitment balance alerts\nare automatically sent to any notification contacts configured on the EA billing account when the balance is 90% or 100% used.\nInvoice alerts\ncan be configured for MCA billing profiles and Microsoft Online Services Program (MOSP) subscriptions. For details, see\nView and download your Azure invoice\n.\nFor more information, see\nMonitor usage and spending with cost alerts\n.\nOptimize costs\nMicrosoft offers a wide range of tools for optimizing your costs. Some of these tools are available outside the Cost Management and Billing experience but are included for completeness.\nThere are many\nfree services\navailable in Azure. Be sure to pay close attention to the constraints. Different services are free indefinitely, for 12 months, or 30 days. Some are free up to a specific amount of usage and some may have dependencies on other services that aren't free.\nAzure Advisor cost recommendations\nshould be your first stop when interested in optimizing existing resources. Advisor recommendations are updated daily and are based on your usage patterns. Advisor is available for subscriptions and resource groups. Management group users can also see recommendations, but they need to select the desired subscriptions. Billing users can only see recommendations for subscriptions they have resource access to.\nAzure savings plans\nsave you money when you have consistent usage of Azure compute resources. A savings plan can significantly reduce your resource costs by up to 65% from pay-as-you-go prices.\nAzure reservations\nhelp you save up to 72% compared to pay-as-you-go rates by pre-committing to specific usage amounts for a set time duration.\nAzure Hybrid Benefit\nhelps you significantly reduce costs by using on-premises Windows Server and SQL Server licenses or RedHat and SUSE Linux subscriptions on Azure.\nNext steps\nFor other options, see\nAzure benefits and incentives\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Cost Management",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/azure/cost-management-billing/costs/tutorial-acm-create-budgets": {
      "content_hash": "sha256:7ac90661feac2b7e4c4421e5df7d87d63428e3350d562cedd343c0561932e257",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nTutorial: Create and manage budgets\nFeedback\nSummarize this article for me\nBudgets in Cost Management help you plan for and drive organizational accountability. They help you proactively inform others about their spending to manage costs and monitor how spending progresses over time.\nYou can configure alerts based on your actual cost or forecasted cost to ensure that your spending is within your organizational spending limit. Notifications are triggered when the budget thresholds are exceeded. Resources aren't affected, and your consumption isn't stopped. You can use budgets to compare and track spending as you analyze costs.\nCost and usage data is typically available within 8-24 hours and budgets are evaluated against these costs every 24 hours. Be sure to get familiar with\nCost and usage data updates\nspecifics. When a budget threshold is met, email notifications are normally sent within an hour of the evaluation.\nBudgets reset automatically at the end of a period (monthly, quarterly, or annually) for the same budget amount when you select an expiration date in the future. Because they reset with the same budget amount, you need to create separate budgets when budgeted currency amounts differ for future periods. When a budget expires, it automatically gets deleted.\nThe examples in this tutorial walk you through creating and editing a budget for an Azure Enterprise Agreement (EA) subscription.\nWatch the\nApply budgets to subscriptions using the Azure portal\nvideo to see how you can create budgets in Azure to monitor spending. To watch other videos, visit the\nCost Management YouTube channel\n.\nIn this tutorial, you learn how to:\nCreate a budget in the Azure portal\nCreate and edit budgets\nCreate a budget with an Azure Resource Manager template\nPrerequisites\nBudgets are supported for the following types of Azure account types and scopes:\nAzure role-based access control (Azure RBAC) scopes\nManagement group\nSubscription\nResource group\nEnterprise Agreement scopes\nBilling account\nDepartment\nEnrollment account\nIndividual agreements\nBilling account\nMicrosoft Customer Agreement scopes\nBilling account â Budget evaluation at billing account scope uses\nUSD currency\n, regardless of the billing currency.\nNote:\nIn sovereign clouds like China 21V, the budget is always evaluated in the\nbilling currency\ninstead of USD.\nBilling profile â Evaluated in billing currency\nInvoice section â Evaluated in billing currency\nCustomer â Evaluated in billing currency\nTo view budgets, you need at least read access for your Azure account.\nIf you have a new subscription, you can't immediately create a budget or use other Cost Management features. It might take up to 48 hours before you can use all Cost Management features.\nRead access is required to view budgets for Azure EA subscriptions. To create and manage budgets, you must have contributor permission.\nThe following Azure permissions, or scopes, are supported per subscription for budgets by user and group.\nOwner â Can create, modify, or delete budgets for a subscription.\nContributor and Cost Management contributor â Can create, modify, or delete their own budgets. Can modify the budget amount for budgets created by others.\nReader and Cost Management reader â Can view budgets that they have permission to.\nSingle currency requirement:\nFor budget evaluations, our system requires that all subscriptions within the scope, like a management group, operate under a single currency. Multi-currency budget evaluations are not supported, and you may miss out on your budget alerts if this situation arises.\nFor more information about scopes, including access needed to configure exports for Enterprise Agreement and Microsoft Customer agreement scopes, see\nUnderstand and work with scopes\n. For more information about assigning permission to Cost Management data, see\nAssign access to Cost Management data\n.\nSign in to Azure\nSign in to the\nAzure portal\n.\nCreate a budget in the Azure portal\nYou can create an Azure subscription budget for a monthly, quarterly, or annual period.\nTo create or view a budget, open a scope in the Azure portal and select\nBudgets\nin the menu. For example, navigate to\nSubscriptions\n, select a subscription from the list, and then select\nBudgets\nin the menu. Use the\nScope\npill to switch to a different scope, like a management group, in Budgets. For more information about scopes, see\nUnderstand and work with scopes\n.\nIf you want to create a budget for a resource group, ensure that you navigate to one first. You can navigate to a resource group by searching for\nResource groups\nin the Azure portal search box. Then, select a resource group from the list. Afterward, the\nBudgets\noption is available in the menu.\nAfter you create budgets, they show a simple view of your current spending against them.\nSelect\nAdd\n.\nIn the\nCreate budget\nwindow, make sure that the scope shown is correct. Choose any filters that you want to add. Filters allow you to create budgets on specific costs, such as resource groups in a subscription or a service like virtual machines. For more information about the common filter properties that you can use in budgets and cost analysis, see\nGroup and filter properties\n.\nAfter you identify your scope and filters, type a budget name. Then, choose a monthly, quarterly, or annual budget reset period. The reset period determines the time window that gets analyzed by the budget. The cost evaluated by the budget starts at zero at the beginning of each new period. When you create a quarterly budget, it works in the same way as a monthly budget. The difference is that the budget amount for the quarter is evenly divided among the three months of the quarter. An annual budget amount is evenly divided among all 12 months of the calendar year.\nIf you have a pay-as-you-go, MSDN, or Visual Studio subscription, your invoice billing period might not align to the calendar month. For those subscription types and resource groups, you can create a budget aligned to your invoice period or to calendar months. To create a budget aligned to your invoice period, select a reset period of\nBilling month\n,\nBilling quarter\n, or\nBilling year\n. To create a budget aligned to the calendar month, select a reset period of\nMonthly\n,\nQuarterly\n, or\nAnnually\n.\nNext, identify the expiration date when the budget becomes invalid and stops evaluating your costs.\nBased on the fields chosen in the budget so far, a graph is shown to help you select a threshold to use for your budget. The suggested budget is based on the highest forecasted cost that you might incur in future periods. You can change the budget amount.\nAfter you configure the budget amount, select\nNext\nto configure budget alerts for actual cost and forecasted budget alerts.\nConfigure actual costs budget alerts\nBudgets require at least one cost threshold (% of budget) and a corresponding email address. You can optionally include up to five thresholds and five email addresses in a single budget. When a budget threshold is met, email notifications are normally sent within an hour of the evaluation. Actual costs budget alerts are generated for the actual cost accrued in relation to the budget thresholds configured.\nConfigure forecasted budget alerts\nForecasted alerts provide advanced notification that your spending trends are likely to exceed your budget. The alerts use forecasted cost predictions. Alerts are generated when the forecasted cost projection exceeds the set threshold. You can configure a forecasted threshold (% of budget). When a forecasted budget threshold is met, notifications are normally sent within an hour of the evaluation.\nTo toggle between configuring an Actual vs Forecasted cost alert, use the\nType\nfield when configuring the alert as shown in the following image.\nIf you want to receive emails, add azure-noreply@microsoft.com to your approved senders list so that emails don't go to your junk email folder. For more information about notifications, see\nUse cost alerts\n.\nIn the following example, an email alert gets generated when 90% of the budget is reached. If you create a budget with the Budgets API, you can also assign roles to people to receive alerts. Assigning roles to people isn't supported in the Azure portal. For more about the Budgets API, see\nBudgets API\n. If you want to have an email alert sent in a different language, see\nSupported locales for budget alert emails\n.\nAlert limits support a range of 0.01% to 1000% of the budget threshold.\nAfter you create a budget, it appears in cost analysis. Viewing your budget against your spending trend is one of the first steps when you start to\nanalyze your costs and spending\n.\nIn the preceding example, you created a budget for a subscription. You can also create a budget for a resource group. If you want to create a budget for a resource group, navigate to\nCost Management + Billing\n>\nSubscriptions\n> select a subscription >\nResource groups\n> select a resource group >\nBudgets\n> and then\nAdd\na budget.\nCosts in budget evaluations\nBudget cost evaluations now include reserved instance and purchase data. If the charges apply to you, then you might receive alerts as charges are incorporated into your evaluations. Sign in to the\nAzure portal\nto verify that budget thresholds are properly configured to account for the new costs. Your Azure billed charges aren't changed. Budgets now evaluate against a more complete set of your costs. If the charges don't apply to you, then your budget behavior remains unchanged.\nIf you want to filter the new costs so that budgets are evaluated against first party Azure consumption charges only, add the following filters to your budget:\nPublisher Type: Azure\nCharge Type: Usage\nBudget cost evaluations are based on actual cost. They don't include amortization. For more information about filtering options available to you in budgets, see\nUnderstanding grouping and filtering options\n.\nTrigger an action group\nWhen you create or edit a budget for a subscription or resource group scope, you can configure it to call an action group. The action group can perform various actions when your budget threshold is met. You can receive mobile push notifications when your budget threshold is met by enabling\nAzure app push notifications\nwhile configuring the action group.\nAction groups are currently only supported for subscription and resource group scopes. For more information about creating action groups, see\naction groups\n.\nFor more information about using budget-based automation with action groups, see\nManage costs with budgets\n.\nTo create or update action groups, select\nManage action group\nwhile you're creating or editing a budget.\nNext, select\nAdd action group\nand create the action group.\nYou can integrate budgets with action groups, regardless of whether the common alert schema is enabled or disabled in those groups. For more information on how to enable common alert schema, see\nHow do I enable the common alert schema?\nBudgets in the Azure mobile app\nYou can view budgets for your subscriptions and resource groups from the\nCost Management\ncard in the\nAzure app\n.\nNavigate to any subscription or resource group.\nFind the\nCost Management\ncard and tap\nMore\n.\nBudgets load below the\nCurrent cost\ncard. They're sorted by descending order of usage.\nTo receive mobile push notifications when your budget threshold is met, you can configure action groups. When setting up budget alerts, make sure to select an action group that has\nAzure app push notifications\nenabled.\nNote\nCurrently, the Azure mobile app only supports the subscription and resource group scopes for budgets.\nCreate and edit budgets\nPowerShell\nCLI\nTerraform\nAzure Resource Manager template\nIf you're an EA customer, you can create and edit budgets programmatically using the Azure PowerShell module. However, we recommend that you use REST APIs to create and edit budgets because CLI commands might not support the latest version of the APIs. Budgets created with PowerShell don't send notifications.\nNote\nCustomers with a Microsoft Customer Agreement should use the\nBudgets REST API\nto create budgets programmatically.\nTo download the latest version of Azure PowerShell, run the following command:\ninstall-module -name Az\nThe following example commands create a budget using PowerShell. Make sure to replace all example prompts with your own info.\n#Sign into Azure PowerShell with your account\n\nConnect-AzAccount\n\n#Select a subscription to monitor with a budget\n\nselect-AzSubscription -Subscription \"Your Subscription\"\n\n#Create an action group email receiver and corresponding action group\n\n$email1 = New-AzActionGroupReceiver -EmailAddress test@test.com -Name EmailReceiver1\n$ActionGroupId = (Set-AzActionGroup -ResourceGroupName YourResourceGroup -Name TestAG -ShortName TestAG -Receiver $email1).Id\n\n#Create a monthly budget that sends an email and triggers an Action Group to send a second email. Make sure the StartDate for your monthly budget is set to the first day of the current month. Note that Action Groups can also be used to trigger automation such as Azure Functions or Webhooks.\n\nGet-AzContext\nNew-AzConsumptionBudget -Amount 100 -Name TestPSBudget -Category Cost -StartDate 2020-02-01 -TimeGrain Monthly -EndDate 2022-12-31 -ContactEmail test@test.com -NotificationKey Key1 -NotificationThreshold 0.8 -NotificationEnabled -ContactGroup $ActionGroupId\nThe following example creates a budget using Azure CLI. Make sure to replace all example prompts with your own info.\n# Sign into Azure CLI with your account\naz login\n \n# Select a subscription to monitor with a budget\naz account set --subscription \"Your Subscription\"\n \n# Create an action group email receiver and corresponding action group\nemail1=$(az monitor action-group receiver email create --email-address test@test.com --name EmailReceiver1 --resource-group YourResourceGroup --query id -o tsv)\nActionGroupId=$(az monitor action-group create --resource-group YourResourceGroup --name TestAG --short-name TestAG --receiver $email1 --query id -o tsv)\n \n# Create a monthly budget that sends an email and triggers an Action Group to send a second email.\n# Make sure the StartDate for your monthly budget is set to the first day of the current month.\n# Note that Action Groups can also be used to trigger automation such as Azure Functions or Webhooks.\n \naz consumption budget create-with-rg --amount 100 --budget-name TestCLIBudget -g $rg --category Cost --time-grain Monthly --time-period '{\"start-date\":\"2024-06-01\",\"end-date\":\"2025-12-31\"}' --notifications \"{\\\"Key1\\\":{\\\"enabled\\\":\\\"true\\\", \\\"operator\\\":\\\"GreaterThanOrEqualTo\\\", \\\"contact-emails\\\":[], \\\"threshold\\\":80.0, \\\"contact-groups\\\":[\\\"$ActionGroupId\\\"]}}\"\nMake sure to properly\ninstall and configure Terraform\nbefore continuing. All examples are based on\nHashiCorp's 'azurerm_subscription_cost_management_export' docs\n.\nThe following example creates a budget using Terraform. Make sure to replace all example prompts with your own info.\nConfigure provider: Ensure you have the Azure provider configured.\nprovider \"azurerm\" {\n features {}\n}\nSelect an Azure subscription: Specify the subscription ID in the provider configuration or via environment variables.\ndata \"azurerm_subscription\" \"example\" {}\nCreate a resource group.\nresource \"azurerm_resource_group\" \"example\" {\n name = \"example-resources\"\n location = \"West Europe\"\n}\nSet up an action group for notifications.\nresource \"azurerm_monitor_action_group\" \"example\" {\n name = \"TestAG\"\n resource_group_name = azurerm_resource_group.example.name\n short_name = \"TestAG\"\n\n email_receiver {\n name = \"EmailReceiver1\"\n email_address = \"test@test.com\"\n use_common_alert_schema = true\n }\n}\nCreate a storage account.\nresource \"azurerm_storage_account\" \"example\" {\n name = \"examplestoracc\"\n resource_group_name = azurerm_resource_group.example.name\n location = azurerm_resource_group.example.location\n account_tier = \"Standard\"\n account_replication_type = \"LRS\"\n}\nCreate a storage container.\nresource \"azurerm_storage_container\" \"example\" {\n name = \"examplecontainer\"\n storage_account_name = azurerm_storage_account.example.name\n}\nSet up subscription cost management export.\nresource \"azurerm_subscription_cost_management_export\" \"example\" {\n name = \"exampleexport\"\n subscription_id = data.azurerm_subscription.example.id\n recurrence_type = \"Monthly\"\n recurrence_period_start_date = \"2020-08-18T00:00:00Z\"\n recurrence_period_end_date = \"2020-09-18T00:00:00Z\"\n\n export_data_storage_location {\n container_id = azurerm_storage_container.example.resource_manager_id\n root_folder_path = \"/root/updated\"\n }\n\n export_data_options {\n type = \"Usage\"\n time_frame = \"WeekToDate\"\n }\n}\nApply the terraform configuration\nHere's the full code if you'd like to modify it directly from source instead of piecing it together through the steps.\nprovider \"azurerm\" {\n features {}\n}\n\ndata \"azurerm_subscription\" \"example\" {}\n\nresource \"azurerm_resource_group\" \"example\" {\n name = \"example-resources\"\n location = \"West Europe\"\n}\n\nresource \"azurerm_monitor_action_group\" \"example\" {\n name = \"TestAG\"\n resource_group_name = azurerm_resource_group.example.name\n short_name = \"TestAG\"\n\n email_receiver {\n name = \"EmailReceiver1\"\n email_address = \"test@test.com\"\n use_common_alert_schema = true\n }\n}\n\nresource \"azurerm_storage_account\" \"example\" {\n name = \"examplestoracc\"\n resource_group_name = azurerm_resource_group.example.name\n\n location = azurerm_resource_group.example.location\n account_tier = \"Standard\"\n account_replication_type = \"LRS\"\n}\n\nresource \"azurerm_storage_container\" \"example\" {\n name = \"examplecontainer\"\n storage_account_name = azurerm_storage_account.example.name\n}\n\nresource \"azurerm_subscription_cost_management_export\" \"example\" {\n name = \"exampleexport\"\n subscription_id = data.azurerm_subscription.example.id\n recurrence_type = \"Monthly\"\n recurrence_period_start_date = \"2020-08-18T00:00:00Z\"\n recurrence_period_end_date = \"2020-09-18T00:00:00Z\"\n\n export_data_storage_location {\n container_id = azurerm_storage_container.example.resource_manager_id\n root_folder_path = \"/root/updated\"\n }\n\n export_data_options {\n type = \"Usage\"\n time_frame = \"WeekToDate\"\n }\n}\nYou can create a budget using an Azure Resource Manager template. To use the template, see\nCreate a budget with an Azure Resource Manager template\n.\nClean up resources\nIf you created a budget and you no longer need it, view its details and delete it.\nNext steps\nIn this tutorial, you learned how to:\nCreate a budget in the Azure portal\nCreate and edit budgets with PowerShell\nCreate a budget with an Azure Resource Manager template\nAdvance to the next tutorial to create a recurring export for your cost management data.\nCreate and manage exported data\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure Budgets",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/azure/devops/test/overview": {
      "content_hash": "sha256:b44971f9c5ba32dc848115e28a7f115d693bf289e0202c5090b1b73598abdacc",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nWhat is Azure Test Plans?\nFeedback\nSummarize this article for me\nAzure DevOps Services | Azure DevOps Server | Azure DevOps Server 2022\nAzure Test Plans offers powerful tools for driving quality and collaboration throughout the development process. This browser-based test management solution supports planned manual testing, user acceptance testing, exploratory testing, and stakeholder feedback.\nNote\nThis article applies to Azure DevOps Services and Azure DevOps Server 2020 and later versions. Most of the information is valid for earlier on-premises versions, however, images show only examples for the latest version. Also, the user interface changed significantly with the release of Azure DevOps Server 2020. For an overview of the new interface and supported capabilities, see\nNavigate Test Plans\n.\nHow does Azure Test Plans work?\nThrough a combination of browser-based toolsâ\nTest plans\n,\nProgress report\n,\nParameters\n,\nConfigurations\n,\nRuns\n, and\nTest tools\nâand DevOps integration features, Azure Test Plans supports the following test objectives:\nPerform manual and exploratory testing\n:\nOrganize planned manual testing\n: Designate testers and test leads to organize tests into test plans and test suites.\nConduct user acceptance testing\n: Designate user acceptance testers to verify that the delivered value meets customer requirements, reusing test artifacts created by engineering teams.\nExecute exploratory testing\n: Have developers, testers, UX teams, product owners, and others explore the software systems without using test plans or test suites.\nGather stakeholder feedback\n: Engage stakeholders outside the development team, such as users from marketing and sales divisions, to carry out testing.\nAutomate testing\n: Integrate Azure Test Plans with Azure Pipelines to support testing within CI/CD. Associate test plans and test cases with build or release pipelines. Add pipeline tasks to capture and publish test results. Review test results via built-in progress reports and pipeline test reports.\nEnsure traceability\n: Link test cases and test suites to user stories, features, or requirements for end-to-end traceability. Automatically link tests and defects to the requirements and builds being tested. Add and run tests from the board or use the Test plans hub for larger teams. Track testing of requirements with pipeline results and the Requirements widget.\nTrack reporting and analysis\n: Monitor test results and progress with configurable tracking charts, test-specific widgets for dashboards, and built-in reports such as Progress reports, pipeline test result reports, and the Analytics service.\nNote\nLoad and performance testing\n: While Azure DevOps cloud-based load testing service is deprecated, Azure Load Testing is available. Azure Load Testing is a fully managed load testing service that enables you to use existing Apache JMeter scripts to generate high-scale load. For more information, see\nWhat is Azure Load Testing?\n. For more information about the deprecation of Azure DevOps load testing, see\nChanges to load test functionality in Visual Studio and cloud load testing in Azure DevOps\n.\nKey benefits\nAzure Test Plans provides software development teams the following benefits.\nTest on any platform\n: With the\nTest Plans\nweb portal, you can use any supported browser to access all the manual testing capabilities. It enables you to\ncreate\nand\nrun manual tests\nthrough an easy-to-use, browser-based interface that users can access from all major browsers on any platform.\nRich diagnostic data collection\n: Using the web-based Test Runner and Test Runner client you can\ncollect rich diagnostic data\nduring your manual tests. This data includes screenshots, an image action log, screen recordings, code coverage, IntelliTrace traces, and test impact data for your apps under test. This data is automatically included in all the bugs you create during test, making it easy for developers to reproduce the issues.\nEnd to End traceability\n: Azure DevOps provides end-to-end traceability of your requirements, builds, tests, and bugs with\nlinking work items to other objects\n. Users can track their requirement quality from cards on the board. Bugs created while testing are automatically linked to the requirements and builds being tested, which helps you track the quality of the requirements or builds.\nIntegrated analytics\n: The Analytics service provides data that feeds into built-in reports, configurable dashboard widgets, and customizable reports using Power BI. Data tracks test plan progress and trends for both manual and automated tests. Test analytics provides near real-time visibility into test data for builds and releases. Teams can act on this data to improve test collateral to help maintain healthy pipelines.\nExtensible platform\n. You can combine the tools and technologies you already know with the development tools that work best for you to integrate with and\nextend Azure DevOps\n. Use the REST APIs and contribution model available for the Test platform to create extensions that provide the experience you need for your test management lifecycle.\nSupported scenarios and access requirements\nAccess to Azure DevOps web portal features are managed through access levels assigned to users. The three main access levels are\nStakeholder\n,\nBasic\n, and\nBasic+Test\nplans as described in\nAbout access levels\n. The following table indicates the access-level required to exercise the associated tasks with Azure Test Plans. In addition to access levels, select features require permissions to execute. For more information, see\nManual test access and permissions\n.\nScenario and tasks\nStakeholder\nBasic\nBasic +Test Plans\nTest planning\nCreate test plans and test suites\nManage test plan run settings\nManage configurations\nâï¸\nTest execution\nRun tests on any platform (Windows, Linux, Mac) with Test Runner\nâï¸\nâï¸\nPerform exploratory testing with the Test & Feedback extension\nâï¸\nâï¸\nâï¸\nAnalyze and review tests\nCreate charts with various pivots like priority, configuration, etc., to track test progress\nBrowse test results\nExport test plans and test suites for review\nUser Acceptance Testing â Assign tests and invite by email\nâï¸\nâï¸\nManual and exploratory testing\nTo support manual and exploratory testing, Azure Test Plans uses test-specific work item types to plan and author tests. In addition, it provides two test tools to support running tests. The\nTest plans\n,\nParameters\n, and\nConfigurations\nhubs provide the tools to efficiently create and manage test items, their settings, and configurations. Test suites can be dynamicârequirements-based-suites and query-based-suitesâto help you understand the quality of associated requirements under development, or static to help you cover regression tests.\nTest-specific work item types\nThe work item typesâ\nTest Plans\n,\nTest Suites\n,\nTest Cases\n,\nShared Steps\n, and\nShared Parameters\nâsupport several explicit links to support requirements tracking and sharing test steps and data across many test cases. Test cases can be assigned as manual or automated. For a description of each of these test items, see\nTest objects and terms\n.\nIn Azure DevOps, the relationship between a test result, test run, and a test case can be understood as follows:\nTest case:\nA specific scenario or set of steps designed to validate a particular feature or functionality.\nTest run:\nAn instance where one or more test cases are executed. Each test run can include multiple test cases.\nTest result:\nThe outcome of a test run. Each test case within a test run has its own test result, indicating whether it passed or failed.\nNote\nWith Azure DevOps Server 2020 and later versions, you can perform automated tests by adding test tasks to pipelines. Defining test plans, test cases, and test suites isn't required when test tasks are used.\nDefine test plans and test suites\nYou create and manage test plans and test suites from the\nTest plans\nhub.\nAdd one or more test suitesâstatic, requirement-based, or query-basedâto the test plans. Export and share test plans and test suites with your teams.\nTo learn how, see\nCreate test plans and test suites\nand\nCopy or clone test plans, test suites, and test cases\n.\nAuthor tests using test cases\nYou define manual test cases by defining the test steps and optionally the test data to reference. Test suites consist of one or more test cases. You can share test cases within test suites. The Grid view for defining test cases supports copy, paste, insert, and delete operations. Quickly assign single or multiple testers to execute tests. View test results and references to a test case across test suites. To learn how, see\nCreate test cases\n.\nWithin each test case, you specify a set of test steps with their expected outcomes. Optionally, you can add\nshared steps\nor\nshared parameters\n. For traceability, link test cases to the user stories, features, or bugs that they test.\nManage shared parameters\nUse the\nParameters\nhub, to define and manage parameters shared across test cases. Shared parameters provide support for repeating manual tests several times with different test data. For example, if your users can add different quantities of a product to a shopping cart, then you want to check that a quantity of 200 works and a quantity of 1.\nManage test configurations and variables\nWith the\nConfigurations\nhub, teams can define, review, and manage test configurations and variables referenced by test plans. Test configurations provide support for testing your applications on different operating systems, web browsers, and versions. As with shared parameters, test configurations can be shared across multiple test plans.\nTest execution and test tools\nWith the following tools, developers, testers, and stakeholders can initiate tests and capture rich data as they execute tests and automatically log code defects linked to the tests. Test your application by executing tests across desktop or web apps.\nTest Runner\n: A browser-based tool for testing web applications and a desktop client version for testing desktop applications that you launch from the\nTest plans\nhub to run manual tests. Test Runner supports rich data collection while performing tests, such as image action log, video recording, code coverage, etc. It also allows users to create bugs and mark the status of tests.\nTest & Feedback extension\n: A free extension to support exploratory testing that you access from Chrome, Microsoft Edge, or Firefox browsers. The extension captures interactions with the application being explored through images or video and entering verbal or type-written comments. Information is captured in the Feedback Response work item type to help track response data.\nTest execution capability\nYou can perform the following tasks using the indicated tools.\nTask\nTest plans hub\nTest Runner\nTest & Feedback extension\nBulk mark tests\nâï¸\nPass or fail tests or test steps\nâï¸\nâï¸\nInline changes to tests during execution\nâï¸\nâï¸\nPause and resume tests\nâï¸\nâï¸\nFile bugs during test execution\nâï¸\nâï¸\nCapture screenshots, image action log, and screen recording during test execution\nâï¸\nâï¸\nUpdate existing bugs during test execution\nâï¸\nâï¸\nVerify bugs\nâï¸\nâï¸\nAssign a build for the test run\nâï¸\nAssign test settings\nâï¸\nReview test runs\nâï¸\nExecute tests\nFrom the\nTest plans\nhub,\nExecute\ntab, team members can initiate test execution for one or more test cases defined for a test suite. Choices include running\nTest Runner\nfor a web or desktop application. Optionally, team members can select\nRun with options\nto choose other supported clients for manual testing, or to select a build for automated testing. For more information, see\nRun manual tests\n.\nTest Runner\nTest Runner\nruns tests for your web and desktop applications. Mark test steps and test outcomes as pass or fail, and collect\ndiagnostic data such as system information, image action logs, screen recordings, and screen captures as you test. Bugs filed during the tests automatically include all captured diagnostic data\nto help your developers reproduce the issues. For more information, see\nRun tests for web apps\nand\nRun tests for desktop apps\n.\nUser acceptance testing\nUser acceptance testing (UAT) helps ensure teams deliver the value requested by customers. You can create UAT test plans and suites, invite several testers to execute these tests, and monitor test progress and results using lightweight charts. To learn how, see\nUser acceptance testing\n.\nExploratory testing with the Test & Feedback extension\nThe\nTest & Feedback extension\nis a simple browser-based extension you can use to test web apps\nanytime and anywhere, and is simple enough for everyone in the team to use.\nIt helps to improve productivity by allowing you to spend more time\nfinding issues, and less time filing them.\nStakeholder feedback\nYou should seek feedback from stakeholders outside the development team, such\nas marketing and sales teams, which is vital for developing good quality software.\nDevelopers can request feedback on their user stories and features. Stakeholders can respond\nto feedback requests using the browser-based Test & Feedback extension -\nnot just to rate and send comments, but also by capturing rich diagnostic\ndata and filing bugs and tasks directly.\nSee more at\nRequest stakeholder feedback\nand\nProvide stakeholder feedback\n.\nAutomated testing\nAutomated testing is facilitated by running tests within Azure Pipelines. Test analytics provides near real-time visibility into your test data for builds and releases. It helps improve pipeline efficiency by identifying repetitive, high impact quality issues.\nAzure Test Plans supports automated testing in the following ways:\nAssociate test plans or test cases with build or release pipelines\nSpecify test-enable tasks within a pipeline definition. Azure Pipelines provides several tasks, including the following tasks that support a comprehensive test reporting and analytics experience.\nPublish Test Results task\n: Use to publish test results to Azure Pipelines.\nVisual Studio Test task\n: Use to run unit and functional tests (Selenium, Appium, Coded UI test, and more) using the Visual Studio Test Runner.\n.NET Core CLI task\n: Use to build, test, package, or publish a dotnet application.\nFor more tasks, see\nPublish Test Results task\nProvide built-in reports and configurable dashboard widgets to display results of pipeline testing.\nCollect test results and associated test data into the Analytics service.\nTraceability\nAzure Test Plans supports linking bugs and requirements to test cases and test suites. In addition, the following web portal, test-related tools support traceability:\nView items linked to a test case\n: View the test plans, test suites, requirements, and bugs that a test case links to.\nAdd and run tests from the board\n: An Azure Boards feature that supports defining test cases from the user stories, features, or bugs from the board. Also, you can launch the Test Runner or the Test & Feedback extension to run tests or perform exploratory testing.\nRequirements quality widget\n: Configurable widget used to track quality continuously from a build or release pipeline. The widget shows the mapping between a requirement and latest test results executed against that requirement. It provides insights into requirements traceability. For example, requirements not meeting the quality, requirements not tested, and so on.\nView items linked to a test case\nFrom the\nTest plans\nhub, you can view and open the test suites, requirements, and bugs linked to a test case. The\nTest Suites\ntab also indicates the test plans and projects that reference the test case. The\nRequirements\ntab lists work items linked to the test case that belong to the requirements category. In addition, you can create a direct-links query that lists items that link to test cases via the\nTests/Tested by\nlink type. For more information, see\nCreate test cases\nand\nUse direct links to view dependencies\n.\nAdd and run tests from the board\nFrom the Azure Boards boards, you can add tests from a user story or feature, automatically linking the test case to the user story or feature. You can view, run, and interact with test cases directly from the board, and progressively monitor status directly from the card. Learn more at\nAdd, run, and update inline tests\n.\nRequirements quality widget\nThe Requirements quality widget displays a list of all the requirements in scope, along with the\nPass Rate\nfor the tests and count of\nFailed\ntests. Selecting a Failed test count opens the\nTests\ntab for the selected build or release. The widget also helps to track the requirements without any associated tests. For more information, see\nRequirements traceability\n.\nReporting and analysis\nTo support reporting and analysis, Azure Test Plans supports test tracking charts, a test\nRuns\nhub, several built-in pipeline test reports, dashboard widgets, and test-data stored in the Analytics service.\nConfigurable test charts\n: You can gain insight into the test plan authoring and execution activity by creating test tracking charts.\nProgress report\n: Track progress of one or test plans or test suites.\nTest Runs\n: Review the results of manual and automated test runs.\nDashboard widgets: Configurable widgets that display test results based on selected builds or releases. Widgets include the\nDeployment status\nwidget and the\nTest Results Trend (Advanced)\nwidget.\nTest Analytics\n: Gain detailed insights from built-in pipeline reports or create custom reports by querying the Analytics service.\nConfigurable test charts\nQuickly configure lightweight charts to track your manual test results\nusing the chart types of your choice, and pin the charts to your dashboard to\neasily analyze these results. Choose a retention policy to control how\nlong your manual testing results are retained.\nSee more at\nTrack test status\n.\nProgress reports\nWith the\nProgress report\nhub, teams can track progress of more than one test plan or test suite. This report helps answer the following questions:\nHow much testing is complete?\nHow many tests passed, failed, or are blocked?\nIs testing likely to complete in time?\nWhat is the daily rate of execution?\nWhich test areas need attention?\nTest runs\nThe\nRuns\nhub displays the results of test runs, which include all test runs, both manual and automated.\nNote\nThe\nRuns\nhub is available with Azure DevOps Server 2020 and later versions. It requires enabling the Analytics service which is used to store and manage test run data. For more information about the service, see\nWhat is the Analytics service?\nChoose any specific run to view a summary of the test run.\nDeployment status\nThe Deployment status widget configurable widget shows a combined view of the deployment status and test pass rate across multiple environments for a recent set of builds. You configure the widget by specifying a build pipeline, branch, and linked release pipelines. To view the test summary across multiple environments in a release, the widget provides a matrix view of each environment and corresponding test pass rate.\nHover over any build summary, and you can view more details, specifically the number of tests passed and failed.\nTest results trend (Advanced)\nThe Test Results Trend (Advanced) widget provides near real-time visibility into test data for multiple builds and releases. The widget shows a trend of your test results for selected pipelines. You can use it to track the daily count of test, pass rate, and test duration. Tracking test quality over time and improving test collateral is key to maintaining a healthy DevOps pipeline. The widget supports tracking advanced metrics for one or more build pipelines or release pipelines. The widget also allows filtering of test results by outcome, stacking metrics, and more. For more information, see\nConfigure the Test Results Trend (Advanced) widget\n.\nTest Analytics\nThe built-in tests and test-supported widgets derive their data from the Analytics service. The Analytics service is the reporting platform for Azure DevOps and supports the\nAnalytics\nand\nTests\ntab and drill-down reports available from the\nPipelines\nhub. The\nTest failure\ndrill-down report provides a summary of passed and failing tests. For more information, see\nTest Analytics\n.\nIn addition, you can create custom reports by querying the Analytics service. For more information, see\nOverview of sample reports using OData queries\n.\nNext steps\nTest objects and terms\nRelated content\nNavigate Test Plans\nCopy or clone test plans, test suites, and test cases\nAssociate automated tests with test cases\nAbout requesting and providing feedback\nCross-service integration and collaboration overview\nAbout pipeline tests\nMore resources\nUnit testing\nUnit test basics\nDurable Functions unit testing\nWhat is Azure Load Testing?\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Azure DevOps Test Plans",
      "section": "Azure Services"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/security/defender-endpoint/device-control-overview": {
      "content_hash": "sha256:21b97fbb89ed4c4d84a619c700d8ceaf462f975244b99aaa7a591288d83ec03a",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nDevice control in Microsoft Defender for Endpoint\nFeedback\nSummarize this article for me\nDevice control capabilities in Microsoft Defender for Endpoint enable your security team to control whether users can install and use peripheral devices, like removable storage (USB thumb drives, CDs, disks, etc.), printers, Bluetooth devices, or other devices with their computers. Your security team can configure device control policies to configure rules like these:\nPrevent users from installing and using certain devices (like USB drives)\nPrevent users from installing and using\nany\nexternal devices with specific exceptions\nAllow users to install and use specific devices\nAllow users to install and use only\nBitLocker\n-encrypted devices with Windows computers\nThis list is intended to provide some examples. It's not an exhaustive list; there are other examples to consider.\nDevice control helps protect your organization from potential data loss, malware, or other cyberthreats by allowing or preventing certain devices to be connected to users' computers. With device control, your security team can determine whether and what peripheral devices users can install and use on their computers.\nTip\nAs a companion to this article, see our\nMicrosoft Defender for Endpoint setup guide\nto review best practices and learn about essential tools such as attack surface reduction and next-generation protection. For a customized experience based on your environment, you can access the Defender for\nEndpoint automated setup guide\nin the Microsoft 365 admin center.\nMicrosoft device control capabilities\nDevice control capabilities from Microsoft can be organized into three main categories: device control in Windows, device control in Defender for Endpoint, and Endpoint Data Loss Prevention (Endpoint DLP).\nDevice control in Windows\n. The Windows operating system has built-in device control capabilities. Your security team can configure device installation settings to prevent (or allow) users from installing certain devices on their computers. Policies are applied at the device level, and use various device properties to determine whether or not a user can install/use a device.\nDevice control in Windows works with BitLocker and ADMX templates, and can be managed using Intune.\nBitLocker\n.\nBitLocker\nis a Windows security feature that provides encryption for entire volumes. BitLocker encryption can be required for writing to removable media. Together with\nIntune\n, policies can be configured to enforce encryption on devices using BitLocker for Windows. For more information, see\nDisk encryption policy settings for endpoint security in Intune\n.\nDevice Installation\n. Windows provides the capability to prevent the installation of specific types of USB devices.\nFor more information on how to configure device installation with Intune, see\nRestrict USB devices and allow specific USB devices using ADMX templates in Intune\n.\nFor more information on how to configure device installation with Group Policy, see\nManage Device Installation with Group Policy\n.\nDevice control in Defender for Endpoint\n. Device control in Defender for Endpoint provides more advanced capabilities and is cross platform.\nGranular access control - create policies to control access by device, device type, operation (read, write, execute), user group, network location, or file type.\nReporting and advanced hunting - complete visibility into add device related activities.\nDevice control in Microsoft Defender can be managed using Intune or\nGroup Policy\n.\nDevice control in Microsoft Defender and Intune\n. Intune provides a rich experience for managing complex device control policies for organizations. You can configure and deploy device restriction settings in Defender for Endpoint, for example. See\nDeploy and manage device control with Microsoft Intune\n.\nEndpoint data loss prevention\n(Endpoint DLP). Endpoint DLP monitors sensitive information on devices that are onboarded to Microsoft Purview solutions. DLP policies can enforce protective actions on sensitive information and where it's stored or used. Endpoint DLP can capture file evidence.\nLearn about Endpoint DLP\n.\nCommon device control scenarios\nIn the following sections, review the scenarios, and then identify which Microsoft capability to use.\nControl access to USB devices\nControl access to BitLocker encrypted removable media (Preview)\nControl access to printers\nControl access to Bluetooth devices\nControl access to USB devices\nYou can control access to USB devices by using device installation restrictions, removable media device control, or Endpoint DLP.\nConfigure device installation restrictions\nThe device installation restrictions available in Windows allow or deny the installation of drivers based on the device ID, device instance ID or set-up class. This can block\nany\ndevice in the device manager including all removable devices. When device installation restrictions are applied, the device is blocked in the device manager, as shown in the following screenshot:\nThere are more details available by clicking on the device.\nThere is also a record in Advanced Hunting. To view it, use the following query:\nDeviceEvents\n| extend parsed=parse_json(AdditionalFields)\n| extend MediaClass = tostring(parsed.ClassName)\n| extend MediaDeviceId = tostring(parsed.DeviceId)\n| extend MediaDescription = tostring(parsed.DeviceDescription)\n| extend MediaSerialNumber = tostring(parsed.SerialNumber)\n| extend DeviceInstanceId = tostring(parsed.DeviceInstanceId)\n| extend DriverName = tostring(parsed.DriverName)\n| extend ClassGUID = tostring(parsed.ClassGuid)\n| where ActionType contains \"PnPDeviceBlocked\"\n| project Timestamp, ActionType, DeviceInstanceId, DriverName, ClassGUID\n| order by Timestamp desc\nWhen a device installation restrictions are configured and a device is installed, an event with\nActionType\nof\nPnPDeviceAllowed\nis created.\nLearn more:\n:\nManage Device Installation with Group Policy - Windows Client Management\nRestrict USB devices and allow specific USB devices using ADMX templates in Intune\n.\nControl access to removable media using device control\nDevice control for Defender for Endpoint provides finer grain access control to a subset of USB devices. Device control can only restrict access to Windows Portal Devices, Removable Media, CD/DVDs and Printers.\nNote\nOn Windows, the term\nremovable media devices\ndoes not mean any USB device. Not\nall\nUSB devices are\nremovable media devices\n. In order to be considered a\nremovable media device\nand therefore in scope of MDE device control, the device\nmust\ncreate a disk (such as\nE:\n) in Windows. Device control can restrict access to the device and files on that device by defining policies.\nImportant\nSome devices create multiple entries in the Windows device manager (for example a removable media device and a Windows portable device). In order for the device to function properly make sure to grant access for\nall entries\nassociated with the physical device. If a policy is configured with an audit entry, then an event will appear in Advanced Hunting with an\nActionType\nof\nRemovableStoragePolicyTriggered\n.\nDeviceEvents\n| extend parsed=parse_json(AdditionalFields)\n| extend MediaClass = tostring(parsed.ClassName)\n| extend MediaDeviceId = tostring(parsed.DeviceId)\n| extend MediaDescription = tostring(parsed.DeviceDescription)\n| extend SerialNumberId = tostring(parsed.SerialNumber)\n| extend RemovableStoragePolicy = tostring(parsed.RemovableStoragePolicy)\n| extend RemovableStorageAccess =tostring(parsed.RemovableStorageAccess)\n| extend RemovableStoragePolicyVerdict = tostring(parsed.RemovableStoragePolicyVerdict)\n| extend PID = tostring(parsed.ProductId)\n| extend VID = tostring(parsed.VendorId)\n| extend VID_PID = strcat(VID,\"_\",PID)\n| extend InstancePathId = tostring(parsed.DeviceInstanceId)\n| where ActionType == \"RemovableStoragePolicyTriggered\"\n| project Timestamp, RemovableStoragePolicy, RemovableStorageAccess,RemovableStoragePolicyVerdict, SerialNumberId,VID, PID, VID_PID, InstancePathId\n| order by Timestamp desc\nThis query returns the name of the policy, the access requested, and the verdict (allow, deny), as shown in the following screenshot:\nTip\nDevice control for Microsoft Defender for Endpoint on macOS can control access to iOS devices, portable devices such as cameras, and removable media such as USB devices. See\nDevice Control for macOS\n.\nUse Endpoint DLP to prevent file copying to USB\nTo prevent copying of files to USB based on file sensitivity use\nEndpoint DLP\n.\nControl access to BitLocker encrypted removable media (Preview)\nYou use BitLocker to control access to removable media or to ensure that devices are encrypted.\nUse BitLocker to deny access to removable media\nWindows provides the ability to deny write to all removable media or deny write access unless a device is BitLocker encrypted. For more information, see\nConfigure BitLocker - Windows Security\n.\nConfigure device control policies for BitLocker (Preview)\nDevice control for Microsoft Defender for Endpoint controls access to a device based on its BitLocker encrypted state (encrypted or plain). This allows for exceptions to be created to allow and audit access to non-BitLocker encrypted devices.\nTip\nIf you're using Mac, device control can control access to removable media based on the APFS encryption state. See\nDevice Control for macOS\n.\nControl access to printers\nYou can control access to printers by using printer installation restrictions, device control policies for printing, or Endpoint DLP.\nSet up printer installation restrictions\nThe device installation restrictions of Windows can be applied to printers.\nConfigure device control policies for printing\nDevice control for Microsoft Defender for Endpoint controls access to the printer based on the properties of the printer (VID/PID), the type of printer (Network, USB, Corporate etc.).\nDevice control can also restrict the types of files that are printed. Device control can also restrict printing on non-corporate environments.\nUse Endpoint DLP to prevent classified document printing\nTo block printing of documents based on information classification use\nEndpoint DLP\n.\nUse Endpoint DLP to capture file evidence of printed files\nTo capture evidence of a file being printed, use\nEndpoint DLP\nControl access to Bluetooth devices\nYou can use device control to control access to Bluetooth services on Windows devices or by using Endpoint DLP.\nTip\nIf you're using Mac, device control can control access to Bluetooth. See\nDevice Control for macOS\n.\nControl access to Bluetooth services on Windows\nAdministrators can control the behavior of the Bluetooth service (Allowing advertising, discovery, preparing and prompting) as well as the Bluetooth services that are allowed. For more information, see\nWindows Bluetooth\n.\nUse Endpoint DLP to prevent document copying to devices\nTo block copying of sensitive document to any Bluetooth Device use\nEndpoint DLP\n.\nUse Endpoint DLP to capture file evidence of files copied to USB\nTo capture evidence of a file being copied to a USB, use\nEndpoint DLP\nDevice control policy samples and scenarios\nDevice control in Defender for Endpoint provides your security team with a robust access control model that enables a wide range of scenarios (see\nDevice control policies\n). We have put together a GitHub repository that contains samples and scenarios you can explore. See the following resources:\nDevice control samples README\nGetting started with device control samples on Windows devices\nDevice control for macOS samples\nIf you're new to device control, see\nDevice control walkthroughs\n.\nPrerequisites for device control\nDevice control in Defender for Endpoint can be applied to devices running Windows 10 or Windows 11 that have the anti-malware client version\n4.18.2103.3\nor later. (Currently, servers are not supported.)\n4.18.2104\nor later: Add\nSerialNumberId\n,\nVID_PID\n, filepath-based GPO support, and\nComputerSid\n.\n4.18.2105\nor later: Add Wildcard support for\nHardwareId/DeviceId/InstancePathId/FriendlyNameId/SerialNumberId\n; the combination of specific users on specific machines, removable SSD (a SanDisk Extreme SSD)/USB Attached SCSI (UAS) support.\n4.18.2107\nor later: Add Windows Portable Device (WPD) support (for mobile devices, such as tablets); add\nAccountName\ninto advanced hunting.\n4.18.2205\nor later: Expand the default enforcement to Printer. If you set it to Deny, it blocks Printer as well, so if you only want to manage storage, make sure to create a custom policy to allow Printer.\n4.18.2207\nor later: Add File support; the common use case can be, \"block people from Read/Write/Execute access specific file on removable storage.\" Add Network and VPN Connection support; the common use case can be, \"block people from access removable storage when the machine isn't connecting corporate network.\"\nFor Mac, see\nDevice Control for macOS\n.\nCurrently, device control is not supported on servers.\nNext steps\nDevice control walkthroughs\nLearn about Device control policies\nView device control reports\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Device Control",
      "section": "Microsoft Defender"
    },
    "https://learn.microsoft.com/en-us/defender-cloud-apps/ai-agent-inventory": {
      "content_hash": "sha256:22a937582ab33f4287fe1811c2fbd6fc6073a2acfd19f63b72741678198b3413",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nDiscover and protect your AI Agents (Preview)\nFeedback\nSummarize this article for me\nMicrosoft Defender detects all Copilot Studio custom AI agents in your tenant and provides tools to identify misconfigured or potentially risky agents, and collects data from Copilot Studio for use in\nadvanced hunting\n.\nPrerequisites\nTo enable AI agent inventory and detection you must opt in to the\nMicrosoft Defender preview features\nof:\nMicrosoft Defender for Cloud Apps\nMicrosoft Defender for Cloud\nMicrosoft Defender XDR\nEnable the Copilot Studio AI agent inventory\nNote\nThe onboarding process for the AI agent inventory requires collaboration with Power Platform administrators.\nTo enable the Copilot Studio AI agent inventory, follow these steps:\nSign in to the\nMicrosoft Defender portal\nas the System Administrator.\nGo to\nSystem > Settings > Cloud Apps > Copilot Studio AI Agents\n.\nTurn on\nCopilot Studio AI Agents\n. Enabling Copilot Studio AI Agents confirms that you read the disclaimer and agree to use the Microsoft Defender AI agent protection features.\nWork together with the Power Platform administrator to complete these steps in the\nPower Platform Portal\n:\nGo to\nSecurity\n->\nThreat Protection\n.\nSelect\nMicrosoft Defender - Copilot Studio AI Agents\n.\nTurn on\nEnable Microsoft Defender - Copilot Studio AI Agents\n.\nWhen Copilot Studio AI Agents are connected, a green indicator appears in the\nAI Agents Inventory\nsection in the Microsoft Defender system settings. It can take up to 30 minutes for the initial connection status to update. Depending on the size and complexity of your environment, it might take longer to see the full deployment of the AI agent inventory.\nIdentify misconfigured or risky AI agents using advanced hunting\nAfter you give Microsoft Defender access to your custom agents, you can use advanced hunting to help identify misconfigured or risky agents and minimize organizational exposure to potential threats.\nSee\nProactively hunt for threats with advanced hunting in Microsoft Defender\nto learn how to use queries to proactively hunt for threats.\nWe recommend that you reach out to the owners of the risky agents for more information, and that you consider quarantining or deleting risky agents.\nSign in to the Defender portal, and go\nInvestigation & response\n->\nHunting\n->\nAdvanced hunting\n.\nIn the\nApps & identities\nsection, the\nAIAgentsInfo table\ncontains data for all your custom AI agents created using Copilot Studio. You can use this data to create custom queries.\nYou can use the collection of community queries to identify misconfigured or risky agents.\nSign in to the\nMicrosoft Defender portal\n.\nGo to\nInvestigation & response\n->\nHunting\n->\nAdvanced hunting\n.\nIn the\nQueries\ntab, select\nCommunity queries\n. The\nAI Agents\nfolder contains queries related to AI agents. For more information, see\nSample queries\n.\nRelated articles\nProtect your Copilot Studio custom AI Agents (Preview)\nEnable real-time protection for Microsoft Copilot Studio Agents\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Defender for Cloud Apps - AI Inventory",
      "section": "Microsoft Defender"
    },
    "https://learn.microsoft.com/en-us/power-automate/get-started-approvals": {
      "content_hash": "sha256:70f8ec29dcd33ac8f832bc8b62046a29af034b3df8086e95bcfafef6b31a4a35",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGet started with approvals\nFeedback\nSummarize this article for me\nWhether you need written acknowledgment from your manager or a formal authorization from a diverse group of stakeholders, getting things approved is part of almost every organization.\nWith the approvals capability in Power Automate, you can automate sign-off requests and combine human decision-making for workflows. Some popular cases where approvals can be used include:\nApproving vacation time requests.\nApproving documents that need sign-off.\nApproving expense reports.\nWhen you submit an approval in a flow, approvers are notified and can review and act on the request.\nApprovals actions\nActions\nare the events you want your flow to perform after the trigger starts the flow. For example, when a new item is added to a list created with Microsoft Lists, trigger an approval to have somebody review the new item.\nThe following image shows the full list of\napproval actions\nthat you can use in your flows.\nIf you want to quickly get started with approvals, use the\nStart and wait for an approval\naction. This action lets you provide the information that should be in the approval request and the approvers who will receive the request.\nWhen you use the\nStart and wait for an approval\naction, the flow starts and then waits for the approvers' response before it completes the run.\nThere are four approval types you can use.\nApproval type\nBehavior\nApprove/Reject - Everyone must approve\nAll approvers are given two options:\nApprove\nor\nReject\n.\nA response is needed from\neach\napprover before the flow run is completed. The actions that follow the\nStart and wait for an approval\naction run after\nall\nthe approvers respond, or when a single rejection occurs.\nApprove/Reject - First to respond\nAssigned approvers are given two options:\nApprove\nor\nReject\n.\nApproval or rejection by any approver completes the request. The actions that follow the\nStart and wait for an approval\naction run after any one of the approvers gives approval.\nCustom Responses - Wait for all responses\nYou define the options the assigned approvers can choose from.\nAll approvers must respond to complete the process.\nCustom Responses - Wait for one response\nYou define the options the assigned approvers can choose from.\nA response from any approver completes the process.\nSequential approval\nApprovals are requested one at a time, in a specific order. Each approver must respond before the request moves to the next approver in the sequence. The actions that follow the\nStart and wait for an approval\naction run after all the approvers in the sequence have responded.\nPrerequisites\nIf it's the first time you're using approvals in your organization, ensure that you've met the following prerequisites:\nA Microsoft Dataverse database\n.\nA valid license to create flows\n.\nPermissions to create a Dataverse database\nWhen you create approval flows, they're saved in Dataverse. Initially, when you use the approvals connector in a cloud flow that's located in a non-default environment, the system automatically provisions a database. To be successful, the user who runs the first approval flow must have an administrator role in the environment.\nIt can take a few minutes for the database provisioning to be completed, and you'll notice this delay the first time that you run the flow. Other users who create approval flows don't need any elevated permissions in the environment.\nNote\nIf you're using the default environment, you don't need to provision the Dataverse database. If you create approval flows, the Dataverse database is created for you automatically in the default environment.\nLicense to create flows\nBecause the approvals connector is a standard connector, any license that grants access to Power Automate and the ability to use standard connectors is sufficient to create approval flows.\nHere are the licenses that grant rights to use standard connectors:\nPower Automate\n.\nOffice 365.\nDynamics 365 license with built-in Power Automate capabilities.\nYou can find a list of the Office 365 and Dynamics 365 licenses in the\nMicrosoft Power Apps and Power Automate licensing guide\n.\nGet started\nUse one of the following options to get started creating approval flows.\nUse an existing templateâYou can search the list of\napprovals templates\nfor your scenario, and then follow steps to create a flow that suits your needs.\nTweak an existing templateâIf one of the existing templates is similar, but doesn't fit your needs precisely, create a flow from that template and then tweak the flow to your liking.\nAfter you create a flow from a template, it's yours to modify or extend. Do this by adding, editing, or removing triggers and actions.\nTip\nYou can\ncopy and paste\nactions in the same flow or across flows to speed up the editing process.\nCreate an approval flow from scratchâIf you can't find a suitable template, you can create a flow from scratch and then connect it to the services and the approvals you need by using the approvals actions. Learn\nhow to create a flow from scratch\n.\nConsult the community for inspiration and helpâPower Automate has a thriving community that can help if you're stuck or looking for some inspiration. Just head over to the\nPower Automate forums\nto ask specific questions and get answers.\nAssign approvals to any user in your tenant\nYou can assign approvals to usersâincluding guest users and Microsoft 365 groupsâin your current Dataverse environment or your Microsoft Entra tenant.\nWhen you assign an approval to users who aren't in your environment, they're automatically given the\nApprovals User\nDataverse security role. Users need this role for their responses to be processed and persisted in their approvals history.\nThe following tenant configurations don't allow this:\nWhen the AllowAdHocSubscriptions setting in Microsoft Entra is disabled. In this case, you can request your tenant administrator to enable it. You can find more information about this in the self-service signup.\nIf a security group has been used to control which users have access to the Dataverse environment.\nPower Automate\nUS Government plans\n.\nAfter you assign an approval request to a user, they can respond directly from an Outlook email, a Microsoft Teams adaptive card, or the Power Automate action center if they have a Power Automate license or an Office 365 or a Dynamics 365 license with built-in Power Automate capabilities. You can find a list of these Office 365 and Dynamics 365 licenses in the Microsoft Power Apps and Power Automate licensing guide.\nNext step\nCreate\napproval flows\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Approval Workflows",
      "section": "Power Automate"
    },
    "https://learn.microsoft.com/en-us/power-automate/run-scheduled-tasks": {
      "content_hash": "sha256:61c16677a575bff5e2f44b24aadfa01d3d67b5c33763f06d2d29f23352369a48",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nRun a cloud flow on a schedule\nFeedback\nSummarize this article for me\nCreate a cloud flow that performs one or more tasks such as sending a report in email.\nOnce a day, an hour, or a minute.\nOn a date that you specify.\nAfter many days, hours, or minutes that you specify.\nCreate a scheduled cloud flow\nYou can create a scheduled cloud flow using natural language in Copilot, or create it from scratch. If you have access to Copilot, select the\nUsing copilot\ntab to create your flow. If you don't have access to Copilot, select the\nWithout copilot\ntab.\nUsing copilot\nWithout copilot\nYou can ask Copilot to create a scheduled cloud flow.\nSign in to\nPower Automate\n.\nOn the navigation pane to the left, make sure that\nHome\nis selected.\nIn the\nCreate your automation with Copilot\nfield, type the following prompt:\nCreate a flow that runs Monday every week starting [DATE] which sends an email to contoso@gmail.com that their MPR doc is due.**\nSelect\nGenerate\n.\nCopilot generates a flow based on your prompt. You can review the generated flow and make any necessary adjustments. If you're satisfied with the suggested flow, select\nKeep it and continue\n.\nReview the connected apps and services. A green checkmark means the connection is ready to go.\nIf you don't have a green checkmark, select the connection to set it up.\nSelect\nCreate flow\n.\nUse Copilot to configure actions\nIn the designer, select\nCopilot\n.\nIn the Copilot panel, ask Copilot to make changes to your scheduled flow. For example, you can enter the following prompt:\nChange the interval from every week to 2 weeks.\nAfter Copilot generates a response, it confirms that it made the update successfully. If you change your mind, you can select\nUndo\nto revert the changes.\nIf you're not using Copilot to configure your actions, go to\nConfigure cloud flow triggers and actions\n.\nSign in to\nPower Automate\n.\nSelect\nMy flows\n>\nNew flow\n>\nScheduled cloud flow\n.\nIn the fields next to\nStarting\n, specify the date and time when your flow should start.\nIn the fields next to\nRepeat every\n, specify the flow's recurrence.\nSelect\nCreate\n.\nGo to\nConfigure cloud flow triggers and actions\n.\nConfigure cloud flow triggers and actions\nPower Automate allows you to use either the\nnew designer\nor the\nclassic designer\nto configure your cloud flow. The steps are similar in both designers. Learn more (with examples) in\nIdentify differences between the new designer and the classic designer\n.\nMake sure you\nCreated a scheduled cloud flow\n.\nSelect the trigger or action to configure.\nConfigure the parameters.\nNew designer: In the designer, select the trigger or action. The configuration pane opens on the left side of the screen.\nClassic designer: In the designer, select\nRecurrence\n>\nShow advanced options\n. When you select\nShow advanced options\n, the dropdown name changes to\nHide advanced options\n.\nNew designer\nClassic designer\nIn the\nTime zone\nfield, select a time zone from the dropdown list to specify whether the\nStart time\nreflects a local time zone, Coordinated Universal Time (UTC), or other time zone.\nIn the\nStart time\nfield, enter a start time in this format: YYYY-MM-DDTHH:MM:SSZ.\nYYYY = four-digit year\nMM = two-digit month (01-12)\nDD = two-digit day of the month (01-31)\nT = literal character that separates the date and time\nHH = two-digit hour in 24-hour format (00-23)\nMM = two-digit minute (00-59)\nSS = two-digit second (00-59)\nZ = literal character that indicates UTC time\nFor example, enter\n2025-03-24T22:00:00Z\nto specify 3:00 PM Pacific time on March 24, 2025.\nIf you specified\nDay\nunder\nFrequency\n, select the time of day when the flow should run in the\nAt these hours\nand\nAt these minutes\ndropdown lists.\nIf you specified\nWeek\nunder\nFrequency\n, do the following.\nIn the\nOn these days\nand\nAt these hours\ndropdown menus, select the day or days of the week on which the flow should run and the time or times of day when the flow should run.\nIn the\nAt these minutes\nfield, enter the minute values (from 0 to 59) separated by a comma.\nIf you run a flow on the month frequency, the flow runs on the same date each month.\nAdd the action or actions that you want the flow to take, as described in\nCreate a cloud flow from scratch\n.\nRelated information\nAdvanced options in Azure Logic Apps\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Scheduled Flows",
      "section": "Power Automate"
    },
    "https://learn.microsoft.com/en-us/power-apps/maker/data-platform/use-powerapps-checker": {
      "content_hash": "sha256:0825ac603e96ff26c33f269ed712d021b2d7fa30e6a867fc6d7377f846cdd531",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nImprove solution performance, stability and reliability\nFeedback\nSummarize this article for me\nSolutions are used to distribute Power Platform objects, such as apps, tables, flows, web resources, and plugins. This article introduces the solution checker feature, a powerful tool that performs a comprehensive static analysis of your solution objects against a set of\nbest practice rules\n. By using solution checker, you can quickly identify problematic patterns in your components and receive detailed reports that highlight issues, affected components, and provide links to documentation on how to resolve each issue. This ensures your solutions are optimized for performance, stability, and reliability.\nSolution checker works with unmanaged solutions that can be exported from an environment.\nYou can run solution checker either from Power Apps (make.powerapps.com) or by using\nPowerShell\n.\nHow solution checker helps you\nTo deliver on complex business requirements, makers often can end up with highly advanced solutions that customize and extend the Power Platform. With advanced implementations come an increased risk where performance, stability, and reliability issues become introduced, which can negatively impact the user experience. Identifying and understanding how to resolve these issues can be complicated and time consuming. With the solution checker feature, you can perform a check within seconds on your solution, which uses a set of best practice rules to quickly identify problematic patterns. After the check completes, you receive a detailed report in Power Apps as well as in an email message that lists the issues identified, the components and code affected, and links to documentation that describes how to resolve each issue.\nThe solution checker analyzes these solution components:\nDataverse custom workflow activities\nDataverse web resources (HTML and JavaScript)\nDataverse configurations, such as SDK message steps\nPower Automate flows (via\nflow checker\n)\nPower Fx expressions (via\napp checker\n)\nNote\nSolution checker supports global variables for ECMAScript 2015 (ES6) and up to ECMAScript 2018 (ES9) syntax. When JavaScript is detected using global variables later than ES6 or syntax later than ES9, a web-unsupported-syntax issue for the web resource is reported.\nUse of solution checker doesn't guarantee that a solution import will be successful. The static analysis checks performed against the solution don't know the configured state of the destination environment and import success might be dependent on other solutions or configurations in the environment.\nRun the solution checker\nSign in to\nPower Apps\n.\nIn the left pane, select\nSolutions\n. If the item isnât in the side panel pane, select\nâ¦More\nand then select the item you want.\nNext to the unmanaged solution that you want to analyze, select\n...\n, point to\nSolution checker\n, and then select\nRun\n.\nThe\nSolution checker\ncommand button has a loading indicator, and you'll notice a\nRunningâ¦\nstate in the\nSolution check\ncolumn of the\nSolution\nlist.\nNote\nThe solution checker can take a few minutes to complete the analysis.\nYou'll receive an email notification and a notification in the\nNotifications\narea of the Power Apps site when the check is completed.\nView the report\nwhen the check is completed.\nCancel a check\nAfter you submit a solutions check in your environment, the check can be canceled through the status pane on the upper right area of the\nSolutions\npage.\nWhen you cancel a check, the solution check stops running and the solution check status returns to the previous state.\nSolution checker states\nWhen you install the solution checker in your environment, the\nSolution check\ncolumn becomes available in the\nSolutions\nlist. This column displays the solution analysis states for a solution.\nState\nDescription\nHasnât been run\nThe solution has never been analyzed.\nRunning\nThe solution is being analyzed.\nCouldnât be completed\nSolution analysis was requested but the analysis didn't complete successfully.\nResults as of\ndate and time\nSolution analysis completed and results are available for download.\nCouldnât be completed. Result as of\ndate and time\nThe latest analysis request didn't complete successfully. The last successful results can be downloaded.\nChecked by Microsoft\nThis is a Microsoft-managed solution. Solution analysis isn't permitted on these solutions.\nChecked by Publisher\nThis is a non-Microsoft managed solution. Currently, solution analysis isn't available for these solutions.\nReview the solution checker report\nWhen a solution check is completed, you can view the analysis report in the portal, or you can download the report from your web browser. In the portal, you have options to sort results by\nIssue\n,\nLocation\nor by\nSeverity\nand view detailed information for issues detected in your solution.\nIn the left pane, select\nSolutions\n. If the item isnât in the side panel pane, select\nâ¦More\nand then select the item you want.\nNext to the unmanaged solution where you want to view the solution checker report, select\n...\n, point to\nSolution checker\n, and then select\nView results\n.\nSelect an issue to view the details and guidance on how to resolve.\nThe solution check results are also available for download. The solution checker zip file is downloaded to the folder specified by your web browser. The download report is in Excel format and contains several visualizations and columns that assist you in identifying the impact, type, and location of each issue detected in your solution. A link to detailed guidance about how to resolve the issue is also provided.\nIn the left pane, select\nSolutions\n. If the item isnât in the side panel pane, select\nâ¦More\nand then select the item you want.\nNext to the unmanaged solution where you want to download the solution checker report, select\n...\n, point to\nSolution checker\n, and then select\nDownload results\n.\nThe solution checker zip file is downloaded to the folder specified by your web browser.\nHere's a summary of each column in the report.\nReport column\nDescription\nApplies-to component\nIssue\nThe title of the issue identified in the solution.\nAll\nCategory\nThe categorization of the issue identified, such as\nPerformance\n,\nMaintainability\n,\nUsage\n,\nSupportability\n,\nDesign\n,\nSecurity\n,\nAccessibility\n, or\nUpgrade readiness\n.\nAll\nSeverity\nRepresents the potential impact of the issue identified. Available impact types are\nCritical\n,\nHigh\n,\nMedium\n,\nLow\n, and\nInformational\n.\nAll\nGuidance\nLink to article detailing the issue, impact, and recommended action.\nAll\nComponent\nThe solution component where the issue was identified.\nAll\nLocation\nThe location and/or source file of the component where the issue that was identified occurred, such as the assembly or JavaScript file name.\nAll\nLine #\nThe line number reference of the issue in the impacted web resource component.\nWeb resources\nModule\nModule name where the issue identified in the assembly was detected.\nCustom workflow activity\nType\nType of the issue identified in the assembly.\nCustom workflow activity\nMember\nMember of the issue identified in the assembly.\nCustom workflow activity\nStatement\nThe code statement or configuration that resulted in the issue.\nAll\nComments\nDetails about the issue that include high-level resolution steps.\nAll\nRun solution checker rules locally\nYou can run solution checker rules in your development environment to detect issues much sooner as you create your solution resources. This is currently supported for web resources (JavaScript and\nTypeScript\n). For more details, go to the NPM package\n@microsoft/eslint-plugin-power-apps\n.\nRun solution checker using PowerShell\nA PowerShell module is available that you can use to interact directly with the service. The Microsoft.PowerApps.Checker.PowerShell module can be used for analysis of unmanaged solutions for Power Apps environments, or to automate and integrate the service into your build and release pipelines. More information:\nMicrosoft.PowerApps.Checker.PowerShell Overview\nBest practice rules used by solution checker\nThe following table lists the component type, rule description, severity, and category. Critical violations are blocked or warned when configured for solution checker enforcement with managed environments. More information:\nUse solution checker in Managed Environments\nSolution component\nRule name\nRule description\nSeverity\nCategory\nPlug-in or workflow activity\nmeta-remove-dup-reg\nAvoid duplicate Dataverse plug-in registrations.\nCritical\nPerformance\nPlug-in or workflow activity\nmeta-avoid-reg-no-attribute\nInclude filtering attributes with Dataverse plug-in registrations.\nMedium\nPerformance\nPlug-in or workflow activity\nmeta-avoid-reg-retrieve\nUse caution with Dataverse plug-ins registered for Retrieve and RetrieveMultiple messages.\nMedium\nPerformance\nPlug-in or workflow activity\nmeta-remove-inactive\nRemove inactive configurations in Dataverse.\nLow\nMaintainability\nPlug-in or workflow activity\nmeta-avoid-crm4-event\nDon't use Microsoft Dynamics CRM 4.0 plug-in registration stage.\nMedium\nUpgrade readiness\nPlug-in or workflow activity\nmeta-avoid-retrievemultiple-annotation\nAvoid registering a plugin on RetrieveMultiple of annotation.\nHigh\nUsage\nModel-driven app\nmeta-license-sales-entity-operations\nSolution contains entities with restricted SDK messages and operations that require a valid Dynamics 365 license.\nLow\nLicensing\nModel-driven app\nmeta-license-fieldservice-customcontrols\nSolution contains custom controls that require a valid Dynamics 365 Field Service license.\nLow\nLicensing\nModel-driven app\nmeta-license-fieldservice-entity-operations\nSolution contains entities with restricted SDK messages and operations that require a valid Dynamics 365 Field Service license.\nLow\nLicensing\nWeb Resources\nuse-async\nInteract with HTTP and HTTPS resources asynchronously.\nCritical\nPerformance\nWeb Resources\navoid-modals\nAvoid using modal dialogs.\nHigh\nSupportability\nWeb Resources\navoid-dom-form\nHigh\nSupportability\nWeb Resources\navoid-dom-form-event\nHigh\nSupportability\nWeb Resources\navoid-crm2011-service-odata\nDon't target the Microsoft Dynamics CRM 2011 OData 2.0 endpoint.\nCritical\nUpgrade readiness\nWeb Resources\navoid-crm2011-service-soap\nDon't target the Microsoft Dynamics CRM 2011 SOAP services.\nCritical\nUpgrade readiness\nWeb Resources\navoid-loadtheme\nDon't use\nloadTheme\nFluent v8 API.\nLow\nSupportability\nWeb Resources\navoid-browser-specific-api\nDon't use Internet Explorer legacy APIs or browser plug-ins.\nCritical\nUpgrade readiness\nWeb Resources\navoid-unpub-api\nHigh\nSupportability\nWeb Resources\navoid-window-top\nHigh\nSupportability\nWeb Resources\navoid-2011-api\nDon't use the deprecated Microsoft Dynamics CRM 2011 object model. Instead follow\nDataverse Web API\ndocumentation.\nHigh\nUpgrade readiness\nWeb Resources\nuse-relative-uri\nDon't use absolute Dataverse endpoint URLs.\nMedium\nMaintainability\nWeb Resources\nuse-cached-webresource\nMedium\nPerformance\nWeb Resources\nuse-client-context\nUse client contexts.\nMedium\nUpgrade readiness\nWeb Resources\nuse-navigation-api\nUse navigation API parameters.\nMedium\nUpgrade readiness\nWeb Resources\nuse-offline\nMedium\nUpgrade readiness\nWeb Resources\ndo-not-make-parent-assumption\nHigh\nDesign\nWeb Resources\nuse-org-setting\nUse organization settings.\nMedium\nUpgrade readiness\nWeb Resources\nuse-global-context\nMedium\nUpgrade readiness\nWeb Resources\nuse-grid-api\nUse the grid APIs.\nMedium\nUpgrade readiness\nWeb Resources\nuse-utility-dialogs\nMedium\nUsage\nWeb Resources\navoid-isActivityType\nReplace Xrm.Utility.isActivityType method with new Xrm.Utility.gettableMetadata and don't use in ribbon rules.\nMedium\nUpgrade readiness\nWeb Resources\nmeta-avoid-silverlight\nSilverlight web resource usage is deprecated.\nMedium\nUpgrade readiness\nWeb Resources\nremove-debug-script\nAvoid including debug script in nondevelopment environments.\nMedium\nUsage\nWeb Resources\nuse-strict-mode\nUse strict mode when possible.\nMedium\nUsage\nWeb Resources\nuse-strict-equality-operators\nUse strict equality operators.\nMedium\nUsage\nWeb Resources\navoid-eval\nDon't use the\neval\nfunction or its functional equivalents.\nCritical\nSecurity\nWeb Resources\navoid-with\nDon't use the 'with' operator.\nHigh\nPerformance\nWeb Resources\nremove-alert\nDon't use the 'alert' function or its functional equivalents.\nMedium\nUsage\nWeb Resources\nremove-console\nAvoid using methods on console.\nMedium\nUsage\nWeb Resources\navoid-ui-refreshribbon\nAvoid using refreshRibbon in form onload and EnableRule.\nCritical\nPerformance\nWeb Resources\nuse-getsecurityroleprivilegesinfo\nAvoid userSettings.securityRolePrivileges. Use userSettings.getSecurityRolePrivilegesInfo instead.\nHigh\nPerformance\nWeb Resources\nuse-appsidepane-api\nUse Xrm.App.sidePanes.createPane instead of Xrm.Panels.loadPanel.\nMedium\nUpgrade readiness\nWeb Resources\nweb-sdl-no-cookies\nHTTP cookies are an old client-side storage mechanism with inherent risks and limitations. Use Web Storage, IndexedDB, or other modern methods instead.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-document-domain\nWrites to document.domain property must be reviewed to avoid bypass of same-origin checks. Usage of top level domains such as azurewebsites.net is strictly prohibited.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-document-write\nCalls to document.write or document.writeln manipulate DOM directly without any sanitization and should be avoided. Use document.createElement() or similar methods instead.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-html-method\nDirect calls to method html() often (for example, in jQuery framework) manipulate DOM without any sanitization and should be avoided. Use document.createElement() or similar methods instead.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-inner-html\nAssignments to innerHTML or outerHTML properties manipulate DOM directly without any sanitization and should be avoided. Use document.createElement() or similar methods instead.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-insecure-url\nInsecure protocols such as HTTP or FTP should be replaced by their encrypted counterparts (HTTPS, FTPS) to avoid sending potentially sensitive data over untrusted networks in plaintext.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-msapp-exec-unsafe\nCalls to MSApp.execUnsafeLocalFunction() bypass script injection validation and should be avoided.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-postmessage-star-origin\nAlways provide specific target origin, not * when sending data to other windows using postMessage to avoid data leakage outside of trust boundary.\nMedium\nSecurity\nWeb Resources\nweb-sdl-no-winjs-html-unsafe\nCalls to WinJS.Utilities.setInnerHTMLUnsafe() and similar methods don't perform any input validation and should be avoided. Use WinJS.Utilities.setInnerHTML() instead.\nMedium\nSecurity\nCanvas App\napp-formula-issues-high\nGo to\nPower Apps formula reference\nfor additional details.\nCritical\nDesign\nCanvas App\napp-formula-issues-medium\nRefer to Power Apps formula references for additional details.\nMedium\nDesign\nCanvas App\napp-formula-issues-low\nRefer to Power Apps formula references for additional details.\nLow\nDesign\nCanvas App\napp-use-delayoutput-text-input\nUse delayed load in some scenarios to improve performance.\nMedium\nPerformance\nCanvas App\napp-reduce-screen-controls\nLimit the number of app controls for improved performance.\nMedium\nPerformance\nCanvas App\napp-include-accessible-label\nUse explicit labels to improve app accessibility.\nMedium\nAccessibility\nCanvas App\napp-include-alternative-input\nEnsure all interactive elements are accessible to alternative inputs.\nMedium\nAccessibility\nCanvas App\napp-avoid-autostart\nAvoid using autostart on players within an app.\nMedium\nAccessibility\nDesktop flow\ndesktopflow-avoid-unsafe-password\nPasswords are managed insecurely in the flow.\nHigh\nSecurity\nDesktop flow\ndesktopflow-avoid-subflow-recursion\nRecursive calls detected between subflows, potentially causing an infinite loop.\nMedium\nDesign\nDesktop flow\ndesktopflow-avoid-infinite-loop\nInfinite loop detected in the flow, potentially causing it to run indefinitely.\nMedium\nDesign\nDesktop flow\ndesktopflow-avoid-incomplete-if-branch\nIncomplete If action detected, lacking content or only containing actions in the Else branch.\nLow\nDesign\nDesktop flow\ndesktopflow-avoid-excessive-nested-ifs\nNested If clauses exceed five levels.\nLow\nMaintainability\nDesktop flow\ndesktopflow-avoid-empty-on-error-block\n\"On block error\" action is empty and not handling errors.\nLow\nDesign\nDesktop flow\ndesktopflow-limit-argument-count\nTotal input/output variables exceed the 25-variable limit.\nLow\nMaintainability\nDesktop flow\ndesktopflow-input-argument-default-value\nInput/output variables aren't using default values.\nLow\nMaintainability\nDesktop flow\ndesktopflow-limit-variable-name-length\nVariable name exceeds the 25-character limit.\nLow\nMaintainability\nDesktop flow\ndesktopflow-avoid-excessive-wait-actions\nMisuse of wait actions detected, with more than 10 wait actions causing potential bottlenecks.\nLow\nPerformance\nDesktop flow\ndesktopflow-avoid-immense-wait-duration\nImmense wait time detected, exceeding the 600-second limit for hardcoded wait actions.\nLow\nPerformance\nSee also\nBest practices and guidance for the Dataverse\nBest practices and guidance for model-driven apps\nCommon issues and resolutions for Solution Checker\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Solution Checker",
      "section": "Power Apps"
    },
    "https://learn.microsoft.com/en-us/power-apps/guidance/planning/testing-phase": {
      "content_hash": "sha256:7cc295c7997a3ca205d296fc98a0836668350dea295c850600c0cf4435d65cac",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nTesting phase\nFeedback\nSummarize this article for me\nNow that your app is built, the next step is to start testing it. In\nthis section you'll learn the basics of how testing should be carried\nout.\nTypes of tests\nUnit tests\nA\nunit test\nis used to check whether a specific function or feature of\nyour app is working correctly.\nEnd-to-end tests\nEnd-to-end tests\nare used to check whether the overall solution runs correctly.\nThis is important because even if all unit tests function correctly, the\nintegration between two units can potentially fail. These tests are done by\nfollowing a test scenario that's close to the use case of the actual business\nprocess.\nUser acceptance tests\nA\nuser acceptance test\n(UAT) is done by the user of the app instead of\nthe maker. This test is to ensure that what has been built by the makers matches the\nrequirements initially requested by the user.\nHere are some tips for getting good results from UATs:\nTest with the real users.\nTry to choose users with diversity in terms of IT skill levels. This way, you can get a variety of feedback.\nDon't give the user instructions; see whether they can understand the app\nintuitively.\nObserve how they navigate the app without assistance, and see where you can improve\nthe design.\nWhen the user is stuck on a screen, ask them to explain what their\nexpectation was.\nTry out different devices to make sure the test cases behave the same.\nIdeally, test the app in the user's actual environment or location if the app uses offline\ncapabilities.\nAsk your users to try to \"break\" your app, such as by entering unusual\ncharacters in text fields.\nUsers will typically test the \"happy path\" (the path a user takes when\neverything is going perfectly); ask them to also test scenarios such as\ncanceling an expense report instead of submitting it, or denying an expense\nreport instead of approving it.\nYour users might not be familiar with testing software. Let them know what kind of\nfeedback you're looking for. It's often helpful to provide a template for\n\"bugs\" to make sure testers explain exactly what they were doing, what happened,\nwhat they expected to happen instead, and any relevant information about their\ntesting environment (such as device type and browser).\nIt's natural and OK for the user to request changes to the specifications or\nask for additional features. These requests should be recorded in the\nfeature list described in\nPrioritizing features and requests\n.\nCreating test cases and scenarios\nTo write comprehensive test scenarios and test cases, you should refer\nback to the\nPlanning phase\nand\nDesigning phase\nsections to make sure you test all the important\nscenarios.\nThe first step is to write the unit tests. Make sure you break the tests down to\neach feature or function. The test cases for unit tests should be listed like\nthe table below:\nTest case No.\nDescription of test\nInputs to test with\nExpected result\nResult\n1-1\nSubmit order details from a form\nOrder No. 16516\nOrder is successfully submitted\n1-2\nCheck that a PDF is generated and attached to the record\nN/A\nPDF file is attached to the record\n1-3\nCheck email notification is sent to user\ntest@contoso.com\nEmail is received by the specified recipient\nTools to help you test canvas apps\nPower Apps Test Studio (experimental)\nFor testing inside canvas apps, you can use a built-in tool named Power Apps Test\nStudio to write, organize, and automate tests for canvas apps. More information:\nTest Studio (experimental)\nAzure Monitor (experimental)\nWhen you're testing for performance issues, you can use Monitor to check\nnetwork activity, similar to a network trace in the browser. For details about the\nMonitor tool, see the blog post\nIntroducing Monitor to debug apps and improve performance\n.\nTools to help you test model-driven apps\nEasyRepro\nEasyRepro is the tool provided for Dynamics 365 and Power Apps model-driven\napps. It not only includes a testing tool but also has over 200 sample test\ncases to help you speed up the testing process. For more information,\nsee the blog post\nEasyRepro automated testing\nframework\n,\nand access it at the\nEasyRepro GitHub\nrepository\n.\nSolution checker\nThe solution checker is a tool that checks whether the solution you've created is healthy. You\ncan quickly review issues and see recommended fixes. More information:\nUse solution checker to validate your model-driven apps in Power Apps\nNext step: Publish and share the app\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Testing Guidance",
      "section": "Power Apps"
    },
    "https://learn.microsoft.com/en-us/microsoftteams/information-barriers-in-teams": {
      "content_hash": "sha256:b888b9502b8cae3f83adfe74e280e260420ac1fd266824002d543cb62800dbe4",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nInformation Barriers in Microsoft Teams\nFeedback\nSummarize this article for me\nMicrosoft Purview Information Barriers\n(IBs) are policies that an admin can set up to prevent individuals or groups from communicating with each other. IBs are useful if, for example, one department handles information that shouldn't be shared with other departments. IBs are also useful when a group needs to be isolated or prevented from communicating with anyone outside of that group. Shared channels in Microsoft Teams are supported by Information Barriers. Depending on the type of sharing, Information Barriers policies might restrict sharing in certain ways. For more information about shared channels and Information Barriers behavior, see\nInformation Barriers and shared channels\n.\nFor Microsoft Teams, Information Barriers can determine and prevent the following kinds of unauthorized collaborations:\nAdding a user to a team or channel\nUser access to team or channel content\nUser access to 1:1 and group chats\nUser access to meetings\nPrevents lookups and discovery, users aren't visible in the people picker.\nNote\nYou can't create information barrier groups across tenants.\nVersion 1 doesn't support using bots, Microsoft Entra apps, APIs to send activity feed notifications, and some APIs to add users.\nPrivate channels comply with Information Barriers policies that you configure.\nFor information about support for barriers for SharePoint sites that are connected to Teams, see\nSegments associated with Microsoft Teams sites\n.\nBackground\nThe financial services industry primarily drives the need for IBs. The Financial Industry Regulatory Authority (\nFINRA\n) reviews IBs and conflicts of interest within member firms and provides guidance about managing such conflicts (FINRA 2241),\nDebt Research Regulatory Notice 15-31\n.\nHowever, many other industries find IBs useful. Other common scenarios include:\nEducation\n: Students in one school can't look up contact details for students of other schools.\nLegal\n: Maintaining the confidentiality of data that a lawyer obtains from one client and preventing it from being accessed by a lawyer for the same firm who represents a different client.\nGovernment\n: Information access and control are limited across departments and groups.\nProfessional services\n: A group of people in a company can only chat with a client or a specific customer via guest access during a customer engagement.\nFor example, Enrico belongs to the Banking segment and Pradeep belongs to the Financial advisor segment. Enrico and Pradeep can't communicate with each other because the organization's IB policy blocks communication and collaboration between these two segments. However, Enrico and Pradeep can communicate with Lee in HR.\nWhen to use Information Barriers\nUse IBs in situations like these:\nYou need to prevent a team from communicating or sharing data with a specific other team.\nYou need to prevent a team from communicating or sharing data with anyone outside of the team.\nThe Information Barrier Policy Evaluation Service determines whether a communication complies with IB policies.\nManaging Information Barriers segments\nManage IB segments in the\nMicrosoft Purview portal\nor by using PowerShell cmdlets. For more information, see\nStep 2: Segment users in your organization\n.\nImportant\nSupport for assigning users to multiple segments is only available when your organization isn't in\nLegacy\nmode. To determine if your organization is in\nLegacy\nmode, see\nCheck the IB mode for your organization)\n.\nUsers are restricted to being assigned to only one segment for organizations in\nLegacy\nmode. Organizations in\nLegacy\nmode are eligible to upgrade to the newest version of Information Barriers in the future. For more information, see the\nInformation Barriers roadmap\n.\nManaging Information Barriers policies\nManage IB policies in the\nMicrosoft Purview portal\nor by using PowerShell cmdlets. For more information, see\nStep 3: Create IB policies\n.\nImportant\nBefore you set up or define policies, you must enable scoped directory search in Microsoft Teams. Wait at least a few hours after enabling scoped directory search before you set up or define policies for Information Barriers. For more information, see\nDefine information barrier policies\n.\nInformation Barriers administrator role\nThe IB Compliance Management role is responsible for managing IB policies. For more information about this role, see\nPermissions in the Microsoft Purview portal\n.\nInformation barrier triggers\nIB policies activate when the following Teams events take place:\nMembers are added to a team\n: Whenever you add a user to a team, the system evaluates the user's policy against the IB policies of other team members. After the user is successfully added, the user can perform all functions in the team without further checks. If the user's policy blocks them from being added to the team, the user doesn't show up in search.\nA new chat is requested\n: Each time that a user requests a new chat with one or more other users, the system evaluates the chat to make sure that it isn't violating any IB policies. If the conversation violates an IB policy, the conversation isn't started.\nHere's an example of a 1:1 chat.\nHere's an example of a group chat.\nA user is invited to join a meeting\n: When a user is invited to join a meeting, the system evaluates the IB policy that applies to the user against the IB policies that apply to the other team members. If there's a violation, the user isn't allowed to join the meeting.\nA screen is shared between two or more users\n: When a user shares a screen with other users, the system evaluates the sharing to make sure that it doesn't violate the IB policies of other users. If an IB policy is violated, the screen share isn't allowed.\nHere's an example of screen share before the policy is applied.\nHere's an example of screen share after the policy is applied. The screen share and call icons aren't visible.\nA user places a phone call in Teams\n: Whenever a user initiates a voice call (via VOIP) to another user or group of users, the system evaluates the call to make sure that it doesn't violate the IB policies of other team members. If there's any violation, the voice call is blocked.\nGuests in Teams\n: IB policies apply to guests in Teams, too. If guests need to be discoverable in your organization's global address list, see\nManage guest access in Microsoft 365 Groups\n. Once guests are discoverable, you can\ndefine IB policies\n.\nHow policy changes impact existing chats\nWhen the IB policy administrator changes a policy or activates a policy change because of a change to a user's profile (such as for a job change), the Information Barrier Policy Evaluation Service automatically searches the members to ensure that their membership in the team doesn't violate any policies.\nIf users have an existing chat or other communication, and you set a new policy or change an existing policy, the service evaluates existing communications to make sure that the communications are still allowed to occur.\n1:1 chat\n: If communication between two users is no longer allowed (because of application to one or both users of a policy that blocks communication), the service blocks further communication. Their existing chat conversations become read-only.\nHere's an example that shows the chat is visible.\nHere's an example that shows the chat is disabled.\nGroup chat\n: If communication from one user to a group is no longer allowed (for example, because a user changed jobs), the service removes the user, along with the other users whose participation violates the policy, from group chat, and blocks further communication with the group. The user can still see old conversations, but can't see or participate in any new conversations with the group. If the new or changed policy that prevents communication is applied to more than one user, the service removes the users who are affected by the policy from group chat. They can still see old conversations.\nIn this example, Enrico moves to a different department within the organization and is removed from the group chat.\nEnrico can no longer send messages to the group chat.\nTeam\n: The service removes any users who are removed from the group from the team and they can't see or participate in existing or new conversations.\nScenario: A user in an existing chat becomes blocked\nCurrently, users experience the following scenarios if an IB policy blocks another user:\nPeople tab\n: A user can't see blocked users on the\nPeople\ntab.\nPeople Picker\n: Blocked users won't be visible in the people picker.\nActivity tab\n: If a user visits the\nActivity\ntab of a blocked user, no posts appear. (The\nActivity\ntab displays channel posts only, and there would be no common channels between the two users.)\nHere's an example of the activity tab view that is blocked.\nOrg charts\n: If a user accesses an org chart on which a blocked user appears, the blocked user won't appear on the org chart. Instead, an error message appears.\nPeople card\n: If a user participates in a conversation and the user is later blocked, other users see an error message instead of the people card when they hover over the blocked user's name. Actions listed on the card (such as calling and chat) are unavailable.\nSuggested contacts\n: Blocked users don't appear on the suggested contacts list (the initial contact list that appears for new users).\nChat contacts\n: A user can see blocked users on the chats contact list, but the blocked users are identified. The only action that the user can perform on the blocked users is to delete them. The user can also select them to view their past conversation.\nCalls contacts\n: A user can see blocked users on the calls contact list, but the blocked users are identified. The only action that the user can perform on the blocked users is to delete them.\nHere's an example of a blocked user in the calls contact list.\nSkype to Teams migration\n: During a migration from Skype for Business to Teams, all users-even those users who are blocked by IB policies-are migrated to Teams. Those users are then handled as described previously.\nHere's an example of a blocked user in the calls contact list.\nHere's an example of the chat being disabled for a user on the calls content list.\nSkype to Teams migration\n: During a migration from Skype for Business to Teams, all usersâeven those users who are blocked by IB policiesâare migrated to Teams. Those users are then handled as described previously.\nTeams policies and SharePoint sites\nWhen you create a team, you also create and associate a SharePoint site with Microsoft Teams for the files experience. Information barrier policies don't apply to this SharePoint site and its files by default. To enable Information Barriers in SharePoint and OneDrive, follow the guidance and steps in the\nUse Information Barriers with SharePoint\narticle.\nInformation barrier modes and Teams\nInformation barrier modes help control who can be added to or removed from a Team. When you use Information Barriers with Teams, the following IB modes are supported:\nOpen\n: This configuration is the default IB mode for all existing groups that were provisioned before Information Barriers were enabled. In this mode, there are no IB policies applicable.\nImplicit\n: This configuration is the default IB mode when a Team is provisioned after enabling Information Barriers. Implicit mode allows you to add all compatible users in the group.\nOwner Moderated\n: This mode is set on a team when you want to allow collaboration between incompatible segment users that are moderated by the owner. The team owner can add new members per their IB policy.\nTeams created before activating an information barrier policy in your tenant are automatically set to\nOpen\nmode by default. When you activate IB policies on your tenant, you must update mode of your existing teams to\nImplicit\nto ensure that existing teams are IB-compliant. For more information about updating modes, see\nChange Information Barriers modes with a PowerShell script\n.\nUse the\nSet-UnifiedGroup\ncmdlet with the\nInformationBarrierMode\nparameter that corresponds to the mode you want to use for your segments. Allowed list of values for the\nInformationBarrierMode\nparameter are\nOpen\n,\nImplicit\n, and\nOwner Moderated\n.\nFor example, to configure the\nImplicit\nmode for a Microsoft 365 Group, use the following PowerShell command:\nSet-UnifiedGroup -InformationBarrierMode Implicit\nTo update the mode from\nOpen\nto\nImplicit\nfor all existing teams, use this\nPowerShell script\n.\nIf you change the\nOpen\nmode configuration on existing Teams-connected groups to meet compliance requirements for your organization, you need to\nupdate the IB modes\nfor associated SharePoint sites connected to the Teams team.\nIB policy application in Teams\nThe IB policy application is a background IB processor for Teams that gets a notification when there are changes to either users (policy or segment changes) or groups (mode changes). The following steps outline the processing flow:\nThe policy application receives a group change notification when mode is updated and retrieves the message thread and Group IDs applicable to the update.\nIf the message thread exists, the application schedules processing and fetches all members from the team. It sends the underlying group and members to downstream Teams components for IB evaluation.\nThe application evaluates the mode on the group and the IB policies per user and sends the results to the policy application.\nThe policy application removes the non-compliant users from the group and team.\nRequired licenses and permissions\nFor more information on licenses and permissions, plans, and pricing, see the\nsubscription requirements\nfor Information Barriers.\nUsage notes\nUsers can't join any scheduled meetings\n: If IB policies are enabled, users can't join meetings if the meeting chat roster reaches its current limit of 1,000 users. IB checks rely on whether a user can be added to the meeting chat roster - only users who can be added are allowed to join the meeting. Every meeting in an IB-enabled tenant performs IB checks at the point of entry, even if the meeting organizer isn't explicitly covered by IB policies.\nTeams also enforces a separate meeting limit of 1,000 users. If overflow is enabled, additional participants can join as view-only attendees. View-only participants aren't subject to IB policy checks. If you invite a large audience (for example, more than 1,000 users), Teams pre-adds 750 users to the meeting chat before the meeting starts. This reserves room for about 250 additional users who actually join the meeting. Because pre-added users count toward the chat roster limit even if they never join the meeting, the chat roster can reach capacity before the meeting attendance limit is met. For recurring meetings, the roster can fill quickly, as any user who joins once remains on the roster for future occurrences. Once the 1,000-user chat roster limit is reached, no additional users can be added to the meeting.\nA short-term solution is to remove inactive members from the meeting chat roster to make space for new users or keep the chat disabled until the meeting begins and enable it only when needed. This helps align the chat participant count more closely with the meeting participant count. Regular Teams meetings work best for audiences of fewer than 1,000 expected attendees. For larger audiences, use\nTeams Town hall\nfor a smoother experience.\nUsers can't join channel meetings\n: If IB policies are enabled, users can't join channel meetings if they're not a member of the team. The root cause is that IB checks rely on whether users can be added to a meeting chat roster, and only when they can be added to the roster are they allowed to join the meeting. The chat thread in a channel meeting is available to Team/Channel members only, and non-members can't see or access the chat thread. If IB is enabled for the organization and a non-team member attempts to join a channel meeting, that user isn't allowed to join the meeting. However, if IB isn't enabled for the organization and a nonteam member attempts to join a channel meeting, the user is allowed to join the meeting but they won't see the chat option in the meeting.\nIB policies don't work for federated users\n: If you allow federation with external organizations, the users of those organizations aren't restricted by IB policies. If users of your organization join a chat or meeting organized by external federated users, then IB policies also won't restrict communication between users of your organization.\nMore information\nTo learn more about IBs, see\nInformation Barriers\n.\nTo set up IB policies, see\nGet started with Information Barriers\n.\nTo edit or remove IB policies, see\nManage information barrier policies\n.\nInformation Barriers and shared channels\nAvailability\nInformation Barriers in Teams is available in the public, GCC, GCC - High, and DOD clouds.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Information Barriers in Teams",
      "section": "Microsoft Teams"
    },
    "https://learn.microsoft.com/en-us/graph/api/resources/application": {
      "content_hash": "sha256:f90bad06511a1dea928847b9e229f47b3c8cc591ae3be8939494589749e9dbbf",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\napplication resource type\nFeedback\nSummarize this article for me\nNamespace: microsoft.graph\nRepresents an application. Any application that outsources authentication to Microsoft Entra ID must be registered in the Microsoft identity platform. Application registration involves telling Microsoft Entra ID about your application, including the URL where it's located, the URL to send replies after authentication, the URI to identify your application, and more.\nInherits from\ndirectoryObject\n.\nThis resource is an open type that allows additional properties beyond those documented here.\nThis resource supports:\nAdding your own data to custom properties as\nextensions\n.\nUsing\ndelta query\nto track incremental additions, deletions, and updates, by providing a\ndelta\nfunction.\nAlternate key syntax. The\nappId\nproperty is a supported alternate key. For more information, see\nGet application\n.\nMethods\nMethod\nReturn Type\nDescription\nList\napplication\ncollection\nRetrieve the list of applications in the organization.\nCreate\napplication\nCreates (registers) a new application.\nGet\napplication\nRead properties and relationships of application object.\nUpdate\nNone\nUpdate application object.\nUpsert\napplication\nCreate a new application if it doesn't exist, or update the properties of an existing application.\nDelete\nNone\nDelete application object.\nGet delta\napplication\nGet newly created, updated, or deleted applications without performing a full read of the entire resource collection.\nDeleted items\nList\ndirectoryObject\ncollection\nRetrieve a list of recently deleted applications.\nGet\ndirectoryObject\nRetrieve the properties of a recently deleted application.\nRestore\ndirectoryObject\nRestore a recently deleted application.\nPermanently delete\nNone\nPermanently delete an application.\nList deleted items owned by user\ndirectoryObject\ncollection\nRetrieve the applications deleted in the tenant in the last 30 days and that are owned by a user.\nCertificates and secrets\nAdd password\npasswordCredential\nAdd a strong password to an application.\nRemove password\npasswordCredential\nRemove a password from an application.\nAdd key\nkeyCredential\nAdd a key credential to an application.\nRemove key\nNone\nRemove a key credential from an application.\nOwners\nList\ndirectoryObject\ncollection\nGet the owners of an application.\nAdd\ndirectoryObject\nAssign an owner to an application. Application owners can be users or service principals.\nRemove\nNone\nRemove an owner from an application. As a recommended best practice, apps should have at least two owners.\nVerified publisher\nSet\nNone\nSet the verified publisher of an application.\nUnset\nNone\nUnset the verified publisher of an application.\nProperties\nImportant\nSpecific usage of\n$filter\nand the\n$search\nquery parameter is supported only when you use the\nConsistencyLevel\nheader set to\neventual\nand\n$count\n. For more information, see\nAdvanced query capabilities on directory objects\n.\nProperty\nType\nDescription\naddIns\naddIn\ncollection\nDefines custom behavior that a consuming service can use to call an app in specific contexts. For example, applications that can render file streams\ncan set the addIns property\nfor its \"FileHandler\" functionality. This lets services like Microsoft 365 call the application in the context of a document the user is working on.\napi\napiApplication\nSpecifies settings for an application that implements a web API.\nappId\nString\nThe unique identifier for the application that is assigned to an application by Microsoft Entra ID. Not nullable. Read-only. Alternate key. Supports\n$filter\n(\neq\n).\napplicationTemplateId\nString\nUnique identifier of the\napplicationTemplate\n. Supports\n$filter\n(\neq\n,\nnot\n,\nne\n). Read-only.\nnull\nif the app wasn't created from an application template.\nappRoles\nappRole\ncollection\nThe collection of roles defined for the application. With\napp role assignments\n, these roles can be assigned to users, groups, or service principals associated with other applications. Not nullable.\ncertification\ncertification\nSpecifies the certification status of the application.\ncreatedDateTime\nDateTimeOffset\nThe date and time the application was registered. The DateTimeOffset type represents date and time information using ISO 8601 format and is always in UTC time. For example, midnight UTC on Jan 1, 2014 is\n2014-01-01T00:00:00Z\n. Read-only.\nSupports\n$filter\n(\neq\n,\nne\n,\nnot\n,\nge\n,\nle\n,\nin\n, and\neq\non\nnull\nvalues) and\n$orderby\n.\ndeletedDateTime\nDateTimeOffset\nThe date and time the application was deleted. The DateTimeOffset type represents date and time information using ISO 8601 format and is always in UTC time. For example, midnight UTC on Jan 1, 2014 is\n2014-01-01T00:00:00Z\n. Read-only.\ndescription\nString\nFree text field to provide a description of the application object to end users. The maximum allowed size is 1,024 characters. Supports\n$filter\n(\neq\n,\nne\n,\nnot\n,\nge\n,\nle\n,\nstartsWith\n) and\n$search\n.\ndisabledByMicrosoftStatus\nString\nSpecifies whether Microsoft has disabled the registered application. The possible values are:\nnull\n(default value),\nNotDisabled\n, and\nDisabledDueToViolationOfServicesAgreement\n(reasons include suspicious, abusive, or malicious activity, or a violation of the Microsoft Services Agreement).\nSupports\n$filter\n(\neq\n,\nne\n,\nnot\n).\ndisplayName\nString\nThe display name for the application. Maximum length is 256 characters. Supports\n$filter\n(\neq\n,\nne\n,\nnot\n,\nge\n,\nle\n,\nin\n,\nstartsWith\n, and\neq\non\nnull\nvalues),\n$search\n, and\n$orderby\n.\ngroupMembershipClaims\nString\nConfigures the\ngroups\nclaim issued in a user or OAuth 2.0 access token that the application expects. To set this attribute, use one of the following valid string values:\nNone\n,\nSecurityGroup\n(for security groups and Microsoft Entra roles),\nAll\n(this gets all of the security groups, distribution groups, and Microsoft Entra directory roles that the signed-in user is a member of).\nid\nString\nUnique identifier for the application object. This property is referred to as\nObject ID\nin the Microsoft Entra admin center. Inherited from\ndirectoryObject\n. Key. Not nullable. Read-only. Supports\n$filter\n(\neq\n,\nne\n,\nnot\n,\nin\n).\nidentifierUris\nString collection\nAlso known as App ID URI, this value is set when an application is used as a resource app. The identifierUris acts as the prefix for the scopes you reference in your API's code, and it must be globally unique across Microsoft Entra ID. For more information on valid identifierUris patterns and best practices, see\nMicrosoft Entra application registration security best practices\n. Not nullable.\nSupports\n$filter\n(\neq\n,\nne\n,\nge\n,\nle\n,\nstartsWith\n).\ninfo\ninformationalUrl\nBasic profile information of the application such as app's marketing, support, terms of service and privacy statement URLs. The terms of service and privacy statement are surfaced to users through the user consent experience. For more info, see How to:\nAdd Terms of service and privacy statement for registered Microsoft Entra apps\n.\nSupports\n$filter\n(\neq\n,\nne\n,\nnot\n,\nge\n,\nle\n, and\neq\non\nnull\nvalues).\nisDeviceOnlyAuthSupported\nBoolean\nSpecifies whether this application supports device authentication without a user. The default is\nfalse\n.\nisFallbackPublicClient\nBoolean\nSpecifies the fallback application type as public client, such as an installed application running on a mobile device. The default value is\nfalse\n, which means the fallback application type is confidential client such as a web app. There are certain scenarios where Microsoft Entra ID can't determine the client application type. For example, the\nROPC\nflow where it's configured without specifying a redirect URI. In those cases, Microsoft Entra ID interprets the application type based on the value of this property.\nkeyCredentials\nkeyCredential\ncollection\nThe collection of key credentials associated with the application. Not nullable. Supports\n$filter\n(\neq\n,\nnot\n,\nge\n,\nle\n).\nlogo\nStream\nThe main logo for the application. Not nullable.\nnativeAuthenticationApisEnabled\nnativeAuthenticationApisEnabled\nSpecifies whether the Native Authentication APIs are enabled for the application. The possible values are:\nnone\nand\nall\n. Default is\nnone\n. For more information, see\nNative Authentication\n.\nnotes\nString\nNotes relevant for the management of the application.\noauth2RequiredPostResponse\nBoolean\nSpecifies whether, as part of OAuth 2.0 token requests, Microsoft Entra ID allows POST requests, as opposed to GET requests. The default is\nfalse\n, which specifies that only GET requests are allowed.\noptionalClaims\noptionalClaims\nApplication developers can configure optional claims in their Microsoft Entra applications to specify the claims that are sent to their application by the Microsoft security token service. For more information, see\nHow to: Provide optional claims to your app\n.\nparentalControlSettings\nparentalControlSettings\nSpecifies parental control settings for an application.\npasswordCredentials\npasswordCredential\ncollection\nThe collection of password credentials associated with the application. Not nullable.\npublicClient\npublicClientApplication\nSpecifies settings for installed clients such as desktop or mobile devices.\npublisherDomain\nString\nThe verified publisher domain for the application. Read-only. For more information, see\nHow to: Configure an application's publisher domain\n. Supports\n$filter\n(\neq\n,\nne\n,\nge\n,\nle\n,\nstartsWith\n).\nrequestSignatureVerification\nrequestSignatureVerification\nSpecifies whether this application requires Microsoft Entra ID to verify the signed authentication requests.\nrequiredResourceAccess\nrequiredResourceAccess\ncollection\nSpecifies the resources that the application needs to access. This property also specifies the set of delegated permissions and application roles that it needs for each of those resources. This configuration of access to the required resources drives the consent experience.\nNo more than 50 resource services (APIs) can be configured. Beginning mid-October 2021, the total number of required permissions must not exceed 400. For more information, see\nLimits on requested permissions per app\n. Not nullable.\nSupports\n$filter\n(\neq\n,\nnot\n,\nge\n,\nle\n).\nsamlMetadataUrl\nString\nThe URL where the service exposes SAML metadata for federation. This property is valid only for single-tenant applications. Nullable.\nserviceManagementReference\nString\nReferences application or service contact information from a Service or Asset Management database. Nullable.\nservicePrincipalLockConfiguration\nservicePrincipalLockConfiguration\nSpecifies whether sensitive properties of a multitenant application should be locked for editing after the application is provisioned in a tenant. Nullable.\nnull\nby default.\nsignInAudience\nString\nSpecifies the Microsoft accounts that are supported for the current application. The possible values are:\nAzureADMyOrg\n(default),\nAzureADMultipleOrgs\n,\nAzureADandPersonalMicrosoftAccount\n, and\nPersonalMicrosoftAccount\n. See more in the\ntable\n.\nThe value of this object also limits the number of permissions an app can request. For more information, see\nLimits on requested permissions per app\n.\nThe value for this property has implications on other app object properties. As a result, if you change this property, you might need to change other properties first. For more information, see\nValidation differences for signInAudience\n.\nSupports\n$filter\n(\neq\n,\nne\n,\nnot\n).\nspa\nspaApplication\nSpecifies settings for a single-page application, including sign out URLs and redirect URIs for authorization codes and access tokens.\ntags\nString collection\nCustom strings that can be used to categorize and identify the application. Not nullable. Strings added here will also appear in the\ntags\nproperty of any associated\nservice principals\n.\nSupports\n$filter\n(\neq\n,\nnot\n,\nge\n,\nle\n,\nstartsWith\n) and\n$search\n.\ntokenEncryptionKeyId\nString\nSpecifies the keyId of a public key from the keyCredentials collection. When configured, Microsoft Entra ID encrypts all the tokens it emits by using the key this property points to. The application code that receives the encrypted token must use the matching private key to decrypt the token before it can be used for the signed-in user.\nuniqueName\nString\nThe unique identifier that can be assigned to an application and used as an alternate key. Immutable. Read-only.\nverifiedPublisher\nverifiedPublisher\nSpecifies the verified publisher of the application. For more information about how publisher verification helps support application security, trustworthiness, and compliance, see\nPublisher verification\n.\nweb\nwebApplication\nSpecifies settings for a web application.\nsignInAudience values\nValue\nDescription\nAzureADMyOrg\nUsers with a Microsoft work or school account in my organization's Microsoft Entra tenant (single tenant). This is the default value for the\nsignInAudience\nproperty.\nAzureADMultipleOrgs\nUsers with a Microsoft work or school account in any organization's Microsoft Entra tenant (multitenant).\nAzureADandPersonalMicrosoftAccount\nUsers with a personal Microsoft account, or a work or school account in any organization's Microsoft Entra tenant. For authenticating users with Azure AD B2C user flows, use\nAzureADandPersonalMicrosoftAccount\n. This value allows for the widest set of user identities including local accounts and user identities from Microsoft, Facebook, Google, Twitter, or any OpenID Connect provider.\nPersonalMicrosoftAccount\nUsers with a personal Microsoft account only.\nLimits on requested permissions per app\nMicrosoft Entra ID limits the number of permissions that can be requested and consented by a client app. These limits depend on the\nsignInAudience\nvalue for an app, shown in the\napp's manifest\n.\nsignInAudience\nAllowed users\nMaximum permissions the app can request\nMaximum Microsoft Graph permissions the app can request\nMaximum permissions that can be consented in a single request\nAzureADMyOrg\nUsers from the organization where the app is registered\n400\n400\nAbout 155 delegated permissions and about 300 application permissions\nAzureADMultipleOrgs\nUsers from any Microsoft Entra organization\n400\n400\nAbout 155 delegated permissions and about 300 application permissions\nPersonalMicrosoftAccount\nConsumer users (such as Outlook.com or Live.com accounts)\n30\n30\n30\nAzureADandPersonalMicrosoftAccount\nConsumer users and users from any Microsoft Entra organization\n30\n30\n30\nRelationships\nImportant\nSpecific usage of the\n$filter\nquery parameter is supported only when you use the\nConsistencyLevel\nheader set to\neventual\nand\n$count\n. For more information, see\nAdvanced query capabilities on directory objects\n.\nRelationship\nType\nDescription\nappManagementPolicies\nappManagementPolicy\ncollection\nThe appManagementPolicy applied to this application.\ncreatedOnBehalfOf\ndirectoryObject\nSupports\n$filter\n(\n/$count eq 0\n,\n/$count ne 0\n). Read-only.\nextensionProperties\nextensionProperty\ncollection\nRead-only. Nullable. Supports\n$expand\nand\n$filter\n(\n/$count eq 0\n,\n/$count ne 0\n).\nfederatedIdentityCredentials\nfederatedIdentityCredential\ncollection\nFederated identities for applications. Supports\n$expand\nand\n$filter\n(\nstartsWith\n,\n/$count eq 0\n,\n/$count ne 0\n).\nowners\ndirectoryObject\ncollection\nDirectory objects that are owners of this application. The owners are a set of nonadmin users or service principals who are allowed to modify this object. Supports\n$expand\n,\n$filter\n(\n/$count eq 0\n,\n/$count ne 0\n,\n/$count eq 1\n,\n/$count ne 1\n), and\n$select\nnested in\n$expand\n.\nsynchronization\nsynchronization\nRepresents the capability for Microsoft Entra identity synchronization through the Microsoft Graph API.\nJSON representation\nThe following JSON representation shows the resource type.\n{\n \"addIns\": [{\"@odata.type\": \"microsoft.graph.addIn\"}],\n \"api\": {\"@odata.type\": \"microsoft.graph.apiApplication\"},\n \"appId\": \"String\",\n \"applicationTemplateId\": \"String\",\n \"appRoles\": [{\"@odata.type\": \"microsoft.graph.appRole\"}],\n \"certification\": {\"@odata.type\": \"microsoft.graph.certification\"},\n \"createdDateTime\": \"String (timestamp)\",\n \"deletedDateTime\": \"String (timestamp)\",\n \"disabledByMicrosoftStatus\": \"String\",\n \"displayName\": \"String\",\n \"groupMembershipClaims\": \"String\",\n \"id\": \"String (identifier)\",\n \"identifierUris\": [\"String\"],\n \"info\": {\"@odata.type\": \"microsoft.graph.informationalUrl\"},\n \"isDeviceOnlyAuthSupported\": false,\n \"isFallbackPublicClient\": false,\n \"keyCredentials\": [{\"@odata.type\": \"microsoft.graph.keyCredential\"}],\n \"logo\": \"Stream\",\n \"nativeAuthenticationApisEnabled\": \"String\",\n \"notes\": \"String\",\n \"oauth2RequiredPostResponse\": false,\n \"optionalClaims\": {\"@odata.type\": \"microsoft.graph.optionalClaims\"},\n \"parentalControlSettings\": {\"@odata.type\": \"microsoft.graph.parentalControlSettings\"},\n \"passwordCredentials\": [{\"@odata.type\": \"microsoft.graph.passwordCredential\"}],\n \"publicClient\": {\"@odata.type\": \"microsoft.graph.publicClientApplication\"},\n \"publisherDomain\": \"String\",\n \"requestSignatureVerification\": {\"@odata.type\": \"microsoft.graph.requestSignatureVerification\"},\n \"requiredResourceAccess\": [{\"@odata.type\": \"microsoft.graph.requiredResourceAccess\"}],\n \"servicePrincipalLockConfiguration\": {\"@odata.type\": \"microsoft.graph.servicePrincipalLockConfiguration\"},\n \"serviceManagementReference\": \"String\",\n \"signInAudience\": \"String\",\n \"spa\": {\"@odata.type\": \"microsoft.graph.spaApplication\"},\n \"tags\": [\"String\"],\n \"tokenEncryptionKeyId\": \"String\",\n \"uniqueName\": \"String\",\n \"verifiedPublisher\": {\"@odata.type\": \"microsoft.graph.verifiedPublisher\"},\n \"web\": {\"@odata.type\": \"microsoft.graph.webApplication\"}\n}\nRelated content\nThe Microsoft Entra app manifest\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Application Resources",
      "section": "Microsoft Graph API"
    },
    "https://learn.microsoft.com/en-us/graph/api/resources/accessreviewsv2-overview": {
      "content_hash": "sha256:1154c2557d33ec749cf83ae87d1f3d2f2d185cea3462eba68c9ba45123e9cf0b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of access reviews APIs\nFeedback\nSummarize this article for me\nNamespace: microsoft.graph\nUse\nMicrosoft Entra access reviews\nto configure one-time or recurring access reviews for attestation of a principal's right to access Microsoft Entra resources. The principals are users or applications (service principals). The Microsoft Entra resources include groups, applications (service principals), access packages, and privileged roles. Access reviews is a feature of Microsoft Entra ID Governance.\nTypical customer scenarios for access reviews include:\nCustomers can review and certify guest user access to groups through group memberships. Reviewers can use the insights that are provided to efficiently decide whether guests should have continued access.\nCustomers can review and certify employee access to Microsoft Entra resources.\nCustomers can review and audit assignments to Microsoft Entra ID privileged roles. This supports organizations in the management of privileged access.\nThe tenant where an access review is being created or managed via the API must have sufficient purchased or trial licenses. For more information about the license requirements, see\nAccess reviews license requirements\n.\nNote\nThis article describes how to export personal data from a device or service. These steps can be used to support your obligations under the General Data Protection Regulation (GDPR). Authorized tenant admins can use Microsoft Graph to correct, update, or delete identifiable information about end users, including customer and employee user profiles or personal data, such as a user's name, work title, address, or phone number, in your\nMicrosoft Entra ID\nenvironment.\nMethods\nThe following table lists the methods that you can use to interact with access review-related resources.\nMethod\nReturn type\nDescription\nSchedule definitions\nList definitions\naccessReviewScheduleDefinition\ncollection\nGet a list of the\naccessReviewScheduleDefinition\nobjects and their properties.\nCreate definitions\naccessReviewScheduleDefinition\nCreate a new\naccessReviewScheduleDefinition\nobject.\nGet accessReviewScheduleDefinition\naccessReviewScheduleDefinition\nRead the properties and relationships of an\naccessReviewScheduleDefinition\nobject.\nUpdate accessReviewScheduleDefinition\naccessReviewScheduleDefinition\nUpdate the properties of an\naccessReviewScheduleDefinition\nobject.\nDelete accessReviewScheduleDefinition\nNone\nDeletes an\naccessReviewScheduleDefinition\nobject.\nfilterByCurrentUser\naccessReviewScheduleDefinition\ncollection\nReturns all definitions where the calling user is the reviewer of any instances.\nInstances\nList instances\naccessReviewInstance\ncollection\nGet a list of the\naccessReviewInstance\nobjects and their properties.\nGet accessReviewInstance\naccessReviewInstance\nRead the properties and relationships of an\naccessReviewInstance\nobject.\nstop\nNone\nManually stop an accessReviewInstance.\nsendReminder\nNone\nSend a reminder to the reviewers of an accessReviewInstance.\nresetDecisions\nNone\nResets all decision items on an instance to\nnotReviewed\napplyDecisions\nNone\nManually apply decision on an accessReviewInstance.\nacceptRecommendations\nNone\nAllows the calling user to accept the decision recommendation for each NotReviewed accessReviewInstanceDecisionItem that they are the reviewer on for a specific accessReviewInstance.\nbatchRecordDecisions\nNone\nReview batches of principals or resources in one call.\nfilterByCurrentUser\naccessReviewInstance\ncollection\nReturns all instance objects on a definition for which the calling user is the reviewer.\nInstance decision items\nList decisions\naccessReviewInstanceDecisionItem\ncollection\nGet a list of the\naccessReviewInstanceDecisionItem\nobjects and their properties.\nGet accessReviewInstanceDecisionItem\naccessReviewInstanceDecisionItem\nRead the properties and relationships of an\naccessReviewInstanceDecisionItem\nobject.\nUpdate accessReviewInstanceDecisionItem\naccessReviewInstanceDecisionItem\nUpdate the properties of an\naccessReviewInstanceDecisionItem\nobject.\naccessReviewInstanceDecisionItem: filterByCurrentUser\naccessReviewInstanceDecisionItem\ncollection\nReturns the decision items for which the calling user is the reviewer of.\nHistory definitions\nList historyDefinitions\naccessReviewHistoryDefinition\ncollection\nGet a list of the\naccessReviewHistoryDefinition\nobjects and their properties.\nCreate historyDefinitions\naccessReviewHistoryDefinition\nCreate a new\naccessReviewHistoryDefinition\nobject.\nGet accessReviewHistoryDefinition\naccessReviewHistoryDefinition\nRead the properties and relationships of an\naccessReviewHistoryDefinition\nobject.\ngenerateDownloadUri\naccessReviewHistoryInstance\nGenerate a URI for an instance that can be used to retrieve review history data.\nList instances\naccessReviewHistoryInstance\nRetrieve a list of the\naccessReviewHistoryInstance\nobjects and their properties.\nRole and application permission authorization checks\nThe following\nMicrosoft Entra roles\nare required for a calling user to manage access reviews.\nOperation\nApplication permissions\nLeast privileged directory role of the calling user\nRead\nAccessReview.Read.All or AccessReview.ReadWrite.All\nGlobal Reader, Security Administrator, Security Reader or User Administrator\nCreate, Update or Delete\nAccessReview.ReadWrite.All\nUser Administrator\nIn addition, a user who is an assigned reviewer of an access review can manage their decisions, without needing to be in a directory role.\nRelated content\nWalk through guided tutorials\nto learn how to use the access reviews API to review access to Microsoft Entra resources.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Access Reviews API",
      "section": "Microsoft Graph API"
    },
    "https://learn.microsoft.com/power-bi/guidance/powerbi-adoption-roadmap-governance": {
      "content_hash": "sha256:90af2168ea769790b98327883af890680fc2d40235dbadb6301db59c862468b5",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Fabric adoption roadmap: Governance\nFeedback\nSummarize this article for me\nNote\nThis article forms part of the\nMicrosoft Fabric adoption roadmap\nseries of articles. For an overview of the series, see\nMicrosoft Fabric adoption roadmap\n.\nData governance is a broad and complex topic. This article introduces key concepts and considerations. It identifies important actions to take when adopting Microsoft Fabric, but it's not a comprehensive reference for data governance.\nAs defined by the\nData Governance Institute\n, data governance is \"a system of decision rights and accountabilities for information-related processes, executed according to agreed-upon models which describe who can take what actions, with what information, and when, under what circumstances, using what methods.\"\nThe term\ndata governance\nis a misnomer. The primary focus for governance isn't on the data itself. The focus is on governing\nwhat users do with the data\n. Put another way: the true focus is on governing user's behavior to ensure organizational data is well managed.\nWhen focused on self-service data and business intelligence (BI), the primary goals of governance are to achieve the proper balance of:\nUser empowerment\n: Empower the internal user community to be productive and efficient, within requisite guardrails.\nRegulatory compliance\n: Comply with the organization's industry, governmental, and contractual regulations.\nInternal requirements\n: Adhere to the organization's internal requirements.\nThe optimal balance between control and empowerment will differ between organizations. It's also likely to differ among different business units within an organization. You'll be most successful with a platform like Fabric when you put as much emphasis on user empowerment as on clarifying its practical usage within established guardrails.\nTip\nThink of governance as a set of established guidelines and formalized policies. All governance guidelines and policies should align with your organizational\ndata culture\nand adoption objectives. Governance is enacted on a day-to-day basis by your\nsystem oversight\n(administration) activities.\nGovernance strategy\nWhen considering data governance in any organization, the best place to start is by defining a governance strategy. By focusing first on the strategic goals for data governance, all detailed decisions when implementing governance policies and processes can be informed by the strategy. In turn, the governance strategy will be defined by the organization's\ndata culture\n.\nGovernance decisions are implemented with documented guidance, policies, and processes. Objectives for governance of a self-service data and BI platform, such as Fabric, include:\nEmpowering users throughout the organization to use data and make decisions, within the defined boundaries.\nImproving the user experience by providing clear and transparent guidance (with minimal friction) on what actions are permitted, why, and how.\nEnsuring that the data usage is appropriate for the needs of the business.\nEnsuring that content ownership and stewardship responsibilities are clear. For more information, see the\nContent ownership and management\narticle.\nEnhancing the consistency and standardization of working with data across organizational boundaries.\nReducing risk of data leakage and misuse of data. For more information, see the\ninformation protection and data loss prevention series of articles\narticle.\nMeeting regulatory, industry, and internal requirements for the proper use of data.\nTip\nA well-executed data governance strategy makes it easier for more users to work with data. When governance is approached from the perspective of user empowerment, users are more likely to follow the documented processes. Accordingly, the users become a trusted partner too.\nGovernance success factors\nGovernance isn't well-received when it's enacted with top-down mandates that are focused more on control than empowerment. Governing Fabric is most successful when:\nThe most lightweight governance model that accomplishes required objectives is used.\nGovernance is approached on an iterative basis and doesn't significantly impede productivity.\nA bottom-up approach to formulating governance guidelines is used whenever practical. The\nCenter of Excellence (COE)\nand/or the data governance team observes successful behaviors that are occurring within a business unit. The COE then takes action to scale out to other areas of the organization.\nGovernance decisions are co-defined with input from different business units before they're enacted. Although there are times when a specific directive is necessary (particularly in heavily regulated industries), mandates should be the exception rather than the rule.\nGovernance needs are balanced with flexibility and the ability to be productive.\nGovernance requirements can be satisfied as part of users' regular workflow, making it easier for users to do the right thing in the right way with little friction.\nThe answer to new requests for data isn't \"no\" by default, but rather \"yes and\" with clear, simple, transparent rules for what governance requirements are for data access, usage, and sharing.\nUsers that need access to data have incentive to do so through normal channels, complying with governance requirements, rather than circumventing them.\nGovernance decisions, policies, and requirements for users to follow are in alignment with organizational data culture goals as well as other existing data governance initiatives.\nDecisions that affect what users canâand can'tâdo aren't made solely by a system administrator.\nIntroduce governance to your organization\nThere are three primary timing methods organizations take when introducing Fabric governance to an organization.\nThe methods in the above diagram include:\nMethod\nStrategy followed\nRoll out Fabric first, then introduce governance\n: Fabric is made widely available to users in the organization as a new self-service data and BI tool. Then, at some time in the future, a governance effort begins. This method prioritizes agility.\nFull governance planning first, then roll out Fabric\n: Extensive governance planning occurs prior to permitting users to begin using Fabric. This method prioritizes control and stability.\nIterative governance planning with rollouts of Fabric in stages\n: Just enough governance planning occurs initially. Then Fabric is iteratively rolled out in stages to individual teams while iterative governance enhancements occur. This method equally prioritizes agility and governance.\nChoose method 1 when Fabric is already used for self-service scenarios, and you're ready to start working in a more efficient manner.\nChoose method 2 when your organization already has a well-established approach to governance that can be readily expanded to include Fabric.\nChoose method 3 when you want to have a balance of control agility. This balanced approach is the best choice for most organizations and most scenarios.\nEach method is described in the following sections.\nMethod 1: Roll out Fabric first\nMethod 1 prioritizes agility and speed. It allows users to quickly get started creating solutions. This method occurs when Fabric has been made widely available to users in the organization as a new self-service data and BI tool. Quick wins and some successes are achieved. At some point in the future, a governance effort begins, usually to bring order to an unacceptable level of chaos since the self-service user population didn't receive sufficient guidance.\nPros\n:\nFastest to get started\nHighly capable users can get things done quickly\nQuick wins are achieved\nCons\n:\nHigher effort to establish governance once Fabric is used prevalently throughout the organization\nResistance from self-service users who are asked to change what they've been doing\nSelf-service users need to figure out things on their own, which is inefficient and results in inconsistencies\nSelf-service users need to use their best judgment, which produces technical debt to be resolved\nSee other possible cons in the\nGovernance challenges\nsection below.\nMethod 2: In-depth governance planning first\nMethod 2 prioritizes control and stability. It lies at the opposite end of the spectrum from method 1. Method 2 involves doing extensive governance planning before rolling out Fabric. This situation is most likely to occur when the implementation of Fabric is led by IT. It's also likely to occur when the organization operates in a highly regulated industry, or when an existing data governance board imposes significant prerequisites and up-front requirements.\nPros\n:\nMore fully prepared to meet regulatory requirements\nMore fully prepared to support the user community\nCons\n:\nFavors enterprise content development more than self-service\nSlower to allow the user population to begin to get value and improve decision-making\nEncourages poor habits and workarounds when there's a significant delay in allowing the use of data for decision-making\nMethod 3: Iterative governance with rollouts\nMethod 3 seeks a balance between agility and governance. It's an ideal scenario that does\njust enough\ngovernance planning upfront. Frequent and continual governance improvements iteratively occur over time alongside Fabric development projects that deliver value.\nPros\n:\nPuts equal priority on governance and user productivity\nEmphasizes a\nlearning as you go\nmentality\nEncourages iterative releases to groups of users in stages\nCons\n:\nRequires a high level of communication to be successful with agile governance practices\nRequires additional discipline to keep documentation and training current\nIntroducing new governance guidelines and policies too often causes a certain level of user disruption\nFor more information about up-front planning, see the\nPreparing to migrate to Power BI\narticle.\nGovernance challenges\nIf your organization has implemented Fabric without a governance approach or strategic direction (as described above by method 1), there could be numerous challenges requiring attention. Depending on the approach that you've taken and your current state, some of the following challenges could be applicable to your organization.\nStrategy challenges\nLack of a cohesive data governance strategy that aligns with the business strategy\nLack of executive support for governing data as a strategic asset\nInsufficient adoption planning for advancing adoption and the maturity level of BI and analytics\nPeople challenges\nLack of aligned priorities between centralized teams and business units\nLack of identified champions with sufficient expertise and enthusiasm throughout the business units to advance organizational adoption objectives\nLack of awareness of self-service best practices\nResistance to following newly introduced governance guidelines and policies\nDuplicate effort spent across business units\nLack of clear accountability, roles, and responsibilities\nProcess challenges\nLack of clearly defined processes resulting in chaos and inconsistencies\nLack of standardization or repeatability\nInsufficient ability to communicate and share lessons learned\nLack of documentation and over-reliance on tribal knowledge\nInability to comply with security and privacy requirements\nData quality and data management challenges\nSprawl of data and reports\nInaccurate, incomplete, or outdated data\nLack of trust in the data, especially for content produced by self-service content creators\nInconsistent reports produced without sufficient data validation\nValuable data not used or difficult to access\nFragmented, siloed, and duplicated data\nLack of data catalog, inventory, glossary, or lineage\nUnclear data ownership and stewardship\nSkills and data literacy challenges\nVarying levels of ability to interpret, create, and communicate with data effectively\nVarying levels of technical skillsets and skill gaps\nLack of ability to confidently manage data diversity and volume\nUnderestimating the level of complexity for BI solution development and management throughout its entire lifecycle\nShort tenure with continual staff transfers and turnover\nCoping with the speed of change for cloud services\nTip\nIdentifying your current challengesâas well as your strengthsâis essential to do proper governance planning. There's no single straightforward solution to the challenges listed above. Each organization needs to find the right balance and approach that solves the challenges that are most important to them. The challenges presented above will help you identify how they might affect your organization, so you can start thinking about what the right solution is for your circumstances.\nGovernance planning\nSome organizations have implemented Fabric without a governance approach or clear strategic direction (as described above by method 1). In this case, the effort to begin governance planning can be daunting.\nIf a formal governance body doesn't currently exist in your organization, then the focus of your governance planning and implementation efforts will be broader. If, however, there's an existing data governance board in the organization, then your focus is primarily to integrate with existing practices and customize them to accommodate the objectives for self-service and enterprise data and BI scenarios.\nImportant\nGovernance is a big undertaking, and it's never completely\ndone\n. Relentlessly prioritizing and iterating on improvements will make the scope more manageable. If you track your progress and accomplishments each week and each month, you'll be amazed at the impact over time. The\nmaturity levels\nat the end of each article in this series can help you to assess where you are currently.\nSome potential governance planning activities and outputs that you might find valuable are described next.\nStrategy\nKey activities\n:\nConduct a series of workshops to gather information and assess the current state of data culture, adoption, and data and BI practices. For guidance about how to gather information and define the current state of BI adoption, including governance, see\nBI strategic planning\n.\nUse the current state assessment and information gathered to define the desired future state, including governance objectives. For guidance about how to use this current state definition to decide on your desired future state, see\nBI tactical planning\n.\nValidate the focus and scope of the governance program.\nIdentify existing bottom-up initiatives in progress.\nIdentify immediate pain points, issues, and risks.\nEducate senior leadership about governance, and ensure\nexecutive sponsorship\nis sufficient to sustain and grow the program.\nClarify where Power BI fits in to the overall\nBI and analytics strategy\nfor the organization.\nAssess internal factors such as organizational readiness, maturity levels, and key challenges.\nAssess external factors such as risk, exposure, regulatory, and legal requirementsâincluding regional differences.\nKey output\n:\nBusiness case with cost/benefit analysis\nApproved governance objectives, focus, and priorities that are in alignment with high-level business objectives\nPlan for short-term goals and priorities (quick wins)\nPlan for long-term and deferred goals and priorities\nSuccess criteria and measurable key performance indicators (KPIs)\nKnown risks documented with a mitigation plan\nPlan for meeting industry, governmental, contractual, and regulatory requirements that impact BI and analytics in the organization\nFunding plan\nPeople\nKey activities\n:\nEstablish a governance board and identify key stakeholders.\nDetermine focus, scope, and a set of responsibilities for the governance board.\nEstablish a COE.\nDetermine focus, scope, and a set of responsibilities for COE.\nDefine roles and responsibilities.\nConfirm who has decision-making, approval, and veto authority.\nKey output\n:\nCharter for the governance board\nCharter and priorities for the COE\nStaffing plan\nRoles and responsibilities\nAccountability and decision-making matrix\nCommunication plan\nIssue management plan\nPolicies and processes\nKey activities\n:\nAnalyze immediate pain points, issues, risks, and areas to improve the user experience.\nPrioritize data policies to be addressed by order of importance.\nIdentify existing processes in place that work well and can be formalized.\nDetermine how new data policies will be socialized.\nDecide to what extent data policies might differ or be customized for different groups.\nKey output\n:\nProcess for how data policies and documentation will be defined, approved, communicated, and maintained\nPlan for requesting valid exceptions and departures from documented policies\nProject management\nThe implementation of the governance program should be planned and managed as a series of projects.\nKey activities\n:\nEstablish a timeline with priorities and milestones.\nIdentify related initiatives and dependencies.\nIdentify and coordinate with existing bottom-up initiatives.\nCreate an iterative project plan that's aligned with high-level prioritization.\nObtain budget approval and funding.\nEstablish a tangible way to track progress.\nKey output\n:\nProject plan with iterations, dependencies, and sequencing\nCadence for retrospectives with a focus on continual improvements\nImportant\nThe scope of activities listed above that will be useful to take on will vary considerably between organizations. If your organization doesn't have existing processes and workflows for creating these types of outputs, refer to the guidance found in the\nadoption roadmap conclusion\nfor some helpful resources, as well as the\nimplementation planning BI strategy articles\n.\nGovernance policies\nDecision criteria\nAll governance decisions should be in alignment with the established goals for\norganizational adoption\n. Once the strategy is clear, more tactical governance decisions will need to be made which affect the day-to-day activities of the self-service user community. These types of tactical decisions correlate directly to the data policies that get created.\nHow we go about making governance decisions depends on:\nWho owns and manages the data and BI content?\nThe\nContent ownership and management\narticle introduced three types of strategies: business-led self-service, managed self-service, and enterprise. Who owns and manages the content has a significant impact on governance requirements.\nWhat is the scope for delivery of the data and BI content?\nThe\nContent delivery scope\narticle introduced four scopes for delivery of content: personal, team, departmental, and enterprise. The scope of delivery has a considerable impact on governance requirements.\nWhat is the data subject area?\nThe data itself, including its sensitivity level, is an important factor. Some data domains inherently require tighter controls. For instance, personally identifiable information (PII), or data subject to regulations, should be subject to stricter governance requirements than less sensitive data.\nIs the data, and/or the BI solution, considered critical?\nIf you can't make an informed decision easily without this data, you're dealing with critical data elements. Certain reports and apps could be deemed critical because they meet a set of predefined criteria. For instance, the content is delivered to executives. Predefined criteria for what's considered\ncritical\nhelps everyone have clear expectations. Critical data is usually subject to stricter governance requirements.\nTip\nDifferent combinations of the above four criteria will result in different governance requirements for Fabric content.\nKey Fabric governance decisions\nAs you explore your goals and objectives and pursue more tactical data governance decisions as described above, it will be important to determine what the highest priorities are. Deciding where to focus your efforts can be challenging.\nThe following list includes items that you might choose to prioritize when introducing governance for Fabric.\nRecommendations and requirements for\ncontent ownership and management\nRecommendations and requirements for\ncontent delivery scope\nRecommendations and requirements for content\ndistribution and sharing\nwith colleagues, as well as for\nexternal users\n, such as customers, partners, or vendors\nHow users are permitted to work with regulated data and highly sensitive data\nAllowed use of unverified data sources that are unknown to IT\nWhen manually maintained data sources, such as Excel or flat files, are permitted\nWho is permitted to\ncreate a workspace\nHow to manage\nworkspaces\neffectively\nHow\npersonal workspaces\nare effectively used\nWhich workspaces are assigned to\nFabric capacity\nWho is allowed to be a\nFabric administrator\nSecurity\n, privacy, and data protection requirements, and allowed actions for content assigned to each\nsensitivity label\nAllowed or encouraged use of\npersonal gateways\nAllowed or encouraged use of\nself-service purchasing\nof user licenses\nRequirements for who can\ncertify\ncontent, as well as requirements that must be met\nApplication lifecycle management for managing content through its entire lifecycle, including\ndevelopment, test, and production stages\nAdditional requirements applicable to critical content, such as data quality verifications and documentation\nRequirements to use standardized master data and common data definitions to improve consistency across data assets\nRecommendations and requirements for use of\nexternal tools\nby advanced content creators\nIf you don't make governance decisions and communicate them well, users will use their own judgment for how things should workâand that often results in inconsistent approaches to common tasks.\nAlthough not every governance decision needs to be made upfront, it's important that you identify the areas of greatest risk in your organization. Then, incrementally implement governance policies and processes that will deliver the most impact.\nData policies\nA data policy is a document that defines what users can and can't do. You might call it something different, but the goal remains the same: when decisionsâsuch as those discussed in the previous sectionâare made, they're documented for use and reference by the community of users.\nA data policy should be as short as possible. That way, it's easy for people to understand what is being asked of them.\nA data policy should include:\nPolicy name, purpose, description, and details\nSpecific responsibilities\nScope of the policy (organization-wide versus departmental-specific)\nAudience for the policy\nPolicy owner, approver, and contact\nHow to request an exception\nHow the policy will be audited and enforced\nRegulatory or legal requirements met by the policy\nReference to terminology definitions\nReference to any related guidelines or policies\nEffective date, last revision date, and change log\nNote\nLocate, or link to, data policies from your\ncentralized portal\n.\nHere are three common data policy examples you might choose to prioritize.\nPolicy\nDescription\nData ownership policy\nSpecifies when an owner is required for a data asset, and what the data owner's responsibilities include, such as: supporting colleagues who view the content, maintaining appropriate confidentiality and security, and ensuring compliance.\nData certification (endorsement) policy\nSpecifies the process that is followed to certify content. Requirements might include activities such as: data accuracy validation, data source and lineage review, technical review of the data model, security review, and documentation review.\nData classification and protection policy\nSpecifies activities that are allowed and not allowed per classification (sensitivity level). It should specify activities such as: allowed sharing with external users, with or without a non-disclosure agreement (NDA), encryption requirements, and ability to download the data. Sometimes, it's also called a\ndata handling policy\nor a\ndata usage policy\n. For more information, see the\nInformation protection for Power BI\narticle.\nCaution\nHaving a lot of documentation can lead to a false sense that everything is under control, which can lead to complacency. The level of engagement that the\nCOE\nhas with the user community is one way to improve the chances that governance guidelines and policies are consistently followed. Auditing and monitoring activities are also important.\nScope of policies\nGovernance decisions will rarely be one-size-fits-all across the entire organization. When practical, it's wise to start with standardized policies, and then implement exceptions as needed. Having a clearly defined strategy for how policies will be handled for centralized and decentralized teams will make it much easier to determine how to handle exceptions.\nPros of organization-wide policies\n:\nMuch easier to manage and maintain\nGreater consistency\nEncompasses more use cases\nFewer policies overall\nCons of organization-wide policies\n:\nInflexible\nLess autonomy and empowerment\nPros of departmental-scope policies\n:\nExpectations are clearer when tailored to a specific group\nCustomizable and flexible\nCons of departmental-scope policies\n:\nMore work to manage\nMore policies that are siloed\nPotential for conflicting information\nDifficult to scale more broadly throughout the organization\nTip\nFinding the right balance of standardization and customization for supporting self-service data and BI across the organization can be challenging. However, by starting with organizational policies and mindfully watching for exceptions, you can make meaningful progress quickly.\nStaffing and accountability\nThe organizational structure for data governance varies substantially between organizations. In larger organizations there might be a data governance office with dedicated staff. Some organizations have a data governance board, council, or steering committee with assigned members coming from different business units. Depending on the extent of the data governance body within the organization, there could be an executive team separate from a functional team of people.\nImportant\nRegardless of how the governance body is structured, it's important that there's a person or group with sufficient influence over data governance decisions. This person should have authority to enforce those decisions across organizational boundaries.\nChecks and balances\nGovernance accountability is about checks and balances.\nStarting with the first level, the levels of checks and balances in the above diagram include:\nLevel\nDescription\nOperational - Business units\n: Level 1 is the foundation of a well-governed system, which includes users within the business units performing their work. Self-service data and BI creators have a lot of responsibilities related to authoring, publishing, sharing, security, and data quality. Self-service data and BI consumers also have responsibilities for the proper use of data.\nTactical - Supporting teams\n: Level 2 includes several groups that support the efforts of the users in the business units. Supporting teams include the COE, enterprise data and BI, the data governance office, as well as other ancillary teams. Ancillary teams can include IT, security, HR, and legal. A change control board is included here as well.\nTactical - Audit and compliance\n: Level 3 includes internal audit, risk management, and compliance teams. These teams provide guidance to levels 1 and 2. They also provide enforcement when necessary.\nStrategic - Executive sponsor and steering committee\n: The highest level includes the executive-level oversight of strategy and priorities. This level handles any escalated issues that couldn't be solved at lower levels. Therefore, it's important to have a leadership team with sufficient authority to be able to make decisions when necessary.\nImportant\nEveryone has a responsibility to adhere to policies for ensuring that organizational data is secure, protected, and well-managed as an organizational asset. Sometimes this is cited as\neveryone is a data steward\n. To make this a reality, start with the users in the business units (level 1 described above) as the foundation.\nRoles and responsibilities\nOnce you have a sense for your governance strategy, roles and responsibilities should be defined to establish clear expectations.\nGovernance team structure, roles (including terminology), and responsibilities vary widely among organizations. Very generalized roles are described in the table below. In some cases, the same person could serve multiple roles. For instance, the Chief Data Officer (CDO) could also be the executive sponsor.\nRole\nDescription\nChief Data Officer or Chief Analytics Officer\nDefines the strategy for use of data as an enterprise asset. Oversees enterprise-wide governance guidelines and policies.\nData governance board\nSteering committee with members from each business unit who, as domain owners, are empowered to make enterprise governance decisions. They make decisions on behalf of the business unit\nand\nin the best interest of the organization. Provides approvals, decisions, priorities, and direction to the enterprise data governance team and working committees.\nData governance team\nCreates governance policies, standards, and processes. Provides enterprise-wide oversight and optimization of data integrity, trustworthiness, privacy, and usability. Collaborates with the COE to provide governance education, support, and mentoring to data owners and content creators.\nData governance working committees\nTemporary or permanent teams that focus on individual governance topics, such as security or data quality.\nChange management board\nCoordinates the requirements, processes, approvals, and scheduling for release management processes with the objective of reducing risk and minimizing the impact of changes to critical applications.\nProject management office\nManages individual governance projects and the ongoing data governance program.\nFabric executive sponsor\nPromotes adoption and the successful use of Fabric. Actively ensures that Fabric decisions are consistently aligned with business objectives, guiding principles, and policies across organizational boundaries. For more information, see the\nExecutive sponsorship\narticle.\nCenter of Excellence\nMentors the community of creators and consumers to promote the effective use of Fabric for decision-making. Provides cross-departmental coordination of Fabric activities to improve practices, increase consistency, and reduce inefficiencies. For more information, see the\nCenter of Excellence\narticle.\nFabric champions\nA subset of content creators found within the business units who help advance the adoption of Fabric. They contribute to data culture growth by advocating the use of best practices and actively assisting colleagues. For more information, see the\nCommunity of practice\narticle.\nFabric administrators\nDay-to-day-system oversight responsibilities to support the internal processes, tools, and people. Handles monitoring, auditing, and management. For more information, see the\nSystem oversight\narticle.\nInformation technology\nProvides occasional assistance to Fabric administrators for services related to Fabric, such as Microsoft Entra ID, Microsoft 365, Teams, SharePoint, or OneDrive.\nRisk management\nReviews and assesses data sharing and security risks. Defines ethical data policies and standards. Communicates regulatory and legal requirements.\nInternal audit\nAuditing of compliance with regulatory and internal requirements.\nData steward\nCollaborates with governance committee and/or COE to ensure that organizational data has acceptable data quality levels.\nAll BI creators and consumers\nAdheres to policies for ensuring that data is secure, protected, and well-managed as an organizational asset.\nTip\nName a backup for each person in key roles, for example, members of the data governance board. In their absence, the backup person can attend meetings and make time-sensitive decisions when necessary.\nConsiderations and key actions\nChecklist\n- Considerations and key actions you can take to establish or strengthen your governance initiatives.\nAlign goals and guiding principles\n: Confirm that the high-level goals and guiding principles of the data culture goals are clearly documented and communicated. Ensure that alignment exists for any new governance guidelines or policies.\nUnderstand what's currently happening\n: Ensure that you have a deep understanding of how Fabric is currently used for self-service and enterprise data and BI scenarios. Document opportunities for improvement. Also, document strengths and good practices that would be helpful to scale out more broadly.\nPrioritize new governance guidelines and policies\n: For prioritizing which new guidelines or policies to create, select an important pain point, high priority need, or known risk for a data domain. It should have significant benefit and can be achieved with a feasible level of effort. When you implement your first governance guidelines, choose something users are likely to support because the change is low impact, or because they are sufficiently motivated to make a change.\nCreate a schedule to review policies\n: Determine the cadence for how often data policies are reevaluated. Reassess and adjust when needs change.\nDecide how to handle exceptions\n: Determine how conflicts, issues, and requests for exceptions to documented policies will be handled.\nUnderstand existing data assets\n: Confirm that you understand what critical data assets exist. Create an inventory of ownership and lineage, if necessary. Keep in mind that you can't govern what you don't know about.\nVerify executive sponsorship\n: Confirm that you have support and sufficient attention from your\nexecutive sponsor\n, as well as from business unit leaders.\nPrepare an action plan\n: Include the following key items:\nInitial priorities\n: Select one data domain or business unit at a time.\nTimeline\n: Work in iterations long enough to accomplish meaningful progress, yet short enough to periodically adjust.\nQuick wins\n: Focus on tangible, tactical, and incremental progress.\nSuccess metrics\n: Create measurable metrics to evaluate progress.\nQuestions to ask\nUse questions like those found below to assess governance.\nAt a high level, what's the current governance strategy? To what extent is the purpose and importance of this governance strategy clear to both end users and the central data and BI teams?\nIn general, is the current governance strategy effective?\nWhat are the key regulatory and compliance criteria that the organization (or specific business units) must adhere to? Where's this criteria documented? Is this information readily available to people who work with data and share data items as a part of their role?\nHow well does the current governance strategy align to the user's way of working?\nIs a specific role or team responsible for governance in the organization?\nWho has the authority to create and change governance policies?\nDo governance teams use\nMicrosoft Purview\nor another tool to support governance activities?\nWhat are the prioritized governance risks, such as risks to\nsecurity\n,\ninformation protection\n, and\ndata loss prevention\n?\nWhat's the potential business impact of the identified governance risks?\nHow frequently is the governance strategy re-evaluated? What metrics are used to evaluate it, and what mechanisms exist for business users to provide feedback?\nWhat types of user behaviors create risk when users work with data? How are those risks mitigated?\nWhat sensitivity labels are in place, if any? Are data and BI decision makers aware of sensitivity labels and the benefits to the business?\nWhat data loss prevention policies are in place, if any?\nHow is \"Export to Excel\" handled? What steps are taken to prevent data loss prevention? What's the prevalence of \"Export to Excel\"? What do people do with data once they have it in Excel?\nAre there practices or solutions that are out of regulatory compliance that must be urgently addressed? Are these examples justified with an explanation of the potential business impact, should they not be addressed?\nTip\n\"Export to Excel\" is typically a controversial topic. Often, business users focus on the requirement to have \"Export to Excel\" possible in BI solutions. Enabling \"Export to Excel\" can be counter-productive because a business objective isn't to get data into Excel. Instead, define why end users need the data in Excel. Ask what they do with the data once it's in Excel, which business questions they try to answer, what decisions they make, and what actions they take with the data.\nFocusing on business decisions and actions helps steer focus away from tools and features and toward helping people achieve their business objectives.\nMaturity levels\nThe following maturity levels will help you assess the current state of your governance initiatives.\nLevel\nState of governance\n100: Initial\nâ¢ Due to a lack of governance planning, the good data management and informal governance practices that are occurring are overly reliant on judgment and experience level of individuals.\nâ¢ There's a significant reliance on undocumented tribal knowledge.\n200: Repeatable\nâ¢ Some areas of the organization have made a purposeful effort to standardize, improve, and document their data management and governance practices.\nâ¢ An initial governance approach exists. Incremental progress is being made.\n300: Defined\nâ¢ A complete governance strategy with focus, objectives, and priorities is enacted and broadly communicated.\nâ¢ Specific governance guidelines and policies are implemented for the top few priorities (pain points or opportunities). They're actively and consistently followed by users.\nâ¢ Roles and responsibilities are clearly defined and documented.\n400: Capable\nâ¢ All Fabric governance priorities align with organizational goals and business objectives. Goals are reassessed regularly.\nâ¢ Processes exist to customize policies for decentralized business units, or to handle valid exceptions to standard governance policies.\nâ¢ It's clear where Fabric fits into the overall data and BI strategy for the organization.\nâ¢ Fabric activity log and API data is actively analyzed to monitor and audit Fabric activities. Proactive action is taken based on the data.\n500: Efficient\nâ¢ Regular reviews of KPIs or OKRs evaluate measurable governance goals. Iterative, continual progress is a priority.\nâ¢ Agility and implementing continual improvements from lessons learned (including scaling out methods that work) are top priorities for the COE.\nâ¢ Fabric activity log and API data is actively used to inform and improve adoption and governance efforts.\nRelated content\nIn the\nnext article\nin the Microsoft Fabric adoption roadmap series, learn about mentoring and user enablement.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Governance Adoption",
      "section": "Power BI"
    },
    "https://learn.microsoft.com/en-us/viva/learning/overview-viva-learning": {
      "content_hash": "sha256:f526714a1cfa6b781860d9f07d4d27043c5341f6c825ed87fe40eb239bfac34d",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOverview of Microsoft Viva Learning\nFeedback\nSummarize this article for me\nViva Learning is a centralized learning hub in Microsoft Teams that lets you seamlessly integrate learning and building skills into your day. In Viva Learning, your team can discover, share, recommend, and learn from content libraries provided by both your organization and partners without leaving Microsoft Teams.\nViva Learning makes it easy to create learning and growing opportunities for your organization without the need to step away from the communication tools you already use.\nLearn while working\nEveryone\nViva Learning makes it easy to incorporate learning into your day. When you open Viva Learning in Microsoft Teams, you see a personalized view of learning content from both your organization and partners such as LinkedIn Learning. As you continue to search for and complete more training, your recommended content updates to reflect your interests.\nEasily find learning opportunities provided by your organization.\nBrowse courses from Microsoft and third-party content providers.\nSearch for specific learning content that appeals to you or supports your career goals.\nShare relevant, interesting, and important learning content with your team members or groups in a Microsoft Teams chat or channel.\nOrganize your custom selections of learning content in Microsoft Teams channels and tabs.\nBookmark courses you're interested in.\nPlay LinkedIn Learning courses in the embedded player without leaving Microsoft Teams.\nManagers\nKeep your team engaged and up to date with necessary skills without the need to coordinate learning across platforms. You can recommend learning content to individuals, share content with your team, and track the reported completion status of learning that you've recommended.\nAdmin roles\nViva Learning is available in Microsoft Teams by default, with some content already available. To set up learning content sources in Viva Learning and manage individual licensing, you need these permissions:\nMicrosoft Teams admin\nSharePoint admin\nKnowledge admin\nKnowledge admin\nThe knowledge admin is a new Microsoft Entra role in the Microsoft 365 admin center that can be assigned to anyone in the organization. This role manages the organization's learning content sources. For more information, see\nMicrosoft Entra built-in roles\n.\nThe knowledge admin is a moderately technical role which has existing SharePoint administrator credentials. Knowledge admins are well versed in the education, learning, training, or employee experience part of the organization.\nLearning content sources\nContent from Microsoft Learn and Microsoft 365 Training is automatically available in Viva Learning. You also have free access to global skilling initiative (GSI) courses from LinkedIn Learning.\nViva Learning can integrate with select third-party content providers and learning management systems. For more information about how to set up content sources, see\nManage content sources for Viva Learning\n.\nData and privacy\nViva Learning data residency is tenant-specific and follows the standard Microsoft 365 data storage guidelines by available geography. For more information, see\nWhere is my Microsoft 365 customer data stored\n.\nIntegration with SharePoint is currently only supported for sites hosted from the home geography of the tenant. For example, a French tenant can only link SharePoint sites hosted in France to Viva Learning.\nData stored from Viva Learning includes:\nLearning object content metadata, such as title, description, author, and language\nUser data, such as bookmarks, recently viewed, recommended courses, assigned courses, and completion records\nRequired service data, such as error logs\nDiagnostic data usage\nNote\nAs an admin, you can turn storage of diagnostic data on or off.\nFor more information, read about\ncompliance\n,\nprivacy\nand\nsecurity\nin Viva.\nGet started\nWhen you're ready to set up and configure Viva Learning in your Microsoft 365 environment:\nUse the Microsoft Teams admin center to\nmanage Viva Learning across your organization\n.\nUse the Microsoft 365 admin center to\nconfigure learning sources available to specific groups\n.\nUse the SharePoint admin center to\nmanage and store your own learning content\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Viva Learning Overview",
      "section": "Microsoft Viva"
    },
    "https://learn.microsoft.com/security/operations/incident-response-planning": {
      "content_hash": "sha256:1372b69ecce1f57f17d0f11d3faa6e7445a84574380ee0108ecba180549fd43b",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nIncident response planning\nFeedback\nSummarize this article for me\nUse this table as a checklist to prepare your Security Operations Center (SOC) to respond to cybersecurity incidents.\nDone\nActivity\nDescription\nBenefit\nTable top exercises\nConduct periodic table top exercises of foreseeable business-impacting cyber incidents that force your organization's management to contemplate difficult risk-based decisions.\nFirmly establishes and illustrates cybersecurity as a business issue. Develops muscle memory and surfaces difficult decisions and decisions rights issues across the organization.\nDetermine pre-attack decisions and decision-makers\nAs a complement to table top exercises, determine risk-based decisions, criteria for making decisions, and who must make and execute those decisions. For example:\nWho/when/if to seek assistance from law enforcement?\nWho/when/if to enlist incident responders?\nWho/when/if to pay ransom?\nWho/when/if to notify external auditors?\nWho/when/if to notify privacy regulatory authorities?\nWho/when/if to notify securities regulators?\nWho/when/if to notify board of directors or audit committee?\nWho has authority to shut down mission-critical workloads?\nDefines the initial response parameters and contacts to involve that streamline the response to an incident.\nMaintaining privilege\nTypically, advice can be privileged, but facts are discoverable. Train key incident leaders in communicating advice, facts and opinions under privilege so that privilege is preserved and risk is reduced.\nMaintaining privilege can be a messy process when considering the multitude of communications channels, including e-mail, collaboration platforms, chats, documents, artifacts. For example, you can use\nMicrosoft Teams Rooms\n. A consistent approach across incident personnel and supporting external organizations can help reduce any potential legal exposure.\nInsider trading considerations\nContemplate notifications to management that should be taken to reduce securities violations risk.\nBoards and external auditors tend to appreciate that you have mitigations that will reduce the risk of questionable securities trades during periods of turbulence.\nIncident roles and responsibilities playbook\nEstablish basic roles and responsibilities that allow various processes to maintain focus and forward progress.\nWhen your response team is remote, it can require other considerations for time zones and proper handoff to investigators.\nYou might have to communicate across other teams that might be involved, such as vendor teams.\nTechnical Incident Leader\nâ Always in the incident, synthesizing inputs and findings and planning next actions.\nCommunications Liaison\nâ Removes the burden of communicating to management from the Technical Incident Leader so they can remain involved in the incident without loss of focus.\nThis activity should include managing executive messaging and interactions with other third parties such as regulators.\nIncident Recorder\nâ Removes the burden of recording findings, decisions, and actions from an incident responder and produces an accurate accounting of the incident from beginning to end.\nForward Planner\nâ Working with mission-critical business process owners, formulates business continuity activities and preparations that contemplate information system impairment that lasts for 24, 48, 72, 96 hours, or more.\nPublic Relations\nâ In the event of an incident that is likely to garner public attention, with Forward Planner, contemplates and drafts public communication approaches that address likely outcomes.\nPrivacy incident response playbook\nTo satisfy increasingly strict privacy regulations, develop a jointly owned playbook between SecOps and the privacy office. This playbook will allow rapid evaluation of potential privacy issues that might arising out of security incidents.\nIt's difficult to evaluate security incidents for their potential to impact privacy because most security incidents arise in a highly technical SOC. The incidents must quickly get surfaced to a privacy office (often with a 72-hour notification expectation) where regulatory risk is determined.\nPenetration testing\nConduct point-in-time simulated attacks against business-critical systems, critical infrastructure, and backups to identify weaknesses in security posture. Typically, this activity is conducted by a team of external experts focused on bypassing preventative controls and surfacing key vulnerabilities.\nIn light of recent human-operated ransomware incidents, penetration testing should be conducted against an increased scope of infrastructure, particularly the ability to attack and control backups of mission-critical systems and data.\nRed Team / Blue Team / Purple Team / Green Team\nConduct continuous or periodic simulated attacks against business-critical systems, critical infrastructure, backups to identify weaknesses in security posture. Typically, this activity is conducted by internal attack teams (Red teams) who are focused on testing the effectiveness of detective controls and teams (Blue teams).\nFor example, you can use\nAttack simulation training\nin Microsoft Defender XDR for Office 365 and\nAttack tutorials & simulations\nfor Microsoft Defender XDR for Endpoint.\nRed, Blue, and Purple team attack simulations, when done well, serve a multitude of purposes:\nAllows engineers from across the IT organization to simulate attacks on their own infrastructure disciplines.\nSurfaces gaps in visibility and detection.\nRaises the security engineering skills across the board.\nServes as a more continuous and expansive process.\nThe Green Team implements changes in IT or security configuration.\nBusiness continuity planning\nFor mission-critical business processes, design and test continuity processes that allow the minimum viable business to function during times of information systems impairment.\nFor example, use\nan Azure backup and restore plan\nto protect your critical business systems during an attack to ensure a rapid recovery of your business operations.\nHighlights the fact that there's no continuity workaround for the impairment or absence of IT systems.\nCan emphasize the need and funding for sophisticated digital resilience over simpler backup and recovery.\nDisaster recovery\nFor information systems that support mission-critical business processes, you should design and test hot/cold and hot/warm backup and recovery scenarios, including staging times.\nOrganizations that conduct bare metal builds often find activities that are impossible to replicate or don't fit into the service level objectives.\nMission-critical systems running on unsupported hardware many times can't be restored to modern hardware.\nRestore of backups is often not tested and experiences issues. Backups may be further offline such that staging times haven't been factored into recovery objectives.\nOut-of-band communications\nPrepare for how you would communicate in the the following scenarios:\nEmail and collaboration service impairment\nRansom of documentation repositories\nUnavailability of personnel phone numbers.\nAlthough it's a difficult exercise, determine how to store important information immutably in off-line devices and locations for distribution at scale. For example:\nPhone numbers\nTopologies\nBuild documents\nIT restoration procedures\nHardening, hygiene, and lifecycle management\nIn line with Center for Internet Security (CIS) Top 20 security controls, harden your infrastructure and perform thorough hygiene activities.\nIn response to recent human-operated ransomware incidents, Microsoft has\nissued specific guidance\nfor protecting every stage of the cyberattack kill chain. This guidance applies to Microsoft capabilities or the capabilities of other providers. Of particular note are:\nThe creation and maintenance of immutable backup copies in the event of ransomed systems. You might also consider how to keep immutable log files that complicate the attacker's ability to cover their tracks.\nRisks related to unsupported hardware for disaster recovery.\nIncident response planning\nAt the outset of the incident, decide on:\nImportant organizational parameters.\nAssignment of people to roles and responsibilities.\nThe sense-of-urgency (such as 24x7 and business hours).\nStaff for sustainability for the duration.\nThere's a tendency to throw all available resources at an incident in the beginning, in the hope of a quick resolution. Once you recognize or anticipate that an incident will go for an extended period of time, take on a different posture that with your staff and suppliers that allows them to settle in for a longer haul.\nIncident responders\nEstablish clear expectations with one another. A popular format of reporting ongoing activities includes:\nWhat have we done (and what were the results)?\nWhat are we doing (and what results will be produced and when)?\nWhat do we plan to do next (and when is it realistic to expect results)?\nIncident responders come with different techniques and approaches, including dead box analysis, big data analysis, and the ability to produce incremental results. Starting with clear expectations will facilitate clear communications.\nIncident response resources\nOverview\nfor Microsoft security products and resources for new-to-role and experienced analysts\nPlaybooks\nfor detailed guidance on responding to common attack methods\nMicrosoft Defender XDR\nincident response\nMicrosoft Defender for Cloud (Azure)\nMicrosoft Sentinel\nincident response\nMicrosoft Incident Response team guide shares best practices for security teams and leaders\nMicrosoft Incident Response guides help security teams analyze suspicious activity\nKey Microsoft security resources\nResource\nDescription\n2021 Microsoft Digital Defense Report\nA report that encompasses learnings from security experts, practitioners, and defenders at Microsoft to empower people everywhere to defend against cyberthreats.\nMicrosoft Cybersecurity Reference Architectures\nA set of visual architecture diagrams that show Microsoft's cybersecurity capabilities and their integration with Microsoft cloud platforms such as Microsoft 365 and Microsoft Azure and third-party cloud platforms and apps.\nMinutes matter infographic\ndownload\nAn overview of how Microsoft's SecOps team does incident response to mitigate ongoing attacks.\nAzure Cloud Adoption Framework security operations\nStrategic guidance for leaders establishing or modernizing a security operation function.\nMicrosoft security best practices for security operations\nHow to best use your SecOps center to move faster than the attackers targeting your organization.\nMicrosoft cloud security for IT architects model\nSecurity across Microsoft cloud services and platforms for identity and device access, threat protection, and information protection.\nMicrosoft security documentation\nAdditional security guidance from Microsoft.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Incident Response Planning",
      "section": "Security Operations"
    },
    "https://learn.microsoft.com/en-us/security/ai-red-team/": {
      "content_hash": "sha256:2314726d55d41afe6371bb7e36b5574cb26c74b7e6b956f2dfbf2fb900a4b2fe",
      "normalized_content": "Table of contents\nRead in English\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nMicrosoft AI Red Team\nLearn to safeguard your organization's AI with guidance and best practices from the industry leading Microsoft AI Red Team.\nAbout AI Red Team\nOverview\nWhat is AI Red teaming and how Microsoft is building safer AI?\nHow-To Guide\nGuide for building AI Red Teams for LLMs\nReference\nResponsible AI tools and practices\nResponsible AI standard and impact assessment\nGetting ready\nOverview\nMicrosoft's Open Automation Framework to Red Team Generative AI Systems (PyRIT)\nHow-To Guide\nPyRIT How to Guide\nReference\nAI Risk Assessment for ML Engineers\nAI shared responsibility model\nUnderstanding Threats\nHow-To Guide\nDeveloper threat modeling guidance for ML systems\nConcept\nTaxonomy for machine learning failure\nReference\nBug Bar to triage attacks on ML systems\nExploring secure solutions\nConcept\nMethodology for safety aligning the Phi-3 series of language models\nReference\nEnterprise security and governance for Azure Machine Learning\nWhat is Azure AI Content Safety?\nHarms mitigation strategies with Azure AI\nMonitor quality and safety of deployed prompt flow applications\nLessons learned\nTraining\nAI Security Training\nOverview\nLessons from red teaming 100 generative AI products",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "AI Red Team",
      "section": "Security Operations"
    },
    "https://learn.microsoft.com/en-us/powershell/module/exchange/new-dlpcompliancepolicy": {
      "content_hash": "sha256:33a932926ffc99b88d0f1dfa121b6334802824d28e0b32aa551a0daee31c201c",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nSummarize this article for me\nNew-Dlp\nCompliance\nPolicy\nThis cmdlet is available only in Security & Compliance PowerShell. For more information, see\nSecurity & Compliance PowerShell\n.\nUse the New-DlpCompliancePolicy cmdlet to create data loss prevention (DLP) policies in the Microsoft Purview compliance portal. DLP policies contain DLP rules that identify, monitor, and protect sensitive information.\nFor information about the parameter sets in the Syntax section below, see\nExchange cmdlet syntax\n.\nSyntax\nDefault (Default)\nNew-DlpCompliancePolicy\n [-Name] <String>\n [-Comment <String>]\n [-Confirm]\n [-DisplayName <String>]\n [-EndpointDlpAdaptiveScopes <MultiValuedProperty>]\n [-EndpointDlpAdaptiveScopesException <MultiValuedProperty>]\n [-EndpointDlpLocation <MultiValuedProperty>]\n [-EndpointDlpLocationException <MultiValuedProperty>]\n [-EnforcementPlanes <MultiValuedProperty>]\n [-ExceptIfOneDriveSharedBy <RecipientIdParameter[]>]\n [-ExceptIfOneDriveSharedByMemberOf <RecipientIdParameter[]>]\n [-ExchangeAdaptiveScopes <MultiValuedProperty>]\n [-ExchangeAdaptiveScopesException <MultiValuedProperty>]\n [-ExchangeLocation <MultiValuedProperty>]\n [-ExchangeSenderMemberOf <RecipientIdParameter[]>]\n [-ExchangeSenderMemberOfException <RecipientIdParameter[]>]\n [-Force]\n [-IsFromSmartInsights <System.Boolean>]\n [-Locations <String>]\n [-Mode <PolicyMode>]\n [-OneDriveAdaptiveScopes <MultiValuedProperty>]\n [-OneDriveAdaptiveScopesException <MultiValuedProperty>]\n [-OneDriveLocation <MultiValuedProperty>]\n [-OneDriveLocationException <MultiValuedProperty>]\n [-OneDriveSharedBy <RecipientIdParameter[]>]\n [-OneDriveSharedByMemberOf <RecipientIdParameter[]>]\n [-OnPremisesScannerDlpLocation <MultiValuedProperty>]\n [-OnPremisesScannerDlpLocationException <MultiValuedProperty>]\n [-PolicyRBACScopes <MultiValuedProperty>]\n [-PolicyTemplateInfo <PswsHashtable>]\n [-PowerBIDlpLocation <MultiValuedProperty>]\n [-PowerBIDlpLocationException <MultiValuedProperty>]\n [-Priority <Int32>]\n [-SharePointAdaptiveScopes <MultiValuedProperty>]\n [-SharePointAdaptiveScopesException <MultiValuedProperty>]\n [-SharePointLocation <MultiValuedProperty>]\n [-SharePointLocationException <MultiValuedProperty>]\n [-TeamsAdaptiveScopes <MultiValuedProperty>]\n [-TeamsAdaptiveScopesException <MultiValuedProperty>]\n [-TeamsLocation <MultiValuedProperty>]\n [-TeamsLocationException <MultiValuedProperty>]\n [-ThirdPartyAppDlpLocation <MultiValuedProperty>]\n [-ThirdPartyAppDlpLocationException <MultiValuedProperty>]\n [-ValidatePolicy]\n [-WhatIf]\n [<CommonParameters>]\nDescription\nTo use this cmdlet in Security & Compliance PowerShell, you need to be assigned permissions. For more information, see\nPermissions in the Microsoft Purview compliance portal\n.\nExamples\nExample 1\nNew-DlpCompliancePolicy -Name \"GlobalPolicy\" -SharePointLocation All\nThis example creates a DLP policy named GlobalPolicy that's enforced across all SharePoint locations.\nExample 2\nNew-DlpCompliancePolicy -Name \"GlobalPolicy\" -Comment \"Primary policy\" -SharePointLocation \"https://my.url\",\"https://my.url2\" -OneDriveLocation \"https://my.url3\",\"https://my.url4\" -Mode Enable\nThis example creates a DLP policy named GlobalPolicy for the specified SharePoint and OneDrive locations. The new policy has a descriptive comment and is enabled on creation.\nExample 3\nNew-DlpCompliancePolicy -Name \"PowerBIPolicy\" -Comment \"Primary policy\" -PowerBIDlpLocation \"All\" -PowerBIDlpLocationException \"workspaceID1\",\"workspaceID2\",\"workspaceID3\" -Mode Enable\nThis example creates a DLP policy named PowerBIPolicy for all qualifying Power BI workspaces (that is, those hosted on Premium Gen2 capacities) except for the specified workspaces. The new policy has a descriptive comment and is enabled on creation.\nExample 4\nGet-Label | Format-List Priority,ContentType,Name,DisplayName,Identity,Guid\n\n$guidVar = \"e222b65a-b3a8-46ec-ae12-00c2c91b71c0\"\n\n$loc = \"[{\"Workload\":\"Applications\",\"Location\":\"470f2276-e011-4e9d-a6ec-20768be3a4b0\",\"Inclusions\":[{Type:\"Tenant\", Identity:\"All\"}]}]\"\n\nNew-DLPCompliancePolicy -Name \"Copilot Policy\" -Locations $loc -EnforcementPlanes @(\"CopilotExperiences\")\n\n$advRule = @{\n \"Version\" = \"1.0\"\n \"Condition\" = @{\n \"Operator\" = \"And\"\n \"SubConditions\" = @(\n @{\n \"ConditionName\" = \"ContentContainsSensitiveInformation\"\n \"Value\" = @(\n @{\n \"groups\" = @(\n @{\n \"Operator\" = \"Or\"\n \"labels\" = @(\n @{\n \"name\" = $guidVar\n \"type\" = \"Sensitivity\"\n }\n )\n \"name\" = \"Default\"\n }\n )\n }\n )\n }\n )\n }\n} | ConvertTo-Json -Depth 100\n\nNew-DLPComplianceRule -Name \"Copilot Rule\" -Policy \"Copilot Policy\" -AdvancedRule $advrule -RestrictAccess @(@{setting=\"ExcludeContentProcessing\";value=\"Block\"})\nThis example creates a DLP policy for Microsoft 365 Copilot in several steps:\nThe first command returns information about all sensitivity labels. Select the GUID value of the sensitivity label that you want to use. For example,\ne222b65a-b3a8-46ec-ae12-00c2c91b71c0\n.\nThe second command stores the GUID value of the sensitivity label in the variable named\n$guidVar\n.\nThe third command stores the Microsoft 365 Copilot location (\n470f2276-e011-4e9d-a6ec-20768be3a4b0\n) in the variable named\n$loc\n. Update the\n$loc\nvalue based on the Inclusions/Exclusions scoping that you want to provide.\nThe fourth command creates the DLP policy using the\n$loc\nvariable for the value of the Locations parameter, and \"Copilot Policy\" as the name of the policy (use any unique name).\nThe fifth command creates the variable named\n$advRule\n. The advanced rule needs to be updated depending on the grouping of labels you want to provide as input.\nThe last command creates the DLP rule with the name \"Copilot Rule\" (use any unique name). Use the name of the DLP policy from step four as the value of the Policy parameter.\nParameters\n-Comment\nApplicable: Security & Compliance\nThe Comment parameter specifies an optional comment. If you specify a value that contains spaces, enclose the value in quotation marks (\"), for example: \"This is an admin note\".\nParameter properties\nType:\nString\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Confirm\nApplicable: Security & Compliance\nThe Confirm switch specifies whether to show or hide the confirmation prompt. How this switch affects the cmdlet depends on if the cmdlet requires confirmation before proceeding.\nDestructive cmdlets (for example, Remove-* cmdlets) have a built-in pause that forces you to acknowledge the command before proceeding. For these cmdlets, you can skip the confirmation prompt by using this exact syntax:\n-Confirm:$false\n.\nMost other cmdlets (for example, New-* and Set-* cmdlets) don't have a built-in pause. For these cmdlets, specifying the Confirm switch without a value introduces a pause that forces you acknowledge the command before proceeding.\nParameter properties\nType:\nSwitchParameter\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nAliases:\ncf\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Display\nName\nApplicable: Security & Compliance\n{{ Fill DisplayName Description }}\nParameter properties\nType:\nString\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Endpoint\nDlp\nAdaptive\nScopes\nApplicable: Security & Compliance\n{{ Fill EndpointDlpAdaptiveScopes Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Endpoint\nDlp\nAdaptive\nScopes\nException\nApplicable: Security & Compliance\n{{ Fill EndpointDlpAdaptiveScopesException Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Endpoint\nDlp\nLocation\nApplicable: Security & Compliance\nNote\n: This parameter requires membership in the Compliance Administrator or Compliance Data Administrator roles in Microsoft Entra ID.\nThe EndpointDLPLocation parameter specifies the user accounts to include in the DLP policy for Endpoint DLP when they are logged on to an onboarded device. You identify the account by name or email address. You can use the value All to include all user accounts.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about Endpoint DLP, see\nLearn about Endpoint data loss prevention\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Endpoint\nDlp\nLocation\nException\nApplicable: Security & Compliance\nNote\n: This parameter requires membership in the Compliance Administrator or Compliance Data Administrator roles in Microsoft Entra ID.\nThe EndpointDlpLocationException parameter specifies the user accounts to exclude from Endpoint DLP when you use the value All for the EndpointDlpLocation parameter. You identify the account by name or email address.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about Endpoint DLP, see\nLearn about Endpoint data loss prevention\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Enforcement\nPlanes\nApplicable: Security & Compliance\nThe EnforcementPlanes parameter defines the layer where policy actions are run. This parameter uses the following syntax:\n-EnforcementPlanes @(\"<Value>\")\n.\nValid values are:\nBrowser: For use with policies applied to unmanaged cloud apps in Edge for Business.\nCopilotExperiences\nEntra: For use with policies applied to Entra-registered enterprise applications in the organization.\nNetwork\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Except\nIfOne\nDrive\nShared\nBy\nApplicable: Security & Compliance\nThe ExceptIfOneDriveSharedBy parameter specifies the users to exclude from the DLP policy (the sites of the OneDrive user accounts are included in the policy). You identify the users by UPN (\nlaura@contoso.onmicrosoft.com\n).\nTo use this parameter, OneDrive sites need to be included in the policy (the OneDriveLocation parameter value is All, which is the default value).\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou can't use this parameter with the OneDriveSharedBy or OneDriveSharedByMemberOf parameters.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Except\nIfOne\nDrive\nShared\nByMember\nOf\nApplicable: Security & Compliance\nThe ExceptIfOneDriveSharedByMemberOf parameter specifies the distribution groups or mail-enabled security groups to exclude from the DLP policy (the OneDrive sites of group members are excluded from the policy). You identify the groups by email address.\nTo use this parameter, OneDrive sites need to be included in the policy (the OneDriveLocation parameter value is All, which is the default value).\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou can't use this parameter with the OneDriveSharedBy or OneDriveSharedByMemberOf parameters.\nYou can't use this parameter to specify Microsoft 365 Groups.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Exchange\nAdaptive\nScopes\nApplicable: Security & Compliance\n{{ Fill ExchangeAdaptiveScopes Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Exchange\nAdaptive\nScopes\nException\nApplicable: Security & Compliance\n{{ Fill ExchangeAdaptiveScopesException Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Exchange\nLocation\nApplicable: Security & Compliance\nThe ExchangeLocation parameter specifies whether to include email messages in the DLP policy. The valid value for this parameter is All. If you don't want to include email messages in the policy, don't use this parameter (the default value is blank or $null).\nYou can use this parameter in the following procedures:\nIf you use\n-ExchangeLocation All\nby itself, the policy applies to email for all users.\nTo include email of specific group members in the policy, use\n-ExchangeLocation All\nwith the ExchangeSenderMemberOf parameter in the same command. Only email of members of the specified groups is included in the policy.\nTo exclude email of specific group members from the policy, use\n-ExchangeLocation All\nwith the ExchangeSenderMemberOfException parameter in the same command. Only email of members of the specified groups is excluded from the policy.\nYou can't specify inclusions and exclusions in the same policy.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Exchange\nSender\nMember\nOf\nApplicable: Security & Compliance\nThe ExchangeSenderMemberOf parameter specifies the distribution groups or security groups to include in the policy (email of the group members is included in the policy). You identify the groups by email address.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou must use this parameter with the ExchangeLocation parameter.\nYou can't use this parameter with the ExchangeSenderMemberOfException parameter.\nYou can't use this parameter to specify Microsoft 365 Groups.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Exchange\nSender\nMember\nOfException\nApplicable: Security & Compliance\nThe ExchangeSenderMemberOfException parameter specifies the distribution groups or security groups to exclude from the policy (email of the group members is excluded from the policy). You identify the groups by email address.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou must use this parameter with the ExchangeLocation parameter.\nYou can't use this parameter with the ExchangeSender or ExchangeSenderMemberOf parameters.\nYou can't use this parameter to specify Microsoft 365 Groups.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Force\nApplicable: Security & Compliance\nThe Force switch hides warning or confirmation messages. You don't need to specify a value with this switch.\nYou can use this switch to run tasks programmatically where prompting for administrative input is inappropriate.\nParameter properties\nType:\nSwitchParameter\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Is\nFrom\nSmart\nInsights\nApplicable: Security & Compliance\n{{ Fill IsFromSmartInsights Description }}\nParameter properties\nType:\nSystem.Boolean\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Locations\nApplicable: Security & Compliance\nThe Locations parameter specifies to whom, what, and where the DLP policy applies. This parameter uses the following properties:\nWorkload: What the DLP policy applies to. Use the value\nApplications\n.\nLocation: Where the DLP policy applies. For Microsoft 365 Copilot, use the value\n470f2276-e011-4e9d-a6ec-20768be3a4b0\n.\nInclusions: Who the DLP policy applies to. For users, use the email address in this syntax:\n{Type:IndividualResource,Identity:<EmailAddress>}\n. For security groups or distribution groups, use the ObjectId value of the group from the Microsoft Entra portal in this syntax:\n{Type:Group,Identity:<ObjectId>}\n. For the entire tenant, use this value:\n{Type:\"Tenant\",Identity:\"All\"}\n.\nExclusions: Exclude security groups, distribution groups, or users from the scope of this DLP policy. For users, use the email address in this syntax:\n{Type:IndividualResource,Identity:<EmailAddress>}\n. For groups, use the ObjectId value of the group from the Microsoft Entra portal in this syntax:\n{Type:Group, Identity:<ObjectId>}\n.\nYou create and store the properties in a variable as shown in the following examples:\nDLP policy scoped to all users in the tenant:\n$loc = \"[{\"Workload\":\"Applications\",\"Location\":\"470f2276-e011-4e9d-a6ec-20768be3a4b0\",\"Inclusions\":[{Type:\"Tenant\",Identity:\"All\"}]}]\"\nDLP policy scoped to the specified user and groups:\n$loc = \"[{\"Workload\":\"Applications\",\"Location\":\"470f2276-e011-4e9d-a6ec-20768be3a4b0\",\"Inclusions\":[{\"Type\":\"Group\",\"Identity\":\"fef0dead-5668-4bfb-9fc2-9879a47f9bdb\"},{\"Type\":\"Group\",\"Identity\":\"b4dc1e1d-8193-4525-b59c-6d6e0f1718d2\"},{\"Type\":\"IndividualResource\",\"Identity\":\"yibing@contoso.com\"}]}]\"\nDLP policy scoped to all users in the tenant except for members of the specified group:\n$loc = \"[{\"Workload\":\"Applications\",\"Location\":\"470f2276-e011-4e9d-a6ec-20768be3a4b0\",\"Inclusions\":[{Type:\"Tenant\",Identity:\"All\"}]}],\"Exclusions\":[{\"Type\":\"Group\",\"Identity\":\"fef0dead-5668-4bfb-9fc2-9879a47f9bdb\"}]}]\"\nAfter you create the\n$loc\nvariable as shown in the previous examples, use the value\n$loc\nfor this parameter.\nParameter properties\nType:\nString\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Mode\nApplicable: Security & Compliance\nThe Mode parameter specifies the action and notification level of the DLP policy. Valid values are:\nEnable: The policy is enabled for actions and notifications. This value is the default.\nDisable: The policy is disabled.\nTestWithNotifications: Simulation mode where no actions are taken, but notifications\nare\nsent.\nTestWithoutNotifications: Simulation mode where no actions are taken, and no notifications are sent.\nParameter properties\nType:\nPolicyMode\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Name\nApplicable: Security & Compliance\nThe Name parameter specifies the unique name of the DLP policy. If the value contains spaces, enclose the value in quotation marks.\nParameter properties\nType:\nString\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\n1\nMandatory:\nTrue\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nAdaptive\nScopes\nApplicable: Security & Compliance\n{{ Fill OneDriveAdaptiveScopes Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nAdaptive\nScopes\nException\nApplicable: Security & Compliance\n{{ Fill OneDriveAdaptiveScopesException Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nLocation\nApplicable: Security & Compliance\nThe OneDriveLocation parameter specifies whether to include OneDrive sites in the policy. A valid value for this parameter is All, which is also the default value.\nYou can use this parameter in the following procedures:\nTo include sites of specific OneDrive accounts in the policy, use the OneDriveSharedBy parameter to specify the users. Only sites of the specified users are included in the policy.\nTo include sites of specific group members in the policy, use the OneDriveSharedByMemberOf parameter to specify the groups. Only sites of members of the specified groups are included in the policy.\nTo exclude sites of specific OneDrive accounts from the policy, use the ExceptIfOneDriveSharedBy parameter to specify the users. Only sites of the specified users are excluded from the policy.\nTo exclude sites of specific group members from the policy, use the ExceptIfOneDriveSharedByMemberOf parameter to specify the groups. Only sites of members of the specified groups are excluded from the policy.\nIf you use\n-OneDriveLocation $null\n, the policy does not apply to OneDrive sites.\nYou can't specify inclusions and exclusions in the same policy.\nNote\n: Although this parameter accepts site URLs, don't specify site URLs values. Use the OneDriveSharedBy, ExceptIfOneDriveShareBy, OneDriveSharedByMemberOf, and ExceptIfOneDriveSharedByMemberOf parameters instead. In the DLP policy settings in the Microsoft Defender portal, you can't identify sites by URL; you specify sites only by users or groups.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nLocation\nException\nApplicable: Security & Compliance\nDon't use this parameter. See the OneDriveLocation parameter for an explanation.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nShared\nBy\nApplicable: Security & Compliance\nThe OneDriveSharedBy parameter specifies the users to include in the DLP policy (the sites of the OneDrive user accounts are included in the policy). You identify the users by UPN (\nlaura@contoso.onmicrosoft.com\n).\nTo use this parameter, OneDrive sites need to be included in the policy (the OneDriveLocation parameter value is All, which is the default value).\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou can't use this parameter with the ExceptIfOneDriveSharedBy or ExceptIfOneDriveSharedByMemberOf parameters.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-One\nDrive\nShared\nByMember\nOf\nApplicable: Security & Compliance\nThe OneDriveSharedByMemberOf parameter specifies the distribution groups or mail-enabled security groups to include in the DLP policy (the OneDrive sites of group members are included in the policy). You identify the groups by email address.\nTo use this parameter, OneDrive sites need to be included in the policy (the OneDriveLocation parameter value is All, which is the default value).\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nYou can't use this parameter with the ExceptIfOneDriveSharedBy or ExceptIfOneDriveSharedByMemberOf parameters.\nYou can't use this parameter to specify Microsoft 365 Groups.\nParameter properties\nType:\nRecipientIdParameter\n[\n]\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-On\nPremises\nScanner\nDlp\nLocation\nApplicable: Security & Compliance\nThe OnPremisesScannerDlpLocation parameter specifies the on-premises file shares and SharePoint document libraries and folders to include in the DLP policy. You can use the value All to include all on-premises file shares and SharePoint document libraries and folders.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about the DLP on-premises scanner, see\nLearn about the data loss prevention on-premises scanner\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-On\nPremises\nScanner\nDlp\nLocation\nException\nApplicable: Security & Compliance\nThe OnPremisesScannerDlpLocationException parameter specifies the on-premises file shares and SharePoint document libraries and folders to exclude from the DLP policy if you use the value All for the OnPremisesScannerDlpLocation parameter.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about the DLP on-premises scanner, see\nLearn about the data loss prevention on-premises scanner\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Policy\nRBACScopes\nApplicable: Security & Compliance\nThe PolicyRBACScopes parameter specifies the administrative units to assign to the policy. A valid value is the Microsoft Entra ObjectID (GUID value) of the administrative unit. You can specify multiple values separated by commas.\nAdministrative units are available only in Microsoft Entra ID P1 or P2. You create and manage administrative units in Microsoft Graph PowerShell.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Policy\nTemplate\nInfo\nApplicable: Security & Compliance\nThe PolicyTemplateInfo specifies the built-in or custom DLP policy templates to use in the DLP policy.\nFor more information about DLP policy templates, see\nWhat the DLP policy templates include\n.\nParameter properties\nType:\nPswsHashtable\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Power\nBIDlp\nLocation\nApplicable: Security & Compliance\nThe PowerBIDlpLocation parameter specifies the Power BI workspace IDs to include in the DLP policy. Only workspaces hosted in Premium Gen2 capacities are permitted. You can use the value All to include all supported workspaces.\nYou can find the workspace ID using any of the following procedures:\nIn the Admin portal, choose\nWorkspaces\n, then select a workspace and choose\n> More options (...) > Details\n.\nLook in the URL of a selected workspace.\nIn PowerShell, use the\nGet-PowerBIWorkspace\ncmdlet.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nNote\n: You can't use this parameter if the DLP policy applies to other locations.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Power\nBIDlp\nLocation\nException\nApplicable: Security & Compliance\nThe PowerBIDlpLocationException parameter specifies the Power BI workspace IDs to exclude from the DLP policy when you use the value All for the PowerBIDlpLocation parameter. Only workspaces hosted in Premium Gen2 capacities are permitted.\nYou can find the workspace ID using any of the following procedures:\nIn the Admin portal, choose\nWorkspaces\n, then select a workspace and choose\n> More options (...) > Details\n.\nLook in the URL of a selected workspace.\nIn PowerShell, use the\nGet-PowerBIWorkspace\ncmdlet.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Priority\nApplicable: Security & Compliance\nThe Priority parameter specifies a priority value for the policy that determines the order of policy processing. A lower integer value indicates a higher priority, the value 0 is the highest priority, and policies can't have the same priority value.\nValid values and the default value depend on the number of existing policies. For example, if there are 5 existing policies:\nValid priority values for the existing 5 policies are from 0 through 4.\nValid priority values for a new 6th policy are from 0 through 5.\nThe default value for a new 6th policy is 5.\nIf you modify the priority value of a policy, the position of the policy in the list changes to match the priority value you specify. In other words, if you set the priority value of a policy to the same value as an existing policy, the priority value of the existing policy and all other lower priority policies after it is increased by 1.\nParameter properties\nType:\nInt32\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Share\nPoint\nAdaptive\nScopes\nApplicable: Security & Compliance\n{{ Fill SharePointAdaptiveScopes Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Share\nPoint\nAdaptive\nScopes\nException\nApplicable: Security & Compliance\n{{ Fill SharePointAdaptiveScopesException Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Share\nPoint\nLocation\nApplicable: Security & Compliance\nThe SharePointLocation parameter specifies the SharePoint sites to include in the DLP policy. You identify the site by its URL value, or you can use the value All to include all sites.\nYou can't add SharePoint sites to the policy until they have been indexed.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Share\nPoint\nLocation\nException\nApplicable: Security & Compliance\nThe SharePointLocationException parameter specifies the SharePoint sites to exclude when you use the value All for the SharePointLocation parameter. You identify the site by its URL value.\nYou can't add SharePoint sites to the policy until they have been indexed.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Teams\nAdaptive\nScopes\nApplicable: Security & Compliance\n{{ Fill TeamsAdaptiveScopes Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Teams\nAdaptive\nScopes\nException\nApplicable: Security & Compliance\n{{ Fill TeamsAdaptiveScopesException Description }}\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Teams\nLocation\nApplicable: Security & Compliance\nThe TeamsLocation parameter specifies the Teams chat and channel messages to include in the DLP policy. You identify the entries by the email address or name of the account, distribution group, or mail-enabled security group. You can use the value All to include all accounts, distribution groups, and mail-enabled security groups.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Teams\nLocation\nException\nApplicable: Security & Compliance\nThe TeamsLocation parameter specifies the Teams chat and channel messages to exclude from the DLP policy when you use the value All for the TeamsLocation parameter. You identify the entries by the email address or name of the account, distribution group, or mail-enabled security group.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Third\nParty\nApp\nDlp\nLocation\nApplicable: Security & Compliance\nNote\n: This parameter requires membership in the Compliance Administrator or Compliance Data Administrator roles in Microsoft Entra ID.\nThe ThirdPartyAppDlpLocation parameter specifies the non-Microsoft cloud apps to include in the DLP policy. You can use the value All to include all connected apps.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about DLP for non-Microsoft cloud apps, see\nUse data loss prevention policies for non-Microsoft cloud apps\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Third\nParty\nApp\nDlp\nLocation\nException\nApplicable: Security & Compliance\nNote\n: This parameter requires membership in the Compliance Administrator or Compliance Data Administrator roles in Microsoft Entra ID.\nThe ThirdPartyAppDlpLocationException parameter specifies the non-Microsoft cloud apps to exclude from the DLP policy when you use the value All for the ThirdPartyAppDlpLocation parameter.\nTo enter multiple values, use the following syntax:\n<value1>,<value2>,...<valueX>\n. If the values contain spaces or otherwise require quotation marks, use the following syntax:\n\"<value1>\",\"<value2>\",...\"<valueX>\"\n.\nFor more information about DLP for non-Microsoft cloud apps, see\nUse data loss prevention policies for non-Microsoft cloud apps\n.\nParameter properties\nType:\nMultiValuedProperty\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-Validate\nPolicy\nApplicable: Security & Compliance\n{{ Fill ValidatePolicy Description }}\nParameter properties\nType:\nSwitchParameter\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\n-What\nIf\nApplicable: Security & Compliance\nThe WhatIf switch doesn't work in Security & Compliance PowerShell.\nParameter properties\nType:\nSwitchParameter\nDefault value:\nNone\nSupports wildcards:\nFalse\nDontShow:\nFalse\nAliases:\nwi\nParameter sets\n(All)\nPosition:\nNamed\nMandatory:\nFalse\nValue from pipeline:\nFalse\nValue from pipeline by property name:\nFalse\nValue from remaining arguments:\nFalse\nCommonParameters\nThis cmdlet supports the common parameters: -Debug, -ErrorAction, -ErrorVariable,\n-InformationAction, -InformationVariable, -OutBuffer, -OutVariable, -PipelineVariable,\n-ProgressAction, -Verbose, -WarningAction, and -WarningVariable. For more information, see\nabout_CommonParameters\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "DLP Cmdlets",
      "section": "PowerShell References"
    },
    "https://learn.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference": {
      "content_hash": "sha256:9b3245ceed9bc5e63e53b9fde600d6f132fe21f67bec6001322d2792117d8d72",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nOffice 365 Management Activity API reference\nFeedback\nSummarize this article for me\nUse the Office 365 Management Activity API to retrieve information about user, admin, system, and policy actions and events from Office 365 and Microsoft Entra activity logs.\nYou can use the actions and events from the Office 365 and Microsoft Entra audit and activity logs to create solutions that provide monitoring, analysis, and data visualization. These solutions give organizations greater visibility into actions taken on their content. These actions and events are also available in the Office 365 Activity Reports. For more information, see\nSearch the audit log in Microsoft 365\n.\nTip\nIf you're interested in creating custom reports from Audit Logs, you might find the following blogs helpful.\nMicrosoft Purview audit log activities via O365 Management API - Part 1\nMicrosoft Purview audit log activities via O365 Management API - Part 2\nThe Office 365 Management Activity API is a REST web service that you can use to develop solutions using any language and hosting environment that supports HTTPS and X.509 certificates. The API relies on Microsoft Entra ID and the OAuth2 protocol for authentication and authorization. To access the API from your application, you'll need to first register it in Microsoft Entra ID and configure it with appropriate permissions. This will enable your application to request the OAuth2 access tokens it needs to call the API. For more information, see\nGet started with Office 365 Management APIs\n.\nFor information about the data that the Office 365 Management Activity API returns, see\nOffice 365 Management Activity API schema\n.\nImportant\nBefore you can access data through the Office 365 Management Activity API, you must enable unified audit logging for your Office 365 organization. You do this by turning on the Office 365 audit log. For instructions, see\nTurn Office 365 audit log search on or off\n.\nWorking with the Office 365 Management Activity API\nThe Office 365 Management Activity API aggregates actions and events into tenant-specific content blobs, which are classified by the type and source of the content they contain. Currently, these content types are supported:\nAudit.AzureActiveDirectory\nAudit.Exchange\nAudit.SharePoint\nAudit.General (includes all other workloads not included in the previous content types)\nDLP.All (DLP events only for all workloads)\nFor details about the events and properties associated with these content types, see\nOffice 365 Management Activity API schema\n.\nTo begin retrieving content blobs for a tenant, you first create a subscription to the desired content types. If you are retrieving content blobs for multiple tenants, you create multiple subscriptions to each of the desired content types, one for each tenant.\nAfter you create a subscription, you can poll regularly to discover new content blobs that are available for download, or you can register a webhook endpoint with the subscription and we will send notifications to this endpoint as new content blobs are available.\nNote\nWhen a subscription is created, it can take up to 12 hours for the first content blobs to become available for that subscription. The content blobs are created by collecting and aggregating actions and events across multiple servers and datacenters. As a result of this distributed process, the actions and events contained in the content blobs will not necessarily appear in the order in which they occurred. One content blob can contain actions and events that occurred prior to the actions and events contained in an earlier content blob. We are working to decrease the latency between the occurrence of actions and events and their availability within a content blob, but we can't guarantee that they appear sequentially.\nNote\nPlease don't submit multiple requests to start a subscription within a short period. Once you submit a subscription request, a waiting period of 15 minutes is required before another request can be made. This throttling policy doesn't apply to stop a subscription. You may submit a request to stop a subscription at any time.\nNote\nDLP sensitive data is only available in the activity feed API to users that have been granted âRead DLP sensitive dataâ permissions. For more on Data Loss Prevention (DLP) see\nOverview of Data Loss Prevention Policies\nActivity API operations\nAll API operations are scoped to a single tenant and the root URL of the API includes a tenant ID that specifies the tenant context. The tenant ID is a GUID. For information about how to get the GUID, see\nGet started with Office 365 Management APIs\n.\nBecause the notifications we send to your webhook include the tenant ID, you can use the same webhook to receive notifications for all tenants.\nThe URL for the API endpoint that you use is based on the type of Microsoft 365 or Office 365 subscription plan for your organization.\nEnterprise plan\nhttps://manage.office.com/api/v1.0/{tenant_id}/activity/feed/{operation}\nGCC government plan\nhttps://manage-gcc.office.com/api/v1.0/{tenant_id}/activity/feed/{operation}\nGCC High government plan\nhttps://manage.office365.us/api/v1.0/{tenant_id}/activity/feed/{operation}\nDoD government plan\nhttps://manage.protection.apps.mil/api/v1.0/{tenant_id}/activity/feed/{operation}\nAll API operations require an Authorization HTTP header with an access token obtained from Microsoft Entra ID. The tenant ID in the access token must match the tenant ID in the root URL of the API and the access token must contain the ActivityFeed.Read claim (this corresponds to the permission [Read activity data for an organization] that you configured for you application in Microsoft Entra ID).\nAuthorization: Bearer eyJ0e...Qa6wg\nThe Activity API supports the following operations:\nStart a subscription\nto begin receiving notifications and retrieving activity data for a tenant.\nStop a subscription\nto discontinue retrieving data for a tenant.\nList current subscriptions\nList available content\nand the corresponding content URLs.\nReceiving notifications\nsent by a webhook when new content is available.\nRetrieving content\nby using the content URL.\nList notifications\nsent by a webhook.\nRetrieve resource friendly names\nfor objects in the data feed identified by guids.\nStart a subscription\nThis operation starts a subscription to the specified content type. If a subscription to the specified content type already exists, this operation is used to:\nUpdate the properties of an active webhook.\nEnable a webhook that was disabled because of excessive failed notifications.\nRe-enable an expired webhook by specifying a later or null expiration date.\nRemove a webhook.\nSubscription\nDescription\nPath\n/subscriptions/start?contentType={ContentType}\nParameters\ncontentType - Must be a valid content type.\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nBody\nwebhook - Optional JSON object with three properties:\naddress\n: Required HTTPS endpoint that can receive notifications. A test message will be sent to the webhook to validate the webhook before creating the subscription.\nauthId\n: Optional string that will be included as the WebHook-AuthID header in notifications sent to the webhook as a means of identifying and authorizing the source of the request to the webhook.\nexpiration\n: Optional datetime that indicates a datetime after which notifications should no longer be sent to the webhook.\nResponse\ncontentType - The content type specified in the call.\nstatus\nThe status of the subscription. If a subscription is disabled, you'll not be able to list or retrieve content.\nwebhook\nThe webhook properties specified in the call together with the status of the webhook. If the webhook is disabled, you'll not receive notification, but you'll still be able to list and retrieve content, provided the subscription is enabled.\nSample request\nPOST {root}/subscriptions/start?contentType=Audit.SharePoint&PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nContent-Type: application/json; utf-8\nAuthorization: Bearer eyJ0e...Qa6wg\n\n{\n \"webhook\" : {\n \"address\": \"https://webhook.myapp.com/o365/\",\n \"authId\": \"o365activityapinotification\",\n \"expiration\": \"\"\n }\n}\nSample response\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\n\n{\n \"contentType\": \"Audit.SharePoint\",\n \"status\": \"enabled\",\n \"webhook\": {\n \"status\": \"enabled\",\n \"address\": \"https://webhook.myapp.com/o365/\",\n \"authId\": \"o365activityapinotification\",\n \"expiration\": null\n }\n}\nWebhook validation\nWhen the /start operation is called and a webhook is specified, we will send a validation notification to the specified webhook address to validate that an active listener can accept and process notifications. If we do not receive an HTTP 200 OK response, the subscription will not be created. Or, if /start is being called to add a webhook to an existing subscription and a response of HTTP 200 OK is not received, the webhook will not be added and the subscription will remain unchanged.\nSample request\nPOST {webhook address}\nContent-Type: application/json; charset=utf-8\nWebhook-AuthID: (webhook authId, if provided)\nWebhook-ValidationCode: (random opaque string)\n\n{\n \"validationCode\": (random opaque string, same as header)\n}\nSample response\nHTTP/1.1 200 OK\nStop a subscription\nThis operation stops a subscription to the specified content type.\nWhen a subscription is stopped, you'll no longer receive notifications and you'll not be able to retrieve available content. If the subscription is later restarted, you'll have access to new content from that point forward. You will not be able to retrieve content that was available between the time the subscription was stopped and restarted.\nSubscription\nDescription\nPath\n/subscriptions/stop?contentType={ContentType}\nParameters\ncontentType - Must be a valid content type.\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nBody\n(empty)\nResponse\n(empty)\nSample request\nPOST {root}/subscriptions/stop?contentType=Audit.SharePoint&PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nAuthorization: Bearer eyJ0e...Qa6wg\nSample response\nHTTP/1.1 200 OK\nList current subscriptions\nThis operation returns a collection of the current subscriptions together with the associated webhooks.\nSubscription\nDescription\nPath\n/subscriptions/list\nParameters\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nBody\n(empty)\nResponse\nJSON array\nEach subscription will be represented by a JSON object with three properties:\ncontentType\n: Indicates the content type.\nstatus\n: Indicates the status of the subscription.\nwebhook\n: Indicates the configured webhook, together with the status (enabled, disabled, expired) of the webhook. If a subscription does not have a webhook, the webhook property will be present but with null value.\nSample request\nGET {root}/subscriptions/list?PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nAuthorization: Bearer eyJ0e...Qa6wg\nSample response\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\n\n[\n {\n \"contentType\" : \"Audit.SharePoint\",\n \"status\": \"enabled\",\n \"webhook\": {\n \"status\": \"enabled\",\n \"address\": \"https://webhook.myapp.com/o365/\",\n \"authId\": \"o365activityapinotification\",\n \"expiration\": null\n }\n },\n\n ...\n\n {\n \"contentType\": \"Audit.Exchange\",\n \"webhook\": null\n }\n]\nList available content\nThis operation lists the content currently available for retrieval for the specified content type. The content is an aggregation of actions and events harvested from multiple servers across multiple datacenters. The content will be listed in the order in which the aggregations become available, but the events and actions within the aggregations are not guaranteed to be sequential. An error is returned if the subscription status is disabled.\nSubscription\nDescription\nPath\n/subscriptions/content?contentType={ContentType}&startTime={0}&endTime={1}\nParameters\ncontentType - Must be a valid content type.\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nstartTime endTime\nOptional datetimes (UTC) indicating the time range of content to return, based on when the content became available. The time range is inclusive with respect to startTime (startTime <= contentCreated) and exclusive with respect to endTime (contentCreated < endTime), so that non-overlapping, incrementing time intervals can used to page through available content.\nYYYY-MM-DD\nYYYY-MM-DDTHH:MM\nYYYY-MM-DDTHH:MM:SS\nBoth must be specified (or both omitted) and they must be no more than 24 hours apart, with the start time no more than 7 days in the past. By default, if startTime and endTime are omitted, then the content available in the last 24 hours is returned.\nNOTE\n: Even though it is possible to specify a startTime and endTime more than 24 hours apart, this is not recommended. Furthermore, if you do get any results in response to a request for more than 24 hours, these could be partial results and should not be taken into account. The request should be issued with an interval of no more than 24 hours between the startTime and endTime.\nResponse\nJSON array - The available content will be represented by JSON objects with the following properties:\ncontentType\n: Indicates the content type.\ncontentId\n: An opaque string that uniquely identifies the content.\ncontentUri\n: The URL to use when retrieving the content.\ncontentCreated\n: The datetime when the content was made available.\ncontentExpiration\n: The datetime after which the content will no longer be available for retrieval.\nSample request\nGET {root}/subscriptions/content?contentType=Audit.SharePoint&PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nAuthorization: Bearer eyJ0e...Qa6wg\nSample response\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\n\n[\n {\n \"contentType\": \"Audit.SharePoint\",\n \"contentId\": \"492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentUri\": \"https://manage.office.com/api/v1.0/f28ab78a-d401-4060-8012-736e373933eb/activity/feed/audit/492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentCreated\": \"2015-05-23T17:35:00.000Z\",\n \"contentExpiration\": \"2015-05-30T17:35:00.000Z\"\n },\n ...\n]\nPagination\nWhen listing available content for a time range, the number of results returned is limited to prevent response timeouts. If there are more results in the specified time range than can be returned in single response, the results will be truncated and a header will be added to the response indicating the URL to use to retrieve the next page of results. The URL will contain the same\nstartTime\nand\nendTime\nparameters that were specified in the original request, together with a parameter indicating the internal ID of the next page. If\nstartTime\nand\nendTime\nwere not specified in the original request, they will be set to reflect the 24-hour interval that preceded the original request.\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nNextPageUri: https://manage.office.com/api/v1/{tenant_id}/activity/feed/subscriptions/content?contentType=Audit.SharePoint&startTime=2015-10-01&endTime=2015-10-02&nextPage=2015101900R022885001761\nTo list all available content for a specified time range, you might need to retrieve multiple pages until a response without the\nNextPageUri\nheader is received.\nReceiving notifications\nNotifications are sent to the configured webhook for a subscription as new content becomes available. Because the notification includes the tenant identifier, you can use the same webhook to receive notifications for all tenants for which you have subscriptions.\nThe notification is made as an HTTP POST over TLS (TLS 1.0 and later versions) to the specified webhook address. If the webhook configuration includes an auth ID, we will send it as an HTTP header: Webhook-AuthID. Any response other than HTTP 200 OK will be considered a failure and the notification will be retried. You can also configure your webhook to require client certificate-based authentication and we will authenticate using the manage.office.com certificate.\nThe body of the request will contain an array of one or more JSON objects that represent the available content blobs. The number of content blobs in each notification is limited to keep the size of the notification relatively small. Because this limit might change, your implementation should query for the length of the array instead of expecting a fixed size. Each object will include the same properties returned by the /content operation, together with the GUID of the tenant to which the data belongs and the GUID of your application that created the subscriptions. This allows the webhook to establish context when it is being used with multiple tenants and applications.\ntenantId\n: The GUID of the tenant to which the content belongs.\nclientId\n: The GUID of your application that created the subscription.\ncontentType\n: Indicates the content type.\ncontentId\n: An opaque string that uniquely identifies the content.\ncontentUri\n: The URL to use when retrieving the content.\ncontentCreated\n: The datetime when the content was made available.\ncontentExpiration\n: The datetime after which the content will no longer be available for retrieval.\nThe following is an example of a notification.\nPOST https://webhook.myapp.com/o365/ \nContent-Type: application/json; utf-8\nWebhook-AuthID: o365activityapinotification\n\n[\n {\n \"tenantId\": \"{GUID}\",\n \"clientId\": \"{GUID}\",\n \"contentType\": \"Audit.SharePoint\",\n \"contentId\": \"492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentUri\": \"https://manage.office.com/api/v1.0/f28ab78a-d401-4060-8012-736e373933eb/activity/feed/audit/492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentCreated\": \"2015-05-23T17:35:00.000Z\",\n \"contentExpiration\": \"2015-05-30T17:35:00.000Z\"\n },\n ...\n]\nNotification failure and retry\nThe notification system sends notifications as new content becomes available. If we encounter excessive failures when sending notifications, our retry mechanism will exponentially increase the time between retries. If we continue to encounter failures, we reserve the right to disable the webhook and stop sending notifications to it altogether. The /start operation can be used to re-enable a disabled webhook.\nRetrieve content\nTo retrieve a content blob, make a GET request against the corresponding content URI that is included in the list of available content and in the notifications sent to a webhook. The returned content will be a collection of one more actions or events in JSON format.\nSample request\nGET https://manage.office.com/api/v1.0/41463f53-8812-40f4-890f-865bf6e35190/activity/feed/audit/301299007231$301299007231$41463f53881240f4890f865bf6e35190aad2015062920$e1c2ab19858a469fb1f1fd097effffc9$04 HTTP/1.1\nAuthorization: Bearer eyJ0e...Qa6wg\nSample response\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\n\n[\n {\n \"CreationTime\": \"2015-06-29T20:03:19\",\n \"Id\": \"80c76bd2-9d81-4c57-a97a-accfc3443dca\",\n \"Operation\": \"PasswordLogonInitialAuthUsingPassword\",\n \"OrganizationId\": \"41463f53-8812-40f4-890f-865bf6e35190\",\n \"RecordType\": 9,\n \"ResultStatus\": \"failed\",\n \"UserKey\": \"1153977025279851686@contoso.onmicrosoft.com\",\n \"UserType\": 0,\n \"Workload\": \"AzureActiveDirectory\",\n \"ClientIP\": \"134.170.188.221\",\n \"ObjectId\": \"admin@contoso.onmicrosoft.com\",\n \"UserId\": \"admin@contoso.onmicrosoft.com\",\n \"AzureActiveDirectoryEventType\": 0,\n \"ExtendedProperties\": [\n {\n \"Name\": \"LoginError\",\n \"Value\": \"-2147217390;PP_E_BAD_PASSWORD;The entered and stored passwords do not match.\"\n }\n ],\n \"Client\": \"Exchange\",\n \"LoginStatus\": -2147217390,\n \"UserDomain\": \"contoso.onmicrosoft.com\"\n },\n {\n \"CreationTime\": \"2015-06-29T20:03:34\",\n \"Id\": \"4e655d3f-35fa-42e0-b050-264b2d255c7a\",\n \"Operation\": \"PasswordLogonInitialAuthUsingPassword\",\n \"OrganizationId\": \"41463f53-8812-40f4-890f-865bf6e35190\",\n \"RecordType\": 9,\n \"ResultStatus\": \"success\",\n \"UserKey\": \"1153977025279851686@contoso.onmicrosoft.com\",\n \"UserType\": 0,\n \"Workload\": \"AzureActiveDirectory\",\n \"ClientIP\": \"134.170.188.221\",\n \"ObjectId\": \"admin@contoso.onmicrosoft.com\",\n \"UserId\": \"admin@contoso.onmicrosoft.com\",\n \"AzureActiveDirectoryEventType\": 0,\n \"Client\": \"Exchange\",\n \"LoginStatus\": 0,\n \"UserDomain\": \"contoso.onmicrosoft.com\"\n },\n {\n \"CreationTime\": \"2015-06-29T20:04:55\",\n \"Id\": \"b567caf0-088e-4c1c-a4ea-633a1e3d66c8\",\n \"Operation\": \"Add User.\",\n \"OrganizationId\": \"41463f53-8812-40f4-890f-865bf6e35190\",\n \"RecordType\": 8,\n \"ResultStatus\": \"success\",\n \"UserKey\": \"1003BFFD8EC47CA6@contoso.onmicrosoft.com\",\n \"UserType\": 0,\n \"Workload\": \"AzureActiveDirectory\",\n \"ObjectId\": \"user001@contoso.onmicrosoft.com\",\n \"UserId\": \"admin@contoso.onmicrosoft.com\",\n \"AzureActiveDirectoryEventType\": 0,\n \"Actor\": [\n {\n \"ID\": \"1cef1fdb-ff52-48c4-8e4e-dfb5ea83d357\",\n \"Type\": 2\n },\n {\n \"ID\": \"admin@contoso.onmicrosoft.com\",\n \"Type\": 5\n },\n {\n \"ID\": \"1003BFFD8EC47CA6\",\n \"Type\": 3\n }\n ],\n \"ActorContextId\": \"41463f53-8812-40f4-890f-865bf6e35190\",\n \"InterSystemsId\": \"c2ced078-ad57-4079-a743-5c37f5284790\",\n \"IntraSystemId\": \"d1497f7e-15b4-49aa-83ad-11a17ca4a2f4\",\n \"Target\": [\n {\n \"ID\": \"user001@contoso.onmicrosoft.com\",\n \"Type\": 5\n },\n {\n \"ID\": \"10037FFE91510806\",\n \"Type\": 3\n }\n ],\n \"TargetContextId\": \"41463f53-8812-40f4-890f-865bf6e35190\"\n }\n]\nList notifications\nThis operation lists all notification attempts for the specified content type. If you did not include a webhook when starting the subscription to the content type, there will be no notifications to retrieve. Because we retry notifications in the event of failure, this operation can return multiple notifications for the same content, and the order in which the notifications are sent will not necessarily match the order in which the content became available (especially when there are failures and retries).\nYou can use this operation to help investigate issues related to webhooks and notifications, but you should not use it to determine what content is currently available for retrieval. Use the /content operation instead. We return an error if the subscription status is disabled.\nSubscription\nDescription\nPath\n/subscriptions/notifications?contentType={ContentType}&startTime={0}&endTime={1}\nParameters\ncontentType - Must be a valid content type.\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nstartTime endTime\nOptional datetimes (UTC) that indicate the time range of content to return, based on when the content became available. The time range is inclusive with respect to\nstartTime\n(\nstartTime\n<= contentCreated) and exclusive with respect to\nendTime\n(\ncontentCreated\n< endTime), so that non-overlapping, incrementing time intervals can used to page through available content.\nYYYY-MM-DD\nYYYY-MM-DDTHH:MM\nYYYY-MM-DDTHH:MM:SS\nBoth must be specified (or both omitted) and they must be no more than 24 hours apart, with the start time no more than 7 days in the past. By default, if\nstartTime\nand\nendTime\nare omitted, the content available in the last 24 hours is returned.\nResponse\nJSON array - The notifications will be represented by JSON objects with the following properties:\ncontentType\n: indicates the content type.\ncontentId\n: an opaque string that uniquely identifies the content.\ncontentUri\n: the URL to use when retrieving the content.\ncontentCreated\n: the datetime when the content was made available.\ncontentExpiration\n: the datetime after which the content will no longer be available for retrieval.\nnotificationSent\n: the datetime when the notification was sent.\nnotificationStatus\n: indicates the success or failure of the notification attempt.\nSample request\nGET {root}/subscriptions/notifications?contentType=Audit.SharePoint&PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nAuthorization: Bearer eyJ0e...Qa6wg\nSample response\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\n\n[\n {\n \"contentType\": \"Audit.SharePoint\",\n \"contentId\": \"492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentUri\": \"https://manage.office.com/api/v1.0/f28ab78a-d401-4060-8012-736e373933eb/activity/feed/audit/492638008028$492638008028$f28ab78ad40140608012736e373933ebspo2015043022$4a81a7c326fc4aed89c62e6039ab833b$04\",\n \"contentCreated\": \"2015-05-23T17:35:00.000Z\",\n \"contentExpiration\": \"2015-05-30T17:35:00.000Z\",\n \"notificationSent\": \"2015-05-23T17:36:00.000Z\",\n \"notificationStatus\": \"success\"\n\n },\n ...\n]\nPagination\nWhen listing notification history for a time range, the number of results returned is limited to prevent response timeouts. If there are more results in the specified time range than can be returned in a single response, the results are truncated and a header is added to the response indicating the URL to use to retrieve the next page of results. The URL will contain the same\nstartTime\nand\nendTime\nparameters that were specified in the original request, together with a parameter indicating the internal ID of the next page. If\nstartTime\nand\nendTime\nwere not specified in the original request, they will be set to reflect the 24-hour interval that preceded the original request.\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nNextPageUri: https://manage.office.com/api/v1/{tenant_id}/activity/feed/subscriptions/content?contentType=Audit.SharePoint&startTime=2015-10-01&endTime=2015-10-02&nextPage=2015101900R022885001761\nTo list all available content for a specified time range, you might need to retrieve multiple pages until a response without the\nNextPageUri\nheader is received.\nRetrieve resource friendly names\nThis operation retrieves friendly names for objects in the data feed identified by guids. Currently \"DlpSensitiveType\" is the only supported object.\nObject\nSubscription\nDescription\nPath\n/resources/dlpSensitiveTypes\nParameters\nPublisherIdentifier\nThe tenant GUID of the vendor coding against the API. This is\nnot\nthe application GUID or the GUID of the customer using the application, but the GUID of the company writing the code. This parameter is used for throttling the request rate. Make sure this parameter is specified in all issued requests to get a dedicated quota. All requests received without this parameter will share the same quota.\nHeaders\nAccept-Language\nHeader to specify the desired language for localized names. For example, use \"en-US\" for English or \"es\" for Spanish. The default language (en-US) will be returned if this header is not present.\nBody\n(empty)\nResponse\nJSON array\nThe available content will be represented by JSON objects with the following properties:\nid\n: Indicates the guid of the sensitive information type.\nname\n: The friendly name of the sensitive information type.\nSample request\nGET {root}/resources/dlpSensitiveTypes?PublisherIdentifier=46b472a7-c68e-4adf-8ade-3db49497518e\nAuthorization: Bearer eyJ0e...Qa6wg\nAccept-Language: {language code}\nSample response\nHTTP/1.1 200 OK\n\n[\n {\n \"id\": \"50842eb7-edc8-4019-85dd-5a5c1f2bb085\",\n \"name\": \"CreditCardNumber\"\n }, \n {\n \"id\": \"0e9b3178-9678-47dd-a509-37222ca96b42\",\n \"name\": \"EUDebitCardNumber\"\n }, \n ...\n {\n }\n]\nAPI throttling\nOrganizations that access auditing logs through the Office 365 Management Activity API were restricted by throttling limits at the publisher level. This means that for a publisher pulling data on behalf of multiple customers, the limit was shared by all those customers.\nWe're moving from a publisher-level limit to a tenant-level limit. The result is that each organization will get their own fully allocated bandwidth quota to access their auditing data. All organizations are initially allocated a baseline of 2,000 requests per minute. This is not a static, predefined limit but is modeled on a combination of factors including the number of seats in the organization and that Office 365 and Microsoft 365 E5 organizations will get approximately twice as much bandwidth as non-E5 organizations. There will also be cap on the maximum bandwidth to protect the health of the service.\nFor more information, see the \"High-bandwidth access to the Office 365 Management Activity API\" section in\nAdvanced audit in Microsoft 365\n.\nNote\nEven though each tenant can initially submit up to 2,000 requests per minute, Microsoft cannot guarantee a response rate. The response rate depends on various factors, such as client system performance, network capacity, and network speed.\nErrors\nWhen the service encounters an error, it will report the error response code to the caller, using standard HTTP error-code syntax. . Additional information is included in the body of the failed call as a single JSON object. An example of a full JSON error body is shown below:\n{ \n \"error\":{ \n \"code\":\"AF50000\",\n \"message\": \"An internal server error occurred. Retry the request.\"\n } \n}\nCode\nMessage\nAF10001\nThe permission set ({0}) sent in the request did not include the expected permission\nActivityFeed.Read\n.\n{0} = the permission set in the access token.\nAF20001\nMissing parameter: {0}.\n{0} = the name of the missing parameter.\nAF20002\nInvalid parameter type: {0}. Expected type: {1}\n{0} = the name of the invalid parameter.\n{1} = the expected type (int, datetime, guid).\nAF20003\nExpiration {0} provided is set to past date and time.\n{0} = the expiration passed in the API call.\nAF20010\nThe tenant ID passed in the URL ({0}) does not match the tenant ID passed in the access token ({1}).\n{0} = tenant ID passed in the URL{1} = tenant ID passed in the access token\nAF20011\nSpecified tenant ID ({0}) does not exist in the system or has been deleted.\n{0} = tenant ID passed in the URL\nAF20012\nSpecified tenant ID ({0}) is incorrectly configured in the system.\n{0} = tenant ID passed in the URL\nAF20013\nThe tenant ID passed in the URL ({0}) is not a valid GUID.\n{0} = tenant ID passed in the URL\nAF20020\nThe specified content type is not valid.\nAF20021\nThe webhook endpoint {{0}) could not be validated. {1}\n{0} = webhook address.\n{1} = \"The endpoint did not return HTTP 200.\" or \"The address must begin with HTTPS.\"\nAF20022\nNo subscription found for the specified content type.\nAF20023\nThe subscription was disabled by {0}.\n{0} = \"a tenant admin\" or \"a service admin\"\nAF20030\nStart time and end time must both be specified (or both omitted) and must be less than or equal to 24 hours apart, with the start time no more than 7 days in the past.\nAF20031\nInvalid nextPage Input: {0}.\n{0} = the next page indicator passed in the URL\nAF20050\nThe specified content ({0}) does not exist.\n{0} = resource id or resource URL\nAF20051\nContent requested with the key {0} has already expired. Content older than 7 days cannot be retrieved.<\n{0} = resource id or resource URL\nAF20052\nContent ID {0} in the URL is invalid.\n{0} = resource id or resource URL\nAF20053\nOnly one language may be present in the Accept-Language header.\nAF20054\nInvalid syntax in Accept-Language header.\nAF20055\nStart time and end time must both be specified (or both omitted) and must be less than or equal to 24 hours apart, with the start time prior to end time and start time no more than 7 days in the past.\nAF429\nToo many requests. Method={0}, PublisherId={1}\n{0} = HTTP Method\n{1} = Tenant GUID used as PublisherIdentifier\nAF50000\nAn internal error occurred. Retry the request.\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Management Activity API",
      "section": "Office 365 Management API"
    },
    "https://learn.microsoft.com/en-us/power-platform/admin/pricing-billing-skus": {
      "content_hash": "sha256:a714c1a7df145b281a469497e82316cb4f9055a66ea65e6b09a763557647c260",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nLicensing overview for Microsoft Power Platform\nFeedback\nSummarize this article for me\nThis article provides detailed information about Microsoft Power Platform licensing. You can also learn more on the\nMicrosoft Power Platform Licensing Guide\n.\nPower Apps, Power Automate, Microsoft Copilot Studio, and Power Pages offers\nPower Apps, Power Automate, Microsoft Copilot Studio, and Power Pages provide licensed users the ability to create and run apps, bots, flows, and custom websites across multiple data sources that extend beyond Microsoft 365 (such as Salesforce and on-premises or custom data sources). Those product licenses also include access to\nDataverse\nto store and manage data.\nLearn more about\nPower Automate licensing\n.\nLearn more about\nPower Apps licensing\n.\nLearn more about\nPower BI licensing\n.\nLearn more about\nCopilot Studio licensing\n.\nNote\nAI Builder\nproposes AI features which can be used in Power Apps, Power Automate, and Microsoft Copilot Studio.\nTrial Plans\nTrial plans are available for both Power Apps and Power Automate. Free trials last 30 days for Power Apps and 90 days for\nPower Automate Trial\nplans. Users can self-service sign up for these trials in your organization. This can be done by explicitly visiting the pricing pages or by being prompted when they attempt an action in the apps that require other licensing.\nFor Power Automate, an unlicensed user who signs into flow.microsoft.com is set up with the\nPower Automate Free\nlicense. If later they try to perform an action like sharing a flow, they get prompted to sign up for a\ntrial\n. In this example, if the user accepted the offer for trial they would be signed up for a Power Automate Trial. This trial wouldn't show up under the user licenses in the Microsoft 365 Portal, however you can see it in the Power Automate and Power Apps license report discussed later in the security section.\nFor Power Apps, if a user signs up for a Power Apps trial, they get a Power Apps per user trial if needed for any of the actions they take such as creating an environment.\nAs the administrator, you'll likely be assisting users that had started in a trial and either want to continue experimenting or are ready to get a regular license to keep working with the app they're building. If you're moving to a regular license for a user, it would also be a good time to work with them to see if their app should stay where it was built or should be moved according to the environment strategy you adopt. For those not ready to get a full license but want to keep experimenting you could help them get set up on the developer plan and help them move their application and flow assets into their new developer environment.\nPower Apps and Power Automate for Microsoft 365\nPower Apps and Power Automate capabilities for Microsoft 365 enable users to extend and customize the Office experience: with these productivity apps, users can create applications and flows based on Microsoft 365 data. Power Apps and Power Automate can also utilize data outside of Microsoft 365 by connecting to common services including Box.com, Facebook, and many more via the use of standard connectors.\nLearn more about Microsoft 365 plans including these capabilities in the\nMicrosoft Power Platform Licensing Guide\n.\nHere's a brief overview of capabilities included with the Power Apps for Microsoft 365 plan:\nFunctionalities\nPower Apps for Microsoft 365\nCreate, run, and share apps\nYes\nRun canvas apps in context of Microsoft 365\nYes\nConnect to Microsoft 365 data\nYes\nConnect to cloud services using standard connectors\nYes\nRun apps in a browser or Power Apps mobile for iOS and Android\nYes\nRun Canvas apps offline\nYes\nSupport for data policies established by the Microsoft 365 administrator\nYes\nAccess on-premises data or use premium or custom connectors\n-\nAccess to Microsoft Dataverse\nYes (see the next section for details)\nTo learn about capabilities included with the Power Automate for Microsoft 365 plan, see\nPower Automate seeded license for Microsoft 365\n.\nDataverse capabilities with Microsoft 365 licenses\nAs Dataverse continues to grow, more Microsoft applications like Microsoft Project are using Dataverse. To enable these Microsoft applications, limited Dataverse functionality is added to select Microsoft 365 licenses. This is achieved by adding a new service plan named \"Dataverse\" to the Microsoft 365 licenses. To see the new service plan in the Microsoft 365 admin center, select a user, select the\nLicenses and Apps\ntab, and then scroll down and expand the\nApps\nsection.\nCapabilities included\nDataverse functionality required by other Microsoft 365 applications appears as theâ¯\"Dataverse\" service plan in theâ¯\nApps\nâ¯section of the Microsoft 365 admin center.\nThis new service plan allows select Microsoft 365 applications to take advantage of Dataverse as a platform for storing application data and use the underlying business logic tier as part of extending application capabilities. This extension also helps these applications to use Dataverse instances within the\ndefault environment\n. However, if you need to create a Dataverse instance within production or sandbox environments (other than the default environment), you're still required to have a premium Power Apps or Power Automate license.\nThese limited capabilities of Dataverse are only available through select Microsoft 365 licenses and can't be used to run any custom apps or Power Automate flows, or run any Microsoft Copilot Studio bots, or use any other data that doesn't belong to the Microsoft 365 applications that take advantage of these capabilities.\nThese limited capabilities aren't the common set included with every Office application. They can be different, based on the Microsoft 365 applications that use these capabilities. For the complete list of various limited capabilities, customers should refer to the service description of these Microsoft 365 applications that contain these Dataverse plans. These limited capabilities of Dataverse don't entitle the licensed user to run standalone Power Apps or Power Automate, or any other Microsoft Power Platform applications that use Dataverse.\nReview the\nMicrosoft Project Service description\nfor more details on the limited use of Dataverse that comes with Project.\nFrequently asked questions\nWhat are the select Office applications where Dataverse plans are included?\nFor now, the Dataverse service plan is included for Project. This list evolves as more Office applications take advantage of Dataverse and Microsoft Power Platform.\nDoes this addition of Dataverse in Microsoft 365 mean that customers don't need a Power Apps license to use Dataverse?\nNo, the capabilities of Dataverse included with select Microsoft 365 licenses don't allow customers to create custom apps with Power Apps or use the premium connectors with Power Automate. The capabilities included with this license entitle Microsoft 365 applications to use Dataverse to enhance the capabilities of the base Microsoft 365 application where Dataverse is included.\nIf customers can't use Dataverse, why is this being shown in the Microsoft 365 admin center during the license assignment experience?\nThe service plan for Dataverse is shown to provide visibility to customers that Dataverse is being used to store and manage customer data related to the Microsoft 365 application that's using Dataverse. This was communicated to all customers so that customers can prepare for this change and update any internal training or user documentation that they might need.\nWhat's the impact if the service plan for Dataverse is turned off (unselected)?\nDataverse functionality appears as theâ¯\nCommon Data Service\nplan in theâ¯\nApps\nsection of the Microsoft 365 admin center. Turning off the service plan results in the Microsoft 365 features being disabled for the users of such a license. For example, when this capability is turned off, any Office application reading data from Dataverse fails to load for the user.\nWhen can Office-licensed users be seen inside of Dataverse?\nUsers who have any Microsoft Power Platform or Dynamics 365 license are always synced into the environments with a Dataverse database. However, for Office licenses where Dataverse service plans are included, users aren't automatically synced into Dataverse until the Office application is accessed by the user. After this occurs, the user can get access to Dataverse tables and rows based on the other security roles and privileges that the administrator assigned to this user. Such users, who just have the Office license, aren't automatically assigned any other security roles or privileges, other than the Maker role privilege in the\ndefault environment\n. As a security best practice, the administrator needs to ensure that security roles and privileges are assigned based on functional roles and needs only, and not automatically assigned based on the user being synced or present in Dataverse.\nKnown issues\nIf you're an existing customer and a user with this license who comes directly to Dataverse, you might get an error message that states \"You are not a member of the organization.\" We're addressing this problem in the coming weeks.\nWe currently sync some of these Microsoft Dataverse licensed users to all environments with a Dataverse database. We're addressing this right now. Currently, these users won't be able to open Power Apps for Microsoft 365 with this license.\nPower Apps and Power Automate for Dynamics 365\nPower Apps and Power Automate capabilities for Dynamics 365 enable users to extend and customize the Dynamics experience:\nPower Apps is the platform to customize and extend applications in Dynamics 365, such as Dynamics 365 Sales and Customer Service, in context of the use rights.\nPower Automate is the platform to customize and extend automations in Dynamics 365, such as Dynamics 365 Sales and Customer Service, in context of the use rights.\nTo learn about capabilities included with the Power Automate for Dynamics 365 plan, see\nPower Automate seeded license for Dynamics 365\n.\nLearn more in\nDynamics 365 Licensing Guide\n.\nPower Apps Developer Plan\nIn addition to the trial plans, there's also a\nfree\nPower Apps Developer Plan. This is a special plan that allows up individual self-service sign and it provides an individual environment that the user can use to build apps and flows. These environments show up on the administratorâs list of environments and list the type of environment as âDeveloperâ. The environments are for individual use, so there's no ability to share with other users. Users in your organization can self-service sign up for this plan even if they have Power Apps and Power Automate license entitlements via another licensing plan. Sign-up for the Power Apps Developer Plan can be found\nhere\nand more details on its features\nhere\n.\nPay-as-you-go plan\nPay-as-you-go is a way to pay for Power Apps and Power Automate using an Azure subscription, which allows you to get started building and sharing apps without any license commitment or upfront purchasing. Learn more in\nPay-as-you-go plan\n.\nTenant-level special licenses\nIf a tenant administrator activates any one of the following SKUs, then all users in the tenant (active and guest) become eligible to be synced into all Dataverse environments in the tenant. Access to the users is granted at runtime when the user accesses the Dataverse environment. In addition, the userâs access mode is set to Read-Write in Dataverse.\nYou can view a list of all assigned licenses in the\nMicrosoft Admin Center\n.\nNote\nA user must be assigned to a security role in Dataverse before the user can access any data in Dataverse.\nPlan name\nSKU ID\nCapability string\nDynamics 365 for Marketing\n00b861da-8087-4e30-beb8-8db3c6d9581e\nDYN365_MARKETING_APP\nDynamics 365 for Marketing Attach\n85430fb9-02e8-48be-9d7e-328beb41fa29\nDYN365_MARKETING_APP_ATTACH\nDynamics 365 Marketing (Self-Service)\n1224df81-ff37-4222-a5fe-85c7feecdba8\nDYN365_MARKETING_APP_DEPT\nDynamics 365 Marketing Attach (Self-Service)\n95b34ddc-99ff-41f0-823d-0051478d9469\nDYN365_MARKETING_APP_ATTACH_DEPT\nDynamics 365 Marketing Additional Application (Self-Service)\nfcc6a509-4249-47bf-8f21-0d882dbbdae3\nDYN365_MARKETING_APPLICATION_ADDON_DEPT\nDynamics 365 Marketing Additional Non-Prod Application (Self-Service)\na7cd421b-9f64-4206-a33b-b9154ae28f97\nDYN365_MARKETING_SANDBOX_APPLICATION_ADDON_DEPT\nProject Plan 3\n53818b1b-4a27-454b-8896-0dba576410e6\nPROJECTPROFESSIONAL\nProject Plan 3 (for Department)\n46102f44-d912-47e7-b0ca-1bd7b70ada3b\nPROJECT_PLAN3_DEPT\nProject Plan 3 for faculty\n46974aed-363e-423c-9e6a-951037cec495\nPROJECTPROFESSIONAL_FACULTY\nProject Plan 3 for students\nef3a3775-8287-4df8-ba28-8ab34902710a\nPROJECTPROFESSIONAL_STUDENT\nProject Plan 5\n09015f9f-377f-4538-bbb5-f75ceb09358a\nPROJECTPREMIUM\nProject Plan 5 for faculty\n930cc132-4d6b-4d8c-8818-587d17c50d56\nPROJECTPREMIUM_FACULTY\nProject Plan 5 for students\n149f0db2-7fde-45fa-80fa-7716317772c5\nPROJECTPREMIUM_STUDENT\nProject Plan 1\nbeb6439c-caad-48d3-bf46-0c82871e12be\nPROJECT_P1\nProject Plan 1 (for Department)\n84cd610f-a3f8-4beb-84ab-d9d2c902c6c9\nPROJECT_PLAN1_DEPT\nProject Plan 3 for GCC\n074c6829-b3a0-430a-ba3d-aca365e57065\nPROJECTPROFESSIONAL_GOV\nProject Plan 5 for GCC\nf2230877-72be-4fec-b1ba-7156d6f75bd6\nPROJECTPREMIUM_GOV\nDynamics 365 Customer Insights (and Attach)\n1720c3f7-7da3-4a11-8324-92aad283eb68\nDYN365_CUSTOMER_INSIGHTS_JOURNEYS_BASE\nWhat users are licensed\nYou can always look at individual user licensing in the Microsoft 365 admin center by drilling into specific users.\nYou can also use the following PowerShell command to export assigned user licenses.\nGet-AdminPowerAppLicenses -OutputFilePath '<licenses.csv>'\nExports all the assigned user licenses (Power Apps and Power Automate) in your tenant into a tabular view .csv file. The exported file contains both self-service sign-up internal trial plans and plans that are sourced from Microsoft Entra ID. The internal trial plans aren't visible to admins in the Microsoft 365 admin center.\nThe export can take a while for tenants with a large number of Microsoft Power Platform users.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Power Platform Licensing",
      "section": "Licensing"
    },
    "https://learn.microsoft.com/en-us/microsoft-365/enterprise/microsoft-365-overview": {
      "content_hash": "sha256:056933f43a0a57da3188ca4c339488382d68944bed4831eefc399447b4128b19",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft 365 for enterprise overview\nFeedback\nSummarize this article for me\nMicrosoft 365 for enterprise is a complete, intelligent solution that empowers everyone to be creative and work together securely.\nMicrosoft 365 for enterprise is designed for large organizations, but it can also be used for medium-sized and small businesses that need the most advanced security and productivity capabilities.\nComponents\nMicrosoft 365 for enterprise consists of:\nServices\nDescription\nLocal apps and cloud-based apps and productivity services\nIncludes both Microsoft 365 Apps for enterprise, the latest Office apps for your PC and Mac (such as Word, Excel, PowerPoint, Outlook, and others), and a full suite of online services for email, file storage and collaboration, meetings, and more.\nWindows 11 Enterprise\nMeets the needs of both large and midsize organizations. It's the most productive and secure version of Windows for users. For IT professionals, it also provides comprehensive deployment, device, and app management.\nDevice management and advanced security services\nIncludes Microsoft Intune, which is a cloud-based enterprise mobility management service that helps enable your workforce to be productive while protecting your organization data. Also includes Microsoft Defender for Endpoint, which provides advanced threat protection and endpoint security. You also get antispam & antimalware protection for your email content.\nPlans\nMicrosoft 365 for enterprise is available in three plans.\nPlan name\nCapabilities\nE3\nAccess the Microsoft 365 core products and features to securely enhance workplace productivity and drive innovation.\nE5\nAccess the Microsoft 365 latest products and features. These include Defender Suite, Purview Suite, and more. This plan includes all E3 capabilities, plus advanced security, voice, and data analysis tools. In the coming months, Security Copilot will be included in Microsoft 365 E5. See\nLearn about Security Copilot inclusion in Microsoft 365 E5 subscription\n.\nF3\nConnect with your first-line workers through purpose-built tools and resources that they can use to help them do their best work.\nIf you have Microsoft 365 E3, you can also get add-ons, such as the Microsoft Defender Suite and the Microsoft Purview Suite to enhance your security and compliance capabilities.\nFor more information, see\nFind the best Microsoft 365 plan for your organization\n.\nPlan for and deploy\nThere are three ways to plan for and deploy the products, features, and components of Microsoft 365 for enterprise:\nIn partnership with FastTrack\n. With FastTrack, Microsoft engineers help you move to the cloud at your own pace. See\nFastTrack for Microsoft 365\n.\nWith the help of Microsoft Consulting Services or a\nMicrosoft partner\n. Consultants can analyze your current infrastructure and help you develop a plan to incorporate all the software and services of Microsoft 365 for enterprise.\nDo it yourself\n. Start with the\nNetworking roadmap\nto build out or verify your existing infrastructure and productivity workloads.\nAdditional Microsoft 365 products\nMicrosoft 365 Business Premium\n: Bring together the best-in-class productivity and collaboration capabilities with device management and security solutions to safeguard business data for small and midsize businesses.\nMicrosoft 365 Education\n: Empower educators to unlock creativity, promote teamwork, and provide a simple and safe experience in a single, affordable solution built for education.\nMicrosoft 365 Government\n: Empower United States public sector employees to work together, securely.\nMicrosoft 365 training\nTo learn more about Microsoft 365 and work toward a Microsoft 365 certification, you can start with\nMicrosoft 365 Fundamentals\n.\nSee also\nMicrosoft 365 for enterprise product page\nMicrosoft 365 Productivity Library\nLearn about Security Copilot inclusion in Microsoft 365 E5 subscription\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Microsoft 365 Licensing",
      "section": "Licensing"
    },
    "https://learn.microsoft.com/en-us/office365/servicedescriptions/microsoft-365-service-descriptions/microsoft-365-tenantlevel-services-licensing-guidance": {
      "content_hash": "sha256:41efbf65e9e4cd6107be47e2a8a0779ffa6a5171c4169ccd57dc5c1c63fdd1c4",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft 365 guidance for security & compliance\nFeedback\nSummarize this article for me\nFor the purposes of this article, a tenant-level service is an online service that is activated in part or in full for all users in the tenant (standalone license and/or as part of a Microsoft 365 or Office 365 plan). Appropriate subscription licenses are required for customer use of online services. To see the options for licensing your users to benefit from Microsoft 365 compliance features, download theâ¯\nMicrosoft 365 Comparison table for Enterprise and Frontline Workers Plans\nor the\nMicrosoft 365 Comparison table for Small and Medium Business\nPlans.\nSome tenant services aren't currently capable of limiting benefits to specific users. To review the terms and conditions governing the use of Microsoft products and Professional Services acquired through Microsoft Licensing programs, see theâ¯\nProduct Terms\n.\nMicrosoft Entra ID Governance\nMicrosoft Entra ID Governance allows you to balance your organization's need for security and employee productivity with the right processes and visibility. It uses entitlement management, access reviews, privileged identity management, and terms-of-use policies to ensure that the right people have the right access to the right resources.\nHow do users benefit from the service?\nMicrosoft Entra ID Governance increases users' productivity by making it easier to request access to apps, groups, and Microsoft Teams in one access package. Users can also be configured as approvers, without involving administrators. For access reviews, users can review memberships of groups with smart recommendations to take action on regular intervals.\nWhich licenses provide the rights for a user to benefit from the service?\nThe Microsoft Entra ID Governance capabilities are currently available in Microsoft Entra ID Governance and Microsoft Entra ID Governance Step Up for Microsoft Entra ID P2. These two products provide the rights for as many users as there are purchased seats to have the identity governance capabilities. Microsoft Entra ID Governance requires that the tenant also has an active subscription to Microsoft Entra ID P1 (formerly known as Azure Active Directory Premium P1) or Microsoft Entra ID P2 (formerly known as Azure Active Directory Premium P2) or a subscription that includes Microsoft Entra ID P1 or P2. Microsoft Entra ID Governance Step Up for Microsoft Entra ID P2 requires that the tenant also have an active subscription to Microsoft Entra ID P2 or a subscription that includes Microsoft Entra ID P2.\nHow is the service provisioned/deployed?\nMicrosoft Entra ID Governance features are enabled at the tenant level but implemented per user. For information about Microsoft Entra ID Governance, see\nWhat is Microsoft Entra ID Governance?\nHow can the service be applied only to users in the tenant who are licensed for the service?\nAdmins should ensure that they have enough seats of Microsoft Entra ID Governance for all employees in scope of or benefiting from Microsoft Entra ID Governance features, including access packages, access reviews, lifecycle workflows and privileged identity management. For instructions on how to scope Microsoft Entra ID Governance deployments, see:\nMicrosoft Entra entitlement management license requirements\nMicrosoft Entra access review license requirements\nLicense requirements to use Privileged Identity Management\nMicrosoft Entra ID Protection\nMicrosoft Entra ID Protection is a feature of the Microsoft Entra ID P2 plan that lets you detect potential vulnerabilities affecting your organization's identities, configure automated responses to detected suspicious actions that are related to your organization's identities, and investigate suspicious incidents and take appropriate action to resolve them.\nHow do users benefit from the service?\nSecOps analysts and security professionals benefit from having consolidated views of flagged users and risk events based on machine learning algorithms. End users benefit from the automatic protection provided through risk-based Conditional Access and the improved security provided by acting on vulnerabilities.\nWhich licenses provide the rights for a user to benefit from the service?\nMicrosoft 365 E5/A5/G5, Enterprise Mobility & Security A5/E5/G5, Microsoft Defender Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nFor details on capabilities included in the different plans available, see\nWhat is Microsoft Entra ID Protection?\nHow is the service provisioned/deployed?\nBy default, Microsoft Entra ID Protection features are enabled at the tenant level for all users within the tenant. For information about Microsoft Entra ID Protection, see\nWhat is Identity Protection?\nHow can the service be applied only to users in the tenant who are licensed for the service?\nAdmins can scope Microsoft Entra ID Protection by assigning risk policies that define the level for password resets and allowing access for licensed users only. For instructions on how to scope Microsoft Entra ID Protection deployments, see\nHow to configure and enable risk policies\n.\nFor more information, see\nMicrosoft Entra ID\nand\nMicrosoft Entra Workload ID\n.\nCompliance Program for Microsoft Cloud\nCompliance Program for Microsoft Cloud\nis designed to offer personalized customer support, education, and networking opportunities. By joining the program, customers will receive the unique chance to engage directly with regulators, industry peers and Microsoft experts in the areas of security, compliance, and privacy. This program replaces the existing Financial Services Industry (FSI) Compliance Program created in 2013.\nWho can access the Compliance Program for Microsoft Cloud?\nThe Compliance Program for Microsoft Cloud is available for organizations with Microsoft 365 and Office 365 licenses.\nCustomers who are currently enrolled in the FSI Compliance Program will need to purchase a subscription for the new Compliance Program for Microsoft Cloud. For more information, see\nCompliance Program for Microsoft Cloud\n.\nHow do users benefit from the service?\nEnterprise organizations that are looking to Microsoft to assist them in their cloud journey, such as risk assessors, compliance officers, internal auditors, privacy officers, regulatory Affairs/Legal, CISOs will benefit from this service. The following are example scenarios of available benefits that customers can receive:\nOngoing risk and compliance assistance for risk assessments to onboard to and use Microsoft cloud services.\nSupport of Microsoft and customer-managed controls for Microsoft cloud services.\nAssistance with internal audits, regulators, or a board level approval of using third-party cloud services.\nSupport with ongoing technical questions related to complex risk and compliance requirements in using our cloud services.\nDirect assistance in filling out a fixed number of customer risk and compliance questionnaires.\nA connection to regulators and industry experts to help solve questions with their compliance journey.\nHow is the service provisioned/deployed?\nBy default, the Compliance Program for Microsoft Cloud is enabled at the tenant level for all users that benefit from the service. For more information, see\nCompliance Program for Microsoft Cloud\n.\nMicrosoft Defender for Business\nMicrosoft Defender for Business is an endpoint security solution designed for small and medium-sized businesses (up to 300 employees). Defender for Business is available as a standalone solution and is also included as part of Microsoft 365 Business Premium. With this endpoint security solution, small and medium-sized business (SMB) organization devices are better protected from ransomware, malware, phishing, and other threats.\nFor more information, see\nMicrosoft Defender for Business\n.\nWhich licenses provide the rights for users to benefit from the service?\nMicrosoft Defender for Business is included as part of the Microsoft 365 Business Premium subscription plan.\nA standalone version of Defender for Business is also available as an option for small and medium business (SMBs) with up to 300 employees. To learn more, seeâ¯\nHow to get Microsoft Defender for Business\n.\nHow do users benefit from the service?\nThe addition of\nMicrosoft Defender for Business\ninto Microsoft 365 Business Premium strengthens Business Premiumâs existing productivity and security offering by adding cross-platform endpoint protection and sophisticated ransomware defenses with technologies like endpoint detection and response and automated investigation and remediation.\nThe standalone version of Defender for Business provides the option for small and medium businesses with up to 300 employees to get enterprise-grade endpoint security technology at an affordable price.\nHow is the service provisioned/deployed?\nIf you have Microsoft 365 Business Premium, you can access Defender for Business via the\nMicrosoft Defender portal\n.\nBy default, Microsoft Defender for Business features are enabled at the tenant level for all users within the tenant. For information on how to set up and configure Defender for Business, see\nMicrosoft Defender for Business documentation | Microsoft Docs\n.\nWhat is the Defender for Business servers add-on for Microsoft Defender for Business?\nMicrosoft Defender for Business servers provides endpoint security for Windows and Linux Servers for small and medium-sized businesses. The Defender for Business servers experience delivers the same level of protection for both clients and servers within a single admin experience inside of Defender for Business, helping you to protect all your endpoints in one location.\nFor more information, see\nGet Microsoft Defender for Business servers | Microsoft Learn\n.\nNote that the maximum quantity/seat cap is 60 licenses per customer for Defender for Business servers. If customers require more than 60 server licenses, please see\nMicrosoft Defender for Servers\n.\nWhich licenses provide the rights for a user to benefit from the service?\nDefender for Business servers is available as an add-on to organizations with:\nMicrosoft Defender for Business (standalone)\nMicrosoft 365 Business Premium\nCustomers are required to have at least one license of Microsoft 365 Business Premium or Microsoft Defender for Business to purchase and use Microsoft Defender for Business servers.\nReview the\nMicrosoft Defender for Business FAQ\nfor more information and links to more resources.\nFor more information, see\nMicrosoft Defender for Business and Microsoft Defender for Business Servers add-on\n.\nMicrosoft Defender for Cloud Apps\nMicrosoft Defender for Cloud Apps is a cloud access security broker (CASB) solution that gives customers flexibility in how to implement core capabilities and supporting multiple types of deployment.\nWhich licenses provide the rights for a user to benefit from the service?\nMicrosoft Defender for Cloud Apps is available as a standalone license and is also available as part of the following plans:\nEnterprise Mobility + Security E5\nMicrosoft 365 E5/A5/G5, Microsoft Defender Suite/EDU/GOV/FLW\nMicrosoft Purview Suite/EDU/GOV/FLW\nMicrosoft Defender + Purview Suite FLW\nMicrosoft 365 E5/F5/G5 Information Protection and Governance\nTo benefit from the Conditional Access App Control capabilities in Defender for Cloud Apps, users must also be licensed for Microsoft Entra ID P1, which is included in Enterprise Mobility + Security F1/F3/E3/A3/G3, Enterprise Mobility + Security E5, Microsoft 365 E3/A3/G3, Microsoft 365 E5/A5/G5, and Microsoft Defender Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW.\nTo benefit from automatic client-side labeling, users must be licensed for Azure Information Protection P2, which is included in Enterprise Mobility + Security E5/A5/G5, Microsoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/F5/G5 Information Protection and Governance.\nNote: Automatic server-side labeling requires Information Protection for Office 365 - Premium licenses (MIP_S_CLP2â¯orâ¯efb0351d-3b08-4503-993d-383af8de41e3). For reference, seeâ¯\nProduct names and service plan identifiers for licensing\n.\nHow is the service provisioned/deployed?\nBy default, Microsoft Defender for Cloud Apps is enabled at the tenant level for all users within the tenant.\nHow can the service be applied only to users in the tenant who are licensed for the service?\nAdmins can scope Microsoft Defender for Cloud Apps deployments to licensed users by using the scoped deployment capabilities available in the service. For more information, see\nScoped deployment\n.\nWhat is app governance?\nApp governance is a security and policy management capability designed for OAuth-enabled apps registered on Microsoft Entra ID. It delivers full visibility, remediation, and governance into how these apps and their users access, use, and share your sensitive data stored in Microsoft 365 through actionable insights and automated policy alerts and actions.\nWhich licenses provide the rights for a user to benefit from this capability?\nApp governance is included in Microsoft Defender for Cloud Apps and product offers that include Defender for Cloud Apps:\nMicrosoft Defender for Cloud Apps (standalone)\nEnterprise Mobility + Security E5/A5/G5\nMicrosoft 365 E5/A5/G5\nMicrosoft Defender Suite/EDU/GOV/FLW\nMicrosoft Purview Suite/EDU/GOV/FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nMicrosoft Defender + Purview Suite FLW\nFor more information, see\nApp governance in Microsoft 365\nand\nGet Started with App Governance\n.\nFor more information, see\nMicrosoft Defender for Cloud Apps\n.\nMicrosoft Defender for Endpoint\nMicrosoft Defender for Endpoint is an endpoint security solution that includes:\nRisk-based vulnerability management and assessment\nAttack surface reduction capabilities\nBehavioral based and cloud-powered next generation protection\nEndpoint detection and response (EDR)\nAutomatic investigation and remediation\nManaged hunting services\nFor more information, see\nMicrosoft Defender for Endpoint\n.\nWhich licenses provide the rights for users to benefit from the service?\nMicrosoft Defender for Endpoint Plan 1 (P1)\nMicrosoft Defender for Endpoint P1 delivers core endpoint protection capabilities such as next generation anti-malware, attack surface reduction rules, device control, endpoint firewall, network protection and more. For details, see\nMicrosoft Defender for Endpoint Plan 1 and Plan 2\n.\nMicrosoft Defender for Endpoint P1 is available as a standalone user subscription license and as part of Microsoft 365 E3/A3/G3.\nMicrosoft Defender for Endpoint Plan 2 (P2)\nMicrosoft Defender for Endpoint P2 delivers comprehensive endpoint protection capabilities including all the capabilities of Microsoft Defender for Endpoint P1 with additional capabilities such as endpoint detection and response, automated investigation and remediation, threat and vulnerability management, threat intelligence, sandbox, and Microsoft threat experts. For details, see\nMicrosoft Defender for Endpoint documentation\n.\nMicrosoft Defender for Endpoint P2, is available as a standalone license and as part of the following plans:\nWindows 11 Enterprise E5/A5\nWindows 10 Enterprise E5/A5\nMicrosoft 365 E5/A5/G5 (which includes Windows 10 or Windows 11 Enterprise E5)\nMicrosoft Defender Suite/EDU/GOV/FLW\nMicrosoft Defender + Purview Suite FLW\nMicrosoft Defender for Endpoint Server\nMicrosoft Defender for server is optimized for traditional on-prem server workloads, but also supports Windows and Linux servers. A separate license required for each Operating System Environment (OSE), for servers or virtual machines.â\nFor more information, see\nMicrosoft Defender for Endpoint\n.\nMicrosoft Defender for IoT â Enterprise IoT security\nMicrosoft Defender IoT â Enterprise IoT security integrates with Microsoft Defender for Endpoint to discover, continuously monitor, and manage vulnerabilities across your enterprise IoT devices from a single experience.\nMicrosoft Defender for IoT â Enterprise IoT security included with Microsoft 365 E5 and Microsoft 365 Defender Suite subscriptions\nMicrosoft Defender IoT â Enterprise IoT security is included in Microsoft 365 E5 and Microsoft 365 Defender Suite subscriptions. Customers with these subscriptions are entitled to Microsoft Defender IoT â Enterprise IoT security coverage for up to 5 eIoT devices per eligible user license.\nMicrosoft Defender for IoT â Enterprise IoT security per device add-on\nMicrosoft Defender IoT â Enterprise IoT security per device add-on is available for customers who have Microsoft Defender for Endpoint P2, or a subscription that includes Microsoft Defender for Endpoint P2:\nMicrosoft 365 A5/E5\nMicrosoft Defender Suite/EDU/FLW\nMicrosoft Defender + Purview Suite FLW\nWindows 10/11 Enterprise A5/E5.\nThe Microsoft Defender IoT â Enterprise IoT security per device add-on license covers one eIoT device per license.\nFor more details, see\nEnable Enterprise IoT security in Microsoft 365 with Defender for Endpoint - Microsoft Defender for IoT | Microsoft Learn\n.\nMicrosoft Defender Vulnerability Management\nMicrosoft Defender Vulnerability management is available as a standalone user subscription license and as an add-on for Microsoft Defender for Endpoint Plan 2 customers.\nDefender Vulnerability Management delivers asset visibility, intelligent assessments, and built-in remediation tools for Windows, macOS, Linux, Android, iOS, and network devices. Leveraging Microsoft threat intelligence, breach likelihood predictions, business contexts, and devices assessments, Defender Vulnerability Management rapidly and continuously prioritizes the biggest vulnerabilities on your most critical assets and provides security recommendations to mitigate risk.\nDefender Vulnerability Management standalone:\nCustomers who do not have Defender for Endpoint Plan 2 can complement their endpoint detection and response (EDR) solution with the Defender Vulnerability Management standalone to meet their vulnerability management program needs.\nDefender Vulnerability Management add-on:\nMicrosoft Defender for Endpoint Plan 2 includes vulnerability management capabilities that can be enhanced by adding new advanced vulnerability management tools included with the Microsoft Defender Vulnerability Management add-on.\nMicrosoft Defender Vulnerability Management add-on to Microsoft Defender for Endpoint for servers:\nProvides premium vulnerability management capabilities for customers with Microsoft Defender for Endpoint for servers.\nMicrosoft Defender for Servers Plan 1 and Defender for Servers Plan 2 also includes access to vulnerability management capabilities.\nFor more information, see\nMicrosoft Defender Vulnerability Management | Microsoft Learn\nand\nCompare Microsoft Defender Vulnerability Management plans and capabilities | Microsoft Learn\n.\nFor more information, see\nMicrosoft Entra ID Protection\n.\nWhat licenses provide the rights for a user to benefit from the service?\nMicrosoft Defender Vulnerability is available as a\nstandalone\nuser subscription license for commercial, education and government cloud customers.\nMicrosoft Defender Vulnerability Management is also available as an add-on to organizations with:\nMicrosoft Defender for Endpoint Plan 2 (standalone)\nMicrosoft 365 E5/A5/G5\nMicrosoft Defender Suite/EDU/GOV/FLW\nMicrosoft Defender + Purview Suite FLW\nWindows 11 Enterprise E5/A5/G5\nWindows 10 Enterprise E5/A5/G5\nMicrosoft Defender Vulnerability Management add-on to Microsoft Defender for Endpoint for servers is available to organizations with Microsoft Defender for Endpoint for servers. For details on included capabilities, see\nCompare Microsoft Defender Vulnerability Management plans and capabilities | Microsoft Learn\n.\nFor more information, see\nMicrosoft Defender Vulnerability Management\n.\nMicrosoft Defender for Identity\nMicrosoft Defender for Identity (formerly Azure Advanced Threat Protection) is a cloud service that helps protect enterprise hybrid environments from multiple types of advanced targeted cyber-attacks and insider threats. Microsoft Defender for Identity is a per user subscription license.\nHow do users benefit from the service?\nSecOp analysts and security professionals benefit from the ability of Microsoft Defender for Identity to detect and investigate advanced threats, compromised identities, and malicious insider actions. End users benefit by having their data monitored by Microsoft Defender for Identity.\nWhich licenses provide the rights for a user to benefit from the service?\nEnterprise Mobility + Security E5/A5, Microsoft 365 E5/A5/G5, Microsoft Defender Suite/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, and Microsoft Defender for Identity for Users provide the rights to benefit from Microsoft Defender for Identity.\nHow is the service provisioned/deployed?\nMicrosoft Defender for Identity features are enabled at the tenant level for all users within the tenant. For information on configuring Microsoft Defender for Identity, see\nCreate your Microsoft Defender for Identity instance\n.\nHow can the service be applied only to users in the tenant who are licensed for the service?\nSome tenant services, such as Microsoft Defender for Identity, aren't currently capable of limiting benefits to specific users. To review the terms and conditions governing the use of Microsoft products and Professional Services acquired through Microsoft Licensing programs, see the\nProduct Terms\n.\nFor more information, see\nMicrosoft Defender for Identity\n.\nMicrosoft Defender for Office 365\nMicrosoft Defender for Office 365 helps protect organizations against sophisticated attacks such as phishing and zero-day malware. Microsoft Defender for Office 365 also provides actionable insights by correlating signals from a broad range of data to help identify, prioritize, and provide recommendations on how to address potential threats.\nHow do users benefit from the service?\nMicrosoft Defender for Office 365 protects users from sophisticated attacks such as phishing and zero-day malware. For the full list of services provided in Plan 1 and Plan 2, see\nMicrosoft Defender for Office 365\n.\nWhich licenses provide the rights for a user to benefit from the service?\nMicrosoft Defender for Office 365 Plan 1 standalone, Microsoft 365 Business Premium, Microsoft 365 E5/A5/G5, Office 365 E5/A5/G5, Microsoft Defender Suite/EDU/GOV/FLW, and Microsoft Defender + Purview Suite FLW provide the rights for a user to benefit from Microsoft Defender for Office 365 Plan 1.\nMicrosoft Defender for Office 365 Plan 2 standalone, Microsoft 365 E5/A5/G5, Office 365 E5/A5/G5, Microsoft Defender Suite/EDU/GOV/FLW, and Microsoft Defender + Purview Suite FLW provide the rights for a user to benefit from Microsoft Defender for Office 365 Plan 2.\nThis quick reference will help you understand what capabilities come with each Microsoft Defender for Office 365 subscription. When combined with your knowledge of EOP features, it can help business decision makers determine what Microsoft Defender for Office 365 is best for their needs.\nMicrosoft Defender for Office 365 Plan 1 vs. Plan 2 Cheat Sheet\nDefender for Office 365 Plan 1\nDefender for Office 365 Plan 2\nConfiguration, protection, and detection capabilities:\nSafe Attachments\nSafe Links\nSafe Attachments for SharePoint, OneDrive, and Microsoft Teams\nAnti-phishing protection in Defender for Office 365\nReal-time detections\nDefender for Office 365 Plan 1 capabilities\n--- plus ---\nAutomation, investigation, remediation, and education capabilities:\nThreat trackers & campaign views\nThreat explorer\nAutomated investigation and response\nAttack simulation training\nMicrosoft Defender XDR Integration\nFor more information, go to\nOffice 365 Security including Microsoft Defender for Office 365 and Exchange Online Protection - Office 365 | Microsoft Docs\n.\nHow is the service provisioned/deployed?\nBy default, Microsoft Defender for Office 365 features are enabled at the tenant level for all users within the tenant.\nHow can the service be applied only to users in the tenant who are licensed for the service?\nAdmins can scope Microsoft Defender for Office 365 deployments to licensed users by using the policy assignment capabilities available in the service.\nFor information on configuring Microsoft Defender for Office 365 policies for licensed users, see\nMicrosoft Defender for Office 365 step-by-step guides and how to use them\n. For information on how Microsoft Defender for Office 365 fits your needs, see\nWhy do I need Microsoft Defender for Office 365?\n.\nFor information on configuring Safe Links for licensed users, see\nSafe Links in Microsoft Defender for Office 365\n.\nFor information on configuring Safe Attachments for licensed users, see\nSafe Attachments in Microsoft Defender for Office 365\n.\nLicensing Terms\nFor licensing terms and conditions for products and servicesâ¯purchasedâ¯through Microsoft Commercial Volume Licensing Programs, see the\nProduct Terms site\n.\nLicenses must beâ¯acquiredâ¯for users or mailboxes falling under one or more of the following scenarios:\nAny user that accesses a mailbox thatâ¯benefitsâ¯from Defender for Office 365 protections.\nShared mailboxes thatâ¯benefitâ¯from Defender for Office 365 protections.\nIf Safe Attachments protection for SharePoint, OneDrive for Business, or Teams is turned on, all users that access SharePoint, OneDrive for Business, or Teams.\nAny user that uses Microsoft 365 apps or Teams when Safe Links protections are enabled.\nInformation Protection: Microsoft Purview Advanced Message Encryption\nFor information on Microsoft Purview Advanced Message Encryption, see\nMicrosoft Purview Information Protection Advanced Message Encryption\n.\nInformation Protection: Microsoft Purview Message Encryption\nFor information on Microsoft Purview Message Encryption, see\nMicrosoft Purview Information Protection Message Encryption\n.\nMicrosoft Priva\nFor more information, see\nMicrosoft Priva\n.\nPrivileged access management in Office 365\nPrivileged access management (PAM)\nprovides granular access control over privileged admin tasks in Office 365. After enabling PAM, to complete elevated and privileged tasks, users will need to request just-in-time access through an approval workflow that is highly scoped and time-bound.\nHow do users benefit from the service?\nEnabling PAM lets organizations operate with zero standing privileges. Users benefit from the added layer of defense against vulnerabilities arising from standing administrative access that provides unfettered access to their data.\nWhich licenses provide the rights for a user to benefit from the service?\nOffice 365 E5/A5, Microsoft 365 E5/A5, Microsoft Purview Suite/EDU/FLW and Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/A5/F5 Insider Risk Management provide the rights for a user to benefit from PAM.\nHow is the service provisioned/deployed?\nBy default, PAM features are enabled at the tenant level for all users within the tenant. For information on configuring PAM policies, see\nGet started with privileged access management\n.\nHow can the service be applied only to users in the tenant who are licensed for the service?\nCustomers can manage PAM on a per-user basis through approver group and access policies, which can be applied to licensed users.\nMicrosoft Purview Audit\nFor more information, see\nMicrosoft Purview Audit service description\nMicrosoft Purview Communication Compliance\nFor more information, see\nMicrosoft Purview Communication Compliance\nMicrosoft Purview Compliance Manager\nFor more information, see\nMicrosoft Purview Compliance Manager\nMicrosoft Purview Customer Lockbox\nFor more information, see\nMicrosoft Purview Customer Lockbox\nMicrosoft Purview Data Connectors\nFor more information, see\nMicrosoft Purview Data Connectors\nMicrosoft Purview Data Lifecycle Management & Microsoft Purview Records Management\nMicrosoft Purview Data Lifecycle Management\n(formerly Microsoft Information Governance) and\nMicrosoft Purview Records Management\nprovide you with tools and capabilities to retain the content that you need to keep and delete the content that you do not need. Often organizations retain and delete content to meet compliance and data regulatory requirements. Deleting content that no longer has business value also helps you manage risk and liability.\nBoth Data Lifecycle Management and Records Management use retention policies, retention labels, and retention label policies to enforce retention and deletion settings. Additionally, this area includes email archiving functionality.\nLicensing for retention policies\nFor organization-wide, location-wide, or include/exclude retention policies, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5/E3/A3/G3, Business Premium\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3\nIf the retention policy location is an Exchange mailbox, then the following licenses also provide user rights:\nExchange Plan 2\nExchange Online Archiving\nIf the retention policy location is SharePoint or OneDrive for Business, the following licenses also provide user rights:\nSharePoint Plan 2\nIf the retention policy location is Microsoft Teams chats, channels, or private channels, then the following licenses also provide user rights. The retention or deletion period must be more than 30 days for the plans that\nare underlined\n:\nMicrosoft 365 E5/G5/A5/E3/G3/A3/\nF3/F1\n,\nBusiness Basic\n,\nBusiness Standard\n, and\nBusiness Premium\nOffice 365 E5/G5/A5/E3/G3/A3/\nF3/E1/G1\nMicrosoft Purview Suite FLW and Microsoft Defender + Purview Suite FLW add-on plans\nIf the retention policy uses an adaptive policy scope, then one of the following licenses is required to provide user rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nOffice 365 E5/A5/G5\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nIf the retention policy applies to Microsoft 365 Copilot interactions, the following licenses provide user rights:\nMicrosoft 365 E3/E5 + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft Purview Suite + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft E5 Information Protection and Governance + Microsoft 365 Copilot\nLicensing for retention labels\nFor retention label creation, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F3/F1/Business Premium\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3/F3/E1/A1/G1\nThe following retention label creation settings:\nStart the retention period based on an event type\nTrigger a disposition review at the end of the retention period\nDuring the retention period mark items as a record or a regulatory record\nAfter the retention period, automatically change the retention label,\nRequire these specific licenses to provide users rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nOffice 365 E5/A5/G5\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nLicensing for retention label policies\nRetention labels are applied to files and emails in one of three ways:\nPublishing labels so they are available to end users for manual labeling.\nAuto-applying them through retention label policy configuration.\nThrough other application methods such as default labels.\nTo publish retention labels, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F3/F1/Business Premium\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3/F3/E1/A1/G1\nIf the publishing location is an Exchange mailbox, then Exchange Online Plan 1 and Plan 2 licenses provide user rights.\nIf the publishing location is SharePoint Online or OneDrive, SharePoint Online Plan 1 and Plan 2 licenses provide user rights.\nThe following deployment methods for retention labels require specific licensing:\nAuto-apply to content that contains sensitive information\nAuto-apply to content that contains specific words, phrases, or properties\nApply a default retention label to a SharePoint document library, folder, or document set\nUsing an adaptive policy scope in the retention label policy\nThe following licenses provide user rights for those deployment methods:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nTo auto-apply retention labels using a trainable classifier, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nLicenses for other retention label application methods\nTo apply a label using an Outlook rule or an Outlook default folder policy, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F3/F1/Business Premium\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3/F3/E1/A1/G1\nTo apply a retention label using a SharePoint Syntex model, the following licenses provide user rights. Additionally, you will need to purchase the appropriate SharePoint Syntex licenses.\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nTo use the file plan to maintain retention labels, including import and export, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nTo use adaptive policies scopes to dynamically target Microsoft Copilot for Microsoft 365 interaction retention policies to specific users and/or retain the exact version of a document shared in a Microsoft 365 Copilot interaction, the following licenses provide user rights:\nMicrosoft 365 E5 + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft Purview Suite + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft 365 E5 Information Protection and Governance + Microsoft 365 Copilot\nTo use the Priority cleanup policy to apply labels that bypass existing retention or eDiscovery holds, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nLicenses for email archiving\nTo bulk-import PST files to Exchange Online mailboxes, the following licenses provide user rights:\nExchange Online P2\nMicrosoft 365 E5/A5/G5/E3/A3/G3\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3\nTo enable an archive mailbox and auto-expanding archive, the following licenses provide user rights:\nArchive mailbox limited to 50 GB\nExchange Online Plan 1\nOffice 365 E1\nArchive mailbox limited to 1.5 TB\nExchange Online Archiving\nExchange Online Plan 2\nMicrosoft 365 E5/A5/G5/E3/A3/G3\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5/E3/A3/G3\nMicrosoft 365 Business Premium\nWhich users need a license?\nAny user benefiting from the service requires a license. For more information about service terms & conditions, see\nProduct Terms\n. Here are examples of users benefiting from the service:\nUsers with the following assigned roles found in the Microsoft Purview compliance portal: disposition management, Record Management, Retention Management, View-Only Record Management, View-Only Retention Management.\nSharePoint site owners and members when a retention policy or retention label policy is used on the site. Site visitors do not need a license.\nMicrosoft 365 Group owners and members when a retention policy or retention label policy is used on the site, mailbox, or Teams messages.\nFor user mailboxes, the user must have the required license assigned.\nUsers, SharePoint sites, and Microsoft 365 Groups included in an adaptive policy scope.\nFor many features, a shared or resource mailbox does not need a license assigned. For features requiring one of the following licenses, a shared, or resource mailbox does need a license assigned to provide usage rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nInactive mailboxes do not require a usage license.\nAdditionally, shared mailboxes are limited to 50 GB without the need for an Exchange add-on. To increase the size limit to 100 GB, the shared mailbox requires Exchange Online Plan 2 or Exchange Online Archiving + Exchange Online Plan 1.\nMicrosoft Purview Data Loss Prevention: Endpoint Data Loss Protection (DLP)\nFor more information, see\nMicrosoft Purview Data Loss Prevention: Endpoint Data Loss Protection (DLP)\nMicrosoft Purview Data Loss Prevention: Data Loss Prevention (DLP) for Exchange Online, SharePoint Online, and OneDrive for Business\nFor more information, see\nMicrosoft Purview Data Loss Prevention: Data Loss Prevention (DLP) for Exchange Online, SharePoint Online, and OneDrive for Business\n.\nMicrosoft Purview Data Loss Prevention: Data Loss Prevention (DLP) for Teams\nFor more information, see\nMicrosoft Purview Data Loss Prevention: Data Loss Prevention (DLP) for Teams\nMicrosoft Purview Data Loss Prevention: Graph APIs for Teams Data Loss Prevention (DLP) and for Teams Export\nFor more information, see\nMicrosoft Purview Data Loss Prevention: Graph APIs for Teams Data Loss Prevention (DLP) and for Teams Export\nMicrosoft Purview Data Loss Prevention (DLP) forâ¯cloudâ¯apps inâ¯the browser\nFor more information, see\nMicrosoft Purview Data Loss Prevention (DLP) forâ¯cloudâ¯apps inâ¯the browser\n.\nMicrosoft Purview Data Loss Prevention (DLP) forâ¯cloudâ¯apps inâ¯the accessed via the network\nFor more information, see\nMicrosoft Purview Data Loss Prevention (DLP) forâ¯cloudâ¯appsâ¯accessed via theâ¯network\n.\nMicrosoft Purview eDiscovery\nFor more information, see\nMicrosoft Purview eDiscovery\nMicrosoft Purview Information Barriers\nFor more information, see\nMicrosoft Purview Information Barriers\nMicrosoft Purview Information Protection: Customer Key\nFor more information, see\nMicrosoft Purview Information Protection: Customer Key\nMicrosoft Purview Information Protection: Data classification analytics: Overview Content & Activity Explorer\nFor information on Data classification analytic capabilities, Activity Explorer, and Content Explorer, see\nMicrosoft Purview Information Protection: Data classification analytics: Overview Content & Activity Explorer\n.\nMicrosoft Purview Information Protection: Double Key Encryption\nFor more information, see\nMicrosoft Purview Information Protection: Double Key Encryption\nMicrosoft Purview Information Protection: Sensitivity labeling\nFor more information, see\nMicrosoft Purview Information Protection: Sensitivity labeling\nWhich licenses provide the rights for a user to benefit from the service?\nFor manual sensitivity labeling, the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium/OneDrive for Business (Plan 2)\nEnterprise Mobility + Security E3/E5\nOffice 365 E5/A5/E3/A3\nAIP Plan 1\nAIP Plan 2\nNote\nMicrosoft 365 Apps require user-based subscription licensing for the users to use sensitivity labels within the Office clients. Device-based licensing isn't supported.\nMicrosoft Purview Insider Risk Management\nFor more information, see\nMicrosoft Purview Insider Risk Management\nInsider Risk Management Forensic Evidence\nFor more information, see\nMicrosoft Purview Insider Risk Management Forensic Evidence\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "M365 Licensing Guidance",
      "section": "Licensing"
    },
    "https://learn.microsoft.com/en-us/office365/servicedescriptions/microsoft-365-service-descriptions/microsoft-365-tenantlevel-services-licensing-guidance/microsoft-purview-service-description": {
      "content_hash": "sha256:b9d749a3a531bf6925212a277b6846c71226167ab5dc2560ec1c8a9c8c0346df",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nMicrosoft Purview service description\nFeedback\nSummarize this article for me\nMicrosoft Purview is a comprehensive set of solutions that can help your organization govern, protect, and manage data, wherever it lives. Microsoft Purview solutions provide integrated coverage and help address the fragmentation of data across organizations, the lack of visibility that hampers data protection and governance, and the blurring of traditional IT management roles.\nAvailable plans\nFor the purposes of this article, a tenant-level service is an online service that is activated in part or in full for all users in the tenant (standalone license and/or as part of a Microsoft 365 or Office 365 plan). Though some tenant services are currently not capable of limiting benefits to specific users, appropriate subscription licenses are required for use of each online service. To review the terms and conditions governing the use of Microsoft products and Professional Services acquired through Microsoft Licensing programs, see theâ¯\nProduct Terms\n.\nTo view how users benefit from Microsoft 365 features, download theâ¯\nMicrosoft 365 Comparison table for Enterprise and Frontline Workers\nPlans or the\nMicrosoft 365 Comparison table for Small and Medium Business\nPlans.\nWhich users need a license?\nAny user benefiting from the service requires a license. For more information about service terms & conditions, see the\nProduct Terms\n. Following are some examples of users benefiting from the service in Microsoft Purview; however, this list isn't exhaustive:\nUsers with a Purview role assigned for use in the Microsoft Purview portal.\nExchange user mailboxes, OneDrive accounts, Teams chats, and devices are associated with a user account, so the user must have the required license assigned when a Purview policy or feature is used in these locations.\nFor shared locations, such as SharePoint sites, Microsoft 365 Groups, and Teams channel messages, users with the owner or member role must have the required license assigned when a Purview policy or feature is used on the site, mailbox, or Team. Users with visitor or view-only roles don't need a license.\nFor features requiring one of the following licenses, a shared or resource mailbox does need one of the following licenses to provide usage rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Defender Suite/EDU/GOV/FLW\nMicrosoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection and Governance\nMicrosoft 365 E5/A5/G5/F5 eDiscovery and Audit\nMicrosoft 365 E5/A5/G5/F5 Insider Risk Management\nOffice 365 E5/A5/G5\nInactive mailboxes don't require a usage license.\nFor information about licensing about Microsoft Purview Data Security Posture Management for AI, see\nConsiderations for deploying Microsoft Purview Data Security Posture Management for AI & data security and compliance protections for Microsoft Copilot and other generative AI apps | Microsoft Learn\n.\nFeature availability\nMicrosoft Purview Audit (Standard)**\nMicrosoft Purview Audit (Standard) provides you with the ability to log and search for audited activities and power your forensic, IT, compliance, and legal investigations. To learn more, see\nLearn about auditing solutions in Microsoft Purview\n.\nFeature\nMicrosoft 365 E5 + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft 365 Copilot\nMicrosoft 365 E5/A5/G5\nAudit (Standard)\nYes\nYes\nYes\nAudit (Standard) for Microsoft 365 Copilot interactions\nYes\nYes\nNo\nMicrosoft Purview Audit (Premium)\nAudit (Premium) (formerly named Microsoft 365 Advanced Audit) provides one-year retention of audit logs for user and admin activities and provides the ability to create custom audit log retention policies to manage audit log retention for other Microsoft 365 services. It also provides access to crucial events for investigations and high-bandwidth access to the Office 365 Management Activity API.\nUsers benefit from Audit (Premium) because audit records related to user activity in Microsoft 365 services can be retained for up to one year. Additionally, high-value auditing events are logged, such as when items in a user's mailbox are accessed or read.\nBy default, Audit (Premium) is enabled at the tenant level for all users that benefit from the service, and automatically provides one-year retention of audit logs for activities (performed by users with the appropriate license) in Microsoft Entra ID, Exchange, and SharePoint.\nAdditionally, organizations can use audit log retention policies to manage the retention period for audit records generated by activity in other Microsoft 365 services.\nOne-year retention of audit logs and the auditing of crucial events only apply to users with the appropriate license. Additionally, admins can use audit log retention policies to specify shorter retention durations for the audit logs of specific users.\n10-year retention of audit logs only applies to users with the appropriate add-on license.\nFeature\nMicrosoft 365 E5 + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft 365 Copilot\nMicrosoft 365 Purview Suite + Copilot\n1\nMicrosoft 365 E5 eDiscovery & Audit + Copilot\n1\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 eDiscovery and Audit, Office 365 E5/A5/G5\nAudit (Premium)\nYes\nNo\nYes\nYes\nAudit (Premium) for Microsoft 365 Copilot interactions\nYes\nNo\nYes\nNo\nFor more information about Audit, check out the following resources:\nFor more information, seeâ¯\nAudit (Premium)\nâ¯andâ¯\nAudit (Standard)\n.\nUsers benefit from\nAudit (Premium)\nbecause audit records related to user activity in Microsoft 365 services can be retained for up to one year. Additionally, high-value auditing events are logged, such as when items in a user's mailbox are accessed or read.\nThe 10-year Audit Log Retention functionality is also enabled using the same retention policies. For more information, seeâ¯\nManage audit log retention policies\n.\nMicrosoft Purview Collection Policies\nCollection policies are a configuration option in the Microsoft Purview portal that allows administrators to fine-tune what are the signals and data that are available to Purview solutions at the tenant level. This fine-tuning includes specifying which Sensitive Information Types (SITs) are classified, what activities are collected, and what AI prompts/responses are stored. Collection policies fine-tuning also scope the signals sent to other Purview solutions including Data Security Posture Management, Insider Risk Management, Communication Compliance, eDiscovery, and more.\nCollection Policies are designed to streamline discovery of relevant information rather than to apply enforcement on that information. The key benefits of Collection Policies include granular control for regulatory compliance, noise reduction, resource efficiency, and expanded coverage to cloud apps.\nThere are no licensing requirements to apply collection policies. Instead, you must be licensed for the workload for which you're creating the policy. For example, creating a collection policy that includes devices requires endpoint DLP licensing, as the device data source is available under that licensing tier. Similarly, creating a collection policy with network data protection requires the tenant to be linked to an Azure subscription as a prerequisite, since network-based enforcement is a pay-as-you-go feature.\nMicrosoft Purview Communications Compliance\nMicrosoft Purview Communication Compliance is an insider risk solution that helps you detect, capture, and act on inappropriate messages that can lead to potential data security or compliance incidents within your organization. Communication compliance evaluates text and image-based messages in Microsoft and third-party apps (Teams, Copilot for Microsoft 365, Viva Engage, Outlook, WhatsApp, etc.) for potential business policy violations including inappropriate sharing of sensitive information, threatening or harassing language as well as potential regulatory violations (such as stock and capital manipulations).\nCommunication compliance's mission is to foster safe and compliant communications across customers' enterprise communication channels. With role-based access controls, human investigators can take remediation actions such as removing a message from Teams or notifying senders of potentially inappropriate conduct.\nCommunication compliance uses machine learning models and keyword matching to identify messages containing potential business conduct or regulatory policy violations that are then reviewed by an investigator. Communication compliance cultivates user privacy with pseudonymization and responsible use of the product by providing role-based access controls.\nFeature\nMicrosoft 365 E5 + Microsoft 365 Copilot\nMicrosoft 365 Purview Suite + Microsoft 365 Copilot\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/A5/F5/G5 Insider Risk Management\nOffice 365 E5/A5/G5\nCommunication Compliance\nYes\nYes\nYes\nYes\nMicrosoft Copilot for Microsoft 365 prompt and response analysis\nYes\nYes\nNo\nNo\nMicrosoft Teams chats\nYes\nYes\nYes\nYes\nViva Engage conversations\nYes\nYes\nYes\nYes\nExchange Online emails\nYes\nYes\nYes\nYes\nFor more information, seeâ¯\nGet started with communication compliance\n.\nMicrosoft Purview Compliance Manager\nCompliance Manager\nâ¯is a feature in the Microsoft Purview that helps you manage your organizationâs compliance requirements with greater ease and convenience. Compliance Manager can help you throughout your compliance journey, from taking inventory of your data protection risks to managing the complexities of implementing controls, staying current with regulations and certifications, and reporting to auditors.\nCompliance Manager helps simplify compliance and reduce risk by providing:\nPrebuilt assessments for common industry and regional standards and regulations.â¯\nWorkflow capabilities to help you efficiently complete your risk assessments through a single tool.\nDetailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. For actions managed by Microsoft, youâll see implementation details and audit results.\nA risk-based compliance score to help you understand your compliance posture by measuring your progress in completing improvement actions.\nCompliance Manager is available to organizations with Office 365 and Microsoft 365 licenses (incl. Business Premium), and to US Government Community Cloud (GCC), GCC High, and Department of Defense (DoD) customers. Assessment availability and management capabilities depend on your licensing agreement.\nFeature\nOffice 365 and Microsoft 365 licenses (incl. Business Premium), and to US Government Community Cloud (GCC), GCC High, and Department of Defense (DoD) customers\nCompliance Managerâ¯\nYes\nLearn more about theâ¯\nlist of premium templates\nfor Compliance Manager.\nMicrosoft Purview Customer Lockbox\nCustomer Lockbox provides an extra layer of control by offering customers the ability to give explicit access authorization for service operations. By demonstrating that procedures are in place for explicit data access authorization, Customer Lockbox can also help organizations meet certain compliance obligations such as HIPAA and FedRAMP.\nCustomer Lockbox ensures that no one at Microsoft can access customer content to perform a service operation without the customer's explicit approval. Customer Lockbox brings the customer into the approval workflow for requests to access their content. Occasionally, Microsoft engineers are involved during the support process to troubleshoot and fix customer-reported issues. In most cases, issues are fixed through extensive telemetry and debugging tools that Microsoft has in place for its services. However, there can be cases that require a Microsoft engineer to access customer content to determine the root cause and fix the issue. Customer Lockbox requires the engineer to request access from the customer as a final step in the approval workflow. This access gives organizations the option to approve or deny these requests, which gives them direct control over whether a Microsoft engineer can access the organizations' end-user data. Admins can turn on Customer Lockbox in the Microsoft 365 admin center.\nWhen Customer Lockbox is turned on, Microsoft is required to obtain an organization's approval before accessing any of their content.\nFeature\nOffice 365 E5/A5/G5\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/A5/F5/G5 Insider Risk Management\nCustomer Lockbox\nYes\nYes\nFor more information, seeâ¯\nCustomer Lockbox\n.\nMicrosoft Purview Data Connectors\nMicrosoft provides third-party data connectors that can be configured in the Microsoft Purview portal. For a list of data connectors provided by Microsoft, see the\nThird-party data connectors\nâ¯table. This table also summarizes the compliance solutions that you can apply to third-party data after you import and archive data in Microsoft 365, and links to the step-by-step instructions for each connector.\nThe primary benefit of using Data Connectors (formerly named Microsoft 365 Data Connectors) to import and archive third-party data in Microsoft 365 is that you can apply various Microsoft Purview solutions to the data after importing it. This helps ensure that your organization's non-Microsoft data is in compliance with the regulations and standards that affect your organization.\nFor data connectors in the Microsoft Purview portal that are provided by a Microsoft partner, your organization needs a business relationship with the partner before you can deploy those connectors.\nData Connectors services are a tenant-level value. Every user intended to benefit from this service must be licensed.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft 365 E5/A5/F5/G5 Information Protection & Governance, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Insider Risk Management, Microsoft 365 E5/A5/F5/G5 eDiscovery and Audit\nOffice 365 E5/A5/G5\nData Connectors\nYes\nYes\nMicrosoft Purview Data Lifecycle & Records Management\nFor more information, see:\nMicrosoft Purview Data Lifecycle and Records Management service description - Service Descriptions | Microsoft Learn\nMicrosoft Data Loss Prevention Endpoint Data Loss Protection (DLP)\nEndpoint data loss prevention\n(Endpoint DLP) extends the activity detection and protection capabilities of DLP to sensitive items that are physically stored on Windows 10, Windows 11, and macOS (Catalina 10.15 and higher) devices.\nOrganizations can use Microsoft Purview Data Loss Prevention (DLP) to detect activity on items determined to be sensitive and to help prevent the unintentional sharing of those items. For more information on DLP, see\nLearn about data loss prevention\n.\nEndpoint data loss prevention\n(Endpoint DLP) extends the activity detection and protection capabilities of DLP to sensitive items that are physically stored on Windows 10, Windows 11, and macOS (Catalina 10.15 and higher) devices.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection & Governance\nEndpoint Data Loss Prevention (DLP)\nYes\nFor more information, seeâ¯\nGet started with Endpoint data loss prevention - Microsoft Purview (compliance) | Microsoft Docs and Learn about data loss prevention - Microsoft Purview (compliance) | Microsoft Docs\n.\nWith the help ofâ¯\nMicrosoft Purview compliance portal\n, Endpoint DLP policies can be scoped to users logging into onboarded devices. Policies are evaluated when a scoped user logs onto an onboarded device. Review the\nMicrosoft Endpoint DLP interactive guide\nâ¯for devices for more details.\nFor more information about using DLP policies, seeâ¯\nOverview of data loss prevention\n.\nMicrosoft Purview Data Loss Prevention (DLP) for cloud apps in the browser\nIn Microsoft Purview, organizations can implement data loss prevention (DLP) by defining and applying DLP policies. With a DLP policy, admins can apply inline data protection to identify, audit, and protect sensitive data sharing with unmanaged cloud apps in the browser.\nUsing theâ¯\nMicrosoft Purview portal\n, admins can configure DLP policies and scope inline data protections to data sharing with cloud apps in the browser.\nLearn more about browser data security features and supported locations\n.\nThe ability to detect and protect sensitive data shared to unmanaged apps from managed devices in Edge for Business is a pay-as-you-go capability.\nLearn more about pay-as-you-go-capabilities\n. Scenarios where data in Entra-registered (managed) apps is shared protected while using Edge for Business are included in a Microsoft 365 E5 or equivalent license.\nFeature\nMicrosoft 365 E5/A5, Microsoft Purview Suite/EDU/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5 Information Protection and Governance\nOffice 365 E5/A5\nPurview Data Loss Prevention (DLP) inline data protection for data sharing to cloud apps in the browser.\nYes\nYes\nMicrosoft Purview Data Loss Prevention (DLP) for cloud apps accessed via the network\nIn Microsoft Purview, organizations can implement data loss prevention (DLP) by defining and applying DLP policies. With a DLP policy, admins can apply inline data protection to identify, monitor, and protect sensitive data sharing at the network level with cloud apps.\nUsing theâ¯\nMicrosoft Purview portal\n, admins can configure DLP policies and scope inline protections to data sharing with cloud apps across the network.\nLearn more about network data security features and supported locations\n.\nThese features are pay-as-you-go capabilities.\nLearn more about pay-as-you-go-capabilities\n.\nFeature\nMicrosoft 365 E5/A5, Microsoft Purview Suite/EDU/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5 Information Protection and Governance\nOffice 365 E5/A5\nPurview Data Loss Prevention (DLP) inline protection for data sharing across the network.\nYes\nYes\nMicrosoft Purview Data Loss Prevention (DLP) for Teams\nWith DLP for Teams, organizations can block chats and channel messages that contain sensitive information, such as financial information, personally identifying information, health-related information, or other confidential information.\nSenders benefit by having sensitive information in their outgoing chat and channel messages inspected for sensitive information, as configured in the organization's DLP policy.\nBy default, Teams chat and channel messages are anâ¯\nenabled Location (workload)\nfor these DLP features for all users within the tenant. To enable Data Loss Prevention for Teams, the \"Microsoft Communications DLP\" service must be selected under one of the above licenses in theâ¯\nMicrosoft 365 Administration\nâ¯portal.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nPurview Data Loss Prevention (DLP) for Teams\nYes\nMicrosoft Purview Data Loss Prevention: Data Loss Prevention (DLP) for Exchange Online, SharePoint Online, and OneDrive for Business\nFor the purposes of this article, a tenant-level service is an online service that is activated in part or in full for all users in the tenant (standalone license and/or as part of a Microsoft 365 or Office 365 plan). Appropriate subscription licenses are required for customer use of online services. To see the options for licensing your users to benefit from Microsoft 365 security features, download the\nMicrosoft 365 Comparison table for Enterprise and Frontline Workers Plans\nâ¯or theâ¯\nMicrosoft 365 Comparison table for Small and Medium Business\nâ¯Plans.\nSome tenant services aren't currently capable of limiting benefits to specific users. To review the terms and conditions governing the use of Microsoft products and Professional Services acquired through Microsoft Licensing programs, see the\nProduct Terms\n.\nWith Microsoft Purview Data Loss Prevention for Exchange Online, SharePoint Online, and OneDrive for Business (formerly named Microsoft Office 365 Data Loss Prevention), organizations can identify, monitor, and automatically protect sensitive information across emails and files (including files stored in Microsoft Teams file repositories).\nWhich licenses provide the rights for a user to benefit from the service?\nMicrosoft 365 E5/A5/G5/E3/A3/G3, Microsoft 365 Business Premium, SharePoint Online Plan 2, OneDrive for Business (Plan 2), Exchange Online Plan 2\nOffice 365 E5/A5/G5/E3/A3/G3\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nHow do users benefit from the service?\nUsers benefit from DLP for Exchange Online, SharePoint Online, and OneDrive for Business when their emails and files are being inspected for sensitive information, as configured in the organization's DLP policy.\nHow is the service provisioned/deployed?\nBy default, Exchange Online emails, SharePoint sites, and OneDrive accounts are enabled locations (workloads) for these DLP features for all users within the tenant. For more information about using DLP policies, see Overview of data loss prevention.\nHow can the service be applied only to users in the tenant who are licensed for the service?\nAdmins can customize locations (workloads), include users, and exclude users in the Microsoft Purview compliance portal.\nData loss prevention (DLP) policy tips for Outlook for Microsoft 365\nFor advanced DLP policy tip support, which makes additional DLP conditions, advanced classifiers, oversharing dialog, and more available, these licenses are required for each scoped user:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW\nMicrosoft 365 E5/A5/F5/G5 Information Protection & Governance\nFor more information, see\nData loss prevention policy tip reference for Outlook for Microsoft 365\n.\nLearn more\nFor more information, seeâ¯\nLearn about data loss prevention\n.\nMicrosoft Purview Data Loss Prevention Graph APIs for Teams Data Loss Prevention (DLP) and for Teams Export\nThese APIs let developers build Security and Compliance apps that can âlistenâ to Microsoft Teams messages in near-real time or export teams messages in 1:1/group chat or Teams channels. These APIs enable DLP and other Information Protection and Governance scenarios for both customers and ISVs. Additionally, Microsoft Graph Patch API allows applying DLP actions to Teams messages.\nData loss prevention (DLP)\ncapabilities are widely used in Microsoft Teams, particularly as organizations have shifted to remote work. If your organization has DLP, you can now define policies that prevent people from sharing sensitive information in a Microsoft Teams channel or chat session.\nInformation protection and governance capabilities are widely used in Microsoft Teams, particularly as organizations have shifted to remote work. Withâ¯\nTeams Export API\n, data can be exported to a third-party eDiscovery or Compliance Archiving application to ensure compliance practices are met.\nAPI access is configured at the tenant level. To enable Microsoft Graph APIs for Teams DLP, the âMicrosoft Communications DLPâ service must be selected under one of the above licenses in theâ¯\nMicrosoft 365 Administration\n.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nPurview Data Loss Prevention Graph APIs for Teams Data Loss Prevention (DLP) and for Teams Export\nYes\nFor more information on the seeded capacity and consumption fees, see\nGraph requirements for accessing chat messages\n.\nMicrosoft Purview Data Loss Prevention (DLP) for Microsoft 365 Copilot\nIn Microsoft Purview, organizations can implement data loss prevention by defining and applying DLP policies. With a DLP policy, admins can identify, monitor, and automatically protect sensitive items across different locations. DLP for Microsoft 365 Copilot as a location allows organizations to identify sensitive content based on sensitivity labels and exclude them from Copilot processing.\nUsing the\nMicrosoft Purview portal\n, admins can configure DLP policies and scope Microsoft 365 Copilot as a location.\nLearn more about Microsoft 365 Copilot as a policy location\n.\nFeature\nMicrosoft 365 E5/A5, Microsoft Purview Suite/EDU/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5 Information Protection and Governance\nOffice 365 E5/A5\nPurview Data Loss Prevention (DLP) for Copilot\nYes\nYes\nMicrosoft Purview eDiscovery\neDiscovery (Standard) enables you to create eDiscovery cases and assign eDiscovery managers to specific cases. eDiscovery managers can only access the cases of which they're members. eDiscovery (Standard) also lets you associate searches and exports with a case and lets you place an eDiscovery hold on content locations relevant to the case.\neDiscovery (Premium)\nprovides an end-to-end workflow to preserve, collect, analyze, review, and export content that's responsive to your organization's internal and external investigations. It also lets legal teams manage the entire legal hold notification workflow to communicate with custodians involved in a case.\nIn Microsoft Purview eDiscovery, a custodian refers to the individual whose content is subject to search, hold, or review as part of a legal, regulatory, or investigative process. A custodian is typically an employee or user whose data (e.g., email, documents, Teams messages) may be relevant to the matter under investigation. This is distinct from the IT administrators or compliance officers who perform searches or manage eDiscovery cases. Licensing requirements apply both to custodians (whose data is preserved or reviewed) and to users performing eDiscovery activities, as defined in the Microsoft Purview licensing terms.\nBy default, eDiscovery features are enabled at the tenant level for all users within the tenant when admins assign eDiscovery permissions in the Microsoft Purview compliance portal.\nThough some tenant services aren't currently capable of limiting benefits to specific users, appropriate subscription licenses are required for use of each online service. To review the terms and conditions governing the use of Microsoft products and Professional Services acquired through Microsoft Licensing programs, see the\nProduct Terms\n.\nHere are\nexamples\nof users in your organization benefiting from the service:\nCustodians (any users) that are part of a case that's placed on hold or who are custodians of data sources that are part of a Search, Collection, or Review set.\nOwners and members of a SharePoint site that is on hold or contains content that is part of a Search, Collection, or Review set.\nOwners of Exchange mailboxes that are placed on hold or contain content that is part of a Search, Collection, or Review set.\nOwners and members of Teams chats, channels or private channels that are placed on hold or contain content that is part of a Search, Collection, or Review set.\nFeature\nMicrosoft 365 E5 + Microsoft 365 Copilot\nMicrosoft 365 E3 + Microsoft 365 Copilot\nMicrosoft 365 Purview Suite + Copilot\n1\nMicrosoft 365 E5 eDiscovery & Audit + Copilot\n1\nE5/A5/F5/G5, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft 365 E5/A5/F5/G5 eDiscovery and Audit, Office 365 E5/A5/G5\nMicrosoft Office 365 E3/A3/G3/F3\neDiscovery (Premium)\nYes\nNo\nYes\nYes\nNo\nPremium search for Copilot interactions\nYes\nNo\nYes\nNo\nNo\neDiscovery content search, legal hold, export search results for Copilot interactions\nYes\nYes\nYes\nNo\nNo\neDiscovery (Standard) for sites and files\nYes\nYes\nYes\nYes\nYes\neDiscovery (Standard) for email\nYes\nYes\nYes\nYes\nYes\n1\nRequires Microsoft 365 E3.\nFor more information about eDiscovery, check out the following resources:\nComparison of key capabilities:â¯\nMicrosoft Purview eDiscovery Solutions\n.\nAny user benefiting from the service requires a license. For more information about service terms & conditions, see\nProduct Terms\n.\nFor information regarding eDiscovery and non-custodial data sources, see\nAdd non-custodial data sources to an eDiscovery (Premium) case\n.\neDiscovery administrators can select specific users as data custodians for a case by using the built-in custodian management tool in eDiscovery (Premium) as described inâ¯\nAdd custodians to an eDiscovery (Premium) case\n.\nMicrosoft Purview Information Barriers\nInformation Barriers are policies that an admin can configure to prevent individuals or groups from communicating with each other. This is useful if, for example, one department is handling information that shouldn't be shared with other departments, or a group needs to be prevented from communicating with outside contacts. Information barrier policies also prevent lookups and discovery. This means that if you attempt to communicate with someone you shouldn't be communicating with, you won't find that user in the people picker.\nUsers benefit from the advanced compliance capabilities of information barriers when they're restricted from communicating with others. Information barriers policies can be defined to prevent a certain segment of users from communicating with each or allow specific segments to communicate only with certain other segments. For more information on defining information barrier policies, seeâ¯\nDefine information barrier (IB) policies\n. While defining IB Policy (Block or Allow),â¯users belonging to segments defined under \"Assigned Segments\" require licenses.\nFor more information about information barriers, see\nLearn about information barriers | Microsoft Learn\n.\nMicrosoft Purview Information Protection\nThis feature lets SharePoint Online document library owners set a new type of protection label on document libraries. This protection label is applied automatically to all unlabeled files or files that donât have an existing label-based protection applied.\nWhen files with these labels are downloaded from SharePoint Online, protection is applied. Only users authorized to view the file in SharePoint Online will be able to view the downloaded file. Further, if the userâs permissions are removed from the document or document library, the downloaded copy becomes inaccessible.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nand\nSharePoint Advanced Management\nConfigure SharePoint with a sensitivity label to extend permissions to downloaded documents\nYes\nFor more information, see\nConfigure SharePoint with a sensitivity label to extend permissions to downloaded documents | Microsoft Learn\n.\nMicrosoft Purview Information Protection Advanced Message Encryption\nMicrosoft Purview Advanced Message Encryption helps customers meet compliance obligations that require more flexible controls over external recipients and their access to encrypted emails. With Purview Advanced Message Encryption, admins can control sensitive emails shared outside the organization by using automatic policies that can detect sensitive information types (for example, personally identifying information, or financial or health IDs), or they can use keywords to enhance protection by applying custom email templates and expiring access to encrypted emails through a secure web portal. Additionally, admins can further control encrypted emails accessed externally through a secure web portal by revoking access at any time. Message senders benefit from the added control over sensitive emails provided by Advanced Message Encryption. Admins create and manage Advanced Message Encryption policies in the Exchange admin center underâ¯\nMail flowâ¯>â¯Rules\n. By default, these rules apply to all users in the tenant. For more information about setting up new Message Encryption capabilities, see\nSet up new Office 365 Message Encryption capabilities\n.\nFeature availability\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nAdvanced Message Encryption\nYes\nYes\nMicrosoft Purview Information Protection Customer Key\nWith Customer Key (formerly named Customer Key for Microsoft 365), you control your organization's encryption keys and configure Microsoft 365 to use them to encrypt your data at rest in Microsoft data centers. In other words, Customer Key allows you to add a layer of encryption that belongs to you, using your own keys. Customer Key provides data-at-rest encryption support for multipleâ¯\nMicrosoft 365 workloads\nthrough Microsoft 365 Data-At-Rest Encryption Service. In addition, Customer Key provides encryption for SharePoint Online and OneDrive for Business data as well as Exchange Online mailbox level encryption.\nUsers benefit from Customer Key by having their data at rest encrypted at the application layer using encryption keys that are provided, controlled, and managed by their own organization.\nMicrosoft 365 data-at-rest service that provides multi-workload encryption support is a tenant level service. Although some unlicensed users can technically be able to access the service, a license is required for any user that you intend to benefit from the service. For Exchange Online mailbox level encryption, the user mailbox needs to be licensed to assign a data encryption policy.\nThe following table lists Customer Key availability across plans. Theâ¯\nSet up Customer Key\nâ¯article describes the steps you need to follow to create and configure the required Azure resources and then provides the steps for setting up Customer Key.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nCustomer Key\nYes\nYes\nTo enable Customer Key within your tenant:\nSet up Customer Key - Microsoft Purview | Microsoft Learn\nAvailability Key uses in Customer Key:\nLearn about the availability key for Customer Key - Microsoft Purview | Microsoft Learn\nManage your Customer Key configuration:\nManage Customer Key - Microsoft Purview | Microsoft Learn\nMicrosoft Purview Information Protection: Data classification analytics: Overview Content & Activity Explorer\nData classification analytic capabilities are available within Microsoft Purview compliance portal. Overview shows the locations of digital content and most common sensitive information types and labels present. Content Explorer provides visibility into amount and types of sensitive data and allows users to filter by label or sensitivity type to get a detailed view of locations where the sensitive data is stored. Activity Explorer show activities related to sensitive data and labels, such as label downgrades or external sharing that could expose your content to risk.\nActivity Explorer provides a single pane of glass for admins to get visibility about activities that are related to sensitive information that's being used by end users. These data include label activities, data loss prevention (DLP) logs, auto-labeling, Endpoint DLP and more.\nContent Explorer provides admins the ability to index the sensitive documents that are stored within supported Microsoft 365 workloads and identify the sensitive information that they're storing. In addition, Content Explorer helps identify documents that are classified with sensitivity and retention labels.\nInformation protection and compliance admins can access the service to get access to these logs and indexed data to understand where sensitive data are stored, and which activities are related to this data and performed by end users.\nFeature availability\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft 365 E5/A5/G5 Compliance, Microsoft 365 E5/A5/G5 Information Protection & Governance\nOffice 365 E5\nData classification analytics\nYes\nYes\nFeature\nMicrosoft 365 E3/A3/G3\nOffice 365 E3/A3/G3\nContent Explorer data aggregation\nYes\nYes\nMicrosoft Purview Information Protection Double Key Encryption\nDouble Key Encryption\n(formerly named Double Key Encryption for Microsoft 365) lets you protect your highly sensitive data to meet specialized requirements and maintain full control of your encryption key. Double Key Encryption uses two keys to protect your data, with one key in your control and the second key stored securely by Microsoft Azure. To view the data, you must have access to both keys. Since Microsoft can access only one key, your key and also your data are unavailable to Microsoft, ensuring that you have full control over the privacy and security of your data.\nUsers benefit from Double Key Encryption by being able to migrate their encrypted data to the cloud, which prevents third-party access as long as the key remains in control of the users. Users can protect and consume Double Key Encrypted content similar to any other sensitivity label protected content.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nEMS E5\nDouble Key Encryption\nYes\nYes\nTo assign encryption keys to data within an Office 365 and/or Microsoft 365 organization for licensed users, follow the Double Key Encryption deployment instructions\nhttps://aka.ms/dke\n.\nMicrosoft Purview Information Protection Message Encryption\nMicrosoft Purview Message Encryption is a service built on Azure Rights Management (Azure RMS) that lets you send encrypted email to people inside or outside your organization, regardless of the destination email address (Gmail, Yahoo! Mail, Outlook.com, etc.).\nTo view encrypted messages, recipients can either get a one-time passcode and sign in with a Microsoft account, or sign in with a work or school account associated with Office 365. Recipients can also send encrypted replies. They don't need a subscription to view encrypted messages or send encrypted replies.\nMessage senders benefit from the added control over sensitive emails provided by Office 365 Message Encryption.\nFeature availability\nFeature\nMicrosoft 365 F3/E3/A3/G3/E5/A5/G5 and Microsoft Business Premium\nOffice 365 A1/E3/A3/G3/E5/A5/G5\n1\nMessage Encryption\nYes\nYes\n1\nAzure Information Protection Plan 1 also provides the rights for an organization to benefit from Office 365 Message Encryption when added to the following plans: Exchange Online Kiosk, Exchange Online Plan 1, Exchange Online Plan 2, Office 365 F3, Microsoft 365 Business Basic, Microsoft 365 Business Standard, or Office 365 Enterprise E1.\nMicrosoft Purview Information Protection sensitivity labeling\nInformation Protection helps organizations discover, classify, label, and protect sensitive documents, emails and meetings, and groups and sites. Admins can define rules and conditions to apply labels automatically, users can apply labels manually, or a combination of the two can be usedâwhere users are given recommendations on applying labels.\nUsers benefit by having the ability to create, manually apply or automatically apply sensitivity labels, and consume content that has sensitivity labels applied.\nBy default, Information Protection features are enabled at the tenant level for all users within the tenant. This means the administrator creating and managing Information Protection features must have the appropriate licenses for the following subscription plans to configure the functionality. Similarly, end users also need the appropriate licenses to use the functionality in their respective client applications. For more information, see\nCreate and configure sensitivity labels and their policies\nor\nApply a sensitivity label to content automatically\n.\nFeature\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium\nOneDrive for Business (Plan 2)\nEnterprise Mobility + Security E3/E5\nOffice 365 E5/A5/E3/A3\nAIP Plan 1, AIP Plan 2\nManual Sensitivity Labeling\nYesâ¯\nYesâ¯\nYesâ¯\nYesâ¯\nYesâ¯\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite (Information Protection for Office 365 - Premium)/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5\nManual Sensitivity Labeling for scheduled meetings\nYesâ¯\nYesâ¯\nFeature\nMicrosoft 365 E5/A5/G5 + Teams Premium, Microsoft Purview Suite/EDU/GOV/FLW + Teams Premium, Microsoft Defender + Purview Suite FLW + Teams Premium, Microsoft 365 E5/A5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5 + Teams Premium\nManual Sensitivity Labeling for Teams online meetings\nYesâ¯\nYesâ¯\nFeature\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium + Microsoft 365 Copilot\nOneDrive for Business (Plan 2) + Microsoft 365 Copilot\nEnterprise Mobility + Security E3/E5 + Microsoft 365 Copilot\nOffice 365 E5/A5/E3/A3 + Microsoft 365 Copilot\nAIP Plan 1, AIP Plan 2 + Microsoft 365 Copilot\nInheriting labels from input to output for Microsoft 365\nYes\nYes\nYes\nYes\nYes\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5 Information Protection and Governance\nOffice 365 E5/A5/G5\nClient and service-side automatic sensitivity labeling\nYes\nYes\nFeature\nEnterprise Mobility + Security E5/A5/G5\nClient-side automatic sensitivity labeling only\nYes\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nEnterprise Mobility + Security E5/A5/G5\nClient-side labeling to apply S/MIME signing or encryption as a result of applying a label, manually or automatically\nYes\nYes\nYes\nFeature\nMicrosoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium\nEnterprise Mobility + Security E3/E5\nApply and view sensitivity labels in Power BI and to protect data when it's exported from Power BI to Excel, PowerPoint, or PDFâ¯\nYes\nYes\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5/A5/G5/F5 Information Protection and Governance\nOffice 365 E5/A5/G5\nApply default sensitivity labeling for SharePoint Document library\nYes\nYes\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft 365 A5/E5/F5/G5 Information Protection and Governance\nOffice 365 E5/A5/G5\nApply conditional access policies via authentication context to SharePoint sites using Sensitivity Labels\nYes\nYes\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/GOV/FLW, Microsoft Defender + Purview Suite FLW, Microsoft 365 E5 Information Protection and Governance\nOffice 365 E5/A5/G5\nConfigure dynamic watermarking for sensitivity labels\nYes\nYes\nFor information on how a user can benefit from the\nAIPService\nâ¯PowerShell module to administer the Azure Rights Management protection service for Azure Information Protection, seeâ¯\nInformation Protection\n.\nFor information on how to create and publish sensitivity labels,\nsee\n.\nWhen using the Microsoft Purview information protection scanner (formerly known as AIP scanner and accessible now via the Purview Compliance Portal) feature, policies can be scoped to specific groups or users and registries can be edited to prevent unlicensed users from running classification or labeling features.\nLearn about the Microsoft Purview Information Protection scanner - Microsoft Purview (compliance) | Microsoft Learn\nGet started with the Microsoft Purview Information Protection scanner - Microsoft Purview (compliance) | Microsoft Learn\nAzure Information Protection service description - Service Descriptions | Microsoft Docs\nFor information on how a user can benefit from the\nAIPService\nâ¯PowerShell module to administer the Azure Rights Management protection service for Azure Information Protection, seeâ¯\nAzure Information Protection\n.\nFor more information, see:\nAzure Information Protection service description\nNote\nYou can also apply conditional access policies via authentication context to SharePoint sites directly via\nSet-SPOSite\nPowerShell cmdlet and the following licenses provide user rights:\nMicrosoft 365 E5/A5/G5\nMicrosoft Purview Suite/FLW\nMicrosoft 365 E5 Information Protection and Governance\nOffice 365 E5/A5/G5\nMicrosoft Syntex - SharePoint Advanced Management\nNote\nIn addition to the licensing information above:\nA standard/Plan 1 license must be\nassigned\nin addition to the premium/P2 license for users to have access to sensitivity labeling for Information Protection for Office 365 and AIP, even if the premium licenses/Plan 2 are assigned. For example, if Information Protection for Office 365 Premium is assigned to a user, that user must also have Information Protection for Office 365 Standard assigned for sensitivity labeling to be available. And if AIP P2 is assigned to a user, that user must also have AIP P1 assigned.\nPower BI is included with Microsoft 365 E5/A5/G5; in all other plans, Power BI must be licensed separately.\nFor user benefit information regarding automatic classification based on Machine Learning (trainable classifiers), see\nData Lifecycle Management\nand/or\nRecords Management\n.\nMicrosoft Purview Insider Risk Management\nInsider Risk Management (formerly named Microsoft 365 Insider Risk Management) is a solution that helps minimize internal risks by letting you detect, investigate, and take action on risky activities in your organization.\nCustom policies allow you to detect and take action on malicious and inadvertently risky activities in your organization, including escalating cases to Microsoft Purview eDiscovery (Premium) (formerly named Microsoft Advanced eDiscovery), if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards. Users benefit by having their activities monitored for risk. Insider Risk Management policies must be created in the Microsoft Purview compliance portal and assigned to users.\nFeature\nMicrosoft 365 E5/A5/G5, Microsoft Purview Suite/EDU/GOV/FLW and Microsoft Defender + Purview Suite FLW, and Microsoft 365 E5/A5/F5/G5 Insider Risk Management\nInsider Risk Management\nYes\nFor more information, seeâ¯\nGet started with insider risk management\n.\nMicrosoft Purview Insider Risk Management Forensic Evidence\nForensic evidence\nis an opt-in, capacity add-on feature in Microsoft Purview Insider Risk Management that gives security teams visual insights into potential insider data security incidents, with user privacy built in.\nCustomers can purchase the forensic evidence add-on in units of 100 GB per month. The purchased capacity will be metered based on forensic evidence ingestion at the tenant level for the users scoped in forensic evidence policies configured by admins.\nCustomers can access the service in the Microsoft Purview compliance portal.\nYou canâ¯\nlearn more about forensic evidence in our technical documentation\n.\nMessaging\nTo stay informed of upcoming changes, including new and changed features, planned maintenance, or other important announcements, visit the Message Center. For more information, see\nMessage center\n.\nLicensing terms\nFor licensing terms and conditions for products and services purchased through Microsoft Commercial Volume Licensing Programs, see the\nProduct Terms site\n.\nAccessibility\nMicrosoft remains committed to the security of your data and the\naccessibility\nof our services. For more information, see the\nMicrosoft Trust Center\nand the\nOffice Accessibility Center\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Purview Licensing",
      "section": "Licensing"
    },
    "https://learn.microsoft.com/en-us/microsoft-copilot-studio/requirements-licensing-subscriptions": {
      "content_hash": "sha256:58ba701e8575c608e9b128e77c098a6510a634f7a15151c07380166ae37529bb",
      "normalized_content": "Table of contents\nExit editor mode\nAsk Learn\nAsk Learn\nFocus mode\nTable of contents\nRead in English\nAdd\nAdd to plan\nEdit\nShare via\nFacebook\nx.com\nLinkedIn\nEmail\nPrint\nNote\nAccess to this page requires authorization. You can try\nsigning in\nor\nchanging directories\n.\nAccess to this page requires authorization. You can try\nchanging directories\n.\nGet access to Copilot Studio\nFeedback\nSummarize this article for me\nThis article provides information about Copilot Studio licensing and the free trial.\nImportant\nFor the most complete and up-to-date Copilot Studio licensing and billing information, refer to the\nMicrosoft Copilot Studio Licensing Guide\n.\nForecast your agent's Copilot Credits volume using the\nMicrosoft Copilot Studio agent usage estimator\n. Create estimates and potential consumption impacts by selecting from agent type, traffic, orchestration, knowledge, and tools.\nIf you already have licenses or you're an administrator, see the\nAssign licenses and manage access to Copilot Studio\narticle.\nCopilot Studio is\navailable in the US Government Community Cloud (GCC) plan\n.\nFirst,\nsign up for Copilot Studio\n. For more information and to request assistance, visit the\nMicrosoft Copilot Studio Community\n.\nPrerequisites\nA modern web browser such as:\nChrome version 91 (May 2021) or more recent\nFirefox version 89 (June 2021) or more recent\nSafari version 16.4 (March 2023) or more recent\nSign up for a Copilot Studio trial\nYou can sign up for Copilot Studio as an individual. After you finish the sign-up process, your free trial for Copilot Studio starts. You see notifications and receive emails to inform you about the trial expiry. When the trial expires, you can extend it by 30 days.\nYour agent continues to work for up to 90 days after your trial expires, so you don't have to worry about extending at the exact time of expiry.\nNote\nThe trial license gives you access to Copilot Studio to create agents. You can test your agents using the test chat panel. However, you can't publish the agent.\nGo to the\nsign-up page\n.\nEnter your email address and select\nNext\n.\nFollow the instructions. After you complete the process, you can use Copilot Studio to\ncreate agents\n.\nNote\nIf you have trouble signing up for the trial, check the following common issues:\nRejected email address: This problem might happen if you used a personal email address for the trial. Instead, use a work or school account.\nReceived a message that your sign-up couldn't be completed: This problem likely means your organization's IT administrator disabled the self-service sign-up for Copilot Studio. To finish signing up, contact your IT administrator and ask them to follow the instructions to\nenable sign-up\n.\nStandalone Copilot Studio subscription\nThe standalone Copilot Studio subscription allows you to build agents on any supported channel and connect to any data by using premium connectors.\nYou can get a standalone Copilot Studio subscription from the Microsoft 365 admin center. For more information, see\nAssign licenses and manage access to Copilot Studio\n.\nCopilot Studio for Microsoft Teams plans\nCopilot Studio for Teams enables customers to build conversational interfaces within Teams. The agents can use data stored in Microsoft Dataverse for Teams or many other sources, using the supplied standard connectors.\nCapabilities available in the Copilot Studio app in Teams are available as part of select Microsoft 365 subscriptions with Microsoft Power Platform and Teams capabilities. This plan excludes plans for US government environments (GCC, GCC High, and DoD), EDU A1, and SUB SKUs.\nThis table compares key capabilities in the Copilot Studio for Teams plan, which is available in select Microsoft 365 subscriptions, against the standalone Copilot Studio subscription. For a full, comparative list, see the\nMicrosoft Power Platform Licensing Guide\n.\nAlso see the\nQuotas and limits\narticle for other capacity considerations.\nCapability\nSelect Microsoft 365 subscriptions\nStandalone Copilot Studio subscription\nGenerative orchestration\nNot available\nOrchestrate agent behavior with generative AI\nDeploy agents to channels\nTeams\nAny channel supported by Copilot Studio\nPower Platform connectors\nStandard connector tools in Copilot Studio\nPremium connector tools in Copilot Studio\nPower Automate flows (automated, instant, scheduled)\nNot available\nCreate a flow\nWeb security\nSecure access enabled by default, can't generate secrets to enable secure access\nCan generate secrets and turn on or off secure access by the agent author\nCreate and edit with Copilot\nNot available\nCan create and iterate on topics by describing what you want, then AI builds it\nUse Microsoft Bot Framework skills\nNot available\nCan extend Copilot Studio agents with Microsoft Bot Framework skills\nUse a Copilot Studio classic chatbot as a Bot Framework skill\nNot available\nUse a classic chatbot as a skill in a Bot Framework bot\nHand off agent conversation to a live representative\nNot available\nHand off to a live agent\nTo access the full range of Copilot Studio capabilities, upgrade your plan to a standalone Copilot Studio subscription.\nAfter you upgrade your license, you can continue using the same agent in the same environment. Capabilities that require a standalone license are now available. These capabilities might include\nbilled sessions that require Copilot Studio capacity\n.\nOther subscriptions that include Copilot Studio\nEntitlements for Copilot Studio are included in Digital Messaging and Chat add-ons for Dynamics 365 Customer Service. For more information, see the\nDynamics 365 Licensing Guide\n.\nFeedback\nWas this page helpful?\nYes\nNo\nNo\nNeed help with this topic?\nWant to try using Ask Learn to clarify or guide you through this topic?\nAsk Learn\nAsk Learn\nSuggest a fix?\nAdditional resources",
      "last_checked": "2026-01-26T01:03:12.094601+00:00",
      "last_status": 200,
      "last_changed": "2026-01-25T23:12:28.455268+00:00",
      "topic": "Copilot Studio Licensing",
      "section": "Licensing"
    }
  },
  "statistics": {
    "total_urls": 191,
    "last_run_checked": 191,
    "last_run_meaningful_changes": 0,
    "last_run_minor_changes": 0,
    "last_run_redirects": 53,
    "last_run_errors": 0
  }
}