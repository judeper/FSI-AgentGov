# Control 3.10: Hallucination Feedback Loop

## Overview

**Control ID:** 3.10
**Control Name:** Hallucination Feedback Loop
**Regulatory Reference:** CFPB UDAAP, SOX 302, FINRA 4511, SEC 17a-4
**Setup Time:** 2-3 hours

---

### Purpose

Establish a systematic process for capturing, categorizing, and remediating AI agent hallucinations (factually incorrect, fabricated, or misleading outputs). This control creates a feedback mechanism that enables continuous improvement of agent accuracy and provides evidence of quality management for regulatory purposes.

!!! info "Hallucination Definition"
    In the context of AI agents, a "hallucination" occurs when the agent generates information that is factually incorrect, fabricated, inconsistent with knowledge sources, or misleading—regardless of how confident the response appears.

---

### Description

The Hallucination Feedback Loop establishes processes for:

- **User Feedback Collection:** Mechanisms for users to report inaccurate responses
- **Hallucination Categorization:** Taxonomy for classifying types of inaccuracies
- **Remediation Tracking:** Workflow to address identified issues
- **Trend Analysis:** Patterns to identify systemic problems
- **Continuous Improvement:** Integration with agent training and prompt refinement

See [Copilot Studio analytics](https://learn.microsoft.com/en-us/microsoft-copilot-studio/analytics-overview) for built-in feedback capabilities.

---

### Key Capabilities

| Capability | Description | FSI Relevance |
|------------|-------------|---------------|
| **User Feedback** | Thumbs down, flag, report mechanisms | Quality signal |
| **Categorization** | Classify hallucination types | Root cause analysis |
| **Tracking** | Remediation workflow | Accountability |
| **Trend Analysis** | Pattern identification | Systemic improvement |
| **Evidence** | Audit trail of issues and fixes | Regulatory compliance |

---

## Prerequisites

**Primary Owner Admin Role:** AI Governance Lead
**Supporting Roles:** Power Platform Admin, Quality Assurance Lead

### Licenses Required

| License | Purpose | Required For |
|---------|---------|--------------|
| Power Platform per-user | Agent feedback features | All levels |
| Microsoft 365 E5 | Audit logging | All levels |
| Power BI | Trend analysis dashboards | Level 2+ |
| ServiceNow/Jira (optional) | Issue tracking integration | Level 4 |

### Permissions Required

| Role | Purpose | Assignment Method |
|------|---------|-------------------|
| AI Governance Lead | Feedback review and remediation | Business role |
| Power Platform Admin | Configure feedback mechanisms | Entra ID |
| QA Lead | Validate fixes | Business role |
| Content Owner | Update knowledge sources | Business role |

### Dependencies

| Dependency | Description | Verification |
|------------|-------------|--------------|
| Control 2.9 (Performance Monitoring) | Baseline metrics | Check dashboards |
| Control 3.4 (Incident Reporting) | Issue escalation | Verify process |
| Control 2.16 (RAG Source Integrity) | Knowledge source updates | Check validation |

### Pre-Setup Checklist

- [ ] Copilot Studio feedback enabled for agents
- [ ] Hallucination categorization taxonomy defined
- [ ] Issue tracking system identified (SharePoint, ServiceNow, etc.)
- [ ] Remediation workflow documented
- [ ] Escalation criteria established
- [ ] Trend reporting cadence defined

---

## Governance Levels

### Baseline (Level 1)

| Requirement | Configuration |
|-------------|---------------|
| Basic feedback | Enable thumbs up/down |
| Manual review | Weekly review of negative feedback |
| Documentation | Log identified hallucinations |

**Minimum requirements:**

- Enable user feedback on agent responses
- Weekly review of negative feedback
- Document hallucinations in spreadsheet or list
- Quarterly summary report

### Recommended (Level 2-3)

| Requirement | Configuration |
|-------------|---------------|
| Structured feedback | Flag/report with categorization |
| Automated collection | Feedback flows to tracking system |
| Trend analysis | Monthly hallucination trend reports |
| Remediation SLA | Defined response times |

**FSI recommendations:**

- Deploy structured feedback collection
- Automate routing to issue tracking
- Monthly trend analysis reports
- Defined SLAs for remediation
- Integration with knowledge source updates

### Regulated/High-Risk (Level 4)

| Requirement | Configuration |
|-------------|---------------|
| Comprehensive tracking | Full remediation workflow |
| Real-time monitoring | Alert on hallucination spikes |
| Root cause analysis | Formal RCA for critical issues |
| Regulatory evidence | Audit-ready documentation |

**FSI considerations (high-risk):**

- Comprehensive tracking with full audit trail
- Real-time alerting on hallucination rate spikes
- Formal RCA for critical hallucinations
- Integration with incident management
- Quarterly compliance reporting
- Evidence retention for 6+ years

---

## Setup & Configuration

### Step 1: Enable User Feedback Collection

**Portal Path:** Copilot Studio → Agent → Settings → Customer satisfaction

1. Open your agent in **Copilot Studio**
2. Navigate to **Settings** → **Customer satisfaction**
3. Enable **Allow users to provide feedback**
4. Configure feedback options:
   - **Thumbs up/down:** Always enable
   - **Comment box:** Enable for detailed feedback
   - **Flag for review:** Enable for escalation

**Custom Feedback Form (Advanced):**

For more detailed categorization, create a Power Automate flow triggered by negative feedback:

```plaintext
Trigger: When feedback is submitted with thumbs down

Actions:
├── Capture feedback context (conversation, response, timestamp)
├── Present categorization form to user:
│   ├── Factually incorrect
│   ├── Outdated information
│   ├── Fabricated/made up
│   ├── Misleading/confusing
│   ├── Inappropriate tone
│   └── Other (free text)
├── Create item in Hallucination Tracking list
├── If critical category → Create incident
└── Send confirmation to user
```

### Step 2: Define Hallucination Taxonomy

**Hallucination Categories:**

| Category | Description | Severity | Example |
|----------|-------------|----------|---------|
| **Factual Error** | Incorrect facts about products/services | High | Wrong interest rate quoted |
| **Fabrication** | Completely made up information | Critical | Non-existent product features |
| **Outdated** | Information no longer current | Medium | Discontinued service mentioned |
| **Misattribution** | Wrong source cited | Medium | Incorrect document reference |
| **Calculation Error** | Math or logic mistakes | High | Wrong fee calculation |
| **Conflation** | Mixing up different items | Medium | Features from different products |
| **Overconfidence** | Certainty about uncertain things | Medium | "Definitely" when "likely" |
| **Misleading** | Technically true but deceptive | High | Selective information |

**Severity Classification:**

| Severity | Impact | Response SLA | Escalation |
|----------|--------|--------------|------------|
| **Critical** | Customer harm, regulatory risk | 4 hours | Immediate to Compliance |
| **High** | Significant misinformation | 24 hours | AI Governance Lead |
| **Medium** | Minor inaccuracy | 72 hours | Content Owner |
| **Low** | Cosmetic/minor | 1 week | Queue for batch review |

### Step 3: Create Hallucination Tracking System

**SharePoint List Configuration:**

Create a SharePoint list with the following columns:

| Column | Type | Required | Values |
|--------|------|----------|--------|
| Issue ID | Auto-number | Yes | HAL-YYYY-#### |
| Report Date | Date/Time | Yes | Auto-populated |
| Agent Name | Lookup | Yes | Link to Agent Inventory |
| Category | Choice | Yes | Taxonomy categories |
| Severity | Choice | Yes | Critical/High/Medium/Low |
| User Query | Multi-line | Yes | What user asked |
| Agent Response | Multi-line | Yes | What agent said |
| Correct Information | Multi-line | No | What should have been said |
| Source of Truth | Hyperlink | No | Reference document |
| Status | Choice | Yes | New/Investigating/Remediation/Closed |
| Assigned To | Person | Yes | Investigator |
| Root Cause | Choice | No | Knowledge gap/Prompt issue/Training data/Unknown |
| Remediation Actions | Multi-line | No | What was done |
| Resolution Date | Date/Time | No | When closed |

### Step 4: Configure Automated Workflows

**Workflow 1: New Hallucination Report**

```plaintext
Trigger: When feedback marked as hallucination

Actions:
├── Create item in Hallucination Tracking list
├── Capture full conversation context
├── Auto-assign based on agent owner
├── If Severity = Critical:
│   ├── Create incident (Control 3.4)
│   ├── Notify Compliance Officer
│   └── Consider temporary agent suspension
├── Send acknowledgment to reporter
└── Start SLA timer
```

**Workflow 2: Trend Alert**

```plaintext
Trigger: Scheduled (daily)

Actions:
├── Query last 24 hours of reports
├── Calculate hallucination rate per agent
├── If rate > threshold (e.g., 5%):
│   ├── Alert AI Governance Lead
│   ├── Flag agent for review
│   └── Create investigation task
├── Update trend dashboard
```

**Workflow 3: Resolution Verification**

```plaintext
Trigger: When Status changed to "Closed"

Actions:
├── Validate required fields completed
├── Calculate time to resolution
├── If Root Cause = "Knowledge gap":
│   └── Trigger knowledge source review (Control 2.16)
├── If Root Cause = "Prompt issue":
│   └── Trigger prompt review (Control 2.6)
├── Update metrics
├── Archive evidence
```

### Step 5: Establish Remediation Process

**Remediation by Root Cause:**

| Root Cause | Remediation Steps | Owner |
|------------|-------------------|-------|
| **Knowledge Gap** | Update knowledge source, validate content | Content Owner |
| **Prompt Issue** | Review/modify system prompt | Prompt Engineer |
| **Training Data** | Flag for model retraining (if applicable) | AI Governance |
| **Source Conflict** | Resolve conflicting sources | Content Owner |
| **Configuration** | Adjust agent settings | Platform Admin |
| **Unknown** | Deeper investigation required | AI Governance |

**Remediation Workflow:**

```markdown
# Hallucination Remediation Form

## Issue Information
- **Issue ID:** [HAL-YYYY-####]
- **Agent:** [Name]
- **Category:** [Category]
- **Severity:** [Severity]

## Investigation
- **Investigator:** [Name]
- **Investigation Date:** [Date]
- **Root Cause Analysis:**
  - [ ] Reviewed conversation context
  - [ ] Checked knowledge sources
  - [ ] Reviewed agent prompts
  - [ ] Tested reproduction scenario

## Root Cause
- **Primary Cause:** [Selection]
- **Contributing Factors:** [Description]

## Remediation
- **Actions Taken:**
  1. [Action 1]
  2. [Action 2]
- **Verification Method:** [How fix was verified]
- **Verification Date:** [Date]
- **Verified By:** [Name]

## Prevention
- **Systemic Changes:** [Any broader changes needed]
- **Monitoring:** [How to detect recurrence]

## Sign-off
- **Investigator:** _______ Date: _____
- **AI Governance Lead:** _______ Date: _____
```

### Step 6: Configure Trend Reporting

**Key Metrics to Track:**

| Metric | Calculation | Target | Alert Threshold |
|--------|-------------|--------|-----------------|
| Hallucination Rate | Reports / Total Interactions | <2% | >5% |
| Critical Hallucinations | Critical issues / Total issues | <5% | >10% |
| MTTR (Mean Time to Resolve) | Avg resolution time | <72 hours | >1 week |
| Repeat Rate | Same issue recurrence | <5% | >10% |
| Open Issues | Unresolved issues | <10 | >25 |

**Power BI Dashboard Elements:**

1. **Hallucination Rate Trend** - Line chart over time
2. **Category Distribution** - Pie chart by category
3. **Severity Breakdown** - Bar chart by severity
4. **Agent Comparison** - Table ranked by hallucination rate
5. **MTTR Trend** - Line chart showing resolution time
6. **Root Cause Analysis** - Pareto chart of causes

---

### PowerShell Configuration

### Hallucination Tracking Report Script

```powershell
# ============================================================
# Control 3.10: Hallucination Feedback Loop
# Reporting and Analysis Script
# ============================================================

param(
    [string]$TrackingListUrl = "https://tenant.sharepoint.com/sites/AI-Governance/Lists/HallucinationTracking",
    [int]$DaysBack = 30,
    [string]$OutputPath = ".\Hallucination-Report-$(Get-Date -Format 'yyyyMMdd')"
)

New-Item -ItemType Directory -Path $OutputPath -Force | Out-Null

Write-Host "=== Hallucination Feedback Loop Report ===" -ForegroundColor Cyan

# Connect to SharePoint
Connect-PnPOnline -Url $TrackingListUrl -Interactive

# Get hallucination reports
$startDate = (Get-Date).AddDays(-$DaysBack)
$items = Get-PnPListItem -List "HallucinationTracking" -PageSize 500 |
    Where-Object { [DateTime]$_["ReportDate"] -ge $startDate }

Write-Host "Analyzing $($items.Count) reports from last $DaysBack days"

# Calculate metrics
$metrics = @{
    TotalReports = $items.Count
    BySeverity = @{
        Critical = ($items | Where-Object { $_["Severity"] -eq "Critical" }).Count
        High = ($items | Where-Object { $_["Severity"] -eq "High" }).Count
        Medium = ($items | Where-Object { $_["Severity"] -eq "Medium" }).Count
        Low = ($items | Where-Object { $_["Severity"] -eq "Low" }).Count
    }
    ByCategory = $items | Group-Object { $_["Category"] } | Select-Object Name, Count | Sort-Object Count -Descending
    ByAgent = $items | Group-Object { $_["AgentName"] } | Select-Object Name, Count | Sort-Object Count -Descending
    ByStatus = $items | Group-Object { $_["Status"] } | Select-Object Name, Count
    ByRootCause = $items | Where-Object { $_["RootCause"] } |
        Group-Object { $_["RootCause"] } | Select-Object Name, Count | Sort-Object Count -Descending
    OpenIssues = ($items | Where-Object { $_["Status"] -ne "Closed" }).Count
}

# Calculate MTTR for closed issues
$closedItems = $items | Where-Object { $_["Status"] -eq "Closed" -and $_["ResolutionDate"] }
if ($closedItems.Count -gt 0) {
    $avgResolutionHours = ($closedItems | ForEach-Object {
        ([DateTime]$_["ResolutionDate"] - [DateTime]$_["ReportDate"]).TotalHours
    } | Measure-Object -Average).Average
    $metrics.AverageMTTR = [math]::Round($avgResolutionHours, 1)
} else {
    $metrics.AverageMTTR = "N/A"
}

# Display summary
Write-Host "`nSummary:" -ForegroundColor Green
Write-Host "  Total Reports: $($metrics.TotalReports)"
Write-Host "  Critical: $($metrics.BySeverity.Critical) | High: $($metrics.BySeverity.High) | Medium: $($metrics.BySeverity.Medium) | Low: $($metrics.BySeverity.Low)"
Write-Host "  Open Issues: $($metrics.OpenIssues)"
Write-Host "  Average MTTR: $($metrics.AverageMTTR) hours"

# Top agents by hallucination count
Write-Host "`nTop Agents by Hallucination Count:" -ForegroundColor Yellow
$metrics.ByAgent | Select-Object -First 5 | Format-Table

# Generate HTML report
$html = @"
<!DOCTYPE html>
<html>
<head>
    <title>Hallucination Feedback Loop Report</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; margin: 40px; }
        h1 { color: #0078d4; }
        .dashboard { display: flex; gap: 20px; flex-wrap: wrap; margin: 20px 0; }
        .card { padding: 20px; background: #f5f5f5; border-radius: 8px; min-width: 120px; }
        .card.critical { background: #fde7e9; }
        .card.warning { background: #fff4ce; }
        .card.success { background: #dff6dd; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }
        th { background: #0078d4; color: white; }
    </style>
</head>
<body>
    <h1>Hallucination Feedback Loop Report</h1>
    <p>Period: Last $DaysBack days | Generated: $(Get-Date -Format "yyyy-MM-dd HH:mm")</p>

    <h2>Summary</h2>
    <div class="dashboard">
        <div class="card"><h3>Total Reports</h3><p style="font-size:28px;">$($metrics.TotalReports)</p></div>
        <div class="card critical"><h3>Critical</h3><p style="font-size:28px;">$($metrics.BySeverity.Critical)</p></div>
        <div class="card warning"><h3>High</h3><p style="font-size:28px;">$($metrics.BySeverity.High)</p></div>
        <div class="card"><h3>Open Issues</h3><p style="font-size:28px;">$($metrics.OpenIssues)</p></div>
        <div class="card"><h3>Avg MTTR</h3><p style="font-size:28px;">$($metrics.AverageMTTR)h</p></div>
    </div>

    <h2>Top Agents by Hallucination Count</h2>
    <table>
        <tr><th>Agent</th><th>Count</th></tr>
        $($metrics.ByAgent | Select-Object -First 10 | ForEach-Object { "<tr><td>$($_.Name)</td><td>$($_.Count)</td></tr>" })
    </table>

    <h2>Root Cause Analysis</h2>
    <table>
        <tr><th>Root Cause</th><th>Count</th></tr>
        $($metrics.ByRootCause | ForEach-Object { "<tr><td>$($_.Name)</td><td>$($_.Count)</td></tr>" })
    </table>

    <h2>Category Distribution</h2>
    <table>
        <tr><th>Category</th><th>Count</th></tr>
        $($metrics.ByCategory | ForEach-Object { "<tr><td>$($_.Name)</td><td>$($_.Count)</td></tr>" })
    </table>

    <h2>Recommendations</h2>
    <ul>
        $(if ($metrics.BySeverity.Critical -gt 0) { "<li><strong>Critical:</strong> Investigate $($metrics.BySeverity.Critical) critical hallucinations immediately</li>" })
        $(if ($metrics.OpenIssues -gt 10) { "<li><strong>High:</strong> Address backlog of $($metrics.OpenIssues) open issues</li>" })
        <li>Review agents with highest hallucination counts</li>
        <li>Address most common root causes systematically</li>
    </ul>
</body>
</html>
"@

$html | Out-File -FilePath "$OutputPath\Hallucination-Report.html" -Encoding UTF8
Write-Host "`nReport generated: $OutputPath\Hallucination-Report.html" -ForegroundColor Green
```

---

## Financial Sector Considerations

### Regulatory Alignment

| Regulation | Requirement | How This Control Helps |
|------------|-------------|------------------------|
| **CFPB UDAAP** | Unfair/deceptive practices | Tracks and remediates misleading outputs |
| **SOX 302** | Accuracy of financial information | Ensures agent output accuracy |
| **FINRA 4511** | Books and records | Documents quality management |
| **SEC 17a-4** | Record retention | Preserves hallucination evidence |

### Zone-Specific Configuration

**Zone 1 (Personal Productivity):**

- Enable basic thumbs up/down feedback
- Quarterly review of feedback patterns
- Rationale: Low-risk personal use, minimal tracking

**Zone 2 (Team Collaboration):**

- Enable structured feedback with categorization
- Weekly review of reports
- Integration with team issue tracking
- Rationale: Shared agents need quality monitoring

**Zone 3 (Enterprise Managed):**

- Comprehensive tracking with full workflow
- Real-time alerting on critical hallucinations
- Integration with incident management
- Formal RCA for critical issues
- Regulatory-ready documentation
- Rationale: Customer-facing agents require rigorous quality control

---

## Verification & Testing

| Step | Action | Expected Result |
|------|--------|-----------------|
| 1 | Submit test feedback via thumbs down | Feedback captured |
| 2 | Verify tracking item created | Item in list with correct data |
| 3 | Complete remediation workflow | Status progression works |
| 4 | Run trend report | Report generates correctly |
| 5 | Test critical escalation | Incident created |

### Compliance Checklist

- [ ] Feedback collection enabled on all agents
- [ ] Hallucination taxonomy defined
- [ ] Tracking system configured
- [ ] Automated workflows operational
- [ ] Remediation process documented
- [ ] Trend reporting configured
- [ ] Escalation criteria established
- [ ] Evidence retention configured

---

## Proactive Output Quality Monitoring

### Purpose

While the feedback loop captures issues after users experience them, proactive output quality monitoring enables detection and intervention before problematic content reaches customers. This section establishes pre-delivery content scanning, quality scoring, and automated flagging processes.

### Quality Scoring Framework

**Confidence-Based Quality Assessment:**

| Score Range | Quality Level | Action | Notification |
|-------------|--------------|--------|--------------|
| 0.95 - 1.00 | High | Deliver immediately | None |
| 0.85 - 0.94 | Medium | Deliver with logging | Optional review queue |
| 0.70 - 0.84 | Low | Flag for review | Notify AI Governance Lead |
| Below 0.70 | Very Low | Hold for human review | Mandatory escalation |

**Implementing Quality Thresholds in Copilot Studio:**

```yaml
# Quality threshold configuration for agent responses
quality_thresholds:
  enabled: true

  confidence_settings:
    high_threshold: 0.95
    medium_threshold: 0.85
    low_threshold: 0.70

  low_confidence_actions:
    - action: "flag_for_review"
      queue: "Quality Review Queue"
    - action: "add_disclaimer"
      text: "I'm not entirely certain about this information. Would you like me to connect you with a specialist?"
    - action: "suggest_escalation"
      prompt: "For questions like this, you may want to speak with a representative."

  very_low_confidence_actions:
    - action: "hold_response"
    - action: "notify_supervisor"
    - action: "offer_human_handoff"
```

### Pre-Delivery Content Scanning

**Portal Path:** Copilot Studio → [Agent] → Topics → Error handling

Configure automated scanning before response delivery:

**Scan Categories:**

| Category | Detection Method | Action on Detection |
|----------|-----------------|---------------------|
| **Specific Investment Advice** | Keyword patterns: "you should buy", "I recommend investing in [specific]" | Block + escalate |
| **Unauthorized Promises** | Patterns: "guaranteed", "promise", "will definitely" | Flag + disclaimer |
| **Outdated Information** | Date reference check against knowledge freshness | Flag + warning |
| **Conflicting Statements** | Cross-reference with prior responses in session | Flag for review |
| **Calculation Errors** | Numeric validation against source data | Block + recalculate |

**PowerShell: Quality Scan Configuration**

```powershell
# Define quality scan rules
$QualityScanRules = @{
    ProhibitedPatterns = @(
        @{ Pattern = "you should (buy|sell|invest in) [A-Z]{1,5}"; Severity = "Critical"; Action = "Block" }
        @{ Pattern = "guaranteed (return|profit|income)"; Severity = "Critical"; Action = "Block" }
        @{ Pattern = "I promise"; Severity = "High"; Action = "Flag" }
        @{ Pattern = "will definitely"; Severity = "High"; Action = "Flag" }
        @{ Pattern = "trust me"; Severity = "Medium"; Action = "Flag" }
    )
    RequiredDisclaimers = @(
        @{ Trigger = "investment"; Disclaimer = "This is general information, not personalized advice." }
        @{ Trigger = "rate|APR|interest"; Disclaimer = "Rates are subject to change and may vary." }
    )
    ConfidenceThreshold = 0.85
}

$QualityScanRules | ConvertTo-Json -Depth 3 | Out-File "Quality-Scan-Rules.json"
```

---

## Content Safety Guardrails

### Purpose

Content safety guardrails prevent agents from generating inappropriate, harmful, or off-brand responses. This includes tone monitoring, harmful content filtering, and financial advice boundaries.

### Guardrail Categories

**Category 1: Tone and Appropriateness**

| Guardrail | Description | Detection | Response |
|-----------|-------------|-----------|----------|
| **Professional Tone** | Ensure responses maintain professional language | Sentiment analysis | Auto-correct or flag |
| **No Emotional Manipulation** | Avoid fear-based or urgency language | Pattern matching | Block + rephrase |
| **Appropriate Formality** | Match brand voice guidelines | Style scoring | Suggest alternatives |
| **Non-Discriminatory** | No bias in language or recommendations | Bias detection | Block + alert |

**Category 2: Financial Advice Boundaries**

| Guardrail | Prohibited Content | Allowed Content | Action |
|-----------|-------------------|-----------------|--------|
| **Investment Recommendations** | "Buy [specific stock]", "Invest in [fund]" | "Consider consulting a financial advisor" | Block |
| **Tax Advice** | "You should claim [deduction]" | "Tax rules vary; consult a tax professional" | Block |
| **Legal Advice** | "You have a case for [action]" | "For legal matters, consult an attorney" | Block |
| **Credit Decisions** | "You will be approved" | "Approval depends on creditworthiness review" | Block |

**Category 3: Harmful Content Prevention**

| Content Type | Detection | Action | Escalation |
|--------------|-----------|--------|------------|
| **Self-harm references** | Keyword + context | Provide crisis resources | Immediate |
| **Fraud facilitation** | Pattern matching | Block completely | Report |
| **Discriminatory content** | ML-based detection | Block + review | Compliance |
| **Competitive disparagement** | Entity recognition | Block + rephrase | Marketing |

### Guardrail Configuration

**Copilot Studio Guardrail Implementation:**

```yaml
# Content safety guardrails configuration
content_safety_guardrails:
  enabled: true
  enforcement_mode: "block_and_log"  # Options: log_only, warn, block_and_log

  tone_guardrails:
    professional_language:
      enabled: true
      action: "auto_correct"
    no_urgency_manipulation:
      enabled: true
      blocked_phrases: ["act now", "limited time", "don't miss out"]
      action: "block"

  financial_boundaries:
    block_specific_recommendations:
      enabled: true
      patterns:
        - "buy [TICKER]"
        - "sell [TICKER]"
        - "invest in [FUND]"
      action: "block"
      replacement: "For specific investment guidance, please consult with a licensed financial advisor."

    block_guarantees:
      enabled: true
      patterns:
        - "guaranteed return"
        - "risk-free investment"
        - "cannot lose"
      action: "block"

  harmful_content:
    crisis_detection:
      enabled: true
      triggers: ["suicide", "self-harm", "kill myself"]
      response: "If you're experiencing a crisis, please contact the National Suicide Prevention Lifeline at 988 or text HOME to 741741."
      escalate_to: "Crisis Response Team"

    fraud_prevention:
      enabled: true
      triggers: ["fake identity", "bypass verification", "avoid detection"]
      action: "block_and_report"
```

**KQL: Monitor Guardrail Triggers**

```kql
// Track content safety guardrail activations
CopilotInteraction
| where TimeGenerated > ago(7d)
| where GuardrailTriggered == true
| summarize
    TriggerCount = count(),
    UniqueAgents = dcount(AgentId),
    UniqueUsers = dcount(UserId)
    by GuardrailCategory, GuardrailRule
| order by TriggerCount desc
```

---

## Sensitive Topic Handling

### Purpose

Define procedures for handling sensitive topics that require special care, including financial hardship, complaints, mental health concerns, and regulatory inquiries. Agents must recognize these situations and respond appropriately, often involving human handoff.

### Sensitive Topic Categories

**Category 1: Financial Hardship**

| Indicator | Detection | Response | Escalation |
|-----------|-----------|----------|------------|
| "Can't pay my bill" | Keyword | Offer hardship program info | Financial counselor queue |
| "Lost my job" | Context + keyword | Empathetic response + options | Hardship specialist |
| "Bankruptcy" | Keyword | Neutral info + human handoff | Compliance + specialist |
| "Foreclosure" | Keyword | Crisis resources + handoff | Urgent specialist queue |

**Hardship Response Template:**

```markdown
I understand you may be going through a difficult time, and I want to help
connect you with the right resources.

We have programs that may be able to assist with your situation. Let me connect
you with a specialist who can discuss your options confidentially.

[Transfer to Hardship Assistance Team]
```

**Category 2: Complaints and Disputes**

| Indicator | Detection | Response | Escalation |
|-----------|-----------|----------|------------|
| "File a complaint" | Explicit request | Acknowledge + capture details | Complaints team |
| "This is unacceptable" | Sentiment + context | De-escalation + offer help | Supervisor queue |
| "I'm calling my lawyer" | Keyword | Neutral + document | Legal + Compliance |
| "Report to regulator" | Keyword | Acknowledge + escalate | Compliance immediate |

**Complaint Response Template:**

```markdown
I hear that you're frustrated, and I want to make sure your concerns are
addressed properly.

I'm going to connect you with a member of our customer care team who can help
resolve this issue and ensure your feedback is documented.

Is there anything specific you'd like me to note before the transfer?

[Transfer to Customer Care with complaint flag]
```

**Category 3: Mental Health and Crisis**

| Indicator | Detection | Response | Escalation |
|-----------|-----------|----------|------------|
| Self-harm keywords | Keyword list | Crisis resources + empathy | Immediate human |
| Extreme distress | Sentiment analysis | Supportive response | Priority queue |
| Threats | Keyword + context | De-escalation + document | Security + Legal |

!!! warning "Crisis Response"
    All agents MUST be configured to recognize crisis indicators and provide appropriate resources immediately. This is not optional for any customer-facing agent.

**Category 4: Regulatory and Legal**

| Indicator | Detection | Response | Escalation |
|-----------|-----------|----------|------------|
| "SEC investigation" | Keyword | Neutral acknowledgment | Legal immediate |
| "FINRA complaint" | Keyword | Document + escalate | Compliance immediate |
| "Subpoena" | Keyword | Do not discuss + escalate | Legal immediate |
| "Audit" | Context-dependent | General info only | Compliance |

### Sensitive Topic Configuration

```yaml
# Sensitive topic handling configuration
sensitive_topics:
  financial_hardship:
    triggers:
      - keywords: ["can't pay", "hardship", "financial difficulty", "lost job", "bankruptcy"]
        confidence_threshold: 0.8
    response_type: "empathetic_handoff"
    handoff_queue: "Hardship Assistance"
    capture_context: true
    priority: "high"

  complaints:
    triggers:
      - keywords: ["complaint", "unacceptable", "supervisor", "manager"]
        sentiment: "negative"
    response_type: "de-escalation_handoff"
    handoff_queue: "Customer Care - Complaints"
    flag_conversation: true
    priority: "high"

  crisis:
    triggers:
      - keywords: ["suicide", "kill myself", "end my life", "self-harm"]
    response_type: "crisis_protocol"
    response_message: "If you're in crisis, please call 988 (Suicide & Crisis Lifeline) or text HOME to 741741."
    handoff_queue: "Crisis Response"
    priority: "immediate"
    notify: ["Crisis Team", "Supervisor On-Call"]

  regulatory:
    triggers:
      - keywords: ["SEC", "FINRA", "regulator", "investigation", "subpoena", "audit"]
    response_type: "neutral_escalate"
    response_message: "For matters involving regulatory inquiries, I need to connect you with our compliance team."
    handoff_queue: "Legal/Compliance"
    priority: "immediate"
    document_verbatim: true
```

---

## Real-Time Quality Scoring

### Purpose

Implement real-time quality scoring that attaches confidence levels to agent outputs, enabling dynamic routing decisions and providing transparency about response reliability.

### Quality Score Components

**Score Calculation:**

| Component | Weight | Measurement |
|-----------|--------|-------------|
| **Source Confidence** | 30% | Strength of knowledge source match |
| **Response Coherence** | 25% | Logical consistency of response |
| **Factual Accuracy** | 25% | Alignment with verified data |
| **Query Match** | 20% | How well response addresses the question |

**Quality Score Display:**

For internal monitoring (not shown to customers):

```json
{
  "response_id": "resp-2026-01-15-001234",
  "quality_score": {
    "overall": 0.87,
    "components": {
      "source_confidence": 0.92,
      "response_coherence": 0.85,
      "factual_accuracy": 0.88,
      "query_match": 0.82
    }
  },
  "action_taken": "delivered",
  "review_flag": false
}
```

### Low-Confidence Routing

**Routing Rules:**

| Score | Routing Decision | User Experience |
|-------|-----------------|-----------------|
| ≥ 0.95 | Direct delivery | Standard response |
| 0.85-0.94 | Deliver + queue for review | Standard + disclaimer option |
| 0.70-0.84 | Supervisor review first | "Let me verify this information..." |
| < 0.70 | Human handoff | "I want to make sure you get accurate information. Let me connect you with a specialist." |

**Quality Dashboard Metrics:**

```kql
// Real-time quality metrics dashboard
CopilotInteraction
| where TimeGenerated > ago(1h)
| extend QualityBand = case(
    QualityScore >= 0.95, "High",
    QualityScore >= 0.85, "Medium",
    QualityScore >= 0.70, "Low",
    "Very Low"
)
| summarize
    ResponseCount = count(),
    AvgQualityScore = round(avg(QualityScore), 3),
    HighQuality = countif(QualityBand == "High"),
    MediumQuality = countif(QualityBand == "Medium"),
    LowQuality = countif(QualityBand == "Low"),
    VeryLowQuality = countif(QualityBand == "Very Low")
    by bin(TimeGenerated, 5m), AgentId
| order by TimeGenerated desc
```

### Quality Trend Alerting

**Alert Configuration:**

```kql
// Alert when quality drops below threshold
CopilotInteraction
| where TimeGenerated > ago(15m)
| summarize AvgQuality = avg(QualityScore) by AgentId, AgentName
| where AvgQuality < 0.80
| project AgentId, AgentName, AvgQuality, AlertTime = now()
```

**Response to Quality Degradation:**

| Quality Trend | Automated Response | Manual Follow-up |
|---------------|-------------------|------------------|
| Single low-quality response | Log + optional review | None required |
| 3+ low-quality in 1 hour | Alert AI Governance Lead | Review agent configuration |
| Average drops below 0.80 | Increase human review rate | Investigate root cause |
| Critical quality failure | Consider temporary suspension | Immediate investigation |

---

## Troubleshooting & Validation

<a id="troubleshooting"></a>

### Issue: Feedback Not Being Captured

**Symptoms:** Users report feedback but no tracking items created

**Resolution:**

1. Verify feedback is enabled in agent settings
2. Check Power Automate flow is enabled
3. Verify list permissions allow item creation
4. Review flow run history for errors
5. Test with manual feedback submission

### Issue: High Volume Overwhelming Team

**Symptoms:** Too many reports to process

**Resolution:**

1. Implement auto-categorization based on keywords
2. Add severity-based prioritization
3. Consider batch processing for low-severity
4. Review thresholds for escalation
5. Add automated resolution for common issues

---

## Additional Resources

<a id="microsoft-learn-references"></a>

- [Copilot Studio Analytics](https://learn.microsoft.com/en-us/microsoft-copilot-studio/analytics-overview)
- [Customer Satisfaction Settings](https://learn.microsoft.com/en-us/microsoft-copilot-studio/analytics-csat)
- [Power Automate Approval Workflows](https://learn.microsoft.com/en-us/power-automate/get-started-approvals)

---

## Related Controls

| Control | Relationship |
|---------|-------------|
| [Control 2.9: Performance Monitoring](../pillar-2-management/2.9-agent-performance-monitoring-and-optimization.md) | Baseline quality metrics |
| [Control 3.4: Incident Reporting](3.4-incident-reporting-and-root-cause-analysis.md) | Critical issue escalation |
| [Control 2.16: RAG Source Integrity](../pillar-2-management/2.16-rag-source-integrity-validation.md) | Knowledge source updates |

---

## Support & Questions

For implementation support or questions about this control, contact:

- **AI Governance Lead:** Feedback process ownership
- **QA Lead:** Remediation verification
- **Power Platform Admin:** Technical configuration
- **Content Owner:** Knowledge source corrections

---

**Updated:** Jan 2026
**Version:** v1.0 (Jan 2026)
**UI Verification Status:** ❌ Needs verification
